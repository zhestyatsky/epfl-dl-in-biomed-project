/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 5
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 5
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 5
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 0.5
    finetuning_lr_init: 0.05
    num_adaptation_steps: 5
    kl_coef: 0.01
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 0.1
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 8
    enable_finetuning_loop: true
  n_task: 4
  latent_space_dim: 8
  leo_inner_lr_init: 0.5
  leo_finetuning_lr_init: 0.05
  num_adaptation_steps: 5
  kl_coef: 0.01
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 0.1
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-06
  optimize_backbone: false
  pretrained_backbone_weights_path: pretrained_weights/tabula_muris_baseline_model.tar
  enable_finetuning_loop: true
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.001
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.001
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.001/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Using pretrained backbone from pretrained_weights/tabula_muris_baseline_model.tar.
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=8, bias=False)
    (relation_net): Sequential(
      (0): Linear(in_features=16, out_features=16, bias=False)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=16, bias=False)
      (3): ReLU()
      (4): Linear(in_features=16, out_features=16, bias=False)
    )
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=8, out_features=130, bias=False)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 1e-06

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Epoch 0 | Batch 0/100 | Loss 2.793048
InnerLR 0.500000
FineTuningLR 0.050000
Epoch 0 | Batch 10/100 | Loss 5.357130
InnerLR 0.502000
FineTuningLR 0.052000
Epoch 0 | Batch 20/100 | Loss 5.655426
InnerLR 0.505000
FineTuningLR 0.055000
Epoch 0 | Batch 30/100 | Loss 5.558139
InnerLR 0.507000
FineTuningLR 0.057000
Epoch 0 | Batch 40/100 | Loss 5.290699
InnerLR 0.510000
FineTuningLR 0.060000
Epoch 0 | Batch 50/100 | Loss 5.398254
InnerLR 0.512000
FineTuningLR 0.062000
Epoch 0 | Batch 60/100 | Loss 5.234336
InnerLR 0.515000
FineTuningLR 0.065000
Epoch 0 | Batch 70/100 | Loss 5.243729
InnerLR 0.517000
FineTuningLR 0.067000
Epoch 0 | Batch 80/100 | Loss 5.171511
InnerLR 0.520000
FineTuningLR 0.070000
Epoch 0 | Batch 90/100 | Loss 5.051366
InnerLR 0.522000
FineTuningLR 0.072000
100 Accuracy = 54.67% +- 2.37%
Epoch 0: 54.67
best model! save...
Epoch 1 | Batch 0/100 | Loss 4.897261
InnerLR 0.525000
FineTuningLR 0.075000
Epoch 1 | Batch 10/100 | Loss 5.052444
InnerLR 0.527000
FineTuningLR 0.077000
Epoch 1 | Batch 20/100 | Loss 4.598093
InnerLR 0.529950
FineTuningLR 0.080023
Epoch 1 | Batch 30/100 | Loss 4.217239
InnerLR 0.531869
FineTuningLR 0.082059
Epoch 1 | Batch 40/100 | Loss 4.270221
InnerLR 0.534784
FineTuningLR 0.085094
Epoch 1 | Batch 50/100 | Loss 4.210152
InnerLR 0.536744
FineTuningLR 0.087107
Epoch 1 | Batch 60/100 | Loss 4.185065
InnerLR 0.539148
FineTuningLR 0.090117
Epoch 1 | Batch 70/100 | Loss 4.252769
InnerLR 0.540848
FineTuningLR 0.092118
Epoch 1 | Batch 80/100 | Loss 4.241570
InnerLR 0.543509
FineTuningLR 0.095114
Epoch 1 | Batch 90/100 | Loss 4.101430
InnerLR 0.545340
FineTuningLR 0.097109
100 Accuracy = 58.72% +- 2.06%
Epoch 1: 58.72
best model! save...
Epoch 2 | Batch 0/100 | Loss 4.752813
InnerLR 0.548130
FineTuningLR 0.100112
Epoch 2 | Batch 10/100 | Loss 3.621453
InnerLR 0.550004
FineTuningLR 0.102127
Epoch 2 | Batch 20/100 | Loss 3.647780
InnerLR 0.552316
FineTuningLR 0.105137
Epoch 2 | Batch 30/100 | Loss 3.323624
InnerLR 0.553583
FineTuningLR 0.107138
Epoch 2 | Batch 40/100 | Loss 3.206695
InnerLR 0.554608
FineTuningLR 0.110133
Epoch 2 | Batch 50/100 | Loss 3.170675
InnerLR 0.554862
FineTuningLR 0.112127
Epoch 2 | Batch 60/100 | Loss 3.155943
InnerLR 0.555649
FineTuningLR 0.115113
Epoch 2 | Batch 70/100 | Loss 3.007515
InnerLR 0.556015
FineTuningLR 0.117157
Epoch 2 | Batch 80/100 | Loss 2.943129
InnerLR 0.556200
FineTuningLR 0.120199
Epoch 2 | Batch 90/100 | Loss 2.858856
InnerLR 0.556647
FineTuningLR 0.122219
100 Accuracy = 65.88% +- 2.14%
Epoch 2: 65.88
best model! save...
Epoch 3 | Batch 0/100 | Loss 1.284746
InnerLR 0.557102
FineTuningLR 0.125241
Epoch 3 | Batch 10/100 | Loss 2.417650
InnerLR 0.557361
FineTuningLR 0.127246
Epoch 3 | Batch 20/100 | Loss 2.142213
InnerLR 0.558059
FineTuningLR 0.130267
Epoch 3 | Batch 30/100 | Loss 2.027549
InnerLR 0.558638
FineTuningLR 0.132300
Epoch 3 | Batch 40/100 | Loss 2.074270
InnerLR 0.559156
FineTuningLR 0.135328
Epoch 3 | Batch 50/100 | Loss 2.070367
InnerLR 0.559333
FineTuningLR 0.137335
Epoch 3 | Batch 60/100 | Loss 2.055231
InnerLR 0.559426
FineTuningLR 0.140333
Epoch 3 | Batch 70/100 | Loss 1.985888
InnerLR 0.559358
FineTuningLR 0.142326
Epoch 3 | Batch 80/100 | Loss 2.044810
InnerLR 0.558579
FineTuningLR 0.145308
Epoch 3 | Batch 90/100 | Loss 2.049902
InnerLR 0.557708
FineTuningLR 0.147293
100 Accuracy = 69.81% +- 2.13%
Epoch 3: 69.81
best model! save...
Epoch 4 | Batch 0/100 | Loss 2.473140
InnerLR 0.556387
FineTuningLR 0.150266
Epoch 4 | Batch 10/100 | Loss 1.749278
InnerLR 0.555354
FineTuningLR 0.152247
Epoch 4 | Batch 20/100 | Loss 1.640598
InnerLR 0.553848
FineTuningLR 0.155216
Epoch 4 | Batch 30/100 | Loss 1.650860
InnerLR 0.552720
FineTuningLR 0.157194
Epoch 4 | Batch 40/100 | Loss 1.611820
InnerLR 0.550719
FineTuningLR 0.160161
Epoch 4 | Batch 50/100 | Loss 1.558842
InnerLR 0.549223
FineTuningLR 0.162139
Epoch 4 | Batch 60/100 | Loss 1.486721
InnerLR 0.546798
FineTuningLR 0.165105
Epoch 4 | Batch 70/100 | Loss 1.455289
InnerLR 0.545087
FineTuningLR 0.167082
Epoch 4 | Batch 80/100 | Loss 1.450894
InnerLR 0.542412
FineTuningLR 0.170049
Epoch 4 | Batch 90/100 | Loss 1.437204
InnerLR 0.540573
FineTuningLR 0.172027
100 Accuracy = 72.17% +- 2.19%
Epoch 4: 72.17
best model! save...
Epoch 5 | Batch 0/100 | Loss 1.102571
InnerLR 0.538136
FineTuningLR 0.174994
Epoch 5 | Batch 10/100 | Loss 1.289775
InnerLR 0.536533
FineTuningLR 0.176973
Epoch 5 | Batch 20/100 | Loss 1.350352
InnerLR 0.533985
FineTuningLR 0.179941
Epoch 5 | Batch 30/100 | Loss 1.241407
InnerLR 0.532211
FineTuningLR 0.181920
Epoch 5 | Batch 40/100 | Loss 1.231540
InnerLR 0.529466
FineTuningLR 0.184889
Epoch 5 | Batch 50/100 | Loss 1.203076
InnerLR 0.527591
FineTuningLR 0.186869
Epoch 5 | Batch 60/100 | Loss 1.135739
InnerLR 0.524729
FineTuningLR 0.189839
Epoch 5 | Batch 70/100 | Loss 1.149433
InnerLR 0.522796
FineTuningLR 0.191819
Epoch 5 | Batch 80/100 | Loss 1.105606
InnerLR 0.519866
FineTuningLR 0.194791
Epoch 5 | Batch 90/100 | Loss 1.069440
InnerLR 0.517897
FineTuningLR 0.196772
100 Accuracy = 75.63% +- 2.16%
Epoch 5: 75.63
best model! save...
Epoch 6 | Batch 0/100 | Loss 0.468156
InnerLR 0.515281
FineTuningLR 0.199766
Epoch 6 | Batch 10/100 | Loss 0.852186
InnerLR 0.513579
FineTuningLR 0.201765
Epoch 6 | Batch 20/100 | Loss 0.780863
InnerLR 0.510916
FineTuningLR 0.204758
Epoch 6 | Batch 30/100 | Loss 0.704216
InnerLR 0.509084
FineTuningLR 0.206750
Epoch 6 | Batch 40/100 | Loss 0.684414
InnerLR 0.506272
FineTuningLR 0.209734
Epoch 6 | Batch 50/100 | Loss 0.660467
InnerLR 0.504364
FineTuningLR 0.211722
Epoch 6 | Batch 60/100 | Loss 0.626387
InnerLR 0.501463
FineTuningLR 0.214702
Epoch 6 | Batch 70/100 | Loss 0.610695
InnerLR 0.499510
FineTuningLR 0.216688
Epoch 6 | Batch 80/100 | Loss 0.598042
InnerLR 0.496558
FineTuningLR 0.219665
Epoch 6 | Batch 90/100 | Loss 0.587001
InnerLR 0.494579
FineTuningLR 0.221650
100 Accuracy = 79.81% +- 1.93%
Epoch 6: 79.81
best model! save...
Epoch 7 | Batch 0/100 | Loss 0.756920
InnerLR 0.491596
FineTuningLR 0.224627
Epoch 7 | Batch 10/100 | Loss 0.526202
InnerLR 0.489602
FineTuningLR 0.226611
Epoch 7 | Batch 20/100 | Loss 0.477729
InnerLR 0.486738
FineTuningLR 0.229655
Epoch 7 | Batch 30/100 | Loss 0.490673
InnerLR 0.484873
FineTuningLR 0.231718
Epoch 7 | Batch 40/100 | Loss 0.481432
InnerLR 0.482022
FineTuningLR 0.234783
Epoch 7 | Batch 50/100 | Loss 0.471741
InnerLR 0.480092
FineTuningLR 0.236811
Epoch 7 | Batch 60/100 | Loss 0.469094
InnerLR 0.477166
FineTuningLR 0.239836
Epoch 7 | Batch 70/100 | Loss 0.464123
InnerLR 0.475198
FineTuningLR 0.241844
Epoch 7 | Batch 80/100 | Loss 0.451833
InnerLR 0.472229
FineTuningLR 0.244846
Epoch 7 | Batch 90/100 | Loss 0.448838
InnerLR 0.470239
FineTuningLR 0.246842
100 Accuracy = 80.04% +- 2.19%
Epoch 7: 80.04
best model! save...
Epoch 8 | Batch 0/100 | Loss 0.403206
InnerLR 0.467243
FineTuningLR 0.249830
Epoch 8 | Batch 10/100 | Loss 0.344274
InnerLR 0.465241
FineTuningLR 0.251819
Epoch 8 | Batch 20/100 | Loss 0.340750
InnerLR 0.462231
FineTuningLR 0.254800
Epoch 8 | Batch 30/100 | Loss 0.333999
InnerLR 0.460221
FineTuningLR 0.256786
Epoch 8 | Batch 40/100 | Loss 0.351407
InnerLR 0.457203
FineTuningLR 0.259762
Epoch 8 | Batch 50/100 | Loss 0.361169
InnerLR 0.455189
FineTuningLR 0.261746
Epoch 8 | Batch 60/100 | Loss 0.360309
InnerLR 0.452166
FineTuningLR 0.264720
Epoch 8 | Batch 70/100 | Loss 0.357216
InnerLR 0.450149
FineTuningLR 0.266702
Epoch 8 | Batch 80/100 | Loss 0.351840
InnerLR 0.447124
FineTuningLR 0.269676
Epoch 8 | Batch 90/100 | Loss 0.342117
InnerLR 0.445106
FineTuningLR 0.271658
100 Accuracy = 81.81% +- 1.71%
Epoch 8: 81.81
best model! save...
Epoch 9 | Batch 0/100 | Loss 0.195871
InnerLR 0.442080
FineTuningLR 0.274631
Epoch 9 | Batch 10/100 | Loss 0.303057
InnerLR 0.440062
FineTuningLR 0.276613
Epoch 9 | Batch 20/100 | Loss 0.325756
InnerLR 0.437035
FineTuningLR 0.279586
Epoch 9 | Batch 30/100 | Loss 0.328709
InnerLR 0.435017
FineTuningLR 0.281568
Epoch 9 | Batch 40/100 | Loss 0.328379
InnerLR 0.431990
FineTuningLR 0.284542
Epoch 9 | Batch 50/100 | Loss 0.337115
InnerLR 0.429972
FineTuningLR 0.286148
Epoch 9 | Batch 60/100 | Loss 0.327256
InnerLR 0.426946
FineTuningLR 0.288686
Epoch 9 | Batch 70/100 | Loss 0.321068
InnerLR 0.424928
FineTuningLR 0.290446
Epoch 9 | Batch 80/100 | Loss 0.327702
InnerLR 0.421902
FineTuningLR 0.293164
Epoch 9 | Batch 90/100 | Loss 0.324087
InnerLR 0.419885
FineTuningLR 0.295015
100 Accuracy = 81.29% +- 1.73%
Epoch 9: 81.29
Epoch 10 | Batch 0/100 | Loss 0.244507
InnerLR 0.416859
FineTuningLR 0.297838
Epoch 10 | Batch 10/100 | Loss 0.323617
InnerLR 0.414842
FineTuningLR 0.299744
Epoch 10 | Batch 20/100 | Loss 0.304949
InnerLR 0.411817
FineTuningLR 0.302630
Epoch 10 | Batch 30/100 | Loss 0.292001
InnerLR 0.409807
FineTuningLR 0.304575
Epoch 10 | Batch 40/100 | Loss 0.292732
InnerLR 0.406791
FineTuningLR 0.307506
Epoch 10 | Batch 50/100 | Loss 0.286175
InnerLR 0.404779
FineTuningLR 0.309467
Epoch 10 | Batch 60/100 | Loss 0.296991
InnerLR 0.401850
FineTuningLR 0.312473
Epoch 10 | Batch 70/100 | Loss 0.287483
InnerLR 0.400292
FineTuningLR 0.314113
Epoch 10 | Batch 80/100 | Loss 0.288303
InnerLR 0.397796
FineTuningLR 0.316690
Epoch 10 | Batch 90/100 | Loss 0.286309
InnerLR 0.396050
FineTuningLR 0.318470
100 Accuracy = 81.49% +- 2.20%
Epoch 10: 81.49
Epoch 11 | Batch 0/100 | Loss 0.225992
InnerLR 0.393336
FineTuningLR 0.321209
Epoch 11 | Batch 10/100 | Loss 0.251636
InnerLR 0.391478
FineTuningLR 0.323072
Epoch 11 | Batch 20/100 | Loss 0.256272
InnerLR 0.388636
FineTuningLR 0.325907
Epoch 11 | Batch 30/100 | Loss 0.261927
InnerLR 0.386713
FineTuningLR 0.327819
Epoch 11 | Batch 40/100 | Loss 0.261660
InnerLR 0.383796
FineTuningLR 0.330711
Epoch 11 | Batch 50/100 | Loss 0.263844
InnerLR 0.381834
FineTuningLR 0.332652
Epoch 11 | Batch 60/100 | Loss 0.272601
InnerLR 0.378872
FineTuningLR 0.335578
Epoch 11 | Batch 70/100 | Loss 0.274034
InnerLR 0.376887
FineTuningLR 0.337537
Epoch 11 | Batch 80/100 | Loss 0.278553
InnerLR 0.373899
FineTuningLR 0.340483
Epoch 11 | Batch 90/100 | Loss 0.276744
InnerLR 0.371902
FineTuningLR 0.342451
100 Accuracy = 83.52% +- 1.69%
Epoch 11: 83.52
best model! save...
Epoch 12 | Batch 0/100 | Loss 0.172183
InnerLR 0.368899
FineTuningLR 0.345410
Epoch 12 | Batch 10/100 | Loss 0.275427
InnerLR 0.366893
FineTuningLR 0.347385
Epoch 12 | Batch 20/100 | Loss 0.263238
InnerLR 0.363777
FineTuningLR 0.350131
Epoch 12 | Batch 30/100 | Loss 0.256190
InnerLR 0.361714
FineTuningLR 0.351998
Epoch 12 | Batch 40/100 | Loss 0.248681
InnerLR 0.358638
FineTuningLR 0.354841
Epoch 12 | Batch 50/100 | Loss 0.247267
InnerLR 0.356596
FineTuningLR 0.356758
Epoch 12 | Batch 60/100 | Loss 0.244706
InnerLR 0.353543
FineTuningLR 0.359658
Epoch 12 | Batch 70/100 | Loss 0.250314
InnerLR 0.351514
FineTuningLR 0.361604
Epoch 12 | Batch 80/100 | Loss 0.249167
InnerLR 0.348475
FineTuningLR 0.364537
Epoch 12 | Batch 90/100 | Loss 0.252820
InnerLR 0.346835
FineTuningLR 0.366501
100 Accuracy = 81.39% +- 1.92%
Epoch 12: 81.39
Epoch 13 | Batch 0/100 | Loss 0.346683
InnerLR 0.344247
FineTuningLR 0.369454
Epoch 13 | Batch 10/100 | Loss 0.252074
InnerLR 0.342837
FineTuningLR 0.371428
Epoch 13 | Batch 20/100 | Loss 0.242243
InnerLR 0.340515
FineTuningLR 0.374394
Epoch 13 | Batch 30/100 | Loss 0.251580
InnerLR 0.338858
FineTuningLR 0.376374
Epoch 13 | Batch 40/100 | Loss 0.262199
InnerLR 0.336797
FineTuningLR 0.379347
Epoch 13 | Batch 50/100 | Loss 0.258912
InnerLR 0.335274
FineTuningLR 0.381330
Epoch 13 | Batch 60/100 | Loss 0.249832
InnerLR 0.332821
FineTuningLR 0.384308
Epoch 13 | Batch 70/100 | Loss 0.253028
InnerLR 0.331098
FineTuningLR 0.386293
Epoch 13 | Batch 80/100 | Loss 0.250789
InnerLR 0.328414
FineTuningLR 0.389273
Epoch 13 | Batch 90/100 | Loss 0.250970
InnerLR 0.326573
FineTuningLR 0.391261
100 Accuracy = 83.59% +- 2.01%
Epoch 13: 83.59
best model! save...
Epoch 14 | Batch 0/100 | Loss 0.195876
InnerLR 0.323754
FineTuningLR 0.394242
Epoch 14 | Batch 10/100 | Loss 0.231623
InnerLR 0.322225
FineTuningLR 0.396230
Epoch 14 | Batch 20/100 | Loss 0.248299
InnerLR 0.319767
FineTuningLR 0.398296
Epoch 14 | Batch 30/100 | Loss 0.244248
InnerLR 0.318041
FineTuningLR 0.399703
Epoch 14 | Batch 40/100 | Loss 0.251139
InnerLR 0.315555
FineTuningLR 0.401816
Epoch 14 | Batch 50/100 | Loss 0.254168
InnerLR 0.314057
FineTuningLR 0.402922
Epoch 14 | Batch 60/100 | Loss 0.262417
InnerLR 0.311632
FineTuningLR 0.404253
Epoch 14 | Batch 70/100 | Loss 0.255579
InnerLR 0.309924
FineTuningLR 0.405284
Epoch 14 | Batch 80/100 | Loss 0.250206
InnerLR 0.307258
FineTuningLR 0.407162
Epoch 14 | Batch 90/100 | Loss 0.247928
InnerLR 0.305426
FineTuningLR 0.408586
100 Accuracy = 83.53% +- 2.10%
Epoch 14: 83.53
Epoch 15 | Batch 0/100 | Loss 0.201914
InnerLR 0.302617
FineTuningLR 0.410917
Epoch 15 | Batch 10/100 | Loss 0.280430
InnerLR 0.300713
FineTuningLR 0.412374
Epoch 15 | Batch 20/100 | Loss 0.257006
InnerLR 0.298200
FineTuningLR 0.414490
Epoch 15 | Batch 30/100 | Loss 0.246972
InnerLR 0.296708
FineTuningLR 0.416109
Epoch 15 | Batch 40/100 | Loss 0.247459
InnerLR 0.294291
FineTuningLR 0.418664
Epoch 15 | Batch 50/100 | Loss 0.245134
InnerLR 0.292586
FineTuningLR 0.420434
Epoch 15 | Batch 60/100 | Loss 0.243946
InnerLR 0.289865
FineTuningLR 0.423078
Epoch 15 | Batch 70/100 | Loss 0.238661
InnerLR 0.287988
FineTuningLR 0.424867
Epoch 15 | Batch 80/100 | Loss 0.241841
InnerLR 0.285127
FineTuningLR 0.427081
Epoch 15 | Batch 90/100 | Loss 0.247010
InnerLR 0.283190
FineTuningLR 0.428483
100 Accuracy = 83.03% +- 1.99%
Epoch 15: 83.03
Epoch 16 | Batch 0/100 | Loss 0.208036
InnerLR 0.280253
FineTuningLR 0.430542
Epoch 16 | Batch 10/100 | Loss 0.289157
InnerLR 0.278406
FineTuningLR 0.431602
Epoch 16 | Batch 20/100 | Loss 0.295584
InnerLR 0.275827
FineTuningLR 0.433248
Epoch 16 | Batch 30/100 | Loss 0.264351
InnerLR 0.274422
FineTuningLR 0.434175
Epoch 16 | Batch 40/100 | Loss 0.250309
InnerLR 0.273032
FineTuningLR 0.435015
Epoch 16 | Batch 50/100 | Loss 0.238934
InnerLR 0.271967
FineTuningLR 0.435418
Epoch 16 | Batch 60/100 | Loss 0.232976
InnerLR 0.269991
FineTuningLR 0.436270
Epoch 16 | Batch 70/100 | Loss 0.226339
InnerLR 0.268498
FineTuningLR 0.437082
Epoch 16 | Batch 80/100 | Loss 0.231887
InnerLR 0.266081
FineTuningLR 0.438329
Epoch 16 | Batch 90/100 | Loss 0.235456
InnerLR 0.264758
FineTuningLR 0.438740
100 Accuracy = 84.68% +- 1.92%
Epoch 16: 84.68
best model! save...
Epoch 17 | Batch 0/100 | Loss 0.145318
InnerLR 0.262540
FineTuningLR 0.439646
Epoch 17 | Batch 10/100 | Loss 0.190907
InnerLR 0.260938
FineTuningLR 0.440575
Epoch 17 | Batch 20/100 | Loss 0.232273
InnerLR 0.258777
FineTuningLR 0.442335
Epoch 17 | Batch 30/100 | Loss 0.220666
InnerLR 0.257319
FineTuningLR 0.443701
Epoch 17 | Batch 40/100 | Loss 0.220570
InnerLR 0.255098
FineTuningLR 0.446058
Epoch 17 | Batch 50/100 | Loss 0.221127
InnerLR 0.253662
FineTuningLR 0.447503
Epoch 17 | Batch 60/100 | Loss 0.222865
InnerLR 0.251523
FineTuningLR 0.449571
Epoch 17 | Batch 70/100 | Loss 0.229101
InnerLR 0.249962
FineTuningLR 0.450715
Epoch 17 | Batch 80/100 | Loss 0.225298
InnerLR 0.247465
FineTuningLR 0.452722
Epoch 17 | Batch 90/100 | Loss 0.223250
InnerLR 0.245720
FineTuningLR 0.454213
100 Accuracy = 83.17% +- 2.03%
Epoch 17: 83.17
Epoch 18 | Batch 0/100 | Loss 0.146803
InnerLR 0.243939
FineTuningLR 0.455703
Epoch 18 | Batch 10/100 | Loss 0.223299
InnerLR 0.242834
FineTuningLR 0.456892
Epoch 18 | Batch 20/100 | Loss 0.222350
InnerLR 0.240864
FineTuningLR 0.458951
Epoch 18 | Batch 30/100 | Loss 0.212070
InnerLR 0.239627
FineTuningLR 0.460403
Epoch 18 | Batch 40/100 | Loss 0.209491
InnerLR 0.237961
FineTuningLR 0.462183
Epoch 18 | Batch 50/100 | Loss 0.205517
InnerLR 0.236866
FineTuningLR 0.463030
Epoch 18 | Batch 60/100 | Loss 0.198954
InnerLR 0.235064
FineTuningLR 0.464533
Epoch 18 | Batch 70/100 | Loss 0.193165
InnerLR 0.233674
FineTuningLR 0.465766
Epoch 18 | Batch 80/100 | Loss 0.194753
InnerLR 0.231380
FineTuningLR 0.467880
Epoch 18 | Batch 90/100 | Loss 0.194427
InnerLR 0.229743
FineTuningLR 0.469429
100 Accuracy = 82.39% +- 2.03%
Epoch 18: 82.39
Epoch 19 | Batch 0/100 | Loss 0.149317
InnerLR 0.227159
FineTuningLR 0.471706
Epoch 19 | Batch 10/100 | Loss 0.155046
InnerLR 0.225380
FineTuningLR 0.473106
Epoch 19 | Batch 20/100 | Loss 0.199587
InnerLR 0.222670
FineTuningLR 0.475439
Epoch 19 | Batch 30/100 | Loss 0.192171
InnerLR 0.221208
FineTuningLR 0.477105
Epoch 19 | Batch 40/100 | Loss 0.199973
InnerLR 0.219266
FineTuningLR 0.479750
Epoch 19 | Batch 50/100 | Loss 0.194818
InnerLR 0.217987
FineTuningLR 0.481607
Epoch 19 | Batch 60/100 | Loss 0.187309
InnerLR 0.216075
FineTuningLR 0.484505
Epoch 19 | Batch 70/100 | Loss 0.191635
InnerLR 0.214906
FineTuningLR 0.486271
Epoch 19 | Batch 80/100 | Loss 0.196647
InnerLR 0.214048
FineTuningLR 0.488741
Epoch 19 | Batch 90/100 | Loss 0.203382
InnerLR 0.213254
FineTuningLR 0.490468
100 Accuracy = 85.36% +- 2.01%
Epoch 19: 85.36
best model! save...
Epoch 20 | Batch 0/100 | Loss 0.128107
InnerLR 0.211844
FineTuningLR 0.493147
Epoch 20 | Batch 10/100 | Loss 0.206019
InnerLR 0.211278
FineTuningLR 0.494781
Epoch 20 | Batch 20/100 | Loss 0.187307
InnerLR 0.209935
FineTuningLR 0.497104
Epoch 20 | Batch 30/100 | Loss 0.182887
InnerLR 0.208896
FineTuningLR 0.498826
Epoch 20 | Batch 40/100 | Loss 0.190031
InnerLR 0.206970
FineTuningLR 0.501349
Epoch 20 | Batch 50/100 | Loss 0.191170
InnerLR 0.205465
FineTuningLR 0.502907
Epoch 20 | Batch 60/100 | Loss 0.188733
InnerLR 0.203032
FineTuningLR 0.505392
Epoch 20 | Batch 70/100 | Loss 0.186263
InnerLR 0.201520
FineTuningLR 0.506927
Epoch 20 | Batch 80/100 | Loss 0.191223
InnerLR 0.199998
FineTuningLR 0.508699
Epoch 20 | Batch 90/100 | Loss 0.195319
InnerLR 0.199131
FineTuningLR 0.509564
100 Accuracy = 86.00% +- 1.84%
Epoch 20: 86.00
best model! save...
Epoch 21 | Batch 0/100 | Loss 0.157082
InnerLR 0.197826
FineTuningLR 0.510447
Epoch 21 | Batch 10/100 | Loss 0.175920
InnerLR 0.197389
FineTuningLR 0.510784
Epoch 21 | Batch 20/100 | Loss 0.186266
InnerLR 0.197204
FineTuningLR 0.511323
Epoch 21 | Batch 30/100 | Loss 0.200693
InnerLR 0.197319
FineTuningLR 0.511993
Epoch 21 | Batch 40/100 | Loss 0.189143
InnerLR 0.197303
FineTuningLR 0.512913
Epoch 21 | Batch 50/100 | Loss 0.191362
InnerLR 0.197207
FineTuningLR 0.513846
Epoch 21 | Batch 60/100 | Loss 0.203026
InnerLR 0.196629
FineTuningLR 0.515517
Epoch 21 | Batch 70/100 | Loss 0.202631
InnerLR 0.195863
FineTuningLR 0.516596
Epoch 21 | Batch 80/100 | Loss 0.223079
InnerLR 0.194684
FineTuningLR 0.517971
Epoch 21 | Batch 90/100 | Loss 0.225255
InnerLR 0.193730
FineTuningLR 0.519131
100 Accuracy = 84.17% +- 1.72%
Epoch 21: 84.17
Epoch 22 | Batch 0/100 | Loss 0.120312
InnerLR 0.191947
FineTuningLR 0.520606
Epoch 22 | Batch 10/100 | Loss 0.136771
InnerLR 0.190565
FineTuningLR 0.521823
Epoch 22 | Batch 20/100 | Loss 0.185646
InnerLR 0.188290
FineTuningLR 0.523550
Epoch 22 | Batch 30/100 | Loss 0.198069
InnerLR 0.187040
FineTuningLR 0.524406
Epoch 22 | Batch 40/100 | Loss 0.200377
InnerLR 0.185274
FineTuningLR 0.525694
Epoch 22 | Batch 50/100 | Loss 0.207900
InnerLR 0.184082
FineTuningLR 0.526735
Epoch 22 | Batch 60/100 | Loss 0.216222
InnerLR 0.182556
FineTuningLR 0.528621
Epoch 22 | Batch 70/100 | Loss 0.213775
InnerLR 0.181265
FineTuningLR 0.529590
Epoch 22 | Batch 80/100 | Loss 0.212436
InnerLR 0.179844
FineTuningLR 0.531129
Epoch 22 | Batch 90/100 | Loss 0.210719
InnerLR 0.178775
FineTuningLR 0.532123
100 Accuracy = 83.31% +- 2.28%
Epoch 22: 83.31
Epoch 23 | Batch 0/100 | Loss 0.195087
InnerLR 0.176845
FineTuningLR 0.533219
Epoch 23 | Batch 10/100 | Loss 0.228296
InnerLR 0.175388
FineTuningLR 0.533806
Epoch 23 | Batch 20/100 | Loss 0.235538
InnerLR 0.173664
FineTuningLR 0.534653
Epoch 23 | Batch 30/100 | Loss 0.223409
InnerLR 0.173073
FineTuningLR 0.534896
Epoch 23 | Batch 40/100 | Loss 0.213661
InnerLR 0.171714
FineTuningLR 0.535244
Epoch 23 | Batch 50/100 | Loss 0.210120
InnerLR 0.170772
FineTuningLR 0.535592
Epoch 23 | Batch 60/100 | Loss 0.206478
InnerLR 0.169248
FineTuningLR 0.536046
Epoch 23 | Batch 70/100 | Loss 0.202274
InnerLR 0.167999
FineTuningLR 0.536629
Epoch 23 | Batch 80/100 | Loss 0.199648
InnerLR 0.166456
FineTuningLR 0.537799
Epoch 23 | Batch 90/100 | Loss 0.191867
InnerLR 0.165564
FineTuningLR 0.538635
100 Accuracy = 83.47% +- 2.12%
Epoch 23: 83.47
Epoch 24 | Batch 0/100 | Loss 0.101563
InnerLR 0.163818
FineTuningLR 0.539934
Epoch 24 | Batch 10/100 | Loss 0.155760
InnerLR 0.162650
FineTuningLR 0.540758
Epoch 24 | Batch 20/100 | Loss 0.159030
InnerLR 0.160983
FineTuningLR 0.541633
Epoch 24 | Batch 30/100 | Loss 0.166851
InnerLR 0.159804
FineTuningLR 0.542277
Epoch 24 | Batch 40/100 | Loss 0.193496
InnerLR 0.157871
FineTuningLR 0.542803
Epoch 24 | Batch 50/100 | Loss 0.187002
InnerLR 0.157014
FineTuningLR 0.542870
Epoch 24 | Batch 60/100 | Loss 0.178872
InnerLR 0.155331
FineTuningLR 0.543634
Epoch 24 | Batch 70/100 | Loss 0.174402
InnerLR 0.154000
FineTuningLR 0.544489
Epoch 24 | Batch 80/100 | Loss 0.171701
InnerLR 0.152152
FineTuningLR 0.545785
Epoch 24 | Batch 90/100 | Loss 0.174635
InnerLR 0.151018
FineTuningLR 0.546446
100 Accuracy = 84.44% +- 1.82%
Epoch 24: 84.44
Epoch 25 | Batch 0/100 | Loss 0.117631
InnerLR 0.150125
FineTuningLR 0.547575
Epoch 25 | Batch 10/100 | Loss 0.204283
InnerLR 0.149314
FineTuningLR 0.548125
Epoch 25 | Batch 20/100 | Loss 0.285186
InnerLR 0.148285
FineTuningLR 0.548997
Epoch 25 | Batch 30/100 | Loss 0.259433
InnerLR 0.147290
FineTuningLR 0.549217
Epoch 25 | Batch 40/100 | Loss 0.235156
InnerLR 0.145416
FineTuningLR 0.549396
Epoch 25 | Batch 50/100 | Loss 0.229023
InnerLR 0.144189
FineTuningLR 0.549574
Epoch 25 | Batch 60/100 | Loss 0.220388
InnerLR 0.142539
FineTuningLR 0.550466
Epoch 25 | Batch 70/100 | Loss 0.219856
InnerLR 0.142056
FineTuningLR 0.550815
Epoch 25 | Batch 80/100 | Loss 0.226025
InnerLR 0.141452
FineTuningLR 0.550539
Epoch 25 | Batch 90/100 | Loss 0.218849
InnerLR 0.140788
FineTuningLR 0.550511
100 Accuracy = 84.45% +- 1.86%
Epoch 25: 84.45
Epoch 26 | Batch 0/100 | Loss 0.143050
InnerLR 0.139895
FineTuningLR 0.550805
Epoch 26 | Batch 10/100 | Loss 0.193134
InnerLR 0.139579
FineTuningLR 0.551129
Epoch 26 | Batch 20/100 | Loss 0.188528
InnerLR 0.139908
FineTuningLR 0.551555
Epoch 26 | Batch 30/100 | Loss 0.177117
InnerLR 0.139963
FineTuningLR 0.552125
Epoch 26 | Batch 40/100 | Loss 0.167404
InnerLR 0.140121
FineTuningLR 0.553526
Epoch 26 | Batch 50/100 | Loss 0.174513
InnerLR 0.140182
FineTuningLR 0.554530
Epoch 26 | Batch 60/100 | Loss 0.170665
InnerLR 0.139526
FineTuningLR 0.556071
Epoch 26 | Batch 70/100 | Loss 0.167131
InnerLR 0.138928
FineTuningLR 0.557336
Epoch 26 | Batch 80/100 | Loss 0.166493
InnerLR 0.138126
FineTuningLR 0.559105
Epoch 26 | Batch 90/100 | Loss 0.162046
InnerLR 0.137804
FineTuningLR 0.560360
100 Accuracy = 84.04% +- 2.05%
Epoch 26: 84.04
Epoch 27 | Batch 0/100 | Loss 0.077694
InnerLR 0.137542
FineTuningLR 0.562496
Epoch 27 | Batch 10/100 | Loss 0.363862
InnerLR 0.136937
FineTuningLR 0.563475
Epoch 27 | Batch 20/100 | Loss 0.400507
InnerLR 0.136103
FineTuningLR 0.564430
Epoch 27 | Batch 30/100 | Loss 0.341858
InnerLR 0.135763
FineTuningLR 0.564832
Epoch 27 | Batch 40/100 | Loss 0.297773
InnerLR 0.135434
FineTuningLR 0.565413
Epoch 27 | Batch 50/100 | Loss 0.270546
InnerLR 0.134726
FineTuningLR 0.565785
Epoch 27 | Batch 60/100 | Loss 0.267932
InnerLR 0.133617
FineTuningLR 0.566429
Epoch 27 | Batch 70/100 | Loss 0.250459
InnerLR 0.133023
FineTuningLR 0.566871
Epoch 27 | Batch 80/100 | Loss 0.242667
InnerLR 0.133063
FineTuningLR 0.567093
Epoch 27 | Batch 90/100 | Loss 0.234949
InnerLR 0.133594
FineTuningLR 0.567113
100 Accuracy = 84.23% +- 1.92%
Epoch 27: 84.23
Epoch 28 | Batch 0/100 | Loss 0.106270
InnerLR 0.134356
FineTuningLR 0.567623
Epoch 28 | Batch 10/100 | Loss 0.161838
InnerLR 0.135049
FineTuningLR 0.567757
Epoch 28 | Batch 20/100 | Loss 0.167195
InnerLR 0.135585
FineTuningLR 0.567713
Epoch 28 | Batch 30/100 | Loss 0.162724
InnerLR 0.136003
FineTuningLR 0.567802
Epoch 28 | Batch 40/100 | Loss 0.187097
InnerLR 0.136891
FineTuningLR 0.567885
Epoch 28 | Batch 50/100 | Loss 0.184142
InnerLR 0.136990
FineTuningLR 0.568278
Epoch 28 | Batch 60/100 | Loss 0.193921
InnerLR 0.137250
FineTuningLR 0.568609
Epoch 28 | Batch 70/100 | Loss 0.187995
InnerLR 0.137637
FineTuningLR 0.568638
Epoch 28 | Batch 80/100 | Loss 0.189522
InnerLR 0.137703
FineTuningLR 0.568748
Epoch 28 | Batch 90/100 | Loss 0.184359
InnerLR 0.137549
FineTuningLR 0.568754
100 Accuracy = 86.56% +- 1.83%
Epoch 28: 86.56
best model! save...
Epoch 29 | Batch 0/100 | Loss 0.337016
InnerLR 0.137513
FineTuningLR 0.569026
Epoch 29 | Batch 10/100 | Loss 0.267078
InnerLR 0.137225
FineTuningLR 0.569138
Epoch 29 | Batch 20/100 | Loss 0.219971
InnerLR 0.136434
FineTuningLR 0.569381
Epoch 29 | Batch 30/100 | Loss 0.208391
InnerLR 0.135912
FineTuningLR 0.569552
Epoch 29 | Batch 40/100 | Loss 0.201458
InnerLR 0.134616
FineTuningLR 0.570237
Epoch 29 | Batch 50/100 | Loss 0.209584
InnerLR 0.134068
FineTuningLR 0.570236
Epoch 29 | Batch 60/100 | Loss 0.227783
InnerLR 0.133323
FineTuningLR 0.570169
Epoch 29 | Batch 70/100 | Loss 0.223477
InnerLR 0.132809
FineTuningLR 0.570170
Epoch 29 | Batch 80/100 | Loss 0.212330
InnerLR 0.132635
FineTuningLR 0.570383
Epoch 29 | Batch 90/100 | Loss 0.206156
InnerLR 0.132264
FineTuningLR 0.570530
100 Accuracy = 83.93% +- 2.25%
Epoch 29: 83.93
Epoch 30 | Batch 0/100 | Loss 0.079546
InnerLR 0.132501
FineTuningLR 0.571168
Epoch 30 | Batch 10/100 | Loss 0.156272
InnerLR 0.132478
FineTuningLR 0.571317
Epoch 30 | Batch 20/100 | Loss 0.193904
InnerLR 0.132853
FineTuningLR 0.571169
Epoch 30 | Batch 30/100 | Loss 0.217893
InnerLR 0.132850
FineTuningLR 0.570845
Epoch 30 | Batch 40/100 | Loss 0.198369
InnerLR 0.132647
FineTuningLR 0.570091
Epoch 30 | Batch 50/100 | Loss 0.188011
InnerLR 0.132276
FineTuningLR 0.570058
Epoch 30 | Batch 60/100 | Loss 0.186688
InnerLR 0.132172
FineTuningLR 0.570044
Epoch 30 | Batch 70/100 | Loss 0.185576
InnerLR 0.131714
FineTuningLR 0.570087
Epoch 30 | Batch 80/100 | Loss 0.185692
InnerLR 0.130694
FineTuningLR 0.570028
Epoch 30 | Batch 90/100 | Loss 0.185225
InnerLR 0.130527
FineTuningLR 0.570084
100 Accuracy = 84.12% +- 2.01%
Epoch 30: 84.12
Epoch 31 | Batch 0/100 | Loss 0.128758
InnerLR 0.130346
FineTuningLR 0.570534
Epoch 31 | Batch 10/100 | Loss 0.397208
InnerLR 0.130120
FineTuningLR 0.570760
Epoch 31 | Batch 20/100 | Loss 0.294417
InnerLR 0.129548
FineTuningLR 0.570562
Epoch 31 | Batch 30/100 | Loss 0.250653
InnerLR 0.129207
FineTuningLR 0.570263
Epoch 31 | Batch 40/100 | Loss 0.239904
InnerLR 0.128378
FineTuningLR 0.570226
Epoch 31 | Batch 50/100 | Loss 0.237884
InnerLR 0.127687
FineTuningLR 0.570560
Epoch 31 | Batch 60/100 | Loss 0.222941
InnerLR 0.126454
FineTuningLR 0.571635
Epoch 31 | Batch 70/100 | Loss 0.214936
InnerLR 0.125679
FineTuningLR 0.572555
Epoch 31 | Batch 80/100 | Loss 0.226049
InnerLR 0.124914
FineTuningLR 0.573544
Epoch 31 | Batch 90/100 | Loss 0.220358
InnerLR 0.124400
FineTuningLR 0.574064
100 Accuracy = 84.45% +- 1.93%
Epoch 31: 84.45
Epoch 32 | Batch 0/100 | Loss 0.111546
InnerLR 0.124297
FineTuningLR 0.574717
Epoch 32 | Batch 10/100 | Loss 0.138794
InnerLR 0.123945
FineTuningLR 0.575437
Epoch 32 | Batch 20/100 | Loss 0.163864
InnerLR 0.123100
FineTuningLR 0.576786
Epoch 32 | Batch 30/100 | Loss 0.231782
InnerLR 0.122390
FineTuningLR 0.577338
Epoch 32 | Batch 40/100 | Loss 0.225439
InnerLR 0.122003
FineTuningLR 0.577544
Epoch 32 | Batch 50/100 | Loss 0.221167
InnerLR 0.122086
FineTuningLR 0.577840
Epoch 32 | Batch 60/100 | Loss 0.216351
InnerLR 0.122128
FineTuningLR 0.578330
Epoch 32 | Batch 70/100 | Loss 0.207091
InnerLR 0.121794
FineTuningLR 0.578467
Epoch 32 | Batch 80/100 | Loss 0.199285
InnerLR 0.121202
FineTuningLR 0.578514
Epoch 32 | Batch 90/100 | Loss 0.192992
InnerLR 0.120720
FineTuningLR 0.578619
100 Accuracy = 82.96% +- 2.27%
Epoch 32: 82.96
Epoch 33 | Batch 0/100 | Loss 0.142595
InnerLR 0.120157
FineTuningLR 0.579123
Epoch 33 | Batch 10/100 | Loss 0.141094
InnerLR 0.119996
FineTuningLR 0.579664
Epoch 33 | Batch 20/100 | Loss 0.155299
InnerLR 0.119873
FineTuningLR 0.580774
Epoch 33 | Batch 30/100 | Loss 0.204320
InnerLR 0.119545
FineTuningLR 0.581622
Epoch 33 | Batch 40/100 | Loss 0.217591
InnerLR 0.119057
FineTuningLR 0.582293
Epoch 33 | Batch 50/100 | Loss 0.208529
InnerLR 0.119329
FineTuningLR 0.582559
Epoch 33 | Batch 60/100 | Loss 0.213432
InnerLR 0.119579
FineTuningLR 0.582708
Epoch 33 | Batch 70/100 | Loss 0.217521
InnerLR 0.119934
FineTuningLR 0.582697
Epoch 33 | Batch 80/100 | Loss 0.223399
InnerLR 0.120862
FineTuningLR 0.582759
Epoch 33 | Batch 90/100 | Loss 0.215800
InnerLR 0.121443
FineTuningLR 0.582938
100 Accuracy = 86.27% +- 1.79%
Epoch 33: 86.27
Epoch 34 | Batch 0/100 | Loss 0.181999
InnerLR 0.121679
FineTuningLR 0.582911
Epoch 34 | Batch 10/100 | Loss 0.146428
InnerLR 0.121914
FineTuningLR 0.583250
Epoch 34 | Batch 20/100 | Loss 0.157119
InnerLR 0.122417
FineTuningLR 0.584129
Epoch 34 | Batch 30/100 | Loss 0.158331
InnerLR 0.122624
FineTuningLR 0.584784
Epoch 34 | Batch 40/100 | Loss 0.165463
InnerLR 0.122428
FineTuningLR 0.585231
Epoch 34 | Batch 50/100 | Loss 0.159956
InnerLR 0.122241
FineTuningLR 0.585687
Epoch 34 | Batch 60/100 | Loss 0.162547
InnerLR 0.121860
FineTuningLR 0.586746
Epoch 34 | Batch 70/100 | Loss 0.165936
InnerLR 0.122117
FineTuningLR 0.587326
Epoch 34 | Batch 80/100 | Loss 0.178240
InnerLR 0.122181
FineTuningLR 0.587850
Epoch 34 | Batch 90/100 | Loss 0.170280
InnerLR 0.121987
FineTuningLR 0.588232
100 Accuracy = 83.53% +- 2.29%
Epoch 34: 83.53
Epoch 35 | Batch 0/100 | Loss 0.160668
InnerLR 0.121798
FineTuningLR 0.589379
Epoch 35 | Batch 10/100 | Loss 0.178363
InnerLR 0.121675
FineTuningLR 0.589852
Epoch 35 | Batch 20/100 | Loss 0.171750
InnerLR 0.121479
FineTuningLR 0.590251
Epoch 35 | Batch 30/100 | Loss 0.171136
InnerLR 0.121407
FineTuningLR 0.590079
Epoch 35 | Batch 40/100 | Loss 0.188857
InnerLR 0.121220
FineTuningLR 0.590237
Epoch 35 | Batch 50/100 | Loss 0.191518
InnerLR 0.121340
FineTuningLR 0.590616
Epoch 35 | Batch 60/100 | Loss 0.195612
InnerLR 0.122108
FineTuningLR 0.590769
Epoch 35 | Batch 70/100 | Loss 0.195356
InnerLR 0.122508
FineTuningLR 0.590793
Epoch 35 | Batch 80/100 | Loss 0.194007
InnerLR 0.123119
FineTuningLR 0.590130
Epoch 35 | Batch 90/100 | Loss 0.192374
InnerLR 0.123519
FineTuningLR 0.589904
100 Accuracy = 85.31% +- 1.93%
Epoch 35: 85.31
Epoch 36 | Batch 0/100 | Loss 0.119105
InnerLR 0.124090
FineTuningLR 0.589411
Epoch 36 | Batch 10/100 | Loss 0.231160
InnerLR 0.123913
FineTuningLR 0.589312
Epoch 36 | Batch 20/100 | Loss 0.219308
InnerLR 0.123699
FineTuningLR 0.589127
Epoch 36 | Batch 30/100 | Loss 0.206405
InnerLR 0.123787
FineTuningLR 0.588968
Epoch 36 | Batch 40/100 | Loss 0.214843
InnerLR 0.124123
FineTuningLR 0.588838
Epoch 36 | Batch 50/100 | Loss 0.197095
InnerLR 0.123940
FineTuningLR 0.589124
Epoch 36 | Batch 60/100 | Loss 0.193399
InnerLR 0.123374
FineTuningLR 0.589454
Epoch 36 | Batch 70/100 | Loss 0.188488
InnerLR 0.122730
FineTuningLR 0.589650
Epoch 36 | Batch 80/100 | Loss 0.196341
InnerLR 0.122039
FineTuningLR 0.589728
Epoch 36 | Batch 90/100 | Loss 0.188564
InnerLR 0.121429
FineTuningLR 0.589839
100 Accuracy = 83.41% +- 2.28%
Epoch 36: 83.41
Epoch 37 | Batch 0/100 | Loss 0.129005
InnerLR 0.121154
FineTuningLR 0.589915
Epoch 37 | Batch 10/100 | Loss 0.195695
InnerLR 0.120915
FineTuningLR 0.589700
Epoch 37 | Batch 20/100 | Loss 0.171628
InnerLR 0.120948
FineTuningLR 0.589249
Epoch 37 | Batch 30/100 | Loss 0.206844
InnerLR 0.120550
FineTuningLR 0.589087
Epoch 37 | Batch 40/100 | Loss 0.222695
InnerLR 0.119601
FineTuningLR 0.589210
Epoch 37 | Batch 50/100 | Loss 0.207683
InnerLR 0.119089
FineTuningLR 0.589246
Epoch 37 | Batch 60/100 | Loss 0.203197
InnerLR 0.118437
FineTuningLR 0.589404
Epoch 37 | Batch 70/100 | Loss 0.191087
InnerLR 0.117951
FineTuningLR 0.589217
Epoch 37 | Batch 80/100 | Loss 0.188674
InnerLR 0.117511
FineTuningLR 0.588756
Epoch 37 | Batch 90/100 | Loss 0.187289
InnerLR 0.117224
FineTuningLR 0.588894
100 Accuracy = 84.21% +- 1.86%
Epoch 37: 84.21
Epoch 38 | Batch 0/100 | Loss 0.240792
InnerLR 0.116817
FineTuningLR 0.589391
Epoch 38 | Batch 10/100 | Loss 0.202408
InnerLR 0.117080
FineTuningLR 0.589614
Epoch 38 | Batch 20/100 | Loss 0.196624
InnerLR 0.117323
FineTuningLR 0.590164
Epoch 38 | Batch 30/100 | Loss 0.188528
InnerLR 0.117079
FineTuningLR 0.590782
Epoch 38 | Batch 40/100 | Loss 0.180314
InnerLR 0.116203
FineTuningLR 0.591958
Epoch 38 | Batch 50/100 | Loss 0.179891
InnerLR 0.116175
FineTuningLR 0.592739
Epoch 38 | Batch 60/100 | Loss 0.188038
InnerLR 0.116253
FineTuningLR 0.593587
Epoch 38 | Batch 70/100 | Loss 0.184742
InnerLR 0.116026
FineTuningLR 0.593666
Epoch 38 | Batch 80/100 | Loss 0.177135
InnerLR 0.115711
FineTuningLR 0.594192
Epoch 38 | Batch 90/100 | Loss 0.180093
InnerLR 0.115577
FineTuningLR 0.594548
100 Accuracy = 83.99% +- 2.17%
Epoch 38: 83.99
Epoch 39 | Batch 0/100 | Loss 0.813654
InnerLR 0.115113
FineTuningLR 0.595652
Epoch 39 | Batch 10/100 | Loss 0.367479
InnerLR 0.115112
FineTuningLR 0.596676
Epoch 39 | Batch 20/100 | Loss 0.272355
InnerLR 0.115811
FineTuningLR 0.597410
Epoch 39 | Batch 30/100 | Loss 0.239914
InnerLR 0.116402
FineTuningLR 0.597468
Epoch 39 | Batch 40/100 | Loss 0.214531
InnerLR 0.116370
FineTuningLR 0.597249
Epoch 39 | Batch 50/100 | Loss 0.212742
InnerLR 0.115905
FineTuningLR 0.597306
Epoch 39 | Batch 60/100 | Loss 0.204934
InnerLR 0.115600
FineTuningLR 0.597263
Epoch 39 | Batch 70/100 | Loss 0.202559
InnerLR 0.115092
FineTuningLR 0.597328
Epoch 39 | Batch 80/100 | Loss 0.205606
InnerLR 0.114350
FineTuningLR 0.597176
Epoch 39 | Batch 90/100 | Loss 0.204600
InnerLR 0.114082
FineTuningLR 0.596873
100 Accuracy = 83.53% +- 2.17%
Epoch 39: 83.53
Epoch 40 | Batch 0/100 | Loss 0.082614
InnerLR 0.113340
FineTuningLR 0.596031
Epoch 40 | Batch 10/100 | Loss 0.239061
InnerLR 0.112695
FineTuningLR 0.595573
Epoch 40 | Batch 20/100 | Loss 0.191332
InnerLR 0.112438
FineTuningLR 0.594609
Epoch 40 | Batch 30/100 | Loss 0.200635
InnerLR 0.111954
FineTuningLR 0.593849
Epoch 40 | Batch 40/100 | Loss 0.272381
InnerLR 0.110706
FineTuningLR 0.592535
Epoch 40 | Batch 50/100 | Loss 0.248109
InnerLR 0.109813
FineTuningLR 0.591789
Epoch 40 | Batch 60/100 | Loss 0.256867
InnerLR 0.108743
FineTuningLR 0.591177
Epoch 40 | Batch 70/100 | Loss 0.251932
InnerLR 0.108223
FineTuningLR 0.590710
Epoch 40 | Batch 80/100 | Loss 0.243624
InnerLR 0.107854
FineTuningLR 0.590864
Epoch 40 | Batch 90/100 | Loss 0.233629
InnerLR 0.107557
FineTuningLR 0.591448
100 Accuracy = 84.31% +- 2.00%
Epoch 40: 84.31
Epoch 41 | Batch 0/100 | Loss 0.231493
InnerLR 0.107286
FineTuningLR 0.592193
Epoch 41 | Batch 10/100 | Loss 0.188867
InnerLR 0.107300
FineTuningLR 0.592471
Epoch 41 | Batch 20/100 | Loss 0.192287
InnerLR 0.107139
FineTuningLR 0.592523
Epoch 41 | Batch 30/100 | Loss 0.180432
InnerLR 0.107169
FineTuningLR 0.592576
Epoch 41 | Batch 40/100 | Loss 0.173102
InnerLR 0.107352
FineTuningLR 0.593073
Epoch 41 | Batch 50/100 | Loss 0.170000
InnerLR 0.107330
FineTuningLR 0.593596
Epoch 41 | Batch 60/100 | Loss 0.176205
InnerLR 0.107594
FineTuningLR 0.593598
Epoch 41 | Batch 70/100 | Loss 0.174945
InnerLR 0.107773
FineTuningLR 0.593356
Epoch 41 | Batch 80/100 | Loss 0.174493
InnerLR 0.107535
FineTuningLR 0.593104
Epoch 41 | Batch 90/100 | Loss 0.172536
InnerLR 0.107400
FineTuningLR 0.593369
100 Accuracy = 85.44% +- 1.90%
Epoch 41: 85.44
Epoch 42 | Batch 0/100 | Loss 0.178654
InnerLR 0.107553
FineTuningLR 0.594168
Epoch 42 | Batch 10/100 | Loss 0.247304
InnerLR 0.107365
FineTuningLR 0.594671
Epoch 42 | Batch 20/100 | Loss 0.211680
InnerLR 0.106653
FineTuningLR 0.595084
Epoch 42 | Batch 30/100 | Loss 0.191035
InnerLR 0.106642
FineTuningLR 0.594940
Epoch 42 | Batch 40/100 | Loss 0.175203
InnerLR 0.106750
FineTuningLR 0.594888
Epoch 42 | Batch 50/100 | Loss 0.166886
InnerLR 0.106624
FineTuningLR 0.594989
Epoch 42 | Batch 60/100 | Loss 0.188044
InnerLR 0.106038
FineTuningLR 0.594783
Epoch 42 | Batch 70/100 | Loss 0.209334
InnerLR 0.105648
FineTuningLR 0.594319
Epoch 42 | Batch 80/100 | Loss 0.219040
InnerLR 0.105051
FineTuningLR 0.593473
Epoch 42 | Batch 90/100 | Loss 0.218225
InnerLR 0.104510
FineTuningLR 0.592839
100 Accuracy = 84.07% +- 2.04%
Epoch 42: 84.07
Epoch 43 | Batch 0/100 | Loss 0.081670
InnerLR 0.104072
FineTuningLR 0.591993
Epoch 43 | Batch 10/100 | Loss 0.122131
InnerLR 0.103733
FineTuningLR 0.591591
Epoch 43 | Batch 20/100 | Loss 0.128633
InnerLR 0.103568
FineTuningLR 0.591365
Epoch 43 | Batch 30/100 | Loss 0.147862
InnerLR 0.103096
FineTuningLR 0.591037
Epoch 43 | Batch 40/100 | Loss 0.153310
InnerLR 0.102398
FineTuningLR 0.591276
Epoch 43 | Batch 50/100 | Loss 0.157268
InnerLR 0.101927
FineTuningLR 0.591284
Epoch 43 | Batch 60/100 | Loss 0.187984
InnerLR 0.101075
FineTuningLR 0.591145
Epoch 43 | Batch 70/100 | Loss 0.184794
InnerLR 0.100642
FineTuningLR 0.590783
Epoch 43 | Batch 80/100 | Loss 0.184767
InnerLR 0.100224
FineTuningLR 0.590520
Epoch 43 | Batch 90/100 | Loss 0.181210
InnerLR 0.100018
FineTuningLR 0.590347
100 Accuracy = 84.84% +- 1.73%
Epoch 43: 84.84
Epoch 44 | Batch 0/100 | Loss 0.396493
InnerLR 0.100024
FineTuningLR 0.590158
Epoch 44 | Batch 10/100 | Loss 0.232320
InnerLR 0.100573
FineTuningLR 0.590030
Epoch 44 | Batch 20/100 | Loss 0.191935
InnerLR 0.101016
FineTuningLR 0.589692
Epoch 44 | Batch 30/100 | Loss 0.192064
InnerLR 0.101519
FineTuningLR 0.589690
Epoch 44 | Batch 40/100 | Loss 0.232110
InnerLR 0.101823
FineTuningLR 0.589597
Epoch 44 | Batch 50/100 | Loss 0.231523
InnerLR 0.101613
FineTuningLR 0.589354
Epoch 44 | Batch 60/100 | Loss 0.236688
InnerLR 0.101676
FineTuningLR 0.589102
Epoch 44 | Batch 70/100 | Loss 0.222243
InnerLR 0.102081
FineTuningLR 0.588807
Epoch 44 | Batch 80/100 | Loss 0.222247
InnerLR 0.102100
FineTuningLR 0.587785
Epoch 44 | Batch 90/100 | Loss 0.226426
InnerLR 0.101845
FineTuningLR 0.586792
100 Accuracy = 84.57% +- 2.21%
Epoch 44: 84.57
Epoch 45 | Batch 0/100 | Loss 0.274744
InnerLR 0.101697
FineTuningLR 0.585496
Epoch 45 | Batch 10/100 | Loss 0.303325
InnerLR 0.101508
FineTuningLR 0.584565
Epoch 45 | Batch 20/100 | Loss 0.253445
InnerLR 0.100920
FineTuningLR 0.583519
Epoch 45 | Batch 30/100 | Loss 0.212459
InnerLR 0.100646
FineTuningLR 0.583011
Epoch 45 | Batch 40/100 | Loss 0.217651
InnerLR 0.099581
FineTuningLR 0.582016
Epoch 45 | Batch 50/100 | Loss 0.206850
InnerLR 0.098573
FineTuningLR 0.581480
Epoch 45 | Batch 60/100 | Loss 0.196570
InnerLR 0.097002
FineTuningLR 0.580836
Epoch 45 | Batch 70/100 | Loss 0.203485
InnerLR 0.096053
FineTuningLR 0.580284
Epoch 45 | Batch 80/100 | Loss 0.201892
InnerLR 0.095179
FineTuningLR 0.579644
Epoch 45 | Batch 90/100 | Loss 0.200343
InnerLR 0.095218
FineTuningLR 0.579091
100 Accuracy = 82.79% +- 2.04%
Epoch 45: 82.79
Epoch 46 | Batch 0/100 | Loss 0.209965
InnerLR 0.095052
FineTuningLR 0.578576
Epoch 46 | Batch 10/100 | Loss 0.207901
InnerLR 0.094889
FineTuningLR 0.578524
Epoch 46 | Batch 20/100 | Loss 0.182669
InnerLR 0.094850
FineTuningLR 0.578798
Epoch 46 | Batch 30/100 | Loss 0.211701
InnerLR 0.094545
FineTuningLR 0.579375
Epoch 46 | Batch 40/100 | Loss 0.196708
InnerLR 0.093963
FineTuningLR 0.579988
Epoch 46 | Batch 50/100 | Loss 0.205978
InnerLR 0.094007
FineTuningLR 0.580154
Epoch 46 | Batch 60/100 | Loss 0.198085
InnerLR 0.093742
FineTuningLR 0.580708
Epoch 46 | Batch 70/100 | Loss 0.195442
InnerLR 0.093491
FineTuningLR 0.581194
Epoch 46 | Batch 80/100 | Loss 0.194551
InnerLR 0.093113
FineTuningLR 0.581667
Epoch 46 | Batch 90/100 | Loss 0.187904
InnerLR 0.092782
FineTuningLR 0.581452
100 Accuracy = 83.69% +- 2.05%
Epoch 46: 83.69
Epoch 47 | Batch 0/100 | Loss 0.132100
InnerLR 0.091843
FineTuningLR 0.580984
Epoch 47 | Batch 10/100 | Loss 0.145565
InnerLR 0.090926
FineTuningLR 0.580977
Epoch 47 | Batch 20/100 | Loss 0.158601
InnerLR 0.089189
FineTuningLR 0.581287
Epoch 47 | Batch 30/100 | Loss 0.146371
InnerLR 0.088320
FineTuningLR 0.581864
Epoch 47 | Batch 40/100 | Loss 0.147490
InnerLR 0.087425
FineTuningLR 0.583026
Epoch 47 | Batch 50/100 | Loss 0.161116
InnerLR 0.086726
FineTuningLR 0.583434
Epoch 47 | Batch 60/100 | Loss 0.198333
InnerLR 0.085907
FineTuningLR 0.584002
Epoch 47 | Batch 70/100 | Loss 0.188822
InnerLR 0.085340
FineTuningLR 0.584377
Epoch 47 | Batch 80/100 | Loss 0.190575
InnerLR 0.084454
FineTuningLR 0.585122
Epoch 47 | Batch 90/100 | Loss 0.197773
InnerLR 0.084015
FineTuningLR 0.585383
100 Accuracy = 87.80% +- 1.90%
Epoch 47: 87.80
best model! save...
Epoch 48 | Batch 0/100 | Loss 0.814950
InnerLR 0.083669
FineTuningLR 0.585510
Epoch 48 | Batch 10/100 | Loss 0.197736
InnerLR 0.083228
FineTuningLR 0.585419
Epoch 48 | Batch 20/100 | Loss 0.178613
InnerLR 0.082666
FineTuningLR 0.585628
Epoch 48 | Batch 30/100 | Loss 0.175370
InnerLR 0.082406
FineTuningLR 0.586093
Epoch 48 | Batch 40/100 | Loss 0.181047
InnerLR 0.082553
FineTuningLR 0.586763
Epoch 48 | Batch 50/100 | Loss 0.197268
InnerLR 0.082538
FineTuningLR 0.586662
Epoch 48 | Batch 60/100 | Loss 0.198973
InnerLR 0.082412
FineTuningLR 0.586232
Epoch 48 | Batch 70/100 | Loss 0.192015
InnerLR 0.082434
FineTuningLR 0.586242
Epoch 48 | Batch 80/100 | Loss 0.187110
InnerLR 0.082572
FineTuningLR 0.586878
Epoch 48 | Batch 90/100 | Loss 0.201383
InnerLR 0.082137
FineTuningLR 0.587440
100 Accuracy = 82.52% +- 2.28%
Epoch 48: 82.52
Epoch 49 | Batch 0/100 | Loss 0.076446
InnerLR 0.081135
FineTuningLR 0.587794
Epoch 49 | Batch 10/100 | Loss 0.246288
InnerLR 0.080972
FineTuningLR 0.587819
Epoch 49 | Batch 20/100 | Loss 0.210831
InnerLR 0.080555
FineTuningLR 0.587959
Epoch 49 | Batch 30/100 | Loss 0.194265
InnerLR 0.080314
FineTuningLR 0.587943
Epoch 49 | Batch 40/100 | Loss 0.197739
InnerLR 0.079735
FineTuningLR 0.587731
Epoch 49 | Batch 50/100 | Loss 0.197960
InnerLR 0.079414
FineTuningLR 0.587652
Epoch 49 | Batch 60/100 | Loss 0.196426
InnerLR 0.079042
FineTuningLR 0.587378
Epoch 49 | Batch 70/100 | Loss 0.190774
InnerLR 0.079010
FineTuningLR 0.587185
Epoch 49 | Batch 80/100 | Loss 0.186772
InnerLR 0.078488
FineTuningLR 0.587275
Epoch 49 | Batch 90/100 | Loss 0.181350
InnerLR 0.078373
FineTuningLR 0.587679
100 Accuracy = 84.21% +- 2.14%
Epoch 49: 84.21
Epoch 50 | Batch 0/100 | Loss 0.317403
InnerLR 0.077712
FineTuningLR 0.588949
Epoch 50 | Batch 10/100 | Loss 0.159295
InnerLR 0.077323
FineTuningLR 0.589889
Epoch 50 | Batch 20/100 | Loss 0.186562
InnerLR 0.076751
FineTuningLR 0.590841
Epoch 50 | Batch 30/100 | Loss 0.188281
InnerLR 0.076168
FineTuningLR 0.591144
Epoch 50 | Batch 40/100 | Loss 0.179924
InnerLR 0.075640
FineTuningLR 0.590998
Epoch 50 | Batch 50/100 | Loss 0.179832
InnerLR 0.075833
FineTuningLR 0.590897
Epoch 50 | Batch 60/100 | Loss 0.186409
InnerLR 0.076740
FineTuningLR 0.591093
Epoch 50 | Batch 70/100 | Loss 0.184147
InnerLR 0.077091
FineTuningLR 0.591348
Epoch 50 | Batch 80/100 | Loss 0.183163
InnerLR 0.076900
FineTuningLR 0.591593
Epoch 50 | Batch 90/100 | Loss 0.184011
InnerLR 0.076578
FineTuningLR 0.591564
100 Accuracy = 84.35% +- 2.23%
Epoch 50: 84.35
Epoch 51 | Batch 0/100 | Loss 0.212292
InnerLR 0.076257
FineTuningLR 0.591092
Epoch 51 | Batch 10/100 | Loss 0.242627
InnerLR 0.075845
FineTuningLR 0.590548
Epoch 51 | Batch 20/100 | Loss 0.279709
InnerLR 0.075810
FineTuningLR 0.589492
Epoch 51 | Batch 30/100 | Loss 0.240729
InnerLR 0.076055
FineTuningLR 0.589066
Epoch 51 | Batch 40/100 | Loss 0.229726
InnerLR 0.075815
FineTuningLR 0.588638
Epoch 51 | Batch 50/100 | Loss 0.224210
InnerLR 0.075700
FineTuningLR 0.588091
Epoch 51 | Batch 60/100 | Loss 0.209628
InnerLR 0.076095
FineTuningLR 0.587496
Epoch 51 | Batch 70/100 | Loss 0.211212
InnerLR 0.076068
FineTuningLR 0.586915
Epoch 51 | Batch 80/100 | Loss 0.215090
InnerLR 0.076070
FineTuningLR 0.585432
Epoch 51 | Batch 90/100 | Loss 0.224145
InnerLR 0.075935
FineTuningLR 0.584647
100 Accuracy = 82.63% +- 1.87%
Epoch 51: 82.63
Epoch 52 | Batch 0/100 | Loss 0.078483
InnerLR 0.075295
FineTuningLR 0.583245
Epoch 52 | Batch 10/100 | Loss 0.213942
InnerLR 0.074983
FineTuningLR 0.582787
Epoch 52 | Batch 20/100 | Loss 0.286154
InnerLR 0.075130
FineTuningLR 0.582307
Epoch 52 | Batch 30/100 | Loss 0.246643
InnerLR 0.074841
FineTuningLR 0.582152
Epoch 52 | Batch 40/100 | Loss 0.249417
InnerLR 0.074929
FineTuningLR 0.581911
Epoch 52 | Batch 50/100 | Loss 0.252614
InnerLR 0.075238
FineTuningLR 0.581430
Epoch 52 | Batch 60/100 | Loss 0.246541
InnerLR 0.075827
FineTuningLR 0.580178
Epoch 52 | Batch 70/100 | Loss 0.245694
InnerLR 0.076353
FineTuningLR 0.579653
Epoch 52 | Batch 80/100 | Loss 0.236994
InnerLR 0.077070
FineTuningLR 0.578994
Epoch 52 | Batch 90/100 | Loss 0.224773
InnerLR 0.076974
FineTuningLR 0.578502
100 Accuracy = 83.37% +- 2.04%
Epoch 52: 83.37
Epoch 53 | Batch 0/100 | Loss 0.746703
InnerLR 0.077094
FineTuningLR 0.577495
Epoch 53 | Batch 10/100 | Loss 0.241063
InnerLR 0.077003
FineTuningLR 0.576508
Epoch 53 | Batch 20/100 | Loss 0.204574
InnerLR 0.077007
FineTuningLR 0.575602
Epoch 53 | Batch 30/100 | Loss 0.184649
InnerLR 0.076995
FineTuningLR 0.574913
Epoch 53 | Batch 40/100 | Loss 0.169281
InnerLR 0.076928
FineTuningLR 0.574814
Epoch 53 | Batch 50/100 | Loss 0.179307
InnerLR 0.076742
FineTuningLR 0.574649
Epoch 53 | Batch 60/100 | Loss 0.175444
InnerLR 0.076674
FineTuningLR 0.574309
Epoch 53 | Batch 70/100 | Loss 0.171284
InnerLR 0.076701
FineTuningLR 0.574329
Epoch 53 | Batch 80/100 | Loss 0.176529
InnerLR 0.076402
FineTuningLR 0.574496
Epoch 53 | Batch 90/100 | Loss 0.173554
InnerLR 0.076445
FineTuningLR 0.574533
100 Accuracy = 84.43% +- 1.80%
Epoch 53: 84.43
Epoch 54 | Batch 0/100 | Loss 0.164142
InnerLR 0.076604
FineTuningLR 0.574811
Epoch 54 | Batch 10/100 | Loss 0.169276
InnerLR 0.076344
FineTuningLR 0.575015
Epoch 54 | Batch 20/100 | Loss 0.226614
InnerLR 0.076350
FineTuningLR 0.574813
Epoch 54 | Batch 30/100 | Loss 0.199037
InnerLR 0.076517
FineTuningLR 0.574454
Epoch 54 | Batch 40/100 | Loss 0.178656
InnerLR 0.076886
FineTuningLR 0.574780
Epoch 54 | Batch 50/100 | Loss 0.180518
InnerLR 0.076707
FineTuningLR 0.574845
Epoch 54 | Batch 60/100 | Loss 0.180016
InnerLR 0.076418
FineTuningLR 0.575011
Epoch 54 | Batch 70/100 | Loss 0.172953
InnerLR 0.076082
FineTuningLR 0.574910
Epoch 54 | Batch 80/100 | Loss 0.190100
InnerLR 0.075752
FineTuningLR 0.575272
Epoch 54 | Batch 90/100 | Loss 0.205711
InnerLR 0.075497
FineTuningLR 0.575342
100 Accuracy = 84.35% +- 2.12%
Epoch 54: 84.35
Epoch 55 | Batch 0/100 | Loss 0.056392
InnerLR 0.075632
FineTuningLR 0.574929
Epoch 55 | Batch 10/100 | Loss 0.138022
InnerLR 0.076040
FineTuningLR 0.574730
Epoch 55 | Batch 20/100 | Loss 0.164215
InnerLR 0.076456
FineTuningLR 0.574313
Epoch 55 | Batch 30/100 | Loss 0.157157
InnerLR 0.076358
FineTuningLR 0.574341
Epoch 55 | Batch 40/100 | Loss 0.165763
InnerLR 0.076749
FineTuningLR 0.575048
Epoch 55 | Batch 50/100 | Loss 0.206162
InnerLR 0.076521
FineTuningLR 0.575485
Epoch 55 | Batch 60/100 | Loss 0.205379
InnerLR 0.076111
FineTuningLR 0.575291
Epoch 55 | Batch 70/100 | Loss 0.214353
InnerLR 0.076014
FineTuningLR 0.574720
Epoch 55 | Batch 80/100 | Loss 0.205991
InnerLR 0.076597
FineTuningLR 0.574283
Epoch 55 | Batch 90/100 | Loss 0.215708
InnerLR 0.076769
FineTuningLR 0.573721
100 Accuracy = 85.08% +- 1.91%
Epoch 55: 85.08
Epoch 56 | Batch 0/100 | Loss 0.210104
InnerLR 0.076798
FineTuningLR 0.572988
Epoch 56 | Batch 10/100 | Loss 0.143557
InnerLR 0.076349
FineTuningLR 0.573084
Epoch 56 | Batch 20/100 | Loss 0.192433
InnerLR 0.075629
FineTuningLR 0.572713
Epoch 56 | Batch 30/100 | Loss 0.206287
InnerLR 0.075240
FineTuningLR 0.572002
Epoch 56 | Batch 40/100 | Loss 0.216814
InnerLR 0.075473
FineTuningLR 0.571415
Epoch 56 | Batch 50/100 | Loss 0.222860
InnerLR 0.075678
FineTuningLR 0.571143
Epoch 56 | Batch 60/100 | Loss 0.208822
InnerLR 0.075980
FineTuningLR 0.570658
Epoch 56 | Batch 70/100 | Loss 0.226006
InnerLR 0.075633
FineTuningLR 0.570241
Epoch 56 | Batch 80/100 | Loss 0.217505
InnerLR 0.075694
FineTuningLR 0.570156
Epoch 56 | Batch 90/100 | Loss 0.213098
InnerLR 0.075614
FineTuningLR 0.570201
100 Accuracy = 85.93% +- 1.96%
Epoch 56: 85.93
Epoch 57 | Batch 0/100 | Loss 0.073390
InnerLR 0.075745
FineTuningLR 0.570011
Epoch 57 | Batch 10/100 | Loss 0.175684
InnerLR 0.075753
FineTuningLR 0.570233
Epoch 57 | Batch 20/100 | Loss 0.190449
InnerLR 0.076190
FineTuningLR 0.570436
Epoch 57 | Batch 30/100 | Loss 0.176775
InnerLR 0.076729
FineTuningLR 0.570255
Epoch 57 | Batch 40/100 | Loss 0.178759
InnerLR 0.077081
FineTuningLR 0.570408
Epoch 57 | Batch 50/100 | Loss 0.172259
InnerLR 0.077501
FineTuningLR 0.570910
Epoch 57 | Batch 60/100 | Loss 0.205734
InnerLR 0.077772
FineTuningLR 0.571418
Epoch 57 | Batch 70/100 | Loss 0.208616
InnerLR 0.077685
FineTuningLR 0.571320
Epoch 57 | Batch 80/100 | Loss 0.196050
InnerLR 0.077440
FineTuningLR 0.571096
Epoch 57 | Batch 90/100 | Loss 0.196385
InnerLR 0.077280
FineTuningLR 0.571378
100 Accuracy = 85.56% +- 1.94%
Epoch 57: 85.56
Epoch 58 | Batch 0/100 | Loss 0.080670
InnerLR 0.076756
FineTuningLR 0.571440
Epoch 58 | Batch 10/100 | Loss 0.290405
InnerLR 0.076327
FineTuningLR 0.571233
Epoch 58 | Batch 20/100 | Loss 0.215199
InnerLR 0.075575
FineTuningLR 0.570922
Epoch 58 | Batch 30/100 | Loss 0.214750
InnerLR 0.074756
FineTuningLR 0.570623
Epoch 58 | Batch 40/100 | Loss 0.201676
InnerLR 0.073333
FineTuningLR 0.570603
Epoch 58 | Batch 50/100 | Loss 0.197421
InnerLR 0.073037
FineTuningLR 0.570910
Epoch 58 | Batch 60/100 | Loss 0.193826
InnerLR 0.073041
FineTuningLR 0.571150
Epoch 58 | Batch 70/100 | Loss 0.188384
InnerLR 0.073504
FineTuningLR 0.571189
Epoch 58 | Batch 80/100 | Loss 0.181892
InnerLR 0.073808
FineTuningLR 0.571214
Epoch 58 | Batch 90/100 | Loss 0.183959
InnerLR 0.074004
FineTuningLR 0.570979
100 Accuracy = 84.48% +- 2.12%
Epoch 58: 84.48
Epoch 59 | Batch 0/100 | Loss 0.288862
InnerLR 0.074989
FineTuningLR 0.570157
Epoch 59 | Batch 10/100 | Loss 0.192884
InnerLR 0.076002
FineTuningLR 0.569959
Epoch 59 | Batch 20/100 | Loss 0.187937
InnerLR 0.076745
FineTuningLR 0.569494
Epoch 59 | Batch 30/100 | Loss 0.171596
InnerLR 0.076664
FineTuningLR 0.569615
Epoch 59 | Batch 40/100 | Loss 0.164461
InnerLR 0.076952
FineTuningLR 0.569940
Epoch 59 | Batch 50/100 | Loss 0.182985
InnerLR 0.077511
FineTuningLR 0.570027
Epoch 59 | Batch 60/100 | Loss 0.186712
InnerLR 0.078309
FineTuningLR 0.570126
Epoch 59 | Batch 70/100 | Loss 0.182320
InnerLR 0.078247
FineTuningLR 0.570472
Epoch 59 | Batch 80/100 | Loss 0.180691
InnerLR 0.078217
FineTuningLR 0.571488
Epoch 59 | Batch 90/100 | Loss 0.184091
InnerLR 0.078026
FineTuningLR 0.572056
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 85.24% +- 1.87%
Epoch 59: 85.24
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.001/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.001/tabula_muris/leo_FCNet/20231211_171758
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 97.98% +- 0.25%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.001/tabula_muris/leo_FCNet/20231211_171758
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 85.03% +- 0.83%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.001/tabula_muris/leo_FCNet/20231211_171758
600 Accuracy = 86.33% +- 0.77%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.001/results.txt
+-------+-------------------+--------------------+
| split |      acc_mean     |      acc_std       |
+-------+-------------------+--------------------+
| train |       97.98       | 3.105009095233295  |
|  val  | 85.02888888888889 | 10.427558690648238 |
|  test | 86.32666666666667 | 9.654779664516969  |
+-------+-------------------+--------------------+
