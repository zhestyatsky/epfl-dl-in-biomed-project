/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 1
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 1
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 1
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 0.5
    finetuning_lr_init: 0.05
    num_adaptation_steps: 5
    kl_coef: 0.01
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 0.1
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 32
    enable_finetuning_loop: true
  n_task: 4
  latent_space_dim: 32
  leo_inner_lr_init: 0.5
  leo_finetuning_lr_init: 0.05
  num_adaptation_steps: 5
  kl_coef: 0.01
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 0.1
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-06
  optimize_backbone: false
  pretrained_backbone_weights_path: pretrained_weights/tabula_muris_baseline_pp_model.tar
  enable_finetuning_loop: true
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.001
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Using pretrained backbone from pretrained_weights/tabula_muris_baseline_pp_model.tar.
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=32, bias=False)
    (relation_net): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=False)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=64, bias=False)
      (3): ReLU()
      (4): Linear(in_features=64, out_features=64, bias=False)
    )
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=32, out_features=130, bias=False)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 1e-06

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Epoch 0 | Batch 0/100 | Loss 3.686027
InnerLR 0.500000
FineTuningLR 0.050000
Epoch 0 | Batch 10/100 | Loss 4.615840
InnerLR 0.502000
FineTuningLR 0.052000
Epoch 0 | Batch 20/100 | Loss 4.380253
InnerLR 0.505000
FineTuningLR 0.055000
Epoch 0 | Batch 30/100 | Loss 4.427950
InnerLR 0.507000
FineTuningLR 0.057000
Epoch 0 | Batch 40/100 | Loss 4.207778
InnerLR 0.510000
FineTuningLR 0.060000
Epoch 0 | Batch 50/100 | Loss 4.218108
InnerLR 0.512000
FineTuningLR 0.062000
Epoch 0 | Batch 60/100 | Loss 4.088812
InnerLR 0.515000
FineTuningLR 0.065000
Epoch 0 | Batch 70/100 | Loss 4.031669
InnerLR 0.517000
FineTuningLR 0.067000
Epoch 0 | Batch 80/100 | Loss 3.920978
InnerLR 0.520000
FineTuningLR 0.070000
Epoch 0 | Batch 90/100 | Loss 3.874996
InnerLR 0.522000
FineTuningLR 0.072000
100 Accuracy = 39.75% +- 2.40%
Epoch 0: 39.75
best model! save...
Epoch 1 | Batch 0/100 | Loss 2.822107
InnerLR 0.525000
FineTuningLR 0.075000
Epoch 1 | Batch 10/100 | Loss 3.748252
InnerLR 0.527000
FineTuningLR 0.077000
Epoch 1 | Batch 20/100 | Loss 3.289296
InnerLR 0.530000
FineTuningLR 0.080000
Epoch 1 | Batch 30/100 | Loss 3.072692
InnerLR 0.531605
FineTuningLR 0.082000
Epoch 1 | Batch 40/100 | Loss 3.015016
InnerLR 0.534154
FineTuningLR 0.085000
Epoch 1 | Batch 50/100 | Loss 2.837973
InnerLR 0.535924
FineTuningLR 0.087000
Epoch 1 | Batch 60/100 | Loss 2.787020
InnerLR 0.538661
FineTuningLR 0.090000
Epoch 1 | Batch 70/100 | Loss 2.752299
InnerLR 0.540142
FineTuningLR 0.092000
Epoch 1 | Batch 80/100 | Loss 2.585192
InnerLR 0.542544
FineTuningLR 0.095000
Epoch 1 | Batch 90/100 | Loss 2.468253
InnerLR 0.544239
FineTuningLR 0.097000
100 Accuracy = 51.09% +- 2.67%
Epoch 1: 51.09
best model! save...
Epoch 2 | Batch 0/100 | Loss 2.086092
InnerLR 0.546887
FineTuningLR 0.100000
Epoch 2 | Batch 10/100 | Loss 1.640818
InnerLR 0.548708
FineTuningLR 0.102000
Epoch 2 | Batch 20/100 | Loss 1.473250
InnerLR 0.551119
FineTuningLR 0.105000
Epoch 2 | Batch 30/100 | Loss 1.503823
InnerLR 0.552324
FineTuningLR 0.107000
Epoch 2 | Batch 40/100 | Loss 1.421596
InnerLR 0.554355
FineTuningLR 0.110037
Epoch 2 | Batch 50/100 | Loss 1.356760
InnerLR 0.555862
FineTuningLR 0.112055
Epoch 2 | Batch 60/100 | Loss 1.296893
InnerLR 0.558275
FineTuningLR 0.115089
Epoch 2 | Batch 70/100 | Loss 1.235284
InnerLR 0.559589
FineTuningLR 0.117110
Epoch 2 | Batch 80/100 | Loss 1.172754
InnerLR 0.561799
FineTuningLR 0.120131
Epoch 2 | Batch 90/100 | Loss 1.152173
InnerLR 0.562916
FineTuningLR 0.122198
100 Accuracy = 66.77% +- 2.62%
Epoch 2: 66.77
best model! save...
Epoch 3 | Batch 0/100 | Loss 0.861200
InnerLR 0.564131
FineTuningLR 0.125291
Epoch 3 | Batch 10/100 | Loss 0.792746
InnerLR 0.565224
FineTuningLR 0.127334
Epoch 3 | Batch 20/100 | Loss 0.697842
InnerLR 0.567090
FineTuningLR 0.130429
Epoch 3 | Batch 30/100 | Loss 0.700016
InnerLR 0.568103
FineTuningLR 0.132488
Epoch 3 | Batch 40/100 | Loss 0.680381
InnerLR 0.569973
FineTuningLR 0.135546
Epoch 3 | Batch 50/100 | Loss 0.684418
InnerLR 0.571402
FineTuningLR 0.137570
Epoch 3 | Batch 60/100 | Loss 0.664012
InnerLR 0.573750
FineTuningLR 0.140590
Epoch 3 | Batch 70/100 | Loss 0.657629
InnerLR 0.575424
FineTuningLR 0.142594
Epoch 3 | Batch 80/100 | Loss 0.652430
InnerLR 0.577934
FineTuningLR 0.145625
Epoch 3 | Batch 90/100 | Loss 0.648939
InnerLR 0.579546
FineTuningLR 0.147675
100 Accuracy = 66.29% +- 2.66%
Epoch 3: 66.29
Epoch 4 | Batch 0/100 | Loss 0.438864
InnerLR 0.581791
FineTuningLR 0.150780
Epoch 4 | Batch 10/100 | Loss 0.506256
InnerLR 0.583135
FineTuningLR 0.152844
Epoch 4 | Batch 20/100 | Loss 0.514730
InnerLR 0.585335
FineTuningLR 0.155945
Epoch 4 | Batch 30/100 | Loss 0.545771
InnerLR 0.586829
FineTuningLR 0.158023
Epoch 4 | Batch 40/100 | Loss 0.571598
InnerLR 0.589123
FineTuningLR 0.161143
Epoch 4 | Batch 50/100 | Loss 0.564385
InnerLR 0.590569
FineTuningLR 0.163194
Epoch 4 | Batch 60/100 | Loss 0.566708
InnerLR 0.592682
FineTuningLR 0.166237
Epoch 4 | Batch 70/100 | Loss 0.578183
InnerLR 0.594257
FineTuningLR 0.167898
Epoch 4 | Batch 80/100 | Loss 0.568071
InnerLR 0.596536
FineTuningLR 0.170582
Epoch 4 | Batch 90/100 | Loss 0.560246
InnerLR 0.597981
FineTuningLR 0.172464
100 Accuracy = 70.12% +- 2.37%
Epoch 4: 70.12
best model! save...
Epoch 5 | Batch 0/100 | Loss 0.463168
InnerLR 0.600360
FineTuningLR 0.175310
Epoch 5 | Batch 10/100 | Loss 0.471674
InnerLR 0.602057
FineTuningLR 0.177219
Epoch 5 | Batch 20/100 | Loss 0.486769
InnerLR 0.604724
FineTuningLR 0.180097
Epoch 5 | Batch 30/100 | Loss 0.500167
InnerLR 0.606567
FineTuningLR 0.182023
Epoch 5 | Batch 40/100 | Loss 0.504277
InnerLR 0.609389
FineTuningLR 0.184933
Epoch 5 | Batch 50/100 | Loss 0.511500
InnerLR 0.611306
FineTuningLR 0.186880
Epoch 5 | Batch 60/100 | Loss 0.508150
InnerLR 0.614219
FineTuningLR 0.189810
Epoch 5 | Batch 70/100 | Loss 0.505646
InnerLR 0.616176
FineTuningLR 0.191772
Epoch 5 | Batch 80/100 | Loss 0.506303
InnerLR 0.618895
FineTuningLR 0.194775
Epoch 5 | Batch 90/100 | Loss 0.521676
InnerLR 0.620466
FineTuningLR 0.196610
100 Accuracy = 73.96% +- 2.65%
Epoch 5: 73.96
best model! save...
Epoch 6 | Batch 0/100 | Loss 0.436138
InnerLR 0.622703
FineTuningLR 0.199177
Epoch 6 | Batch 10/100 | Loss 0.470516
InnerLR 0.624254
FineTuningLR 0.200991
Epoch 6 | Batch 20/100 | Loss 0.431719
InnerLR 0.626755
FineTuningLR 0.203757
Epoch 6 | Batch 30/100 | Loss 0.470332
InnerLR 0.628385
FineTuningLR 0.205306
Epoch 6 | Batch 40/100 | Loss 0.474828
InnerLR 0.630488
FineTuningLR 0.207907
Epoch 6 | Batch 50/100 | Loss 0.490179
InnerLR 0.631852
FineTuningLR 0.209700
Epoch 6 | Batch 60/100 | Loss 0.493477
InnerLR 0.633686
FineTuningLR 0.212454
Epoch 6 | Batch 70/100 | Loss 0.492118
InnerLR 0.634777
FineTuningLR 0.214365
Epoch 6 | Batch 80/100 | Loss 0.496699
InnerLR 0.636387
FineTuningLR 0.217340
Epoch 6 | Batch 90/100 | Loss 0.495767
InnerLR 0.637609
FineTuningLR 0.219325
100 Accuracy = 71.87% +- 2.33%
Epoch 6: 71.87
Epoch 7 | Batch 0/100 | Loss 0.403029
InnerLR 0.639258
FineTuningLR 0.222295
Epoch 7 | Batch 10/100 | Loss 0.583983
InnerLR 0.640593
FineTuningLR 0.224256
Epoch 7 | Batch 20/100 | Loss 0.499115
InnerLR 0.642091
FineTuningLR 0.227254
Epoch 7 | Batch 30/100 | Loss 0.503403
InnerLR 0.643147
FineTuningLR 0.229273
Epoch 7 | Batch 40/100 | Loss 0.479264
InnerLR 0.645074
FineTuningLR 0.232281
Epoch 7 | Batch 50/100 | Loss 0.461112
InnerLR 0.646489
FineTuningLR 0.234299
Epoch 7 | Batch 60/100 | Loss 0.458993
InnerLR 0.648774
FineTuningLR 0.237142
Epoch 7 | Batch 70/100 | Loss 0.453835
InnerLR 0.650427
FineTuningLR 0.238815
Epoch 7 | Batch 80/100 | Loss 0.450764
InnerLR 0.652779
FineTuningLR 0.241473
Epoch 7 | Batch 90/100 | Loss 0.448165
InnerLR 0.654165
FineTuningLR 0.243357
100 Accuracy = 71.53% +- 2.55%
Epoch 7: 71.53
Epoch 8 | Batch 0/100 | Loss 0.544970
InnerLR 0.656125
FineTuningLR 0.245800
Epoch 8 | Batch 10/100 | Loss 0.549016
InnerLR 0.656941
FineTuningLR 0.247516
Epoch 8 | Batch 20/100 | Loss 0.489577
InnerLR 0.658014
FineTuningLR 0.250192
Epoch 8 | Batch 30/100 | Loss 0.437896
InnerLR 0.659027
FineTuningLR 0.252028
Epoch 8 | Batch 40/100 | Loss 0.464685
InnerLR 0.661017
FineTuningLR 0.254275
Epoch 8 | Batch 50/100 | Loss 0.454689
InnerLR 0.662537
FineTuningLR 0.255745
Epoch 8 | Batch 60/100 | Loss 0.441375
InnerLR 0.664950
FineTuningLR 0.257597
Epoch 8 | Batch 70/100 | Loss 0.435520
InnerLR 0.666132
FineTuningLR 0.258817
Epoch 8 | Batch 80/100 | Loss 0.430914
InnerLR 0.668169
FineTuningLR 0.260252
Epoch 8 | Batch 90/100 | Loss 0.420869
InnerLR 0.669343
FineTuningLR 0.261357
100 Accuracy = 73.52% +- 2.73%
Epoch 8: 73.52
Epoch 9 | Batch 0/100 | Loss 0.811238
InnerLR 0.671269
FineTuningLR 0.262860
Epoch 9 | Batch 10/100 | Loss 0.588811
InnerLR 0.672090
FineTuningLR 0.263580
Epoch 9 | Batch 20/100 | Loss 0.476569
InnerLR 0.673490
FineTuningLR 0.264554
Epoch 9 | Batch 30/100 | Loss 0.461415
InnerLR 0.674461
FineTuningLR 0.265496
Epoch 9 | Batch 40/100 | Loss 0.452282
InnerLR 0.676014
FineTuningLR 0.267231
Epoch 9 | Batch 50/100 | Loss 0.443859
InnerLR 0.677074
FineTuningLR 0.268586
Epoch 9 | Batch 60/100 | Loss 0.438933
InnerLR 0.678753
FineTuningLR 0.270826
Epoch 9 | Batch 70/100 | Loss 0.431597
InnerLR 0.680062
FineTuningLR 0.272449
Epoch 9 | Batch 80/100 | Loss 0.426558
InnerLR 0.682111
FineTuningLR 0.275070
Epoch 9 | Batch 90/100 | Loss 0.423439
InnerLR 0.683456
FineTuningLR 0.276912
100 Accuracy = 73.84% +- 2.70%
Epoch 9: 73.84
Epoch 10 | Batch 0/100 | Loss 0.296355
InnerLR 0.685502
FineTuningLR 0.279253
Epoch 10 | Batch 10/100 | Loss 0.442941
InnerLR 0.686790
FineTuningLR 0.280398
Epoch 10 | Batch 20/100 | Loss 0.425920
InnerLR 0.688819
FineTuningLR 0.281698
Epoch 10 | Batch 30/100 | Loss 0.416980
InnerLR 0.690350
FineTuningLR 0.282751
Epoch 10 | Batch 40/100 | Loss 0.454339
InnerLR 0.692918
FineTuningLR 0.284507
Epoch 10 | Batch 50/100 | Loss 0.429486
InnerLR 0.694625
FineTuningLR 0.285429
Epoch 10 | Batch 60/100 | Loss 0.425087
InnerLR 0.697315
FineTuningLR 0.286637
Epoch 10 | Batch 70/100 | Loss 0.420921
InnerLR 0.699177
FineTuningLR 0.287513
Epoch 10 | Batch 80/100 | Loss 0.430271
InnerLR 0.701325
FineTuningLR 0.287981
Epoch 10 | Batch 90/100 | Loss 0.428007
InnerLR 0.702742
FineTuningLR 0.288575
100 Accuracy = 72.27% +- 2.39%
Epoch 10: 72.27
Epoch 11 | Batch 0/100 | Loss 0.363643
InnerLR 0.704828
FineTuningLR 0.289679
Epoch 11 | Batch 10/100 | Loss 0.487940
InnerLR 0.706114
FineTuningLR 0.290471
Epoch 11 | Batch 20/100 | Loss 0.457817
InnerLR 0.707586
FineTuningLR 0.291548
Epoch 11 | Batch 30/100 | Loss 0.421124
InnerLR 0.708715
FineTuningLR 0.292455
Epoch 11 | Batch 40/100 | Loss 0.404795
InnerLR 0.710727
FineTuningLR 0.293967
Epoch 11 | Batch 50/100 | Loss 0.423983
InnerLR 0.712231
FineTuningLR 0.295026
Epoch 11 | Batch 60/100 | Loss 0.417734
InnerLR 0.714481
FineTuningLR 0.296999
Epoch 11 | Batch 70/100 | Loss 0.419826
InnerLR 0.715915
FineTuningLR 0.298539
Epoch 11 | Batch 80/100 | Loss 0.427994
InnerLR 0.717743
FineTuningLR 0.300425
Epoch 11 | Batch 90/100 | Loss 0.421464
InnerLR 0.718975
FineTuningLR 0.301392
100 Accuracy = 73.63% +- 2.53%
Epoch 11: 73.63
Epoch 12 | Batch 0/100 | Loss 0.429471
InnerLR 0.720583
FineTuningLR 0.302651
Epoch 12 | Batch 10/100 | Loss 0.367493
InnerLR 0.721830
FineTuningLR 0.303193
Epoch 12 | Batch 20/100 | Loss 0.356781
InnerLR 0.723760
FineTuningLR 0.303994
Epoch 12 | Batch 30/100 | Loss 0.342979
InnerLR 0.725090
FineTuningLR 0.304786
Epoch 12 | Batch 40/100 | Loss 0.336419
InnerLR 0.727077
FineTuningLR 0.306462
Epoch 12 | Batch 50/100 | Loss 0.365261
InnerLR 0.728450
FineTuningLR 0.307460
Epoch 12 | Batch 60/100 | Loss 0.374092
InnerLR 0.730323
FineTuningLR 0.309093
Epoch 12 | Batch 70/100 | Loss 0.381456
InnerLR 0.731426
FineTuningLR 0.309578
Epoch 12 | Batch 80/100 | Loss 0.380796
InnerLR 0.733088
FineTuningLR 0.310083
Epoch 12 | Batch 90/100 | Loss 0.393653
InnerLR 0.734344
FineTuningLR 0.310656
100 Accuracy = 74.59% +- 2.46%
Epoch 12: 74.59
best model! save...
Epoch 13 | Batch 0/100 | Loss 0.379826
InnerLR 0.736533
FineTuningLR 0.311725
Epoch 13 | Batch 10/100 | Loss 0.412353
InnerLR 0.738110
FineTuningLR 0.312741
Epoch 13 | Batch 20/100 | Loss 0.423113
InnerLR 0.739797
FineTuningLR 0.314480
Epoch 13 | Batch 30/100 | Loss 0.395160
InnerLR 0.741069
FineTuningLR 0.315509
Epoch 13 | Batch 40/100 | Loss 0.383693
InnerLR 0.743227
FineTuningLR 0.316741
Epoch 13 | Batch 50/100 | Loss 0.380463
InnerLR 0.744592
FineTuningLR 0.317576
Epoch 13 | Batch 60/100 | Loss 0.368545
InnerLR 0.746330
FineTuningLR 0.319234
Epoch 13 | Batch 70/100 | Loss 0.363865
InnerLR 0.747492
FineTuningLR 0.320368
Epoch 13 | Batch 80/100 | Loss 0.372037
InnerLR 0.749199
FineTuningLR 0.321430
Epoch 13 | Batch 90/100 | Loss 0.371719
InnerLR 0.750470
FineTuningLR 0.322072
100 Accuracy = 73.37% +- 2.17%
Epoch 13: 73.37
Epoch 14 | Batch 0/100 | Loss 0.347206
InnerLR 0.752661
FineTuningLR 0.322679
Epoch 14 | Batch 10/100 | Loss 0.344992
InnerLR 0.754287
FineTuningLR 0.322873
Epoch 14 | Batch 20/100 | Loss 0.364012
InnerLR 0.756331
FineTuningLR 0.323394
Epoch 14 | Batch 30/100 | Loss 0.351367
InnerLR 0.757147
FineTuningLR 0.323714
Epoch 14 | Batch 40/100 | Loss 0.353512
InnerLR 0.758315
FineTuningLR 0.324193
Epoch 14 | Batch 50/100 | Loss 0.363958
InnerLR 0.759388
FineTuningLR 0.324431
Epoch 14 | Batch 60/100 | Loss 0.388274
InnerLR 0.760893
FineTuningLR 0.324534
Epoch 14 | Batch 70/100 | Loss 0.380667
InnerLR 0.762096
FineTuningLR 0.324773
Epoch 14 | Batch 80/100 | Loss 0.371557
InnerLR 0.763810
FineTuningLR 0.325754
Epoch 14 | Batch 90/100 | Loss 0.385104
InnerLR 0.764918
FineTuningLR 0.326607
100 Accuracy = 77.55% +- 2.31%
Epoch 14: 77.55
best model! save...
Epoch 15 | Batch 0/100 | Loss 0.247909
InnerLR 0.766273
FineTuningLR 0.327986
Epoch 15 | Batch 10/100 | Loss 0.366115
InnerLR 0.767138
FineTuningLR 0.329142
Epoch 15 | Batch 20/100 | Loss 0.384414
InnerLR 0.768595
FineTuningLR 0.330553
Epoch 15 | Batch 30/100 | Loss 0.368550
InnerLR 0.769795
FineTuningLR 0.331721
Epoch 15 | Batch 40/100 | Loss 0.351493
InnerLR 0.771916
FineTuningLR 0.333731
Epoch 15 | Batch 50/100 | Loss 0.368699
InnerLR 0.773118
FineTuningLR 0.335224
Epoch 15 | Batch 60/100 | Loss 0.386601
InnerLR 0.775247
FineTuningLR 0.337415
Epoch 15 | Batch 70/100 | Loss 0.380614
InnerLR 0.776594
FineTuningLR 0.338772
Epoch 15 | Batch 80/100 | Loss 0.380537
InnerLR 0.777965
FineTuningLR 0.340153
Epoch 15 | Batch 90/100 | Loss 0.375164
InnerLR 0.778847
FineTuningLR 0.340611
100 Accuracy = 74.91% +- 2.64%
Epoch 15: 74.91
Epoch 16 | Batch 0/100 | Loss 0.414591
InnerLR 0.780590
FineTuningLR 0.341075
Epoch 16 | Batch 10/100 | Loss 0.311327
InnerLR 0.781859
FineTuningLR 0.341549
Epoch 16 | Batch 20/100 | Loss 0.329713
InnerLR 0.783726
FineTuningLR 0.342679
Epoch 16 | Batch 30/100 | Loss 0.340007
InnerLR 0.784756
FineTuningLR 0.343792
Epoch 16 | Batch 40/100 | Loss 0.320366
InnerLR 0.786391
FineTuningLR 0.345692
Epoch 16 | Batch 50/100 | Loss 0.315687
InnerLR 0.787440
FineTuningLR 0.346991
Epoch 16 | Batch 60/100 | Loss 0.313089
InnerLR 0.788498
FineTuningLR 0.348858
Epoch 16 | Batch 70/100 | Loss 0.315269
InnerLR 0.789291
FineTuningLR 0.349851
Epoch 16 | Batch 80/100 | Loss 0.325972
InnerLR 0.790491
FineTuningLR 0.351778
Epoch 16 | Batch 90/100 | Loss 0.327256
InnerLR 0.790993
FineTuningLR 0.353086
100 Accuracy = 75.33% +- 2.51%
Epoch 16: 75.33
Epoch 17 | Batch 0/100 | Loss 0.299669
InnerLR 0.791797
FineTuningLR 0.354675
Epoch 17 | Batch 10/100 | Loss 0.351993
InnerLR 0.792425
FineTuningLR 0.355563
Epoch 17 | Batch 20/100 | Loss 0.355094
InnerLR 0.793671
FineTuningLR 0.356355
Epoch 17 | Batch 30/100 | Loss 0.346195
InnerLR 0.794490
FineTuningLR 0.356571
Epoch 17 | Batch 40/100 | Loss 0.339646
InnerLR 0.795431
FineTuningLR 0.357185
Epoch 17 | Batch 50/100 | Loss 0.350442
InnerLR 0.796149
FineTuningLR 0.357731
Epoch 17 | Batch 60/100 | Loss 0.362083
InnerLR 0.797052
FineTuningLR 0.358308
Epoch 17 | Batch 70/100 | Loss 0.362941
InnerLR 0.797655
FineTuningLR 0.358239
Epoch 17 | Batch 80/100 | Loss 0.360195
InnerLR 0.798328
FineTuningLR 0.358759
Epoch 17 | Batch 90/100 | Loss 0.372731
InnerLR 0.798605
FineTuningLR 0.359569
100 Accuracy = 77.64% +- 2.74%
Epoch 17: 77.64
best model! save...
Epoch 18 | Batch 0/100 | Loss 0.307712
InnerLR 0.799725
FineTuningLR 0.360159
Epoch 18 | Batch 10/100 | Loss 0.390982
InnerLR 0.800743
FineTuningLR 0.360579
Epoch 18 | Batch 20/100 | Loss 0.366145
InnerLR 0.801993
FineTuningLR 0.361257
Epoch 18 | Batch 30/100 | Loss 0.338007
InnerLR 0.802838
FineTuningLR 0.361900
Epoch 18 | Batch 40/100 | Loss 0.323671
InnerLR 0.804278
FineTuningLR 0.362920
Epoch 18 | Batch 50/100 | Loss 0.337468
InnerLR 0.805091
FineTuningLR 0.363721
Epoch 18 | Batch 60/100 | Loss 0.327065
InnerLR 0.806671
FineTuningLR 0.364488
Epoch 18 | Batch 70/100 | Loss 0.334162
InnerLR 0.807689
FineTuningLR 0.365271
Epoch 18 | Batch 80/100 | Loss 0.341286
InnerLR 0.808774
FineTuningLR 0.366839
Epoch 18 | Batch 90/100 | Loss 0.341148
InnerLR 0.809877
FineTuningLR 0.368018
100 Accuracy = 78.29% +- 2.25%
Epoch 18: 78.29
best model! save...
Epoch 19 | Batch 0/100 | Loss 0.251635
InnerLR 0.811901
FineTuningLR 0.369114
Epoch 19 | Batch 10/100 | Loss 0.324312
InnerLR 0.813386
FineTuningLR 0.369492
Epoch 19 | Batch 20/100 | Loss 0.325661
InnerLR 0.815798
FineTuningLR 0.370247
Epoch 19 | Batch 30/100 | Loss 0.331024
InnerLR 0.817227
FineTuningLR 0.371134
Epoch 19 | Batch 40/100 | Loss 0.382078
InnerLR 0.818511
FineTuningLR 0.372361
Epoch 19 | Batch 50/100 | Loss 0.366786
InnerLR 0.819340
FineTuningLR 0.373003
Epoch 19 | Batch 60/100 | Loss 0.365722
InnerLR 0.820344
FineTuningLR 0.374028
Epoch 19 | Batch 70/100 | Loss 0.372934
InnerLR 0.820371
FineTuningLR 0.374644
Epoch 19 | Batch 80/100 | Loss 0.368881
InnerLR 0.820292
FineTuningLR 0.375134
Epoch 19 | Batch 90/100 | Loss 0.367317
InnerLR 0.820273
FineTuningLR 0.375510
100 Accuracy = 77.65% +- 2.38%
Epoch 19: 77.65
Epoch 20 | Batch 0/100 | Loss 0.137796
InnerLR 0.820520
FineTuningLR 0.375507
Epoch 20 | Batch 10/100 | Loss 0.265152
InnerLR 0.820966
FineTuningLR 0.375572
Epoch 20 | Batch 20/100 | Loss 0.321222
InnerLR 0.821338
FineTuningLR 0.376230
Epoch 20 | Batch 30/100 | Loss 0.344058
InnerLR 0.822028
FineTuningLR 0.376313
Epoch 20 | Batch 40/100 | Loss 0.332734
InnerLR 0.823041
FineTuningLR 0.376185
Epoch 20 | Batch 50/100 | Loss 0.341751
InnerLR 0.824021
FineTuningLR 0.376118
Epoch 20 | Batch 60/100 | Loss 0.336131
InnerLR 0.825383
FineTuningLR 0.376314
Epoch 20 | Batch 70/100 | Loss 0.335056
InnerLR 0.826171
FineTuningLR 0.376450
Epoch 20 | Batch 80/100 | Loss 0.329275
InnerLR 0.827611
FineTuningLR 0.376632
Epoch 20 | Batch 90/100 | Loss 0.328036
InnerLR 0.828721
FineTuningLR 0.376779
100 Accuracy = 74.51% +- 2.68%
Epoch 20: 74.51
Epoch 21 | Batch 0/100 | Loss 0.305799
InnerLR 0.829542
FineTuningLR 0.376676
Epoch 21 | Batch 10/100 | Loss 0.430084
InnerLR 0.829593
FineTuningLR 0.376108
Epoch 21 | Batch 20/100 | Loss 0.378769
InnerLR 0.829673
FineTuningLR 0.375975
Epoch 21 | Batch 30/100 | Loss 0.327718
InnerLR 0.829868
FineTuningLR 0.376292
Epoch 21 | Batch 40/100 | Loss 0.337886
InnerLR 0.829990
FineTuningLR 0.376717
Epoch 21 | Batch 50/100 | Loss 0.343087
InnerLR 0.830383
FineTuningLR 0.377047
Epoch 21 | Batch 60/100 | Loss 0.346143
InnerLR 0.831102
FineTuningLR 0.378169
Epoch 21 | Batch 70/100 | Loss 0.337238
InnerLR 0.831629
FineTuningLR 0.379312
Epoch 21 | Batch 80/100 | Loss 0.339336
InnerLR 0.832799
FineTuningLR 0.381157
Epoch 21 | Batch 90/100 | Loss 0.343011
InnerLR 0.833737
FineTuningLR 0.382201
100 Accuracy = 74.80% +- 2.18%
Epoch 21: 74.80
Epoch 22 | Batch 0/100 | Loss 0.293842
InnerLR 0.835024
FineTuningLR 0.383917
Epoch 22 | Batch 10/100 | Loss 0.356340
InnerLR 0.835938
FineTuningLR 0.384806
Epoch 22 | Batch 20/100 | Loss 0.271555
InnerLR 0.837254
FineTuningLR 0.385868
Epoch 22 | Batch 30/100 | Loss 0.272435
InnerLR 0.838080
FineTuningLR 0.386383
Epoch 22 | Batch 40/100 | Loss 0.272561
InnerLR 0.839358
FineTuningLR 0.386784
Epoch 22 | Batch 50/100 | Loss 0.277277
InnerLR 0.840208
FineTuningLR 0.387389
Epoch 22 | Batch 60/100 | Loss 0.278487
InnerLR 0.841566
FineTuningLR 0.388724
Epoch 22 | Batch 70/100 | Loss 0.292927
InnerLR 0.842342
FineTuningLR 0.389686
Epoch 22 | Batch 80/100 | Loss 0.302178
InnerLR 0.842887
FineTuningLR 0.390558
Epoch 22 | Batch 90/100 | Loss 0.302206
InnerLR 0.842988
FineTuningLR 0.391055
100 Accuracy = 76.72% +- 2.39%
Epoch 22: 76.72
Epoch 23 | Batch 0/100 | Loss 0.333748
InnerLR 0.843208
FineTuningLR 0.391898
Epoch 23 | Batch 10/100 | Loss 0.274424
InnerLR 0.843587
FineTuningLR 0.392287
Epoch 23 | Batch 20/100 | Loss 0.260898
InnerLR 0.844690
FineTuningLR 0.392654
Epoch 23 | Batch 30/100 | Loss 0.316360
InnerLR 0.845091
FineTuningLR 0.392717
Epoch 23 | Batch 40/100 | Loss 0.308057
InnerLR 0.845918
FineTuningLR 0.392449
Epoch 23 | Batch 50/100 | Loss 0.303966
InnerLR 0.846533
FineTuningLR 0.392523
Epoch 23 | Batch 60/100 | Loss 0.316838
InnerLR 0.847165
FineTuningLR 0.392770
Epoch 23 | Batch 70/100 | Loss 0.318519
InnerLR 0.847456
FineTuningLR 0.392956
Epoch 23 | Batch 80/100 | Loss 0.333893
InnerLR 0.847897
FineTuningLR 0.393183
Epoch 23 | Batch 90/100 | Loss 0.341584
InnerLR 0.847768
FineTuningLR 0.393237
100 Accuracy = 77.40% +- 2.51%
Epoch 23: 77.40
Epoch 24 | Batch 0/100 | Loss 0.770605
InnerLR 0.847210
FineTuningLR 0.392705
Epoch 24 | Batch 10/100 | Loss 0.363662
InnerLR 0.847191
FineTuningLR 0.391992
Epoch 24 | Batch 20/100 | Loss 0.327154
InnerLR 0.847684
FineTuningLR 0.390984
Epoch 24 | Batch 30/100 | Loss 0.312696
InnerLR 0.848330
FineTuningLR 0.390796
Epoch 24 | Batch 40/100 | Loss 0.305695
InnerLR 0.849370
FineTuningLR 0.391285
Epoch 24 | Batch 50/100 | Loss 0.288195
InnerLR 0.850440
FineTuningLR 0.391778
Epoch 24 | Batch 60/100 | Loss 0.297475
InnerLR 0.851684
FineTuningLR 0.392024
Epoch 24 | Batch 70/100 | Loss 0.297601
InnerLR 0.852483
FineTuningLR 0.391808
Epoch 24 | Batch 80/100 | Loss 0.303157
InnerLR 0.853863
FineTuningLR 0.391986
Epoch 24 | Batch 90/100 | Loss 0.310795
InnerLR 0.854740
FineTuningLR 0.392419
100 Accuracy = 74.79% +- 2.73%
Epoch 24: 74.79
Epoch 25 | Batch 0/100 | Loss 0.640502
InnerLR 0.856366
FineTuningLR 0.392382
Epoch 25 | Batch 10/100 | Loss 0.376590
InnerLR 0.857195
FineTuningLR 0.392466
Epoch 25 | Batch 20/100 | Loss 0.328600
InnerLR 0.858787
FineTuningLR 0.393163
Epoch 25 | Batch 30/100 | Loss 0.329161
InnerLR 0.859702
FineTuningLR 0.393394
Epoch 25 | Batch 40/100 | Loss 0.360625
InnerLR 0.860155
FineTuningLR 0.393892
Epoch 25 | Batch 50/100 | Loss 0.346151
InnerLR 0.860538
FineTuningLR 0.394391
Epoch 25 | Batch 60/100 | Loss 0.337724
InnerLR 0.860980
FineTuningLR 0.394943
Epoch 25 | Batch 70/100 | Loss 0.328339
InnerLR 0.861282
FineTuningLR 0.395227
Epoch 25 | Batch 80/100 | Loss 0.323605
InnerLR 0.861226
FineTuningLR 0.395334
Epoch 25 | Batch 90/100 | Loss 0.316582
InnerLR 0.861443
FineTuningLR 0.395798
100 Accuracy = 78.29% +- 2.61%
Epoch 25: 78.29
Epoch 26 | Batch 0/100 | Loss 0.400893
InnerLR 0.861481
FineTuningLR 0.396694
Epoch 26 | Batch 10/100 | Loss 0.456721
InnerLR 0.861492
FineTuningLR 0.397372
Epoch 26 | Batch 20/100 | Loss 0.370514
InnerLR 0.860627
FineTuningLR 0.398262
Epoch 26 | Batch 30/100 | Loss 0.368713
InnerLR 0.860461
FineTuningLR 0.398627
Epoch 26 | Batch 40/100 | Loss 0.355930
InnerLR 0.860642
FineTuningLR 0.398932
Epoch 26 | Batch 50/100 | Loss 0.356230
InnerLR 0.860889
FineTuningLR 0.398985
Epoch 26 | Batch 60/100 | Loss 0.341897
InnerLR 0.861563
FineTuningLR 0.398911
Epoch 26 | Batch 70/100 | Loss 0.351248
InnerLR 0.862032
FineTuningLR 0.398978
Epoch 26 | Batch 80/100 | Loss 0.345960
InnerLR 0.862341
FineTuningLR 0.398971
Epoch 26 | Batch 90/100 | Loss 0.345706
InnerLR 0.862630
FineTuningLR 0.399485
100 Accuracy = 76.28% +- 2.52%
Epoch 26: 76.28
Epoch 27 | Batch 0/100 | Loss 0.364610
InnerLR 0.863755
FineTuningLR 0.400002
Epoch 27 | Batch 10/100 | Loss 0.283066
InnerLR 0.864560
FineTuningLR 0.400463
Epoch 27 | Batch 20/100 | Loss 0.288804
InnerLR 0.865205
FineTuningLR 0.401027
Epoch 27 | Batch 30/100 | Loss 0.269940
InnerLR 0.865539
FineTuningLR 0.401773
Epoch 27 | Batch 40/100 | Loss 0.277215
InnerLR 0.866621
FineTuningLR 0.402550
Epoch 27 | Batch 50/100 | Loss 0.299919
InnerLR 0.867641
FineTuningLR 0.403101
Epoch 27 | Batch 60/100 | Loss 0.312647
InnerLR 0.869206
FineTuningLR 0.403682
Epoch 27 | Batch 70/100 | Loss 0.320148
InnerLR 0.870220
FineTuningLR 0.404020
Epoch 27 | Batch 80/100 | Loss 0.317055
InnerLR 0.871830
FineTuningLR 0.404182
Epoch 27 | Batch 90/100 | Loss 0.322654
InnerLR 0.872810
FineTuningLR 0.403744
100 Accuracy = 74.53% +- 2.72%
Epoch 27: 74.53
Epoch 28 | Batch 0/100 | Loss 0.450499
InnerLR 0.874396
FineTuningLR 0.403089
Epoch 28 | Batch 10/100 | Loss 0.284642
InnerLR 0.874892
FineTuningLR 0.403105
Epoch 28 | Batch 20/100 | Loss 0.360375
InnerLR 0.875272
FineTuningLR 0.402865
Epoch 28 | Batch 30/100 | Loss 0.347614
InnerLR 0.875714
FineTuningLR 0.402880
Epoch 28 | Batch 40/100 | Loss 0.339341
InnerLR 0.876888
FineTuningLR 0.402858
Epoch 28 | Batch 50/100 | Loss 0.326653
InnerLR 0.878065
FineTuningLR 0.402918
Epoch 28 | Batch 60/100 | Loss 0.313706
InnerLR 0.880191
FineTuningLR 0.403510
Epoch 28 | Batch 70/100 | Loss 0.325553
InnerLR 0.881512
FineTuningLR 0.404150
Epoch 28 | Batch 80/100 | Loss 0.321990
InnerLR 0.883252
FineTuningLR 0.405306
Epoch 28 | Batch 90/100 | Loss 0.318447
InnerLR 0.883951
FineTuningLR 0.405419
100 Accuracy = 75.99% +- 2.35%
Epoch 28: 75.99
Epoch 29 | Batch 0/100 | Loss 0.464695
InnerLR 0.884330
FineTuningLR 0.405522
Epoch 29 | Batch 10/100 | Loss 0.327809
InnerLR 0.884684
FineTuningLR 0.405377
Epoch 29 | Batch 20/100 | Loss 0.283216
InnerLR 0.885290
FineTuningLR 0.405301
Epoch 29 | Batch 30/100 | Loss 0.316476
InnerLR 0.886003
FineTuningLR 0.405105
Epoch 29 | Batch 40/100 | Loss 0.316927
InnerLR 0.886886
FineTuningLR 0.404428
Epoch 29 | Batch 50/100 | Loss 0.314880
InnerLR 0.887705
FineTuningLR 0.404096
Epoch 29 | Batch 60/100 | Loss 0.306770
InnerLR 0.889351
FineTuningLR 0.404181
Epoch 29 | Batch 70/100 | Loss 0.303705
InnerLR 0.890614
FineTuningLR 0.404241
Epoch 29 | Batch 80/100 | Loss 0.300860
InnerLR 0.892473
FineTuningLR 0.403745
Epoch 29 | Batch 90/100 | Loss 0.312510
InnerLR 0.893903
FineTuningLR 0.403498
100 Accuracy = 76.87% +- 2.27%
Epoch 29: 76.87
Epoch 30 | Batch 0/100 | Loss 0.330706
InnerLR 0.895847
FineTuningLR 0.403232
Epoch 30 | Batch 10/100 | Loss 0.555421
InnerLR 0.896411
FineTuningLR 0.402954
Epoch 30 | Batch 20/100 | Loss 0.489769
InnerLR 0.897189
FineTuningLR 0.402735
Epoch 30 | Batch 30/100 | Loss 0.435321
InnerLR 0.897570
FineTuningLR 0.402935
Epoch 30 | Batch 40/100 | Loss 0.390008
InnerLR 0.898325
FineTuningLR 0.403747
Epoch 30 | Batch 50/100 | Loss 0.365527
InnerLR 0.899041
FineTuningLR 0.404169
Epoch 30 | Batch 60/100 | Loss 0.361102
InnerLR 0.899858
FineTuningLR 0.404775
Epoch 30 | Batch 70/100 | Loss 0.373274
InnerLR 0.900511
FineTuningLR 0.405288
Epoch 30 | Batch 80/100 | Loss 0.359422
InnerLR 0.901538
FineTuningLR 0.406243
Epoch 30 | Batch 90/100 | Loss 0.363376
InnerLR 0.902445
FineTuningLR 0.407152
100 Accuracy = 77.87% +- 2.47%
Epoch 30: 77.87
Epoch 31 | Batch 0/100 | Loss 1.040388
InnerLR 0.903868
FineTuningLR 0.408595
Epoch 31 | Batch 10/100 | Loss 0.472710
InnerLR 0.904331
FineTuningLR 0.408944
Epoch 31 | Batch 20/100 | Loss 0.399799
InnerLR 0.904797
FineTuningLR 0.409191
Epoch 31 | Batch 30/100 | Loss 0.358527
InnerLR 0.905068
FineTuningLR 0.409326
Epoch 31 | Batch 40/100 | Loss 0.351137
InnerLR 0.905776
FineTuningLR 0.409624
Epoch 31 | Batch 50/100 | Loss 0.321059
InnerLR 0.906533
FineTuningLR 0.409547
Epoch 31 | Batch 60/100 | Loss 0.319003
InnerLR 0.907593
FineTuningLR 0.409934
Epoch 31 | Batch 70/100 | Loss 0.319819
InnerLR 0.908176
FineTuningLR 0.410110
Epoch 31 | Batch 80/100 | Loss 0.319815
InnerLR 0.908573
FineTuningLR 0.409957
Epoch 31 | Batch 90/100 | Loss 0.329924
InnerLR 0.908381
FineTuningLR 0.409567
100 Accuracy = 75.08% +- 2.35%
Epoch 31: 75.08
Epoch 32 | Batch 0/100 | Loss 0.233179
InnerLR 0.908040
FineTuningLR 0.409084
Epoch 32 | Batch 10/100 | Loss 0.310947
InnerLR 0.908022
FineTuningLR 0.409307
Epoch 32 | Batch 20/100 | Loss 0.293454
InnerLR 0.908309
FineTuningLR 0.409879
Epoch 32 | Batch 30/100 | Loss 0.267601
InnerLR 0.908820
FineTuningLR 0.410257
Epoch 32 | Batch 40/100 | Loss 0.265330
InnerLR 0.909870
FineTuningLR 0.410296
Epoch 32 | Batch 50/100 | Loss 0.275548
InnerLR 0.910320
FineTuningLR 0.410169
Epoch 32 | Batch 60/100 | Loss 0.270235
InnerLR 0.911161
FineTuningLR 0.410475
Epoch 32 | Batch 70/100 | Loss 0.288282
InnerLR 0.911662
FineTuningLR 0.410435
Epoch 32 | Batch 80/100 | Loss 0.292289
InnerLR 0.912288
FineTuningLR 0.410238
Epoch 32 | Batch 90/100 | Loss 0.311708
InnerLR 0.912743
FineTuningLR 0.410039
100 Accuracy = 79.17% +- 2.21%
Epoch 32: 79.17
best model! save...
Epoch 33 | Batch 0/100 | Loss 0.108344
InnerLR 0.913120
FineTuningLR 0.409717
Epoch 33 | Batch 10/100 | Loss 0.284313
InnerLR 0.913339
FineTuningLR 0.409651
Epoch 33 | Batch 20/100 | Loss 0.281553
InnerLR 0.914211
FineTuningLR 0.410110
Epoch 33 | Batch 30/100 | Loss 0.297307
InnerLR 0.914685
FineTuningLR 0.410407
Epoch 33 | Batch 40/100 | Loss 0.320849
InnerLR 0.915618
FineTuningLR 0.410201
Epoch 33 | Batch 50/100 | Loss 0.306320
InnerLR 0.916220
FineTuningLR 0.409759
Epoch 33 | Batch 60/100 | Loss 0.325293
InnerLR 0.916648
FineTuningLR 0.408541
Epoch 33 | Batch 70/100 | Loss 0.313001
InnerLR 0.916869
FineTuningLR 0.408110
Epoch 33 | Batch 80/100 | Loss 0.309418
InnerLR 0.916857
FineTuningLR 0.408194
Epoch 33 | Batch 90/100 | Loss 0.305375
InnerLR 0.916720
FineTuningLR 0.408211
100 Accuracy = 76.71% +- 2.40%
Epoch 33: 76.71
Epoch 34 | Batch 0/100 | Loss 0.271521
InnerLR 0.916848
FineTuningLR 0.408613
Epoch 34 | Batch 10/100 | Loss 0.215972
InnerLR 0.917286
FineTuningLR 0.409116
Epoch 34 | Batch 20/100 | Loss 0.229936
InnerLR 0.918354
FineTuningLR 0.409583
Epoch 34 | Batch 30/100 | Loss 0.220985
InnerLR 0.919417
FineTuningLR 0.409748
Epoch 34 | Batch 40/100 | Loss 0.268545
InnerLR 0.920855
FineTuningLR 0.409183
Epoch 34 | Batch 50/100 | Loss 0.262392
InnerLR 0.921812
FineTuningLR 0.408788
Epoch 34 | Batch 60/100 | Loss 0.277350
InnerLR 0.923180
FineTuningLR 0.408623
Epoch 34 | Batch 70/100 | Loss 0.282730
InnerLR 0.924211
FineTuningLR 0.408779
Epoch 34 | Batch 80/100 | Loss 0.284222
InnerLR 0.925509
FineTuningLR 0.408572
Epoch 34 | Batch 90/100 | Loss 0.290775
InnerLR 0.926482
FineTuningLR 0.408289
100 Accuracy = 76.96% +- 2.60%
Epoch 34: 76.96
Epoch 35 | Batch 0/100 | Loss 0.134586
InnerLR 0.927957
FineTuningLR 0.407825
Epoch 35 | Batch 10/100 | Loss 0.201864
InnerLR 0.928944
FineTuningLR 0.407664
Epoch 35 | Batch 20/100 | Loss 0.254335
InnerLR 0.930821
FineTuningLR 0.407565
Epoch 35 | Batch 30/100 | Loss 0.271281
InnerLR 0.932215
FineTuningLR 0.407496
Epoch 35 | Batch 40/100 | Loss 0.268699
InnerLR 0.933838
FineTuningLR 0.407367
Epoch 35 | Batch 50/100 | Loss 0.278678
InnerLR 0.935032
FineTuningLR 0.407062
Epoch 35 | Batch 60/100 | Loss 0.276796
InnerLR 0.936908
FineTuningLR 0.406636
Epoch 35 | Batch 70/100 | Loss 0.280077
InnerLR 0.938143
FineTuningLR 0.406206
Epoch 35 | Batch 80/100 | Loss 0.276159
InnerLR 0.939636
FineTuningLR 0.405651
Epoch 35 | Batch 90/100 | Loss 0.282023
InnerLR 0.940365
FineTuningLR 0.405300
100 Accuracy = 76.68% +- 2.62%
Epoch 35: 76.68
Epoch 36 | Batch 0/100 | Loss 0.199807
InnerLR 0.941132
FineTuningLR 0.404978
Epoch 36 | Batch 10/100 | Loss 0.226714
InnerLR 0.941670
FineTuningLR 0.405133
Epoch 36 | Batch 20/100 | Loss 0.256179
InnerLR 0.942543
FineTuningLR 0.405950
Epoch 36 | Batch 30/100 | Loss 0.309667
InnerLR 0.942981
FineTuningLR 0.406707
Epoch 36 | Batch 40/100 | Loss 0.290906
InnerLR 0.943666
FineTuningLR 0.408057
Epoch 36 | Batch 50/100 | Loss 0.304046
InnerLR 0.944361
FineTuningLR 0.408736
Epoch 36 | Batch 60/100 | Loss 0.296498
InnerLR 0.944745
FineTuningLR 0.410006
Epoch 36 | Batch 70/100 | Loss 0.317823
InnerLR 0.945007
FineTuningLR 0.410892
Epoch 36 | Batch 80/100 | Loss 0.307440
InnerLR 0.945797
FineTuningLR 0.411802
Epoch 36 | Batch 90/100 | Loss 0.303566
InnerLR 0.946336
FineTuningLR 0.412560
100 Accuracy = 76.75% +- 2.61%
Epoch 36: 76.75
Epoch 37 | Batch 0/100 | Loss 0.989767
InnerLR 0.947536
FineTuningLR 0.413436
Epoch 37 | Batch 10/100 | Loss 0.316646
InnerLR 0.948539
FineTuningLR 0.413691
Epoch 37 | Batch 20/100 | Loss 0.323975
InnerLR 0.950462
FineTuningLR 0.413902
Epoch 37 | Batch 30/100 | Loss 0.303186
InnerLR 0.951915
FineTuningLR 0.414057
Epoch 37 | Batch 40/100 | Loss 0.292011
InnerLR 0.953593
FineTuningLR 0.414764
Epoch 37 | Batch 50/100 | Loss 0.283007
InnerLR 0.954571
FineTuningLR 0.415416
Epoch 37 | Batch 60/100 | Loss 0.284169
InnerLR 0.955720
FineTuningLR 0.415574
Epoch 37 | Batch 70/100 | Loss 0.280451
InnerLR 0.956674
FineTuningLR 0.415517
Epoch 37 | Batch 80/100 | Loss 0.293304
InnerLR 0.957795
FineTuningLR 0.416129
Epoch 37 | Batch 90/100 | Loss 0.285930
InnerLR 0.958287
FineTuningLR 0.416894
100 Accuracy = 77.21% +- 2.43%
Epoch 37: 77.21
Epoch 38 | Batch 0/100 | Loss 0.183996
InnerLR 0.958803
FineTuningLR 0.417835
Epoch 38 | Batch 10/100 | Loss 0.231907
InnerLR 0.959257
FineTuningLR 0.418230
Epoch 38 | Batch 20/100 | Loss 0.241746
InnerLR 0.959864
FineTuningLR 0.418295
Epoch 38 | Batch 30/100 | Loss 0.228948
InnerLR 0.959897
FineTuningLR 0.418289
Epoch 38 | Batch 40/100 | Loss 0.230688
InnerLR 0.959580
FineTuningLR 0.418653
Epoch 38 | Batch 50/100 | Loss 0.229997
InnerLR 0.959432
FineTuningLR 0.418627
Epoch 38 | Batch 60/100 | Loss 0.229898
InnerLR 0.959243
FineTuningLR 0.418292
Epoch 38 | Batch 70/100 | Loss 0.227097
InnerLR 0.959015
FineTuningLR 0.418500
Epoch 38 | Batch 80/100 | Loss 0.236448
InnerLR 0.958564
FineTuningLR 0.419040
Epoch 38 | Batch 90/100 | Loss 0.243648
InnerLR 0.958235
FineTuningLR 0.419459
100 Accuracy = 76.65% +- 2.43%
Epoch 38: 76.65
Epoch 39 | Batch 0/100 | Loss 0.240406
InnerLR 0.957977
FineTuningLR 0.419601
Epoch 39 | Batch 10/100 | Loss 0.217221
InnerLR 0.958091
FineTuningLR 0.419953
Epoch 39 | Batch 20/100 | Loss 0.231218
InnerLR 0.958298
FineTuningLR 0.420811
Epoch 39 | Batch 30/100 | Loss 0.270605
InnerLR 0.958494
FineTuningLR 0.420974
Epoch 39 | Batch 40/100 | Loss 0.260568
InnerLR 0.959210
FineTuningLR 0.421905
Epoch 39 | Batch 50/100 | Loss 0.257436
InnerLR 0.959212
FineTuningLR 0.422525
Epoch 39 | Batch 60/100 | Loss 0.253274
InnerLR 0.958918
FineTuningLR 0.423174
Epoch 39 | Batch 70/100 | Loss 0.255838
InnerLR 0.958834
FineTuningLR 0.423301
Epoch 39 | Batch 80/100 | Loss 0.243457
InnerLR 0.959019
FineTuningLR 0.423965
Epoch 39 | Batch 90/100 | Loss 0.249853
InnerLR 0.959160
FineTuningLR 0.424579
100 Accuracy = 76.63% +- 2.22%
Epoch 39: 76.63
Epoch 40 | Batch 0/100 | Loss 0.132154
InnerLR 0.960025
FineTuningLR 0.425134
Epoch 40 | Batch 10/100 | Loss 0.362900
InnerLR 0.960721
FineTuningLR 0.425403
Epoch 40 | Batch 20/100 | Loss 0.339446
InnerLR 0.961488
FineTuningLR 0.425359
Epoch 40 | Batch 30/100 | Loss 0.300180
InnerLR 0.962056
FineTuningLR 0.425295
Epoch 40 | Batch 40/100 | Loss 0.317320
InnerLR 0.962606
FineTuningLR 0.425251
Epoch 40 | Batch 50/100 | Loss 0.359696
InnerLR 0.962708
FineTuningLR 0.425338
Epoch 40 | Batch 60/100 | Loss 0.364589
InnerLR 0.963312
FineTuningLR 0.425157
Epoch 40 | Batch 70/100 | Loss 0.348580
InnerLR 0.963544
FineTuningLR 0.425499
Epoch 40 | Batch 80/100 | Loss 0.345605
InnerLR 0.963382
FineTuningLR 0.425789
Epoch 40 | Batch 90/100 | Loss 0.345850
InnerLR 0.963276
FineTuningLR 0.426126
100 Accuracy = 78.68% +- 2.34%
Epoch 40: 78.68
Epoch 41 | Batch 0/100 | Loss 0.724548
InnerLR 0.963456
FineTuningLR 0.426470
Epoch 41 | Batch 10/100 | Loss 0.276254
InnerLR 0.963744
FineTuningLR 0.427092
Epoch 41 | Batch 20/100 | Loss 0.269355
InnerLR 0.964062
FineTuningLR 0.428292
Epoch 41 | Batch 30/100 | Loss 0.277675
InnerLR 0.964570
FineTuningLR 0.429095
Epoch 41 | Batch 40/100 | Loss 0.284265
InnerLR 0.965111
FineTuningLR 0.430102
Epoch 41 | Batch 50/100 | Loss 0.270000
InnerLR 0.965921
FineTuningLR 0.430637
Epoch 41 | Batch 60/100 | Loss 0.257339
InnerLR 0.966998
FineTuningLR 0.431553
Epoch 41 | Batch 70/100 | Loss 0.272443
InnerLR 0.967230
FineTuningLR 0.432305
Epoch 41 | Batch 80/100 | Loss 0.299888
InnerLR 0.966984
FineTuningLR 0.432905
Epoch 41 | Batch 90/100 | Loss 0.298080
InnerLR 0.966940
FineTuningLR 0.433214
100 Accuracy = 76.36% +- 2.45%
Epoch 41: 76.36
Epoch 42 | Batch 0/100 | Loss 0.145425
InnerLR 0.966572
FineTuningLR 0.433889
Epoch 42 | Batch 10/100 | Loss 0.349592
InnerLR 0.966820
FineTuningLR 0.433991
Epoch 42 | Batch 20/100 | Loss 0.302883
InnerLR 0.967474
FineTuningLR 0.434427
Epoch 42 | Batch 30/100 | Loss 0.275220
InnerLR 0.968144
FineTuningLR 0.434690
Epoch 42 | Batch 40/100 | Loss 0.277538
InnerLR 0.969480
FineTuningLR 0.435255
Epoch 42 | Batch 50/100 | Loss 0.265512
InnerLR 0.970285
FineTuningLR 0.435712
Epoch 42 | Batch 60/100 | Loss 0.268855
InnerLR 0.970735
FineTuningLR 0.436729
Epoch 42 | Batch 70/100 | Loss 0.276866
InnerLR 0.970978
FineTuningLR 0.437170
Epoch 42 | Batch 80/100 | Loss 0.267499
InnerLR 0.971715
FineTuningLR 0.437613
Epoch 42 | Batch 90/100 | Loss 0.270430
InnerLR 0.972142
FineTuningLR 0.437839
100 Accuracy = 76.20% +- 2.55%
Epoch 42: 76.20
Epoch 43 | Batch 0/100 | Loss 0.436341
InnerLR 0.973123
FineTuningLR 0.438714
Epoch 43 | Batch 10/100 | Loss 0.256738
InnerLR 0.974081
FineTuningLR 0.439247
Epoch 43 | Batch 20/100 | Loss 0.301777
InnerLR 0.975880
FineTuningLR 0.439602
Epoch 43 | Batch 30/100 | Loss 0.302903
InnerLR 0.977082
FineTuningLR 0.440126
Epoch 43 | Batch 40/100 | Loss 0.294350
InnerLR 0.978342
FineTuningLR 0.441318
Epoch 43 | Batch 50/100 | Loss 0.289059
InnerLR 0.978983
FineTuningLR 0.442158
Epoch 43 | Batch 60/100 | Loss 0.279099
InnerLR 0.979980
FineTuningLR 0.443025
Epoch 43 | Batch 70/100 | Loss 0.273144
InnerLR 0.980422
FineTuningLR 0.443611
Epoch 43 | Batch 80/100 | Loss 0.289032
InnerLR 0.981112
FineTuningLR 0.444213
Epoch 43 | Batch 90/100 | Loss 0.278497
InnerLR 0.981546
FineTuningLR 0.444405
100 Accuracy = 75.35% +- 2.60%
Epoch 43: 75.35
Epoch 44 | Batch 0/100 | Loss 0.240685
InnerLR 0.982409
FineTuningLR 0.444917
Epoch 44 | Batch 10/100 | Loss 0.326643
InnerLR 0.983116
FineTuningLR 0.445397
Epoch 44 | Batch 20/100 | Loss 0.351269
InnerLR 0.984438
FineTuningLR 0.446185
Epoch 44 | Batch 30/100 | Loss 0.329857
InnerLR 0.985135
FineTuningLR 0.446170
Epoch 44 | Batch 40/100 | Loss 0.319790
InnerLR 0.986026
FineTuningLR 0.446123
Epoch 44 | Batch 50/100 | Loss 0.322979
InnerLR 0.986899
FineTuningLR 0.445755
Epoch 44 | Batch 60/100 | Loss 0.314824
InnerLR 0.987726
FineTuningLR 0.445591
Epoch 44 | Batch 70/100 | Loss 0.301872
InnerLR 0.987923
FineTuningLR 0.445323
Epoch 44 | Batch 80/100 | Loss 0.294888
InnerLR 0.988344
FineTuningLR 0.445329
Epoch 44 | Batch 90/100 | Loss 0.293788
InnerLR 0.988549
FineTuningLR 0.445124
100 Accuracy = 77.40% +- 2.42%
Epoch 44: 77.40
Epoch 45 | Batch 0/100 | Loss 0.169973
InnerLR 0.988938
FineTuningLR 0.445092
Epoch 45 | Batch 10/100 | Loss 0.166455
InnerLR 0.989277
FineTuningLR 0.445329
Epoch 45 | Batch 20/100 | Loss 0.266262
InnerLR 0.989978
FineTuningLR 0.445549
Epoch 45 | Batch 30/100 | Loss 0.300349
InnerLR 0.990687
FineTuningLR 0.445857
Epoch 45 | Batch 40/100 | Loss 0.309166
InnerLR 0.990975
FineTuningLR 0.445998
Epoch 45 | Batch 50/100 | Loss 0.305370
InnerLR 0.990888
FineTuningLR 0.446065
Epoch 45 | Batch 60/100 | Loss 0.312541
InnerLR 0.991120
FineTuningLR 0.446233
Epoch 45 | Batch 70/100 | Loss 0.303357
InnerLR 0.991511
FineTuningLR 0.445950
Epoch 45 | Batch 80/100 | Loss 0.295220
InnerLR 0.992730
FineTuningLR 0.445452
Epoch 45 | Batch 90/100 | Loss 0.293101
InnerLR 0.993904
FineTuningLR 0.445172
100 Accuracy = 79.05% +- 2.55%
Epoch 45: 79.05
Epoch 46 | Batch 0/100 | Loss 0.170947
InnerLR 0.995736
FineTuningLR 0.445120
Epoch 46 | Batch 10/100 | Loss 0.235999
InnerLR 0.997105
FineTuningLR 0.444969
Epoch 46 | Batch 20/100 | Loss 0.222691
InnerLR 0.999467
FineTuningLR 0.444205
Epoch 46 | Batch 30/100 | Loss 0.245395
InnerLR 1.001104
FineTuningLR 0.444077
Epoch 46 | Batch 40/100 | Loss 0.242909
InnerLR 1.002908
FineTuningLR 0.444477
Epoch 46 | Batch 50/100 | Loss 0.269304
InnerLR 1.004088
FineTuningLR 0.444556
Epoch 46 | Batch 60/100 | Loss 0.282630
InnerLR 1.005939
FineTuningLR 0.444196
Epoch 46 | Batch 70/100 | Loss 0.284580
InnerLR 1.007330
FineTuningLR 0.443746
Epoch 46 | Batch 80/100 | Loss 0.283308
InnerLR 1.008786
FineTuningLR 0.443344
Epoch 46 | Batch 90/100 | Loss 0.278347
InnerLR 1.009841
FineTuningLR 0.443078
100 Accuracy = 75.57% +- 2.38%
Epoch 46: 75.57
Epoch 47 | Batch 0/100 | Loss 0.206686
InnerLR 1.011314
FineTuningLR 0.443210
Epoch 47 | Batch 10/100 | Loss 0.360200
InnerLR 1.012479
FineTuningLR 0.442996
Epoch 47 | Batch 20/100 | Loss 0.355628
InnerLR 1.013635
FineTuningLR 0.442269
Epoch 47 | Batch 30/100 | Loss 0.331446
InnerLR 1.014571
FineTuningLR 0.441666
Epoch 47 | Batch 40/100 | Loss 0.336959
InnerLR 1.015962
FineTuningLR 0.441032
Epoch 47 | Batch 50/100 | Loss 0.317866
InnerLR 1.016790
FineTuningLR 0.440822
Epoch 47 | Batch 60/100 | Loss 0.306432
InnerLR 1.018428
FineTuningLR 0.440053
Epoch 47 | Batch 70/100 | Loss 0.303454
InnerLR 1.019012
FineTuningLR 0.439519
Epoch 47 | Batch 80/100 | Loss 0.302262
InnerLR 1.019088
FineTuningLR 0.439604
Epoch 47 | Batch 90/100 | Loss 0.291826
InnerLR 1.018902
FineTuningLR 0.439517
100 Accuracy = 76.72% +- 2.74%
Epoch 47: 76.72
Epoch 48 | Batch 0/100 | Loss 0.366926
InnerLR 1.018505
FineTuningLR 0.438744
Epoch 48 | Batch 10/100 | Loss 0.387145
InnerLR 1.018038
FineTuningLR 0.438309
Epoch 48 | Batch 20/100 | Loss 0.403388
InnerLR 1.016908
FineTuningLR 0.438022
Epoch 48 | Batch 30/100 | Loss 0.376002
InnerLR 1.016258
FineTuningLR 0.437982
Epoch 48 | Batch 40/100 | Loss 0.389601
InnerLR 1.015820
FineTuningLR 0.438493
Epoch 48 | Batch 50/100 | Loss 0.342046
InnerLR 1.015816
FineTuningLR 0.438910
Epoch 48 | Batch 60/100 | Loss 0.335713
InnerLR 1.015502
FineTuningLR 0.439947
Epoch 48 | Batch 70/100 | Loss 0.322069
InnerLR 1.015324
FineTuningLR 0.440231
Epoch 48 | Batch 80/100 | Loss 0.312692
InnerLR 1.015469
FineTuningLR 0.440716
Epoch 48 | Batch 90/100 | Loss 0.310559
InnerLR 1.015769
FineTuningLR 0.441298
100 Accuracy = 78.27% +- 2.22%
Epoch 48: 78.27
Epoch 49 | Batch 0/100 | Loss 0.203643
InnerLR 1.016118
FineTuningLR 0.441484
Epoch 49 | Batch 10/100 | Loss 0.198916
InnerLR 1.016721
FineTuningLR 0.441406
Epoch 49 | Batch 20/100 | Loss 0.264561
InnerLR 1.017550
FineTuningLR 0.441626
Epoch 49 | Batch 30/100 | Loss 0.300893
InnerLR 1.017773
FineTuningLR 0.442049
Epoch 49 | Batch 40/100 | Loss 0.311227
InnerLR 1.018350
FineTuningLR 0.442320
Epoch 49 | Batch 50/100 | Loss 0.309296
InnerLR 1.018187
FineTuningLR 0.442581
Epoch 49 | Batch 60/100 | Loss 0.302951
InnerLR 1.017980
FineTuningLR 0.442744
Epoch 49 | Batch 70/100 | Loss 0.296676
InnerLR 1.017530
FineTuningLR 0.442886
Epoch 49 | Batch 80/100 | Loss 0.294366
InnerLR 1.017016
FineTuningLR 0.442981
Epoch 49 | Batch 90/100 | Loss 0.283321
InnerLR 1.016798
FineTuningLR 0.443229
100 Accuracy = 77.61% +- 2.48%
Epoch 49: 77.61
Epoch 50 | Batch 0/100 | Loss 0.129177
InnerLR 1.016549
FineTuningLR 0.443660
Epoch 50 | Batch 10/100 | Loss 0.207827
InnerLR 1.016564
FineTuningLR 0.443937
Epoch 50 | Batch 20/100 | Loss 0.248645
InnerLR 1.016298
FineTuningLR 0.444923
Epoch 50 | Batch 30/100 | Loss 0.268343
InnerLR 1.016352
FineTuningLR 0.445452
Epoch 50 | Batch 40/100 | Loss 0.273259
InnerLR 1.016992
FineTuningLR 0.445744
Epoch 50 | Batch 50/100 | Loss 0.279033
InnerLR 1.017042
FineTuningLR 0.445911
Epoch 50 | Batch 60/100 | Loss 0.283126
InnerLR 1.016727
FineTuningLR 0.446053
Epoch 50 | Batch 70/100 | Loss 0.285575
InnerLR 1.016329
FineTuningLR 0.446354
Epoch 50 | Batch 80/100 | Loss 0.282056
InnerLR 1.015479
FineTuningLR 0.446348
Epoch 50 | Batch 90/100 | Loss 0.296759
InnerLR 1.014761
FineTuningLR 0.446672
100 Accuracy = 77.23% +- 2.55%
Epoch 50: 77.23
Epoch 51 | Batch 0/100 | Loss 0.125614
InnerLR 1.013865
FineTuningLR 0.446659
Epoch 51 | Batch 10/100 | Loss 0.347686
InnerLR 1.013589
FineTuningLR 0.446229
Epoch 51 | Batch 20/100 | Loss 0.315573
InnerLR 1.013295
FineTuningLR 0.446032
Epoch 51 | Batch 30/100 | Loss 0.291384
InnerLR 1.013366
FineTuningLR 0.445822
Epoch 51 | Batch 40/100 | Loss 0.318156
InnerLR 1.013194
FineTuningLR 0.445800
Epoch 51 | Batch 50/100 | Loss 0.299253
InnerLR 1.013467
FineTuningLR 0.445398
Epoch 51 | Batch 60/100 | Loss 0.295880
InnerLR 1.014031
FineTuningLR 0.445059
Epoch 51 | Batch 70/100 | Loss 0.299455
InnerLR 1.014350
FineTuningLR 0.444838
Epoch 51 | Batch 80/100 | Loss 0.297281
InnerLR 1.014911
FineTuningLR 0.444221
Epoch 51 | Batch 90/100 | Loss 0.300678
InnerLR 1.015162
FineTuningLR 0.444003
100 Accuracy = 75.47% +- 2.23%
Epoch 51: 75.47
Epoch 52 | Batch 0/100 | Loss 0.157291
InnerLR 1.015072
FineTuningLR 0.444213
Epoch 52 | Batch 10/100 | Loss 0.177818
InnerLR 1.015036
FineTuningLR 0.444472
Epoch 52 | Batch 20/100 | Loss 0.217262
InnerLR 1.014932
FineTuningLR 0.445149
Epoch 52 | Batch 30/100 | Loss 0.244693
InnerLR 1.014942
FineTuningLR 0.445474
Epoch 52 | Batch 40/100 | Loss 0.281961
InnerLR 1.014717
FineTuningLR 0.445713
Epoch 52 | Batch 50/100 | Loss 0.275402
InnerLR 1.014461
FineTuningLR 0.445684
Epoch 52 | Batch 60/100 | Loss 0.268373
InnerLR 1.014338
FineTuningLR 0.445899
Epoch 52 | Batch 70/100 | Loss 0.278507
InnerLR 1.014668
FineTuningLR 0.445852
Epoch 52 | Batch 80/100 | Loss 0.292894
InnerLR 1.014873
FineTuningLR 0.445205
Epoch 52 | Batch 90/100 | Loss 0.296002
InnerLR 1.015041
FineTuningLR 0.445216
100 Accuracy = 77.75% +- 2.13%
Epoch 52: 77.75
Epoch 53 | Batch 0/100 | Loss 0.257287
InnerLR 1.015266
FineTuningLR 0.444974
Epoch 53 | Batch 10/100 | Loss 0.240330
InnerLR 1.015477
FineTuningLR 0.444687
Epoch 53 | Batch 20/100 | Loss 0.237477
InnerLR 1.015678
FineTuningLR 0.444542
Epoch 53 | Batch 30/100 | Loss 0.291396
InnerLR 1.015991
FineTuningLR 0.444626
Epoch 53 | Batch 40/100 | Loss 0.285894
InnerLR 1.015932
FineTuningLR 0.444680
Epoch 53 | Batch 50/100 | Loss 0.321087
InnerLR 1.015936
FineTuningLR 0.444175
Epoch 53 | Batch 60/100 | Loss 0.317306
InnerLR 1.015566
FineTuningLR 0.443309
Epoch 53 | Batch 70/100 | Loss 0.313824
InnerLR 1.015146
FineTuningLR 0.442823
Epoch 53 | Batch 80/100 | Loss 0.326057
InnerLR 1.015091
FineTuningLR 0.442832
Epoch 53 | Batch 90/100 | Loss 0.317989
InnerLR 1.014958
FineTuningLR 0.443347
100 Accuracy = 78.24% +- 2.47%
Epoch 53: 78.24
Epoch 54 | Batch 0/100 | Loss 0.119198
InnerLR 1.014421
FineTuningLR 0.443570
Epoch 54 | Batch 10/100 | Loss 0.297260
InnerLR 1.014511
FineTuningLR 0.443393
Epoch 54 | Batch 20/100 | Loss 0.322540
InnerLR 1.014574
FineTuningLR 0.443205
Epoch 54 | Batch 30/100 | Loss 0.320380
InnerLR 1.014582
FineTuningLR 0.442567
Epoch 54 | Batch 40/100 | Loss 0.303080
InnerLR 1.014466
FineTuningLR 0.441742
Epoch 54 | Batch 50/100 | Loss 0.289820
InnerLR 1.014910
FineTuningLR 0.441148
Epoch 54 | Batch 60/100 | Loss 0.294177
InnerLR 1.015526
FineTuningLR 0.440241
Epoch 54 | Batch 70/100 | Loss 0.283595
InnerLR 1.015728
FineTuningLR 0.439786
Epoch 54 | Batch 80/100 | Loss 0.278523
InnerLR 1.015976
FineTuningLR 0.438383
Epoch 54 | Batch 90/100 | Loss 0.269748
InnerLR 1.016419
FineTuningLR 0.437081
100 Accuracy = 77.24% +- 2.27%
Epoch 54: 77.24
Epoch 55 | Batch 0/100 | Loss 0.480465
InnerLR 1.017016
FineTuningLR 0.435622
Epoch 55 | Batch 10/100 | Loss 0.295182
InnerLR 1.017462
FineTuningLR 0.434815
Epoch 55 | Batch 20/100 | Loss 0.242147
InnerLR 1.017967
FineTuningLR 0.433869
Epoch 55 | Batch 30/100 | Loss 0.243507
InnerLR 1.017711
FineTuningLR 0.433232
Epoch 55 | Batch 40/100 | Loss 0.250455
InnerLR 1.017666
FineTuningLR 0.432453
Epoch 55 | Batch 50/100 | Loss 0.267879
InnerLR 1.017726
FineTuningLR 0.432448
Epoch 55 | Batch 60/100 | Loss 0.273971
InnerLR 1.018109
FineTuningLR 0.432681
Epoch 55 | Batch 70/100 | Loss 0.268717
InnerLR 1.018332
FineTuningLR 0.432860
Epoch 55 | Batch 80/100 | Loss 0.267732
InnerLR 1.018295
FineTuningLR 0.433482
Epoch 55 | Batch 90/100 | Loss 0.267094
InnerLR 1.018522
FineTuningLR 0.433776
100 Accuracy = 78.52% +- 2.56%
Epoch 55: 78.52
Epoch 56 | Batch 0/100 | Loss 0.696276
InnerLR 1.019002
FineTuningLR 0.434672
Epoch 56 | Batch 10/100 | Loss 0.411605
InnerLR 1.019462
FineTuningLR 0.435116
Epoch 56 | Batch 20/100 | Loss 0.364090
InnerLR 1.020194
FineTuningLR 0.435400
Epoch 56 | Batch 30/100 | Loss 0.347150
InnerLR 1.020082
FineTuningLR 0.435418
Epoch 56 | Batch 40/100 | Loss 0.337075
InnerLR 1.020028
FineTuningLR 0.435079
Epoch 56 | Batch 50/100 | Loss 0.308778
InnerLR 1.019884
FineTuningLR 0.434876
Epoch 56 | Batch 60/100 | Loss 0.303892
InnerLR 1.020391
FineTuningLR 0.434873
Epoch 56 | Batch 70/100 | Loss 0.296120
InnerLR 1.020558
FineTuningLR 0.434806
Epoch 56 | Batch 80/100 | Loss 0.282803
InnerLR 1.020619
FineTuningLR 0.434830
Epoch 56 | Batch 90/100 | Loss 0.273426
InnerLR 1.020381
FineTuningLR 0.434890
100 Accuracy = 77.16% +- 2.55%
Epoch 56: 77.16
Epoch 57 | Batch 0/100 | Loss 0.357822
InnerLR 1.020040
FineTuningLR 0.434901
Epoch 57 | Batch 10/100 | Loss 0.233848
InnerLR 1.020173
FineTuningLR 0.434861
Epoch 57 | Batch 20/100 | Loss 0.240484
InnerLR 1.020848
FineTuningLR 0.434272
Epoch 57 | Batch 30/100 | Loss 0.228456
InnerLR 1.021263
FineTuningLR 0.433770
Epoch 57 | Batch 40/100 | Loss 0.210687
InnerLR 1.022103
FineTuningLR 0.433317
Epoch 57 | Batch 50/100 | Loss 0.266864
InnerLR 1.022357
FineTuningLR 0.433072
Epoch 57 | Batch 60/100 | Loss 0.267376
InnerLR 1.022472
FineTuningLR 0.432624
Epoch 57 | Batch 70/100 | Loss 0.267394
InnerLR 1.022113
FineTuningLR 0.431970
Epoch 57 | Batch 80/100 | Loss 0.260481
InnerLR 1.021735
FineTuningLR 0.431093
Epoch 57 | Batch 90/100 | Loss 0.267698
InnerLR 1.021826
FineTuningLR 0.430613
100 Accuracy = 75.65% +- 2.70%
Epoch 57: 75.65
Epoch 58 | Batch 0/100 | Loss 0.298354
InnerLR 1.022605
FineTuningLR 0.429767
Epoch 58 | Batch 10/100 | Loss 0.301065
InnerLR 1.023567
FineTuningLR 0.429449
Epoch 58 | Batch 20/100 | Loss 0.251476
InnerLR 1.024421
FineTuningLR 0.428757
Epoch 58 | Batch 30/100 | Loss 0.266243
InnerLR 1.024919
FineTuningLR 0.428459
Epoch 58 | Batch 40/100 | Loss 0.285080
InnerLR 1.026434
FineTuningLR 0.427739
Epoch 58 | Batch 50/100 | Loss 0.313880
InnerLR 1.027487
FineTuningLR 0.426964
Epoch 58 | Batch 60/100 | Loss 0.300868
InnerLR 1.028394
FineTuningLR 0.426344
Epoch 58 | Batch 70/100 | Loss 0.317892
InnerLR 1.028827
FineTuningLR 0.426447
Epoch 58 | Batch 80/100 | Loss 0.318333
InnerLR 1.029288
FineTuningLR 0.426593
Epoch 58 | Batch 90/100 | Loss 0.314186
InnerLR 1.029523
FineTuningLR 0.426627
100 Accuracy = 77.84% +- 2.30%
Epoch 58: 77.84
Epoch 59 | Batch 0/100 | Loss 0.102944
InnerLR 1.029458
FineTuningLR 0.426704
Epoch 59 | Batch 10/100 | Loss 0.268797
InnerLR 1.029312
FineTuningLR 0.426292
Epoch 59 | Batch 20/100 | Loss 0.252326
InnerLR 1.029026
FineTuningLR 0.425469
Epoch 59 | Batch 30/100 | Loss 0.264885
InnerLR 1.028427
FineTuningLR 0.425114
Epoch 59 | Batch 40/100 | Loss 0.255399
InnerLR 1.027757
FineTuningLR 0.424777
Epoch 59 | Batch 50/100 | Loss 0.264447
InnerLR 1.027232
FineTuningLR 0.425110
Epoch 59 | Batch 60/100 | Loss 0.251466
InnerLR 1.026503
FineTuningLR 0.425640
Epoch 59 | Batch 70/100 | Loss 0.255820
InnerLR 1.026355
FineTuningLR 0.425906
Epoch 59 | Batch 80/100 | Loss 0.246395
InnerLR 1.026394
FineTuningLR 0.425958
Epoch 59 | Batch 90/100 | Loss 0.250710
InnerLR 1.026754
FineTuningLR 0.425907
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 79.17% +- 2.39%
Epoch 59: 79.17
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/tabula_muris/leo_FCNet/20231212_122222
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 96.24% +- 0.41%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/tabula_muris/leo_FCNet/20231212_122222
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 76.13% +- 1.03%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/tabula_muris/leo_FCNet/20231212_122222
600 Accuracy = 68.78% +- 1.03%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/results.txt
+-------+-------------------+--------------------+
| split |      acc_mean     |      acc_std       |
+-------+-------------------+--------------------+
| train | 96.23777777777778 | 5.121897314351924  |
|  val  | 76.12888888888888 | 12.867230077858373 |
|  test | 68.77777777777779 | 12.89844473350217  |
+-------+-------------------+--------------------+
