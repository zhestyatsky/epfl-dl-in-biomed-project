/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/said.gurbuz/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/said.gurbuz/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 5
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 5
n_query: 15
method:
  name: matchingnet
  train_batch: null
  val_batch: null
  fast_weight: false
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 5
    _target_: methods.matchingnet.MatchingNet
model: FCNet
mode: train
exp:
  name: method_matchingnet_dataset_tabula_muris_n_shot_5
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.001
checkpoint:
  dir: checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_5/tabula_muris/matchingnet_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Model Architecture:
MatchingNet(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (loss_fn): NLLLoss()
  (FCE): FullyContextualEmbedding(
    (lstmcell): LSTMCell(128, 64)
    (softmax): Softmax(dim=None)
  )
  (G_encoder): LSTM(64, 64, batch_first=True, bidirectional=True)
  (relu): ReLU()
  (softmax): Softmax(dim=None)
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
Epoch 0 | Batch 0/100 | Loss 4.756605
Epoch 0 | Batch 10/100 | Loss 3.440328
Epoch 0 | Batch 20/100 | Loss 2.749484
Epoch 0 | Batch 30/100 | Loss 2.261953
Epoch 0 | Batch 40/100 | Loss 1.977753
Epoch 0 | Batch 50/100 | Loss 1.853744
Epoch 0 | Batch 60/100 | Loss 1.768150
Epoch 0 | Batch 70/100 | Loss 1.654050
Epoch 0 | Batch 80/100 | Loss 1.588619
Epoch 0 | Batch 90/100 | Loss 1.509156
100 Test Acc = 84.73% +- 2.07%
Epoch 0: 84.73
best model! save...
Epoch 1 | Batch 0/100 | Loss 0.922094
Epoch 1 | Batch 10/100 | Loss 0.713299
Epoch 1 | Batch 20/100 | Loss 0.796899
Epoch 1 | Batch 30/100 | Loss 0.811720
Epoch 1 | Batch 40/100 | Loss 0.793546
Epoch 1 | Batch 50/100 | Loss 0.778557
Epoch 1 | Batch 60/100 | Loss 0.748041
Epoch 1 | Batch 70/100 | Loss 0.735505
Epoch 1 | Batch 80/100 | Loss 0.763255
Epoch 1 | Batch 90/100 | Loss 0.711070
100 Test Acc = 83.65% +- 2.10%
Epoch 1: 83.65
Epoch 2 | Batch 0/100 | Loss 0.230649
Epoch 2 | Batch 10/100 | Loss 0.415976
Epoch 2 | Batch 20/100 | Loss 0.396523
Epoch 2 | Batch 30/100 | Loss 0.488166
Epoch 2 | Batch 40/100 | Loss 0.502525
Epoch 2 | Batch 50/100 | Loss 0.472910
Epoch 2 | Batch 60/100 | Loss 0.463836
Epoch 2 | Batch 70/100 | Loss 0.469931
Epoch 2 | Batch 80/100 | Loss 0.471979
Epoch 2 | Batch 90/100 | Loss 0.459268
100 Test Acc = 85.28% +- 1.98%
Epoch 2: 85.28
best model! save...
Epoch 3 | Batch 0/100 | Loss 0.334250
Epoch 3 | Batch 10/100 | Loss 0.407205
Epoch 3 | Batch 20/100 | Loss 0.383133
Epoch 3 | Batch 30/100 | Loss 0.388784
Epoch 3 | Batch 40/100 | Loss 0.351121
Epoch 3 | Batch 50/100 | Loss 0.355775
Epoch 3 | Batch 60/100 | Loss 0.377150
Epoch 3 | Batch 70/100 | Loss 0.358386
Epoch 3 | Batch 80/100 | Loss 0.360425
Epoch 3 | Batch 90/100 | Loss 0.353703
100 Test Acc = 85.45% +- 2.01%
Epoch 3: 85.45
best model! save...
Epoch 4 | Batch 0/100 | Loss 0.252809
Epoch 4 | Batch 10/100 | Loss 0.328219
Epoch 4 | Batch 20/100 | Loss 0.325927
Epoch 4 | Batch 30/100 | Loss 0.309317
Epoch 4 | Batch 40/100 | Loss 0.330495
Epoch 4 | Batch 50/100 | Loss 0.321204
Epoch 4 | Batch 60/100 | Loss 0.329807
Epoch 4 | Batch 70/100 | Loss 0.317869
Epoch 4 | Batch 80/100 | Loss 0.312352
Epoch 4 | Batch 90/100 | Loss 0.307480
100 Test Acc = 85.44% +- 1.98%
Epoch 4: 85.44
Epoch 5 | Batch 0/100 | Loss 0.694795
Epoch 5 | Batch 10/100 | Loss 0.354004
Epoch 5 | Batch 20/100 | Loss 0.298136
Epoch 5 | Batch 30/100 | Loss 0.303387
Epoch 5 | Batch 40/100 | Loss 0.281260
Epoch 5 | Batch 50/100 | Loss 0.291959
Epoch 5 | Batch 60/100 | Loss 0.301796
Epoch 5 | Batch 70/100 | Loss 0.294756
Epoch 5 | Batch 80/100 | Loss 0.284988
Epoch 5 | Batch 90/100 | Loss 0.291279
100 Test Acc = 84.49% +- 2.09%
Epoch 5: 84.49
Epoch 6 | Batch 0/100 | Loss 0.669369
Epoch 6 | Batch 10/100 | Loss 0.228600
Epoch 6 | Batch 20/100 | Loss 0.266116
Epoch 6 | Batch 30/100 | Loss 0.248492
Epoch 6 | Batch 40/100 | Loss 0.244747
Epoch 6 | Batch 50/100 | Loss 0.228299
Epoch 6 | Batch 60/100 | Loss 0.222002
Epoch 6 | Batch 70/100 | Loss 0.223578
Epoch 6 | Batch 80/100 | Loss 0.225215
Epoch 6 | Batch 90/100 | Loss 0.234724
100 Test Acc = 85.63% +- 2.01%
Epoch 6: 85.63
best model! save...
Epoch 7 | Batch 0/100 | Loss 0.325177
Epoch 7 | Batch 10/100 | Loss 0.251461
Epoch 7 | Batch 20/100 | Loss 0.265562
Epoch 7 | Batch 30/100 | Loss 0.266154
Epoch 7 | Batch 40/100 | Loss 0.257640
Epoch 7 | Batch 50/100 | Loss 0.247004
Epoch 7 | Batch 60/100 | Loss 0.230757
Epoch 7 | Batch 70/100 | Loss 0.216977
Epoch 7 | Batch 80/100 | Loss 0.206694
Epoch 7 | Batch 90/100 | Loss 0.204298
100 Test Acc = 85.81% +- 2.09%
Epoch 7: 85.81
best model! save...
Epoch 8 | Batch 0/100 | Loss 0.279250
Epoch 8 | Batch 10/100 | Loss 0.157643
Epoch 8 | Batch 20/100 | Loss 0.151881
Epoch 8 | Batch 30/100 | Loss 0.170507
Epoch 8 | Batch 40/100 | Loss 0.208692
Epoch 8 | Batch 50/100 | Loss 0.200422
Epoch 8 | Batch 60/100 | Loss 0.201140
Epoch 8 | Batch 70/100 | Loss 0.206402
Epoch 8 | Batch 80/100 | Loss 0.192006
Epoch 8 | Batch 90/100 | Loss 0.199118
100 Test Acc = 85.95% +- 1.95%
Epoch 8: 85.95
best model! save...
Epoch 9 | Batch 0/100 | Loss 0.544276
Epoch 9 | Batch 10/100 | Loss 0.216041
Epoch 9 | Batch 20/100 | Loss 0.207451
Epoch 9 | Batch 30/100 | Loss 0.202303
Epoch 9 | Batch 40/100 | Loss 0.218817
Epoch 9 | Batch 50/100 | Loss 0.223543
Epoch 9 | Batch 60/100 | Loss 0.209394
Epoch 9 | Batch 70/100 | Loss 0.209875
Epoch 9 | Batch 80/100 | Loss 0.209865
Epoch 9 | Batch 90/100 | Loss 0.215803
100 Test Acc = 85.07% +- 2.03%
Epoch 9: 85.07
Epoch 10 | Batch 0/100 | Loss 0.095729
Epoch 10 | Batch 10/100 | Loss 0.186292
Epoch 10 | Batch 20/100 | Loss 0.209213
Epoch 10 | Batch 30/100 | Loss 0.195003
Epoch 10 | Batch 40/100 | Loss 0.178375
Epoch 10 | Batch 50/100 | Loss 0.171218
Epoch 10 | Batch 60/100 | Loss 0.190900
Epoch 10 | Batch 70/100 | Loss 0.195920
Epoch 10 | Batch 80/100 | Loss 0.189436
Epoch 10 | Batch 90/100 | Loss 0.194908
100 Test Acc = 84.84% +- 2.13%
Epoch 10: 84.84
Epoch 11 | Batch 0/100 | Loss 0.481420
Epoch 11 | Batch 10/100 | Loss 0.174899
Epoch 11 | Batch 20/100 | Loss 0.198548
Epoch 11 | Batch 30/100 | Loss 0.194629
Epoch 11 | Batch 40/100 | Loss 0.196184
Epoch 11 | Batch 50/100 | Loss 0.188253
Epoch 11 | Batch 60/100 | Loss 0.178528
Epoch 11 | Batch 70/100 | Loss 0.188678
Epoch 11 | Batch 80/100 | Loss 0.185765
Epoch 11 | Batch 90/100 | Loss 0.186495
100 Test Acc = 85.20% +- 2.01%
Epoch 11: 85.20
Epoch 12 | Batch 0/100 | Loss 0.163228
Epoch 12 | Batch 10/100 | Loss 0.197850
Epoch 12 | Batch 20/100 | Loss 0.178413
Epoch 12 | Batch 30/100 | Loss 0.145573
Epoch 12 | Batch 40/100 | Loss 0.160357
Epoch 12 | Batch 50/100 | Loss 0.153165
Epoch 12 | Batch 60/100 | Loss 0.164366
Epoch 12 | Batch 70/100 | Loss 0.169559
Epoch 12 | Batch 80/100 | Loss 0.157757
Epoch 12 | Batch 90/100 | Loss 0.151685
100 Test Acc = 83.73% +- 2.12%
Epoch 12: 83.73
Epoch 13 | Batch 0/100 | Loss 0.088467
Epoch 13 | Batch 10/100 | Loss 0.170326
Epoch 13 | Batch 20/100 | Loss 0.199237
Epoch 13 | Batch 30/100 | Loss 0.182373
Epoch 13 | Batch 40/100 | Loss 0.192407
Epoch 13 | Batch 50/100 | Loss 0.188507
Epoch 13 | Batch 60/100 | Loss 0.201851
Epoch 13 | Batch 70/100 | Loss 0.195904
Epoch 13 | Batch 80/100 | Loss 0.190107
Epoch 13 | Batch 90/100 | Loss 0.185331
100 Test Acc = 84.84% +- 2.25%
Epoch 13: 84.84
Epoch 14 | Batch 0/100 | Loss 0.047098
Epoch 14 | Batch 10/100 | Loss 0.141190
Epoch 14 | Batch 20/100 | Loss 0.172717
Epoch 14 | Batch 30/100 | Loss 0.189448
Epoch 14 | Batch 40/100 | Loss 0.186682
Epoch 14 | Batch 50/100 | Loss 0.189017
Epoch 14 | Batch 60/100 | Loss 0.196539
Epoch 14 | Batch 70/100 | Loss 0.186973
Epoch 14 | Batch 80/100 | Loss 0.182432
Epoch 14 | Batch 90/100 | Loss 0.176406
100 Test Acc = 84.13% +- 2.03%
Epoch 14: 84.13
Epoch 15 | Batch 0/100 | Loss 0.049019
Epoch 15 | Batch 10/100 | Loss 0.110195
Epoch 15 | Batch 20/100 | Loss 0.156557
Epoch 15 | Batch 30/100 | Loss 0.148422
Epoch 15 | Batch 40/100 | Loss 0.157248
Epoch 15 | Batch 50/100 | Loss 0.163060
Epoch 15 | Batch 60/100 | Loss 0.167202
Epoch 15 | Batch 70/100 | Loss 0.162058
Epoch 15 | Batch 80/100 | Loss 0.168407
Epoch 15 | Batch 90/100 | Loss 0.169546
100 Test Acc = 85.56% +- 2.19%
Epoch 15: 85.56
Epoch 16 | Batch 0/100 | Loss 0.216956
Epoch 16 | Batch 10/100 | Loss 0.184530
Epoch 16 | Batch 20/100 | Loss 0.170795
Epoch 16 | Batch 30/100 | Loss 0.148306
Epoch 16 | Batch 40/100 | Loss 0.146126
Epoch 16 | Batch 50/100 | Loss 0.141735
Epoch 16 | Batch 60/100 | Loss 0.131347
Epoch 16 | Batch 70/100 | Loss 0.132571
Epoch 16 | Batch 80/100 | Loss 0.134486
Epoch 16 | Batch 90/100 | Loss 0.143023
100 Test Acc = 86.76% +- 1.98%
Epoch 16: 86.76
best model! save...
Epoch 17 | Batch 0/100 | Loss 0.081593
Epoch 17 | Batch 10/100 | Loss 0.199516
Epoch 17 | Batch 20/100 | Loss 0.189902
Epoch 17 | Batch 30/100 | Loss 0.196672
Epoch 17 | Batch 40/100 | Loss 0.188442
Epoch 17 | Batch 50/100 | Loss 0.166609
Epoch 17 | Batch 60/100 | Loss 0.154187
Epoch 17 | Batch 70/100 | Loss 0.156028
Epoch 17 | Batch 80/100 | Loss 0.156311
Epoch 17 | Batch 90/100 | Loss 0.153956
100 Test Acc = 85.24% +- 1.92%
Epoch 17: 85.24
Epoch 18 | Batch 0/100 | Loss 0.048513
Epoch 18 | Batch 10/100 | Loss 0.120584
Epoch 18 | Batch 20/100 | Loss 0.101794
Epoch 18 | Batch 30/100 | Loss 0.126784
Epoch 18 | Batch 40/100 | Loss 0.122704
Epoch 18 | Batch 50/100 | Loss 0.122675
Epoch 18 | Batch 60/100 | Loss 0.140028
Epoch 18 | Batch 70/100 | Loss 0.141217
Epoch 18 | Batch 80/100 | Loss 0.144048
Epoch 18 | Batch 90/100 | Loss 0.139632
100 Test Acc = 84.84% +- 2.38%
Epoch 18: 84.84
Epoch 19 | Batch 0/100 | Loss 0.240050
Epoch 19 | Batch 10/100 | Loss 0.096278
Epoch 19 | Batch 20/100 | Loss 0.111060
Epoch 19 | Batch 30/100 | Loss 0.121489
Epoch 19 | Batch 40/100 | Loss 0.134411
Epoch 19 | Batch 50/100 | Loss 0.138833
Epoch 19 | Batch 60/100 | Loss 0.135980
Epoch 19 | Batch 70/100 | Loss 0.142744
Epoch 19 | Batch 80/100 | Loss 0.133616
Epoch 19 | Batch 90/100 | Loss 0.131090
100 Test Acc = 86.68% +- 1.94%
Epoch 19: 86.68
Epoch 20 | Batch 0/100 | Loss 0.089162
Epoch 20 | Batch 10/100 | Loss 0.103336
Epoch 20 | Batch 20/100 | Loss 0.129808
Epoch 20 | Batch 30/100 | Loss 0.137735
Epoch 20 | Batch 40/100 | Loss 0.139579
Epoch 20 | Batch 50/100 | Loss 0.141751
Epoch 20 | Batch 60/100 | Loss 0.145047
Epoch 20 | Batch 70/100 | Loss 0.141491
Epoch 20 | Batch 80/100 | Loss 0.143438
Epoch 20 | Batch 90/100 | Loss 0.137479
100 Test Acc = 84.47% +- 2.11%
Epoch 20: 84.47
Epoch 21 | Batch 0/100 | Loss 0.172855
Epoch 21 | Batch 10/100 | Loss 0.136931
Epoch 21 | Batch 20/100 | Loss 0.127444
Epoch 21 | Batch 30/100 | Loss 0.135170
Epoch 21 | Batch 40/100 | Loss 0.137596
Epoch 21 | Batch 50/100 | Loss 0.146337
Epoch 21 | Batch 60/100 | Loss 0.149006
Epoch 21 | Batch 70/100 | Loss 0.140415
Epoch 21 | Batch 80/100 | Loss 0.144548
Epoch 21 | Batch 90/100 | Loss 0.142768
100 Test Acc = 85.37% +- 1.96%
Epoch 21: 85.37
Epoch 22 | Batch 0/100 | Loss 0.018655
Epoch 22 | Batch 10/100 | Loss 0.165312
Epoch 22 | Batch 20/100 | Loss 0.151496
Epoch 22 | Batch 30/100 | Loss 0.155389
Epoch 22 | Batch 40/100 | Loss 0.146017
Epoch 22 | Batch 50/100 | Loss 0.139855
Epoch 22 | Batch 60/100 | Loss 0.135571
Epoch 22 | Batch 70/100 | Loss 0.138711
Epoch 22 | Batch 80/100 | Loss 0.139455
Epoch 22 | Batch 90/100 | Loss 0.140466
100 Test Acc = 84.85% +- 1.80%
Epoch 22: 84.85
Epoch 23 | Batch 0/100 | Loss 0.004014
Epoch 23 | Batch 10/100 | Loss 0.130758
Epoch 23 | Batch 20/100 | Loss 0.105750
Epoch 23 | Batch 30/100 | Loss 0.114161
Epoch 23 | Batch 40/100 | Loss 0.149383
Epoch 23 | Batch 50/100 | Loss 0.135046
Epoch 23 | Batch 60/100 | Loss 0.138536
Epoch 23 | Batch 70/100 | Loss 0.139010
Epoch 23 | Batch 80/100 | Loss 0.141329
Epoch 23 | Batch 90/100 | Loss 0.139960
100 Test Acc = 85.36% +- 2.20%
Epoch 23: 85.36
Epoch 24 | Batch 0/100 | Loss 0.132237
Epoch 24 | Batch 10/100 | Loss 0.136825
Epoch 24 | Batch 20/100 | Loss 0.146187
Epoch 24 | Batch 30/100 | Loss 0.149499
Epoch 24 | Batch 40/100 | Loss 0.131082
Epoch 24 | Batch 50/100 | Loss 0.123632
Epoch 24 | Batch 60/100 | Loss 0.123869
Epoch 24 | Batch 70/100 | Loss 0.129909
Epoch 24 | Batch 80/100 | Loss 0.132912
Epoch 24 | Batch 90/100 | Loss 0.125221
100 Test Acc = 86.16% +- 1.87%
Epoch 24: 86.16
Epoch 25 | Batch 0/100 | Loss 0.639501
Epoch 25 | Batch 10/100 | Loss 0.157039
Epoch 25 | Batch 20/100 | Loss 0.144240
Epoch 25 | Batch 30/100 | Loss 0.142117
Epoch 25 | Batch 40/100 | Loss 0.136171
Epoch 25 | Batch 50/100 | Loss 0.131274
Epoch 25 | Batch 60/100 | Loss 0.125762
Epoch 25 | Batch 70/100 | Loss 0.124230
Epoch 25 | Batch 80/100 | Loss 0.133245
Epoch 25 | Batch 90/100 | Loss 0.130326
100 Test Acc = 86.01% +- 1.89%
Epoch 25: 86.01
Epoch 26 | Batch 0/100 | Loss 0.114359
Epoch 26 | Batch 10/100 | Loss 0.107350
Epoch 26 | Batch 20/100 | Loss 0.119783
Epoch 26 | Batch 30/100 | Loss 0.119875
Epoch 26 | Batch 40/100 | Loss 0.127244
Epoch 26 | Batch 50/100 | Loss 0.127435
Epoch 26 | Batch 60/100 | Loss 0.128892
Epoch 26 | Batch 70/100 | Loss 0.120911
Epoch 26 | Batch 80/100 | Loss 0.118986
Epoch 26 | Batch 90/100 | Loss 0.120461
100 Test Acc = 86.59% +- 1.85%
Epoch 26: 86.59
Epoch 27 | Batch 0/100 | Loss 0.049562
Epoch 27 | Batch 10/100 | Loss 0.097027
Epoch 27 | Batch 20/100 | Loss 0.109773
Epoch 27 | Batch 30/100 | Loss 0.103952
Epoch 27 | Batch 40/100 | Loss 0.102732
Epoch 27 | Batch 50/100 | Loss 0.105261
Epoch 27 | Batch 60/100 | Loss 0.119159
Epoch 27 | Batch 70/100 | Loss 0.125220
Epoch 27 | Batch 80/100 | Loss 0.121434
Epoch 27 | Batch 90/100 | Loss 0.113960
100 Test Acc = 85.09% +- 2.01%
Epoch 27: 85.09
Epoch 28 | Batch 0/100 | Loss 0.007014
Epoch 28 | Batch 10/100 | Loss 0.133674
Epoch 28 | Batch 20/100 | Loss 0.125395
Epoch 28 | Batch 30/100 | Loss 0.132141
Epoch 28 | Batch 40/100 | Loss 0.122276
Epoch 28 | Batch 50/100 | Loss 0.111863
Epoch 28 | Batch 60/100 | Loss 0.117899
Epoch 28 | Batch 70/100 | Loss 0.132771
Epoch 28 | Batch 80/100 | Loss 0.137217
Epoch 28 | Batch 90/100 | Loss 0.132520
100 Test Acc = 87.09% +- 1.86%
Epoch 28: 87.09
best model! save...
Epoch 29 | Batch 0/100 | Loss 0.190172
Epoch 29 | Batch 10/100 | Loss 0.109851
Epoch 29 | Batch 20/100 | Loss 0.105647
Epoch 29 | Batch 30/100 | Loss 0.105146
Epoch 29 | Batch 40/100 | Loss 0.098819
Epoch 29 | Batch 50/100 | Loss 0.106395
Epoch 29 | Batch 60/100 | Loss 0.121762
Epoch 29 | Batch 70/100 | Loss 0.137898
Epoch 29 | Batch 80/100 | Loss 0.134277
Epoch 29 | Batch 90/100 | Loss 0.129867
100 Test Acc = 85.92% +- 2.01%
Epoch 29: 85.92
Epoch 30 | Batch 0/100 | Loss 0.079593
Epoch 30 | Batch 10/100 | Loss 0.119946
Epoch 30 | Batch 20/100 | Loss 0.114572
Epoch 30 | Batch 30/100 | Loss 0.103782
Epoch 30 | Batch 40/100 | Loss 0.107276
Epoch 30 | Batch 50/100 | Loss 0.102571
Epoch 30 | Batch 60/100 | Loss 0.100985
Epoch 30 | Batch 70/100 | Loss 0.106121
Epoch 30 | Batch 80/100 | Loss 0.111687
Epoch 30 | Batch 90/100 | Loss 0.107223
100 Test Acc = 83.51% +- 1.94%
Epoch 30: 83.51
Epoch 31 | Batch 0/100 | Loss 0.089792
Epoch 31 | Batch 10/100 | Loss 0.095353
Epoch 31 | Batch 20/100 | Loss 0.125266
Epoch 31 | Batch 30/100 | Loss 0.123983
Epoch 31 | Batch 40/100 | Loss 0.127680
Epoch 31 | Batch 50/100 | Loss 0.116734
Epoch 31 | Batch 60/100 | Loss 0.126193
Epoch 31 | Batch 70/100 | Loss 0.118016
Epoch 31 | Batch 80/100 | Loss 0.113709
Epoch 31 | Batch 90/100 | Loss 0.109495
100 Test Acc = 84.03% +- 1.80%
Epoch 31: 84.03
Epoch 32 | Batch 0/100 | Loss 0.199882
Epoch 32 | Batch 10/100 | Loss 0.118427
Epoch 32 | Batch 20/100 | Loss 0.132003
Epoch 32 | Batch 30/100 | Loss 0.122555
Epoch 32 | Batch 40/100 | Loss 0.121715
Epoch 32 | Batch 50/100 | Loss 0.121623
Epoch 32 | Batch 60/100 | Loss 0.122580
Epoch 32 | Batch 70/100 | Loss 0.117287
Epoch 32 | Batch 80/100 | Loss 0.110624
Epoch 32 | Batch 90/100 | Loss 0.102164
100 Test Acc = 85.76% +- 1.79%
Epoch 32: 85.76
Epoch 33 | Batch 0/100 | Loss 0.006887
Epoch 33 | Batch 10/100 | Loss 0.132803
Epoch 33 | Batch 20/100 | Loss 0.112852
Epoch 33 | Batch 30/100 | Loss 0.127725
Epoch 33 | Batch 40/100 | Loss 0.138061
Epoch 33 | Batch 50/100 | Loss 0.137690
Epoch 33 | Batch 60/100 | Loss 0.130575
Epoch 33 | Batch 70/100 | Loss 0.122999
Epoch 33 | Batch 80/100 | Loss 0.121680
Epoch 33 | Batch 90/100 | Loss 0.117285
100 Test Acc = 86.00% +- 1.90%
Epoch 33: 86.00
Epoch 34 | Batch 0/100 | Loss 0.015380
Epoch 34 | Batch 10/100 | Loss 0.083917
Epoch 34 | Batch 20/100 | Loss 0.118388
Epoch 34 | Batch 30/100 | Loss 0.116693
Epoch 34 | Batch 40/100 | Loss 0.111335
Epoch 34 | Batch 50/100 | Loss 0.121993
Epoch 34 | Batch 60/100 | Loss 0.113818
Epoch 34 | Batch 70/100 | Loss 0.108118
Epoch 34 | Batch 80/100 | Loss 0.109896
Epoch 34 | Batch 90/100 | Loss 0.109133
100 Test Acc = 86.56% +- 2.03%
Epoch 34: 86.56
Epoch 35 | Batch 0/100 | Loss 0.005000
Epoch 35 | Batch 10/100 | Loss 0.057961
Epoch 35 | Batch 20/100 | Loss 0.132034
Epoch 35 | Batch 30/100 | Loss 0.113234
Epoch 35 | Batch 40/100 | Loss 0.121726
Epoch 35 | Batch 50/100 | Loss 0.119285
Epoch 35 | Batch 60/100 | Loss 0.115787
Epoch 35 | Batch 70/100 | Loss 0.114541
Epoch 35 | Batch 80/100 | Loss 0.112960
Epoch 35 | Batch 90/100 | Loss 0.122482
100 Test Acc = 84.11% +- 2.24%
Epoch 35: 84.11
Epoch 36 | Batch 0/100 | Loss 0.754836
Epoch 36 | Batch 10/100 | Loss 0.176357
Epoch 36 | Batch 20/100 | Loss 0.132110
Epoch 36 | Batch 30/100 | Loss 0.122207
Epoch 36 | Batch 40/100 | Loss 0.110625
Epoch 36 | Batch 50/100 | Loss 0.117025
Epoch 36 | Batch 60/100 | Loss 0.121552
Epoch 36 | Batch 70/100 | Loss 0.115118
Epoch 36 | Batch 80/100 | Loss 0.108839
Epoch 36 | Batch 90/100 | Loss 0.100959
100 Test Acc = 84.97% +- 1.86%
Epoch 36: 84.97
Epoch 37 | Batch 0/100 | Loss 0.038765
Epoch 37 | Batch 10/100 | Loss 0.136790
Epoch 37 | Batch 20/100 | Loss 0.123175
Epoch 37 | Batch 30/100 | Loss 0.115195
Epoch 37 | Batch 40/100 | Loss 0.104540
Epoch 37 | Batch 50/100 | Loss 0.104644
Epoch 37 | Batch 60/100 | Loss 0.104096
Epoch 37 | Batch 70/100 | Loss 0.105723
Epoch 37 | Batch 80/100 | Loss 0.100378
Epoch 37 | Batch 90/100 | Loss 0.101231
100 Test Acc = 85.00% +- 2.06%
Epoch 37: 85.00
Epoch 38 | Batch 0/100 | Loss 0.097325
Epoch 38 | Batch 10/100 | Loss 0.126537
Epoch 38 | Batch 20/100 | Loss 0.091614
Epoch 38 | Batch 30/100 | Loss 0.113661
Epoch 38 | Batch 40/100 | Loss 0.111660
Epoch 38 | Batch 50/100 | Loss 0.129333
Epoch 38 | Batch 60/100 | Loss 0.116457
Epoch 38 | Batch 70/100 | Loss 0.117680
Epoch 38 | Batch 80/100 | Loss 0.116511
Epoch 38 | Batch 90/100 | Loss 0.113998
100 Test Acc = 85.32% +- 1.90%
Epoch 38: 85.32
Epoch 39 | Batch 0/100 | Loss 0.017865
Epoch 39 | Batch 10/100 | Loss 0.087171
Epoch 39 | Batch 20/100 | Loss 0.091840
Epoch 39 | Batch 30/100 | Loss 0.110562
Epoch 39 | Batch 40/100 | Loss 0.134740
Epoch 39 | Batch 50/100 | Loss 0.126408
Epoch 39 | Batch 60/100 | Loss 0.130512
Epoch 39 | Batch 70/100 | Loss 0.126215
Epoch 39 | Batch 80/100 | Loss 0.125322
Epoch 39 | Batch 90/100 | Loss 0.123104
100 Test Acc = 84.60% +- 1.99%
Epoch 39: 84.60
Epoch 40 | Batch 0/100 | Loss 0.088713
Epoch 40 | Batch 10/100 | Loss 0.094645
Epoch 40 | Batch 20/100 | Loss 0.125370
Epoch 40 | Batch 30/100 | Loss 0.099301
Epoch 40 | Batch 40/100 | Loss 0.089525
Epoch 40 | Batch 50/100 | Loss 0.093851
Epoch 40 | Batch 60/100 | Loss 0.104806
Epoch 40 | Batch 70/100 | Loss 0.105061
Epoch 40 | Batch 80/100 | Loss 0.104815
Epoch 40 | Batch 90/100 | Loss 0.108796
100 Test Acc = 85.37% +- 1.97%
Epoch 40: 85.37
Epoch 41 | Batch 0/100 | Loss 0.012527
Epoch 41 | Batch 10/100 | Loss 0.086357
Epoch 41 | Batch 20/100 | Loss 0.095546
Epoch 41 | Batch 30/100 | Loss 0.091514
Epoch 41 | Batch 40/100 | Loss 0.090625
Epoch 41 | Batch 50/100 | Loss 0.099208
Epoch 41 | Batch 60/100 | Loss 0.095553
Epoch 41 | Batch 70/100 | Loss 0.104536
Epoch 41 | Batch 80/100 | Loss 0.107987
Epoch 41 | Batch 90/100 | Loss 0.111061
100 Test Acc = 86.09% +- 2.05%
Epoch 41: 86.09
Epoch 42 | Batch 0/100 | Loss 0.203210
Epoch 42 | Batch 10/100 | Loss 0.091675
Epoch 42 | Batch 20/100 | Loss 0.077115
Epoch 42 | Batch 30/100 | Loss 0.082697
Epoch 42 | Batch 40/100 | Loss 0.096710
Epoch 42 | Batch 50/100 | Loss 0.114315
Epoch 42 | Batch 60/100 | Loss 0.109210
Epoch 42 | Batch 70/100 | Loss 0.106637
Epoch 42 | Batch 80/100 | Loss 0.104228
Epoch 42 | Batch 90/100 | Loss 0.099401
100 Test Acc = 86.37% +- 1.87%
Epoch 42: 86.37
Epoch 43 | Batch 0/100 | Loss 0.199552
Epoch 43 | Batch 10/100 | Loss 0.052723
Epoch 43 | Batch 20/100 | Loss 0.118099
Epoch 43 | Batch 30/100 | Loss 0.111810
Epoch 43 | Batch 40/100 | Loss 0.117373
Epoch 43 | Batch 50/100 | Loss 0.119377
Epoch 43 | Batch 60/100 | Loss 0.116068
Epoch 43 | Batch 70/100 | Loss 0.113879
Epoch 43 | Batch 80/100 | Loss 0.108454
Epoch 43 | Batch 90/100 | Loss 0.107597
100 Test Acc = 84.43% +- 1.89%
Epoch 43: 84.43
Epoch 44 | Batch 0/100 | Loss 0.051345
Epoch 44 | Batch 10/100 | Loss 0.084412
Epoch 44 | Batch 20/100 | Loss 0.080598
Epoch 44 | Batch 30/100 | Loss 0.080772
Epoch 44 | Batch 40/100 | Loss 0.087142
Epoch 44 | Batch 50/100 | Loss 0.093454
Epoch 44 | Batch 60/100 | Loss 0.093081
Epoch 44 | Batch 70/100 | Loss 0.093947
Epoch 44 | Batch 80/100 | Loss 0.096823
Epoch 44 | Batch 90/100 | Loss 0.100812
100 Test Acc = 85.41% +- 1.93%
Epoch 44: 85.41
Epoch 45 | Batch 0/100 | Loss 0.098472
Epoch 45 | Batch 10/100 | Loss 0.064436
Epoch 45 | Batch 20/100 | Loss 0.052822
Epoch 45 | Batch 30/100 | Loss 0.072761
Epoch 45 | Batch 40/100 | Loss 0.099988
Epoch 45 | Batch 50/100 | Loss 0.098805
Epoch 45 | Batch 60/100 | Loss 0.108402
Epoch 45 | Batch 70/100 | Loss 0.111140
Epoch 45 | Batch 80/100 | Loss 0.116236
Epoch 45 | Batch 90/100 | Loss 0.116770
100 Test Acc = 84.03% +- 2.22%
Epoch 45: 84.03
Epoch 46 | Batch 0/100 | Loss 0.050056
Epoch 46 | Batch 10/100 | Loss 0.089565
Epoch 46 | Batch 20/100 | Loss 0.129557
Epoch 46 | Batch 30/100 | Loss 0.127788
Epoch 46 | Batch 40/100 | Loss 0.137319
Epoch 46 | Batch 50/100 | Loss 0.133345
Epoch 46 | Batch 60/100 | Loss 0.126700
Epoch 46 | Batch 70/100 | Loss 0.122782
Epoch 46 | Batch 80/100 | Loss 0.113254
Epoch 46 | Batch 90/100 | Loss 0.111961
100 Test Acc = 85.36% +- 1.83%
Epoch 46: 85.36
Epoch 47 | Batch 0/100 | Loss 0.008588
Epoch 47 | Batch 10/100 | Loss 0.124630
Epoch 47 | Batch 20/100 | Loss 0.133889
Epoch 47 | Batch 30/100 | Loss 0.122409
Epoch 47 | Batch 40/100 | Loss 0.118289
Epoch 47 | Batch 50/100 | Loss 0.129158
Epoch 47 | Batch 60/100 | Loss 0.128977
Epoch 47 | Batch 70/100 | Loss 0.117327
Epoch 47 | Batch 80/100 | Loss 0.115665
Epoch 47 | Batch 90/100 | Loss 0.113796
100 Test Acc = 86.41% +- 1.83%
Epoch 47: 86.41
Epoch 48 | Batch 0/100 | Loss 0.338959
Epoch 48 | Batch 10/100 | Loss 0.126369
Epoch 48 | Batch 20/100 | Loss 0.106002
Epoch 48 | Batch 30/100 | Loss 0.095434
Epoch 48 | Batch 40/100 | Loss 0.098536
Epoch 48 | Batch 50/100 | Loss 0.106009
Epoch 48 | Batch 60/100 | Loss 0.104433
Epoch 48 | Batch 70/100 | Loss 0.098939
Epoch 48 | Batch 80/100 | Loss 0.096321
Epoch 48 | Batch 90/100 | Loss 0.100024
100 Test Acc = 86.28% +- 1.98%
Epoch 48: 86.28
Epoch 49 | Batch 0/100 | Loss 0.142305
Epoch 49 | Batch 10/100 | Loss 0.078955
Epoch 49 | Batch 20/100 | Loss 0.077161
Epoch 49 | Batch 30/100 | Loss 0.077930
Epoch 49 | Batch 40/100 | Loss 0.076894
Epoch 49 | Batch 50/100 | Loss 0.079239
Epoch 49 | Batch 60/100 | Loss 0.085205
Epoch 49 | Batch 70/100 | Loss 0.096609
Epoch 49 | Batch 80/100 | Loss 0.105228
Epoch 49 | Batch 90/100 | Loss 0.106074
100 Test Acc = 84.21% +- 2.25%
Epoch 49: 84.21
Epoch 50 | Batch 0/100 | Loss 0.070231
Epoch 50 | Batch 10/100 | Loss 0.108751
Epoch 50 | Batch 20/100 | Loss 0.086534
Epoch 50 | Batch 30/100 | Loss 0.096619
Epoch 50 | Batch 40/100 | Loss 0.095319
Epoch 50 | Batch 50/100 | Loss 0.100547
Epoch 50 | Batch 60/100 | Loss 0.110800
Epoch 50 | Batch 70/100 | Loss 0.113850
Epoch 50 | Batch 80/100 | Loss 0.114296
Epoch 50 | Batch 90/100 | Loss 0.112136
100 Test Acc = 85.64% +- 2.05%
Epoch 50: 85.64
Epoch 51 | Batch 0/100 | Loss 0.098009
Epoch 51 | Batch 10/100 | Loss 0.055166
Epoch 51 | Batch 20/100 | Loss 0.062554
Epoch 51 | Batch 30/100 | Loss 0.109713
Epoch 51 | Batch 40/100 | Loss 0.098189
Epoch 51 | Batch 50/100 | Loss 0.086753
Epoch 51 | Batch 60/100 | Loss 0.092339
Epoch 51 | Batch 70/100 | Loss 0.089777
Epoch 51 | Batch 80/100 | Loss 0.089309
Epoch 51 | Batch 90/100 | Loss 0.089053
100 Test Acc = 85.40% +- 1.99%
Epoch 51: 85.40
Epoch 52 | Batch 0/100 | Loss 0.288948
Epoch 52 | Batch 10/100 | Loss 0.135479
Epoch 52 | Batch 20/100 | Loss 0.128871
Epoch 52 | Batch 30/100 | Loss 0.130014
Epoch 52 | Batch 40/100 | Loss 0.133975
Epoch 52 | Batch 50/100 | Loss 0.126662
Epoch 52 | Batch 60/100 | Loss 0.127953
Epoch 52 | Batch 70/100 | Loss 0.119939
Epoch 52 | Batch 80/100 | Loss 0.119787
Epoch 52 | Batch 90/100 | Loss 0.119390
100 Test Acc = 86.01% +- 1.86%
Epoch 52: 86.01
Epoch 53 | Batch 0/100 | Loss 0.153466
Epoch 53 | Batch 10/100 | Loss 0.077069
Epoch 53 | Batch 20/100 | Loss 0.083186
Epoch 53 | Batch 30/100 | Loss 0.106654
Epoch 53 | Batch 40/100 | Loss 0.101409
Epoch 53 | Batch 50/100 | Loss 0.104676
Epoch 53 | Batch 60/100 | Loss 0.105489
Epoch 53 | Batch 70/100 | Loss 0.112229
Epoch 53 | Batch 80/100 | Loss 0.115315
Epoch 53 | Batch 90/100 | Loss 0.117461
100 Test Acc = 87.17% +- 1.70%
Epoch 53: 87.17
best model! save...
Epoch 54 | Batch 0/100 | Loss 0.118044
Epoch 54 | Batch 10/100 | Loss 0.071336
Epoch 54 | Batch 20/100 | Loss 0.075009
Epoch 54 | Batch 30/100 | Loss 0.101884
Epoch 54 | Batch 40/100 | Loss 0.105737
Epoch 54 | Batch 50/100 | Loss 0.108167
Epoch 54 | Batch 60/100 | Loss 0.109131
Epoch 54 | Batch 70/100 | Loss 0.107609
Epoch 54 | Batch 80/100 | Loss 0.110579
Epoch 54 | Batch 90/100 | Loss 0.102639
100 Test Acc = 86.05% +- 1.72%
Epoch 54: 86.05
Epoch 55 | Batch 0/100 | Loss 0.014640
Epoch 55 | Batch 10/100 | Loss 0.122000
Epoch 55 | Batch 20/100 | Loss 0.108948
Epoch 55 | Batch 30/100 | Loss 0.125226
Epoch 55 | Batch 40/100 | Loss 0.114595
Epoch 55 | Batch 50/100 | Loss 0.103668
Epoch 55 | Batch 60/100 | Loss 0.104273
Epoch 55 | Batch 70/100 | Loss 0.108844
Epoch 55 | Batch 80/100 | Loss 0.100716
Epoch 55 | Batch 90/100 | Loss 0.099601
100 Test Acc = 87.56% +- 1.74%
Epoch 55: 87.56
best model! save...
Epoch 56 | Batch 0/100 | Loss 0.068692
Epoch 56 | Batch 10/100 | Loss 0.113530
Epoch 56 | Batch 20/100 | Loss 0.123690
Epoch 56 | Batch 30/100 | Loss 0.103989
Epoch 56 | Batch 40/100 | Loss 0.099603
Epoch 56 | Batch 50/100 | Loss 0.112141
Epoch 56 | Batch 60/100 | Loss 0.101394
Epoch 56 | Batch 70/100 | Loss 0.097889
Epoch 56 | Batch 80/100 | Loss 0.092006
Epoch 56 | Batch 90/100 | Loss 0.099327
100 Test Acc = 87.91% +- 1.80%
Epoch 56: 87.91
best model! save...
Epoch 57 | Batch 0/100 | Loss 0.021825
Epoch 57 | Batch 10/100 | Loss 0.105964
Epoch 57 | Batch 20/100 | Loss 0.093232
Epoch 57 | Batch 30/100 | Loss 0.080905
Epoch 57 | Batch 40/100 | Loss 0.068538
Epoch 57 | Batch 50/100 | Loss 0.074626
Epoch 57 | Batch 60/100 | Loss 0.073750
Epoch 57 | Batch 70/100 | Loss 0.075608
Epoch 57 | Batch 80/100 | Loss 0.078909
Epoch 57 | Batch 90/100 | Loss 0.079017
100 Test Acc = 85.48% +- 2.04%
Epoch 57: 85.48
Epoch 58 | Batch 0/100 | Loss 0.004979
Epoch 58 | Batch 10/100 | Loss 0.111345
Epoch 58 | Batch 20/100 | Loss 0.098517
Epoch 58 | Batch 30/100 | Loss 0.093520
Epoch 58 | Batch 40/100 | Loss 0.081075
Epoch 58 | Batch 50/100 | Loss 0.073444
Epoch 58 | Batch 60/100 | Loss 0.072370
Epoch 58 | Batch 70/100 | Loss 0.070641
Epoch 58 | Batch 80/100 | Loss 0.069049
Epoch 58 | Batch 90/100 | Loss 0.069675
100 Test Acc = 85.57% +- 1.79%
Epoch 58: 85.57
Epoch 59 | Batch 0/100 | Loss 0.249073
Epoch 59 | Batch 10/100 | Loss 0.107671
Epoch 59 | Batch 20/100 | Loss 0.098897
Epoch 59 | Batch 30/100 | Loss 0.099267
Epoch 59 | Batch 40/100 | Loss 0.097968
Epoch 59 | Batch 50/100 | Loss 0.095377
Epoch 59 | Batch 60/100 | Loss 0.091729
Epoch 59 | Batch 70/100 | Loss 0.092023
Epoch 59 | Batch 80/100 | Loss 0.086719
Epoch 59 | Batch 90/100 | Loss 0.094987
/home/said.gurbuz/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
100 Test Acc = 84.95% +- 1.98%
Epoch 59: 84.95
Checkpoint directory: checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_5/tabula_muris/matchingnet_FCNet
Using checkpoint dir: checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_5/tabula_muris/matchingnet_FCNet/20231209_051926
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
/home/said.gurbuz/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
600 Test Acc = 97.94% +- 0.32%
Using checkpoint dir: checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_5/tabula_muris/matchingnet_FCNet/20231209_051926
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
/home/said.gurbuz/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
600 Test Acc = 86.81% +- 0.75%
Using checkpoint dir: checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_5/tabula_muris/matchingnet_FCNet/20231209_051926
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
600 Test Acc = 83.67% +- 0.78%
Results logged to ./checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_5/results.txt
+-------+-------------------+-------------------+
| split |      acc_mean     |      acc_std      |
+-------+-------------------+-------------------+
| train |       97.94       | 4.003992451985338 |
|  val  | 86.80888888888889 | 9.311271279449771 |
|  test | 83.67333333333333 | 9.724041988421924 |
+-------+-------------------+-------------------+
