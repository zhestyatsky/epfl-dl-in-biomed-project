/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 1
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 1
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 1
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 1
    finetuning_lr_init: 0.001
    num_adaptation_steps: 5
    kl_coef: 0.001
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 1.0e-09
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 8
    optimize_backbone: false
  n_task: 4
  latent_space_dim: 8
  leo_inner_lr_init: 1
  leo_finetuning_lr_init: 0.001
  num_adaptation_steps: 5
  kl_coef: 0.001
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 1.0e-09
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-08
  optimize_backbone: false
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_1_lr_0.0001_latent_space_dim_8_weight_decay_1e-08_num_adaptation_steps_5
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.0001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.0001
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_1_lr_0.0001_latent_space_dim_8_weight_decay_1e-08_num_adaptation_steps_5/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=8, bias=True)
    (relation_net): Linear(in_features=16, out_features=16, bias=True)
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=40, out_features=650, bias=True)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 1e-08
)
Epoch 0 | Batch 0/100 | Loss 3.214873
InnerLR 1.000000
FineTuningLR 0.001000
Epoch 0 | Batch 10/100 | Loss 3.890332
InnerLR 0.999800
FineTuningLR 0.001200
Epoch 0 | Batch 20/100 | Loss 4.087465
InnerLR 0.999501
FineTuningLR 0.001499
Epoch 0 | Batch 30/100 | Loss 4.017015
InnerLR 0.999300
FineTuningLR 0.001700
Epoch 0 | Batch 40/100 | Loss 3.998703
InnerLR 0.999001
FineTuningLR 0.001999
Epoch 0 | Batch 50/100 | Loss 4.039575
InnerLR 0.998801
FineTuningLR 0.002199
Epoch 0 | Batch 60/100 | Loss 4.018335
InnerLR 0.998502
FineTuningLR 0.002498
Epoch 0 | Batch 70/100 | Loss 3.977195
InnerLR 0.998302
FineTuningLR 0.002698
Epoch 0 | Batch 80/100 | Loss 4.015027
InnerLR 0.998003
FineTuningLR 0.002997
Epoch 0 | Batch 90/100 | Loss 4.012087
InnerLR 0.997804
FineTuningLR 0.003196
100 Accuracy = 25.31% +- 1.37%
Epoch 0: 25.31
best model! save...
Epoch 1 | Batch 0/100 | Loss 3.218664
InnerLR 0.997504
FineTuningLR 0.003495
Epoch 1 | Batch 10/100 | Loss 3.874022
InnerLR 0.997304
FineTuningLR 0.003695
Epoch 1 | Batch 20/100 | Loss 3.933923
InnerLR 0.997003
FineTuningLR 0.003997
Epoch 1 | Batch 30/100 | Loss 3.812893
InnerLR 0.996802
FineTuningLR 0.004198
Epoch 1 | Batch 40/100 | Loss 3.801176
InnerLR 0.996499
FineTuningLR 0.004500
Epoch 1 | Batch 50/100 | Loss 3.857565
InnerLR 0.996297
FineTuningLR 0.004702
Epoch 1 | Batch 60/100 | Loss 3.809693
InnerLR 0.995996
FineTuningLR 0.005004
Epoch 1 | Batch 70/100 | Loss 3.805364
InnerLR 0.995795
FineTuningLR 0.005205
Epoch 1 | Batch 80/100 | Loss 3.801887
InnerLR 0.995495
FineTuningLR 0.005505
Epoch 1 | Batch 90/100 | Loss 3.825883
InnerLR 0.995294
FineTuningLR 0.005706
100 Accuracy = 24.21% +- 1.32%
Epoch 1: 24.21
Epoch 2 | Batch 0/100 | Loss 3.052508
InnerLR 0.994993
FineTuningLR 0.006007
Epoch 2 | Batch 10/100 | Loss 3.489530
InnerLR 0.994792
FineTuningLR 0.006208
Epoch 2 | Batch 20/100 | Loss 3.559124
InnerLR 0.994490
FineTuningLR 0.006510
Epoch 2 | Batch 30/100 | Loss 3.724276
InnerLR 0.994288
FineTuningLR 0.006712
Epoch 2 | Batch 40/100 | Loss 3.844500
InnerLR 0.993984
FineTuningLR 0.007015
Epoch 2 | Batch 50/100 | Loss 3.804955
InnerLR 0.993782
FineTuningLR 0.007218
Epoch 2 | Batch 60/100 | Loss 3.755617
InnerLR 0.993478
FineTuningLR 0.007522
Epoch 2 | Batch 70/100 | Loss 3.765729
InnerLR 0.993276
FineTuningLR 0.007724
Epoch 2 | Batch 80/100 | Loss 3.747097
InnerLR 0.992972
FineTuningLR 0.008027
Epoch 2 | Batch 90/100 | Loss 3.772343
InnerLR 0.992771
FineTuningLR 0.008229
100 Accuracy = 26.11% +- 1.44%
Epoch 2: 26.11
best model! save...
Epoch 3 | Batch 0/100 | Loss 3.657587
InnerLR 0.992470
FineTuningLR 0.008530
Epoch 3 | Batch 10/100 | Loss 3.428344
InnerLR 0.992268
FineTuningLR 0.008732
Epoch 3 | Batch 20/100 | Loss 3.527659
InnerLR 0.991966
FineTuningLR 0.009034
Epoch 3 | Batch 30/100 | Loss 3.619429
InnerLR 0.991765
FineTuningLR 0.009235
Epoch 3 | Batch 40/100 | Loss 3.546536
InnerLR 0.991463
FineTuningLR 0.009537
Epoch 3 | Batch 50/100 | Loss 3.475035
InnerLR 0.991260
FineTuningLR 0.009739
Epoch 3 | Batch 60/100 | Loss 3.499287
InnerLR 0.990955
FineTuningLR 0.010045
Epoch 3 | Batch 70/100 | Loss 3.528832
InnerLR 0.990753
FineTuningLR 0.010247
Epoch 3 | Batch 80/100 | Loss 3.514660
InnerLR 0.990447
FineTuningLR 0.010553
Epoch 3 | Batch 90/100 | Loss 3.558225
InnerLR 0.990244
FineTuningLR 0.010756
100 Accuracy = 26.31% +- 1.38%
Epoch 3: 26.31
best model! save...
Epoch 4 | Batch 0/100 | Loss 5.762197
InnerLR 0.989941
FineTuningLR 0.011059
Epoch 4 | Batch 10/100 | Loss 4.046993
InnerLR 0.989739
FineTuningLR 0.011261
Epoch 4 | Batch 20/100 | Loss 3.832633
InnerLR 0.989437
FineTuningLR 0.011563
Epoch 4 | Batch 30/100 | Loss 3.752113
InnerLR 0.989235
FineTuningLR 0.011765
Epoch 4 | Batch 40/100 | Loss 3.843443
InnerLR 0.988932
FineTuningLR 0.012068
Epoch 4 | Batch 50/100 | Loss 3.840102
InnerLR 0.988731
FineTuningLR 0.012269
Epoch 4 | Batch 60/100 | Loss 3.775738
InnerLR 0.988429
FineTuningLR 0.012571
Epoch 4 | Batch 70/100 | Loss 3.821791
InnerLR 0.988227
FineTuningLR 0.012772
Epoch 4 | Batch 80/100 | Loss 3.814356
InnerLR 0.987927
FineTuningLR 0.013073
Epoch 4 | Batch 90/100 | Loss 3.794176
InnerLR 0.987725
FineTuningLR 0.013275
100 Accuracy = 26.71% +- 1.38%
Epoch 4: 26.71
best model! save...
Epoch 5 | Batch 0/100 | Loss 2.652925
InnerLR 0.987420
FineTuningLR 0.013580
Epoch 5 | Batch 10/100 | Loss 3.621065
InnerLR 0.987217
FineTuningLR 0.013783
Epoch 5 | Batch 20/100 | Loss 3.572831
InnerLR 0.986911
FineTuningLR 0.014089
Epoch 5 | Batch 30/100 | Loss 3.494716
InnerLR 0.986706
FineTuningLR 0.014294
Epoch 5 | Batch 40/100 | Loss 3.512124
InnerLR 0.986398
FineTuningLR 0.014601
Epoch 5 | Batch 50/100 | Loss 3.514042
InnerLR 0.986195
FineTuningLR 0.014805
Epoch 5 | Batch 60/100 | Loss 3.477586
InnerLR 0.985889
FineTuningLR 0.015111
Epoch 5 | Batch 70/100 | Loss 3.497602
InnerLR 0.985686
FineTuningLR 0.015313
Epoch 5 | Batch 80/100 | Loss 3.514237
InnerLR 0.985382
FineTuningLR 0.015618
Epoch 5 | Batch 90/100 | Loss 3.528798
InnerLR 0.985179
FineTuningLR 0.015821
100 Accuracy = 25.72% +- 1.18%
Epoch 5: 25.72
Epoch 6 | Batch 0/100 | Loss 4.010427
InnerLR 0.984876
FineTuningLR 0.016124
Epoch 6 | Batch 10/100 | Loss 3.464837
InnerLR 0.984673
FineTuningLR 0.016327
Epoch 6 | Batch 20/100 | Loss 3.384496
InnerLR 0.984366
FineTuningLR 0.016634
Epoch 6 | Batch 30/100 | Loss 3.443142
InnerLR 0.984160
FineTuningLR 0.016840
Epoch 6 | Batch 40/100 | Loss 3.541420
InnerLR 0.983851
FineTuningLR 0.017149
Epoch 6 | Batch 50/100 | Loss 3.545693
InnerLR 0.983645
FineTuningLR 0.017355
Epoch 6 | Batch 60/100 | Loss 3.522466
InnerLR 0.983338
FineTuningLR 0.017662
Epoch 6 | Batch 70/100 | Loss 3.553268
InnerLR 0.983134
FineTuningLR 0.017866
Epoch 6 | Batch 80/100 | Loss 3.531300
InnerLR 0.982827
FineTuningLR 0.018173
Epoch 6 | Batch 90/100 | Loss 3.524429
InnerLR 0.982623
FineTuningLR 0.018377
100 Accuracy = 26.25% +- 1.33%
Epoch 6: 26.25
Epoch 7 | Batch 0/100 | Loss 3.020792
InnerLR 0.982317
FineTuningLR 0.018683
Epoch 7 | Batch 10/100 | Loss 3.733484
InnerLR 0.982114
FineTuningLR 0.018886
Epoch 7 | Batch 20/100 | Loss 3.520033
InnerLR 0.981807
FineTuningLR 0.019192
Epoch 7 | Batch 30/100 | Loss 3.482571
InnerLR 0.981604
FineTuningLR 0.019396
Epoch 7 | Batch 40/100 | Loss 3.509358
InnerLR 0.981300
FineTuningLR 0.019700
Epoch 7 | Batch 50/100 | Loss 3.494330
InnerLR 0.981097
FineTuningLR 0.019903
Epoch 7 | Batch 60/100 | Loss 3.520018
InnerLR 0.980792
FineTuningLR 0.020208
Epoch 7 | Batch 70/100 | Loss 3.500203
InnerLR 0.980588
FineTuningLR 0.020412
Epoch 7 | Batch 80/100 | Loss 3.492966
InnerLR 0.980283
FineTuningLR 0.020717
Epoch 7 | Batch 90/100 | Loss 3.484560
InnerLR 0.980080
FineTuningLR 0.020920
100 Accuracy = 25.75% +- 1.29%
Epoch 7: 25.75
Epoch 8 | Batch 0/100 | Loss 2.760185
InnerLR 0.979774
FineTuningLR 0.021226
Epoch 8 | Batch 10/100 | Loss 3.539973
InnerLR 0.979570
FineTuningLR 0.021431
Epoch 8 | Batch 20/100 | Loss 3.654857
InnerLR 0.979262
FineTuningLR 0.021738
Epoch 8 | Batch 30/100 | Loss 3.574244
InnerLR 0.979058
FineTuningLR 0.021942
Epoch 8 | Batch 40/100 | Loss 3.632609
InnerLR 0.978752
FineTuningLR 0.022248
Epoch 8 | Batch 50/100 | Loss 3.616682
InnerLR 0.978549
FineTuningLR 0.022451
Epoch 8 | Batch 60/100 | Loss 3.590626
InnerLR 0.978245
FineTuningLR 0.022755
Epoch 8 | Batch 70/100 | Loss 3.616359
InnerLR 0.978042
FineTuningLR 0.022958
Epoch 8 | Batch 80/100 | Loss 3.602834
InnerLR 0.977739
FineTuningLR 0.023262
Epoch 8 | Batch 90/100 | Loss 3.589626
InnerLR 0.977536
FineTuningLR 0.023464
100 Accuracy = 25.53% +- 1.33%
Epoch 8: 25.53
Epoch 9 | Batch 0/100 | Loss 4.255024
InnerLR 0.977231
FineTuningLR 0.023769
Epoch 9 | Batch 10/100 | Loss 3.517436
InnerLR 0.977028
FineTuningLR 0.023972
Epoch 9 | Batch 20/100 | Loss 3.461891
InnerLR 0.976725
FineTuningLR 0.024275
Epoch 9 | Batch 30/100 | Loss 3.389667
InnerLR 0.976522
FineTuningLR 0.024478
Epoch 9 | Batch 40/100 | Loss 3.488614
InnerLR 0.976217
FineTuningLR 0.024783
Epoch 9 | Batch 50/100 | Loss 3.468377
InnerLR 0.976013
FineTuningLR 0.024987
Epoch 9 | Batch 60/100 | Loss 3.443990
InnerLR 0.975707
FineTuningLR 0.025293
Epoch 9 | Batch 70/100 | Loss 3.460785
InnerLR 0.975503
FineTuningLR 0.025497
Epoch 9 | Batch 80/100 | Loss 3.516865
InnerLR 0.975196
FineTuningLR 0.025804
Epoch 9 | Batch 90/100 | Loss 3.482025
InnerLR 0.974992
FineTuningLR 0.026008
100 Accuracy = 25.13% +- 1.45%
Epoch 9: 25.13
Epoch 10 | Batch 0/100 | Loss 4.374931
InnerLR 0.974688
FineTuningLR 0.026312
Epoch 10 | Batch 10/100 | Loss 3.647108
InnerLR 0.974484
FineTuningLR 0.026516
Epoch 10 | Batch 20/100 | Loss 3.520480
InnerLR 0.974178
FineTuningLR 0.026821
Epoch 10 | Batch 30/100 | Loss 3.610166
InnerLR 0.973976
FineTuningLR 0.027023
Epoch 10 | Batch 40/100 | Loss 3.614882
InnerLR 0.973672
FineTuningLR 0.027328
Epoch 10 | Batch 50/100 | Loss 3.639176
InnerLR 0.973469
FineTuningLR 0.027531
Epoch 10 | Batch 60/100 | Loss 3.589946
InnerLR 0.973163
FineTuningLR 0.027837
Epoch 10 | Batch 70/100 | Loss 3.606592
InnerLR 0.972960
FineTuningLR 0.028040
Epoch 10 | Batch 80/100 | Loss 3.532959
InnerLR 0.972654
FineTuningLR 0.028346
Epoch 10 | Batch 90/100 | Loss 3.510639
InnerLR 0.972449
FineTuningLR 0.028551
100 Accuracy = 25.87% +- 1.43%
Epoch 10: 25.87
Epoch 11 | Batch 0/100 | Loss 3.381222
InnerLR 0.972141
FineTuningLR 0.028859
Epoch 11 | Batch 10/100 | Loss 3.274889
InnerLR 0.971935
FineTuningLR 0.029064
Epoch 11 | Batch 20/100 | Loss 3.220960
InnerLR 0.971626
FineTuningLR 0.029374
Epoch 11 | Batch 30/100 | Loss 3.305163
InnerLR 0.971420
FineTuningLR 0.029580
Epoch 11 | Batch 40/100 | Loss 3.302412
InnerLR 0.971110
FineTuningLR 0.029889
Epoch 11 | Batch 50/100 | Loss 3.295529
InnerLR 0.970904
FineTuningLR 0.030096
Epoch 11 | Batch 60/100 | Loss 3.277271
InnerLR 0.970594
FineTuningLR 0.030405
Epoch 11 | Batch 70/100 | Loss 3.302158
InnerLR 0.970389
FineTuningLR 0.030611
Epoch 11 | Batch 80/100 | Loss 3.341842
InnerLR 0.970080
FineTuningLR 0.030920
Epoch 11 | Batch 90/100 | Loss 3.354265
InnerLR 0.969874
FineTuningLR 0.031125
100 Accuracy = 26.68% +- 1.40%
Epoch 11: 26.68
Epoch 12 | Batch 0/100 | Loss 3.647106
InnerLR 0.969567
FineTuningLR 0.031433
Epoch 12 | Batch 10/100 | Loss 3.294737
InnerLR 0.969359
FineTuningLR 0.031641
Epoch 12 | Batch 20/100 | Loss 3.342854
InnerLR 0.969048
FineTuningLR 0.031952
Epoch 12 | Batch 30/100 | Loss 3.328660
InnerLR 0.968841
FineTuningLR 0.032159
Epoch 12 | Batch 40/100 | Loss 3.326703
InnerLR 0.968529
FineTuningLR 0.032471
Epoch 12 | Batch 50/100 | Loss 3.315610
InnerLR 0.968323
FineTuningLR 0.032677
Epoch 12 | Batch 60/100 | Loss 3.283559
InnerLR 0.968012
FineTuningLR 0.032988
Epoch 12 | Batch 70/100 | Loss 3.340320
InnerLR 0.967806
FineTuningLR 0.033194
Epoch 12 | Batch 80/100 | Loss 3.331730
InnerLR 0.967497
FineTuningLR 0.033503
Epoch 12 | Batch 90/100 | Loss 3.315411
InnerLR 0.967292
FineTuningLR 0.033708
100 Accuracy = 26.05% +- 1.39%
Epoch 12: 26.05
Epoch 13 | Batch 0/100 | Loss 3.280301
InnerLR 0.966985
FineTuningLR 0.034015
Epoch 13 | Batch 10/100 | Loss 3.420992
InnerLR 0.966781
FineTuningLR 0.034218
Epoch 13 | Batch 20/100 | Loss 3.327840
InnerLR 0.966476
FineTuningLR 0.034524
Epoch 13 | Batch 30/100 | Loss 3.379277
InnerLR 0.966274
FineTuningLR 0.034726
Epoch 13 | Batch 40/100 | Loss 3.394735
InnerLR 0.965968
FineTuningLR 0.035032
Epoch 13 | Batch 50/100 | Loss 3.339343
InnerLR 0.965763
FineTuningLR 0.035237
Epoch 13 | Batch 60/100 | Loss 3.360427
InnerLR 0.965455
FineTuningLR 0.035545
Epoch 13 | Batch 70/100 | Loss 3.322205
InnerLR 0.965249
FineTuningLR 0.035750
Epoch 13 | Batch 80/100 | Loss 3.335995
InnerLR 0.964941
FineTuningLR 0.036059
Epoch 13 | Batch 90/100 | Loss 3.314758
InnerLR 0.964735
FineTuningLR 0.036265
100 Accuracy = 26.93% +- 1.29%
Epoch 13: 26.93
best model! save...
Epoch 14 | Batch 0/100 | Loss 3.432427
InnerLR 0.964426
FineTuningLR 0.036574
Epoch 14 | Batch 10/100 | Loss 3.182281
InnerLR 0.964219
FineTuningLR 0.036781
Epoch 14 | Batch 20/100 | Loss 3.310432
InnerLR 0.963909
FineTuningLR 0.037091
Epoch 14 | Batch 30/100 | Loss 3.410052
InnerLR 0.963702
FineTuningLR 0.037298
Epoch 14 | Batch 40/100 | Loss 3.359747
InnerLR 0.963391
FineTuningLR 0.037609
Epoch 14 | Batch 50/100 | Loss 3.317916
InnerLR 0.963184
FineTuningLR 0.037816
Epoch 14 | Batch 60/100 | Loss 3.321627
InnerLR 0.962872
FineTuningLR 0.038128
Epoch 14 | Batch 70/100 | Loss 3.318589
InnerLR 0.962666
FineTuningLR 0.038334
Epoch 14 | Batch 80/100 | Loss 3.347187
InnerLR 0.962358
FineTuningLR 0.038642
Epoch 14 | Batch 90/100 | Loss 3.385120
InnerLR 0.962153
FineTuningLR 0.038847
100 Accuracy = 25.95% +- 1.40%
Epoch 14: 25.95
Epoch 15 | Batch 0/100 | Loss 3.266348
InnerLR 0.961847
FineTuningLR 0.039153
Epoch 15 | Batch 10/100 | Loss 3.259697
InnerLR 0.961643
FineTuningLR 0.039357
Epoch 15 | Batch 20/100 | Loss 3.200510
InnerLR 0.961335
FineTuningLR 0.039665
Epoch 15 | Batch 30/100 | Loss 3.177911
InnerLR 0.961128
FineTuningLR 0.039872
Epoch 15 | Batch 40/100 | Loss 3.223717
InnerLR 0.960819
FineTuningLR 0.040181
Epoch 15 | Batch 50/100 | Loss 3.188579
InnerLR 0.960613
FineTuningLR 0.040386
Epoch 15 | Batch 60/100 | Loss 3.193915
InnerLR 0.960304
FineTuningLR 0.040696
Epoch 15 | Batch 70/100 | Loss 3.185390
InnerLR 0.960098
FineTuningLR 0.040902
Epoch 15 | Batch 80/100 | Loss 3.171397
InnerLR 0.959789
FineTuningLR 0.041211
Epoch 15 | Batch 90/100 | Loss 3.163871
InnerLR 0.959583
FineTuningLR 0.041417
100 Accuracy = 26.05% +- 1.48%
Epoch 15: 26.05
Epoch 16 | Batch 0/100 | Loss 3.086761
InnerLR 0.959273
FineTuningLR 0.041727
Epoch 16 | Batch 10/100 | Loss 3.138672
InnerLR 0.959067
FineTuningLR 0.041933
Epoch 16 | Batch 20/100 | Loss 3.078785
InnerLR 0.958757
FineTuningLR 0.042243
Epoch 16 | Batch 30/100 | Loss 3.255727
InnerLR 0.958552
FineTuningLR 0.042448
Epoch 16 | Batch 40/100 | Loss 3.284212
InnerLR 0.958243
FineTuningLR 0.042757
Epoch 16 | Batch 50/100 | Loss 3.295633
InnerLR 0.958037
FineTuningLR 0.042964
Epoch 16 | Batch 60/100 | Loss 3.277062
InnerLR 0.957728
FineTuningLR 0.043272
Epoch 16 | Batch 70/100 | Loss 3.264052
InnerLR 0.957521
FineTuningLR 0.043479
Epoch 16 | Batch 80/100 | Loss 3.270214
InnerLR 0.957210
FineTuningLR 0.043790
Epoch 16 | Batch 90/100 | Loss 3.288254
InnerLR 0.957003
FineTuningLR 0.043997
100 Accuracy = 25.95% +- 1.47%
Epoch 16: 25.95
Epoch 17 | Batch 0/100 | Loss 3.749504
InnerLR 0.956693
FineTuningLR 0.044308
Epoch 17 | Batch 10/100 | Loss 3.007794
InnerLR 0.956485
FineTuningLR 0.044515
Epoch 17 | Batch 20/100 | Loss 3.278280
InnerLR 0.956172
FineTuningLR 0.044828
Epoch 17 | Batch 30/100 | Loss 3.255478
InnerLR 0.955964
FineTuningLR 0.045036
Epoch 17 | Batch 40/100 | Loss 3.251836
InnerLR 0.955653
FineTuningLR 0.045347
Epoch 17 | Batch 50/100 | Loss 3.270011
InnerLR 0.955446
FineTuningLR 0.045554
Epoch 17 | Batch 60/100 | Loss 3.239506
InnerLR 0.955135
FineTuningLR 0.045865
Epoch 17 | Batch 70/100 | Loss 3.224650
InnerLR 0.954928
FineTuningLR 0.046072
Epoch 17 | Batch 80/100 | Loss 3.223678
InnerLR 0.954616
FineTuningLR 0.046384
Epoch 17 | Batch 90/100 | Loss 3.220902
InnerLR 0.954408
FineTuningLR 0.046592
100 Accuracy = 27.59% +- 1.48%
Epoch 17: 27.59
best model! save...
Epoch 18 | Batch 0/100 | Loss 2.817986
InnerLR 0.954096
FineTuningLR 0.046904
Epoch 18 | Batch 10/100 | Loss 3.130020
InnerLR 0.953887
FineTuningLR 0.047113
Epoch 18 | Batch 20/100 | Loss 3.161158
InnerLR 0.953576
FineTuningLR 0.047424
Epoch 18 | Batch 30/100 | Loss 3.166681
InnerLR 0.953368
FineTuningLR 0.047632
Epoch 18 | Batch 40/100 | Loss 3.258165
InnerLR 0.953060
FineTuningLR 0.047940
Epoch 18 | Batch 50/100 | Loss 3.251831
InnerLR 0.952855
FineTuningLR 0.048145
Epoch 18 | Batch 60/100 | Loss 3.301453
InnerLR 0.952548
FineTuningLR 0.048452
Epoch 18 | Batch 70/100 | Loss 3.243155
InnerLR 0.952343
FineTuningLR 0.048657
Epoch 18 | Batch 80/100 | Loss 3.275713
InnerLR 0.952034
FineTuningLR 0.048966
Epoch 18 | Batch 90/100 | Loss 3.224070
InnerLR 0.951828
FineTuningLR 0.049172
100 Accuracy = 26.71% +- 1.21%
Epoch 18: 26.71
Epoch 19 | Batch 0/100 | Loss 4.142845
InnerLR 0.951516
FineTuningLR 0.049484
Epoch 19 | Batch 10/100 | Loss 3.130996
InnerLR 0.951309
FineTuningLR 0.049692
Epoch 19 | Batch 20/100 | Loss 3.162611
InnerLR 0.950998
FineTuningLR 0.050002
Epoch 19 | Batch 30/100 | Loss 3.098377
InnerLR 0.950791
FineTuningLR 0.050209
Epoch 19 | Batch 40/100 | Loss 3.134972
InnerLR 0.950480
FineTuningLR 0.050520
Epoch 19 | Batch 50/100 | Loss 3.108431
InnerLR 0.950272
FineTuningLR 0.050728
Epoch 19 | Batch 60/100 | Loss 3.102022
InnerLR 0.949958
FineTuningLR 0.051042
Epoch 19 | Batch 70/100 | Loss 3.072656
InnerLR 0.949749
FineTuningLR 0.051251
Epoch 19 | Batch 80/100 | Loss 3.072300
InnerLR 0.949433
FineTuningLR 0.051567
Epoch 19 | Batch 90/100 | Loss 3.059502
InnerLR 0.949222
FineTuningLR 0.051778
100 Accuracy = 26.40% +- 1.38%
Epoch 19: 26.40
Epoch 20 | Batch 0/100 | Loss 3.389761
InnerLR 0.948906
FineTuningLR 0.052094
Epoch 20 | Batch 10/100 | Loss 3.095388
InnerLR 0.948698
FineTuningLR 0.052302
Epoch 20 | Batch 20/100 | Loss 3.176255
InnerLR 0.948386
FineTuningLR 0.052614
Epoch 20 | Batch 30/100 | Loss 3.181613
InnerLR 0.948178
FineTuningLR 0.052822
Epoch 20 | Batch 40/100 | Loss 3.157582
InnerLR 0.947865
FineTuningLR 0.053135
Epoch 20 | Batch 50/100 | Loss 3.114229
InnerLR 0.947657
FineTuningLR 0.053343
Epoch 20 | Batch 60/100 | Loss 3.103196
InnerLR 0.947343
FineTuningLR 0.053657
Epoch 20 | Batch 70/100 | Loss 3.078251
InnerLR 0.947133
FineTuningLR 0.053867
Epoch 20 | Batch 80/100 | Loss 3.085542
InnerLR 0.946817
FineTuningLR 0.054183
Epoch 20 | Batch 90/100 | Loss 3.042571
InnerLR 0.946607
FineTuningLR 0.054393
100 Accuracy = 25.12% +- 1.47%
Epoch 20: 25.12
Epoch 21 | Batch 0/100 | Loss 2.615516
InnerLR 0.946291
FineTuningLR 0.054709
Epoch 21 | Batch 10/100 | Loss 3.094981
InnerLR 0.946079
FineTuningLR 0.054921
Epoch 21 | Batch 20/100 | Loss 3.020391
InnerLR 0.945761
FineTuningLR 0.055239
Epoch 21 | Batch 30/100 | Loss 3.090053
InnerLR 0.945549
FineTuningLR 0.055451
Epoch 21 | Batch 40/100 | Loss 3.075322
InnerLR 0.945232
FineTuningLR 0.055768
Epoch 21 | Batch 50/100 | Loss 3.107709
InnerLR 0.945021
FineTuningLR 0.055979
Epoch 21 | Batch 60/100 | Loss 3.108963
InnerLR 0.944707
FineTuningLR 0.056293
Epoch 21 | Batch 70/100 | Loss 3.065004
InnerLR 0.944497
FineTuningLR 0.056503
Epoch 21 | Batch 80/100 | Loss 3.039825
InnerLR 0.944184
FineTuningLR 0.056816
Epoch 21 | Batch 90/100 | Loss 3.055467
InnerLR 0.943975
FineTuningLR 0.057025
100 Accuracy = 26.68% +- 1.46%
Epoch 21: 26.68
Epoch 22 | Batch 0/100 | Loss 3.729247
InnerLR 0.943665
FineTuningLR 0.057335
Epoch 22 | Batch 10/100 | Loss 3.119620
InnerLR 0.943458
FineTuningLR 0.057542
Epoch 22 | Batch 20/100 | Loss 2.940545
InnerLR 0.943148
FineTuningLR 0.057852
Epoch 22 | Batch 30/100 | Loss 2.982054
InnerLR 0.942941
FineTuningLR 0.058059
Epoch 22 | Batch 40/100 | Loss 3.018315
InnerLR 0.942629
FineTuningLR 0.058371
Epoch 22 | Batch 50/100 | Loss 3.023179
InnerLR 0.942421
FineTuningLR 0.058579
Epoch 22 | Batch 60/100 | Loss 3.007657
InnerLR 0.942107
FineTuningLR 0.058893
Epoch 22 | Batch 70/100 | Loss 2.971138
InnerLR 0.941897
FineTuningLR 0.059103
Epoch 22 | Batch 80/100 | Loss 2.944849
InnerLR 0.941582
FineTuningLR 0.059418
Epoch 22 | Batch 90/100 | Loss 2.981717
InnerLR 0.941372
FineTuningLR 0.059628
100 Accuracy = 26.13% +- 1.48%
Epoch 22: 26.13
Epoch 23 | Batch 0/100 | Loss 2.976604
InnerLR 0.941058
FineTuningLR 0.059942
Epoch 23 | Batch 10/100 | Loss 3.261172
InnerLR 0.940848
FineTuningLR 0.060152
Epoch 23 | Batch 20/100 | Loss 3.111395
InnerLR 0.940536
FineTuningLR 0.060464
Epoch 23 | Batch 30/100 | Loss 3.047533
InnerLR 0.940327
FineTuningLR 0.060674
Epoch 23 | Batch 40/100 | Loss 3.045629
InnerLR 0.940009
FineTuningLR 0.060991
Epoch 23 | Batch 50/100 | Loss 3.017620
InnerLR 0.939796
FineTuningLR 0.061204
Epoch 23 | Batch 60/100 | Loss 2.982606
InnerLR 0.939477
FineTuningLR 0.061523
Epoch 23 | Batch 70/100 | Loss 2.954252
InnerLR 0.939265
FineTuningLR 0.061735
Epoch 23 | Batch 80/100 | Loss 2.946811
InnerLR 0.938948
FineTuningLR 0.062052
Epoch 23 | Batch 90/100 | Loss 2.939058
InnerLR 0.938737
FineTuningLR 0.062263
100 Accuracy = 27.61% +- 1.44%
Epoch 23: 27.61
best model! save...
Epoch 24 | Batch 0/100 | Loss 2.369978
InnerLR 0.938420
FineTuningLR 0.062580
Epoch 24 | Batch 10/100 | Loss 2.994318
InnerLR 0.938209
FineTuningLR 0.062791
Epoch 24 | Batch 20/100 | Loss 2.961784
InnerLR 0.937891
FineTuningLR 0.063109
Epoch 24 | Batch 30/100 | Loss 2.965646
InnerLR 0.937681
FineTuningLR 0.063319
Epoch 24 | Batch 40/100 | Loss 2.955367
InnerLR 0.937364
FineTuningLR 0.063636
Epoch 24 | Batch 50/100 | Loss 2.995338
InnerLR 0.937152
FineTuningLR 0.063848
Epoch 24 | Batch 60/100 | Loss 2.982169
InnerLR 0.936833
FineTuningLR 0.064167
Epoch 24 | Batch 70/100 | Loss 3.007038
InnerLR 0.936620
FineTuningLR 0.064380
Epoch 24 | Batch 80/100 | Loss 3.026255
InnerLR 0.936303
FineTuningLR 0.064697
Epoch 24 | Batch 90/100 | Loss 3.055196
InnerLR 0.936094
FineTuningLR 0.064906
100 Accuracy = 26.37% +- 1.32%
Epoch 24: 26.37
Epoch 25 | Batch 0/100 | Loss 2.937286
InnerLR 0.935781
FineTuningLR 0.065219
Epoch 25 | Batch 10/100 | Loss 2.945601
InnerLR 0.935571
FineTuningLR 0.065429
Epoch 25 | Batch 20/100 | Loss 2.846436
InnerLR 0.935253
FineTuningLR 0.065747
Epoch 25 | Batch 30/100 | Loss 2.887749
InnerLR 0.935041
FineTuningLR 0.065959
Epoch 25 | Batch 40/100 | Loss 2.855429
InnerLR 0.934724
FineTuningLR 0.066276
Epoch 25 | Batch 50/100 | Loss 2.876294
InnerLR 0.934514
FineTuningLR 0.066486
Epoch 25 | Batch 60/100 | Loss 2.872307
InnerLR 0.934199
FineTuningLR 0.066801
Epoch 25 | Batch 70/100 | Loss 2.889949
InnerLR 0.933988
FineTuningLR 0.067012
Epoch 25 | Batch 80/100 | Loss 2.886319
InnerLR 0.933672
FineTuningLR 0.067328
Epoch 25 | Batch 90/100 | Loss 2.911981
InnerLR 0.933461
FineTuningLR 0.067538
100 Accuracy = 26.60% +- 1.41%
Epoch 25: 26.60
Epoch 26 | Batch 0/100 | Loss 2.616609
InnerLR 0.933146
FineTuningLR 0.067854
Epoch 26 | Batch 10/100 | Loss 2.750560
InnerLR 0.932936
FineTuningLR 0.068064
Epoch 26 | Batch 20/100 | Loss 2.913838
InnerLR 0.932622
FineTuningLR 0.068378
Epoch 26 | Batch 30/100 | Loss 2.942141
InnerLR 0.932413
FineTuningLR 0.068586
Epoch 26 | Batch 40/100 | Loss 3.021274
InnerLR 0.932100
FineTuningLR 0.068899
Epoch 26 | Batch 50/100 | Loss 3.033171
InnerLR 0.931892
FineTuningLR 0.069108
Epoch 26 | Batch 60/100 | Loss 3.031360
InnerLR 0.931579
FineTuningLR 0.069421
Epoch 26 | Batch 70/100 | Loss 2.986437
InnerLR 0.931368
FineTuningLR 0.069632
Epoch 26 | Batch 80/100 | Loss 2.975878
InnerLR 0.931053
FineTuningLR 0.069946
Epoch 26 | Batch 90/100 | Loss 2.968235
InnerLR 0.930842
FineTuningLR 0.070157
100 Accuracy = 27.25% +- 1.58%
Epoch 26: 27.25
Epoch 27 | Batch 0/100 | Loss 2.577719
InnerLR 0.930527
FineTuningLR 0.070473
Epoch 27 | Batch 10/100 | Loss 3.041115
InnerLR 0.930317
FineTuningLR 0.070683
Epoch 27 | Batch 20/100 | Loss 3.167232
InnerLR 0.930003
FineTuningLR 0.070997
Epoch 27 | Batch 30/100 | Loss 3.091879
InnerLR 0.929795
FineTuningLR 0.071205
Epoch 27 | Batch 40/100 | Loss 3.050292
InnerLR 0.929482
FineTuningLR 0.071518
Epoch 27 | Batch 50/100 | Loss 3.023012
InnerLR 0.929271
FineTuningLR 0.071729
Epoch 27 | Batch 60/100 | Loss 3.073602
InnerLR 0.928954
FineTuningLR 0.072045
Epoch 27 | Batch 70/100 | Loss 3.076259
InnerLR 0.928745
FineTuningLR 0.072254
Epoch 27 | Batch 80/100 | Loss 3.059039
InnerLR 0.928433
FineTuningLR 0.072567
Epoch 27 | Batch 90/100 | Loss 3.029396
InnerLR 0.928225
FineTuningLR 0.072775
100 Accuracy = 26.17% +- 1.29%
Epoch 27: 26.17
Epoch 28 | Batch 0/100 | Loss 2.502746
InnerLR 0.927914
FineTuningLR 0.073086
Epoch 28 | Batch 10/100 | Loss 2.945515
InnerLR 0.927705
FineTuningLR 0.073295
Epoch 28 | Batch 20/100 | Loss 2.948753
InnerLR 0.927391
FineTuningLR 0.073609
Epoch 28 | Batch 30/100 | Loss 2.953729
InnerLR 0.927182
FineTuningLR 0.073818
Epoch 28 | Batch 40/100 | Loss 2.915333
InnerLR 0.926867
FineTuningLR 0.074133
Epoch 28 | Batch 50/100 | Loss 2.987797
InnerLR 0.926660
FineTuningLR 0.074340
Epoch 28 | Batch 60/100 | Loss 2.950064
InnerLR 0.926350
FineTuningLR 0.074650
Epoch 28 | Batch 70/100 | Loss 2.934496
InnerLR 0.926142
FineTuningLR 0.074858
Epoch 28 | Batch 80/100 | Loss 2.927202
InnerLR 0.925828
FineTuningLR 0.075172
Epoch 28 | Batch 90/100 | Loss 2.916420
InnerLR 0.925618
FineTuningLR 0.075382
100 Accuracy = 27.31% +- 1.45%
Epoch 28: 27.31
Epoch 29 | Batch 0/100 | Loss 3.113286
InnerLR 0.925303
FineTuningLR 0.075697
Epoch 29 | Batch 10/100 | Loss 2.976884
InnerLR 0.925092
FineTuningLR 0.075908
Epoch 29 | Batch 20/100 | Loss 2.856351
InnerLR 0.924773
FineTuningLR 0.076227
Epoch 29 | Batch 30/100 | Loss 2.834568
InnerLR 0.924563
FineTuningLR 0.076437
Epoch 29 | Batch 40/100 | Loss 2.890924
InnerLR 0.924249
FineTuningLR 0.076751
Epoch 29 | Batch 50/100 | Loss 2.931540
InnerLR 0.924040
FineTuningLR 0.076960
Epoch 29 | Batch 60/100 | Loss 2.878574
InnerLR 0.923726
FineTuningLR 0.077274
Epoch 29 | Batch 70/100 | Loss 2.880019
InnerLR 0.923515
FineTuningLR 0.077485
Epoch 29 | Batch 80/100 | Loss 2.874426
InnerLR 0.923198
FineTuningLR 0.077802
Epoch 29 | Batch 90/100 | Loss 2.877580
InnerLR 0.922988
FineTuningLR 0.078012
100 Accuracy = 26.83% +- 1.39%
Epoch 29: 26.83
Epoch 30 | Batch 0/100 | Loss 2.095023
InnerLR 0.922673
FineTuningLR 0.078327
Epoch 30 | Batch 10/100 | Loss 2.954971
InnerLR 0.922464
FineTuningLR 0.078536
Epoch 30 | Batch 20/100 | Loss 2.943720
InnerLR 0.922148
FineTuningLR 0.078852
Epoch 30 | Batch 30/100 | Loss 2.867671
InnerLR 0.921937
FineTuningLR 0.079063
Epoch 30 | Batch 40/100 | Loss 2.846941
InnerLR 0.921617
FineTuningLR 0.079383
Epoch 30 | Batch 50/100 | Loss 2.846965
InnerLR 0.921403
FineTuningLR 0.079597
Epoch 30 | Batch 60/100 | Loss 2.849248
InnerLR 0.921083
FineTuningLR 0.079917
Epoch 30 | Batch 70/100 | Loss 2.874463
InnerLR 0.920871
FineTuningLR 0.080129
Epoch 30 | Batch 80/100 | Loss 2.850815
InnerLR 0.920553
FineTuningLR 0.080447
Epoch 30 | Batch 90/100 | Loss 2.846933
InnerLR 0.920341
FineTuningLR 0.080659
100 Accuracy = 26.40% +- 1.41%
Epoch 30: 26.40
Epoch 31 | Batch 0/100 | Loss 2.994494
InnerLR 0.920024
FineTuningLR 0.080976
Epoch 31 | Batch 10/100 | Loss 3.042470
InnerLR 0.919813
FineTuningLR 0.081187
Epoch 31 | Batch 20/100 | Loss 2.935451
InnerLR 0.919498
FineTuningLR 0.081502
Epoch 31 | Batch 30/100 | Loss 2.903487
InnerLR 0.919286
FineTuningLR 0.081714
Epoch 31 | Batch 40/100 | Loss 2.826904
InnerLR 0.918968
FineTuningLR 0.082032
Epoch 31 | Batch 50/100 | Loss 2.849373
InnerLR 0.918755
FineTuningLR 0.082245
Epoch 31 | Batch 60/100 | Loss 2.804157
InnerLR 0.918438
FineTuningLR 0.082562
Epoch 31 | Batch 70/100 | Loss 2.827548
InnerLR 0.918227
FineTuningLR 0.082773
Epoch 31 | Batch 80/100 | Loss 2.844469
InnerLR 0.917912
FineTuningLR 0.083089
Epoch 31 | Batch 90/100 | Loss 2.845814
InnerLR 0.917701
FineTuningLR 0.083299
100 Accuracy = 28.21% +- 1.34%
Epoch 31: 28.21
best model! save...
Epoch 32 | Batch 0/100 | Loss 2.504560
InnerLR 0.917386
FineTuningLR 0.083614
Epoch 32 | Batch 10/100 | Loss 2.960327
InnerLR 0.917175
FineTuningLR 0.083825
Epoch 32 | Batch 20/100 | Loss 2.957528
InnerLR 0.916859
FineTuningLR 0.084141
Epoch 32 | Batch 30/100 | Loss 2.823482
InnerLR 0.916647
FineTuningLR 0.084353
Epoch 32 | Batch 40/100 | Loss 2.833814
InnerLR 0.916329
FineTuningLR 0.084671
Epoch 32 | Batch 50/100 | Loss 2.815686
InnerLR 0.916118
FineTuningLR 0.084882
Epoch 32 | Batch 60/100 | Loss 2.855651
InnerLR 0.915802
FineTuningLR 0.085198
Epoch 32 | Batch 70/100 | Loss 2.873478
InnerLR 0.915592
FineTuningLR 0.085408
Epoch 32 | Batch 80/100 | Loss 2.907157
InnerLR 0.915278
FineTuningLR 0.085722
Epoch 32 | Batch 90/100 | Loss 2.897628
InnerLR 0.915068
FineTuningLR 0.085932
100 Accuracy = 28.60% +- 1.65%
Epoch 32: 28.60
best model! save...
Epoch 33 | Batch 0/100 | Loss 3.097983
InnerLR 0.914752
FineTuningLR 0.086248
Epoch 33 | Batch 10/100 | Loss 2.521183
InnerLR 0.914540
FineTuningLR 0.086460
Epoch 33 | Batch 20/100 | Loss 2.704397
InnerLR 0.914223
FineTuningLR 0.086777
Epoch 33 | Batch 30/100 | Loss 2.644310
InnerLR 0.914012
FineTuningLR 0.086988
Epoch 33 | Batch 40/100 | Loss 2.660602
InnerLR 0.913692
FineTuningLR 0.087308
Epoch 33 | Batch 50/100 | Loss 2.711568
InnerLR 0.913478
FineTuningLR 0.087522
Epoch 33 | Batch 60/100 | Loss 2.715277
InnerLR 0.913158
FineTuningLR 0.087842
Epoch 33 | Batch 70/100 | Loss 2.718301
InnerLR 0.912943
FineTuningLR 0.088057
Epoch 33 | Batch 80/100 | Loss 2.737257
InnerLR 0.912621
FineTuningLR 0.088379
Epoch 33 | Batch 90/100 | Loss 2.745286
InnerLR 0.912406
FineTuningLR 0.088594
100 Accuracy = 27.97% +- 1.55%
Epoch 33: 27.97
Epoch 34 | Batch 0/100 | Loss 2.564942
InnerLR 0.912085
FineTuningLR 0.088916
Epoch 34 | Batch 10/100 | Loss 2.777882
InnerLR 0.911872
FineTuningLR 0.089128
Epoch 34 | Batch 20/100 | Loss 2.792996
InnerLR 0.911554
FineTuningLR 0.089446
Epoch 34 | Batch 30/100 | Loss 2.805267
InnerLR 0.911342
FineTuningLR 0.089658
Epoch 34 | Batch 40/100 | Loss 2.765800
InnerLR 0.911023
FineTuningLR 0.089977
Epoch 34 | Batch 50/100 | Loss 2.798173
InnerLR 0.910809
FineTuningLR 0.090191
Epoch 34 | Batch 60/100 | Loss 2.779924
InnerLR 0.910488
FineTuningLR 0.090512
Epoch 34 | Batch 70/100 | Loss 2.796041
InnerLR 0.910276
FineTuningLR 0.090724
Epoch 34 | Batch 80/100 | Loss 2.779362
InnerLR 0.909957
FineTuningLR 0.091043
Epoch 34 | Batch 90/100 | Loss 2.770444
InnerLR 0.909745
FineTuningLR 0.091255
100 Accuracy = 26.79% +- 1.66%
Epoch 34: 26.79
Epoch 35 | Batch 0/100 | Loss 2.465906
InnerLR 0.909427
FineTuningLR 0.091573
Epoch 35 | Batch 10/100 | Loss 2.667227
InnerLR 0.909215
FineTuningLR 0.091785
Epoch 35 | Batch 20/100 | Loss 2.681448
InnerLR 0.908900
FineTuningLR 0.092100
Epoch 35 | Batch 30/100 | Loss 2.684585
InnerLR 0.908688
FineTuningLR 0.092311
Epoch 35 | Batch 40/100 | Loss 2.723849
InnerLR 0.908372
FineTuningLR 0.092628
Epoch 35 | Batch 50/100 | Loss 2.712291
InnerLR 0.908162
FineTuningLR 0.092838
Epoch 35 | Batch 60/100 | Loss 2.692154
InnerLR 0.907848
FineTuningLR 0.093152
Epoch 35 | Batch 70/100 | Loss 2.696014
InnerLR 0.907640
FineTuningLR 0.093360
Epoch 35 | Batch 80/100 | Loss 2.742492
InnerLR 0.907326
FineTuningLR 0.093674
Epoch 35 | Batch 90/100 | Loss 2.749319
InnerLR 0.907117
FineTuningLR 0.093883
100 Accuracy = 28.24% +- 1.49%
Epoch 35: 28.24
Epoch 36 | Batch 0/100 | Loss 2.833692
InnerLR 0.906802
FineTuningLR 0.094198
Epoch 36 | Batch 10/100 | Loss 2.567643
InnerLR 0.906592
FineTuningLR 0.094408
Epoch 36 | Batch 20/100 | Loss 2.730406
InnerLR 0.906274
FineTuningLR 0.094726
Epoch 36 | Batch 30/100 | Loss 2.773005
InnerLR 0.906063
FineTuningLR 0.094937
Epoch 36 | Batch 40/100 | Loss 2.751985
InnerLR 0.905745
FineTuningLR 0.095256
Epoch 36 | Batch 50/100 | Loss 2.748549
InnerLR 0.905533
FineTuningLR 0.095468
Epoch 36 | Batch 60/100 | Loss 2.759865
InnerLR 0.905215
FineTuningLR 0.095785
Epoch 36 | Batch 70/100 | Loss 2.742180
InnerLR 0.905003
FineTuningLR 0.095997
Epoch 36 | Batch 80/100 | Loss 2.728124
InnerLR 0.904684
FineTuningLR 0.096317
Epoch 36 | Batch 90/100 | Loss 2.725517
InnerLR 0.904471
FineTuningLR 0.096529
100 Accuracy = 28.12% +- 1.68%
Epoch 36: 28.12
Epoch 37 | Batch 0/100 | Loss 3.323389
InnerLR 0.904151
FineTuningLR 0.096849
Epoch 37 | Batch 10/100 | Loss 2.720141
InnerLR 0.903938
FineTuningLR 0.097062
Epoch 37 | Batch 20/100 | Loss 2.794161
InnerLR 0.903617
FineTuningLR 0.097384
Epoch 37 | Batch 30/100 | Loss 2.742948
InnerLR 0.903402
FineTuningLR 0.097598
Epoch 37 | Batch 40/100 | Loss 2.707677
InnerLR 0.903082
FineTuningLR 0.097918
Epoch 37 | Batch 50/100 | Loss 2.693192
InnerLR 0.902869
FineTuningLR 0.098131
Epoch 37 | Batch 60/100 | Loss 2.686232
InnerLR 0.902550
FineTuningLR 0.098450
Epoch 37 | Batch 70/100 | Loss 2.670278
InnerLR 0.902335
FineTuningLR 0.098665
Epoch 37 | Batch 80/100 | Loss 2.685886
InnerLR 0.902014
FineTuningLR 0.098986
Epoch 37 | Batch 90/100 | Loss 2.703190
InnerLR 0.901802
FineTuningLR 0.099198
100 Accuracy = 28.27% +- 1.61%
Epoch 37: 28.27
Epoch 38 | Batch 0/100 | Loss 1.646665
InnerLR 0.901483
FineTuningLR 0.099517
Epoch 38 | Batch 10/100 | Loss 2.692950
InnerLR 0.901270
FineTuningLR 0.099730
Epoch 38 | Batch 20/100 | Loss 2.641119
InnerLR 0.900949
FineTuningLR 0.100052
Epoch 38 | Batch 30/100 | Loss 2.695568
InnerLR 0.900734
FineTuningLR 0.100266
Epoch 38 | Batch 40/100 | Loss 2.714377
InnerLR 0.900415
FineTuningLR 0.100585
Epoch 38 | Batch 50/100 | Loss 2.748839
InnerLR 0.900204
FineTuningLR 0.100796
Epoch 38 | Batch 60/100 | Loss 2.739844
InnerLR 0.899885
FineTuningLR 0.101115
Epoch 38 | Batch 70/100 | Loss 2.738693
InnerLR 0.899672
FineTuningLR 0.101328
Epoch 38 | Batch 80/100 | Loss 2.715900
InnerLR 0.899353
FineTuningLR 0.101648
Epoch 38 | Batch 90/100 | Loss 2.715324
InnerLR 0.899140
FineTuningLR 0.101861
100 Accuracy = 27.89% +- 1.47%
Epoch 38: 27.89
Epoch 39 | Batch 0/100 | Loss 2.731819
InnerLR 0.898818
FineTuningLR 0.102182
Epoch 39 | Batch 10/100 | Loss 2.602483
InnerLR 0.898605
FineTuningLR 0.102395
Epoch 39 | Batch 20/100 | Loss 2.691124
InnerLR 0.898286
FineTuningLR 0.102714
Epoch 39 | Batch 30/100 | Loss 2.718683
InnerLR 0.898074
FineTuningLR 0.102927
Epoch 39 | Batch 40/100 | Loss 2.717189
InnerLR 0.897755
FineTuningLR 0.103245
Epoch 39 | Batch 50/100 | Loss 2.671977
InnerLR 0.897543
FineTuningLR 0.103457
Epoch 39 | Batch 60/100 | Loss 2.677817
InnerLR 0.897226
FineTuningLR 0.103775
Epoch 39 | Batch 70/100 | Loss 2.658350
InnerLR 0.897012
FineTuningLR 0.103988
Epoch 39 | Batch 80/100 | Loss 2.674790
InnerLR 0.896691
FineTuningLR 0.104309
Epoch 39 | Batch 90/100 | Loss 2.662396
InnerLR 0.896478
FineTuningLR 0.104522
100 Accuracy = 28.35% +- 1.48%
Epoch 39: 28.35
Epoch 40 | Batch 0/100 | Loss 2.421943
InnerLR 0.896156
FineTuningLR 0.104844
Epoch 40 | Batch 10/100 | Loss 2.656360
InnerLR 0.895941
FineTuningLR 0.105059
Epoch 40 | Batch 20/100 | Loss 2.742384
InnerLR 0.895619
FineTuningLR 0.105381
Epoch 40 | Batch 30/100 | Loss 2.665328
InnerLR 0.895405
FineTuningLR 0.105595
Epoch 40 | Batch 40/100 | Loss 2.722367
InnerLR 0.895083
FineTuningLR 0.105917
Epoch 40 | Batch 50/100 | Loss 2.678568
InnerLR 0.894869
FineTuningLR 0.106131
Epoch 40 | Batch 60/100 | Loss 2.676377
InnerLR 0.894549
FineTuningLR 0.106451
Epoch 40 | Batch 70/100 | Loss 2.676462
InnerLR 0.894336
FineTuningLR 0.106664
Epoch 40 | Batch 80/100 | Loss 2.692779
InnerLR 0.894017
FineTuningLR 0.106984
Epoch 40 | Batch 90/100 | Loss 2.672689
InnerLR 0.893804
FineTuningLR 0.107196
100 Accuracy = 28.28% +- 1.38%
Epoch 40: 28.28
Epoch 41 | Batch 0/100 | Loss 3.059835
InnerLR 0.893484
FineTuningLR 0.107517
Epoch 41 | Batch 10/100 | Loss 2.748815
InnerLR 0.893269
FineTuningLR 0.107732
Epoch 41 | Batch 20/100 | Loss 2.616130
InnerLR 0.892946
FineTuningLR 0.108054
Epoch 41 | Batch 30/100 | Loss 2.603770
InnerLR 0.892731
FineTuningLR 0.108270
Epoch 41 | Batch 40/100 | Loss 2.560253
InnerLR 0.892409
FineTuningLR 0.108591
Epoch 41 | Batch 50/100 | Loss 2.564596
InnerLR 0.892196
FineTuningLR 0.108804
Epoch 41 | Batch 60/100 | Loss 2.591207
InnerLR 0.891877
FineTuningLR 0.109123
Epoch 41 | Batch 70/100 | Loss 2.601236
InnerLR 0.891664
FineTuningLR 0.109336
Epoch 41 | Batch 80/100 | Loss 2.602594
InnerLR 0.891344
FineTuningLR 0.109656
Epoch 41 | Batch 90/100 | Loss 2.590606
InnerLR 0.891130
FineTuningLR 0.109871
100 Accuracy = 28.25% +- 1.40%
Epoch 41: 28.25
Epoch 42 | Batch 0/100 | Loss 2.475192
InnerLR 0.890807
FineTuningLR 0.110194
Epoch 42 | Batch 10/100 | Loss 2.401548
InnerLR 0.890590
FineTuningLR 0.110411
Epoch 42 | Batch 20/100 | Loss 2.485368
InnerLR 0.890266
FineTuningLR 0.110734
Epoch 42 | Batch 30/100 | Loss 2.533741
InnerLR 0.890051
FineTuningLR 0.110949
Epoch 42 | Batch 40/100 | Loss 2.581185
InnerLR 0.889727
FineTuningLR 0.111273
Epoch 42 | Batch 50/100 | Loss 2.628902
InnerLR 0.889512
FineTuningLR 0.111488
Epoch 42 | Batch 60/100 | Loss 2.628099
InnerLR 0.889190
FineTuningLR 0.111810
Epoch 42 | Batch 70/100 | Loss 2.650387
InnerLR 0.888975
FineTuningLR 0.112025
Epoch 42 | Batch 80/100 | Loss 2.647592
InnerLR 0.888654
FineTuningLR 0.112346
Epoch 42 | Batch 90/100 | Loss 2.640686
InnerLR 0.888441
FineTuningLR 0.112559
100 Accuracy = 27.28% +- 1.48%
Epoch 42: 27.28
Epoch 43 | Batch 0/100 | Loss 2.768357
InnerLR 0.888120
FineTuningLR 0.112880
Epoch 43 | Batch 10/100 | Loss 2.457077
InnerLR 0.887906
FineTuningLR 0.113094
Epoch 43 | Batch 20/100 | Loss 2.549088
InnerLR 0.887587
FineTuningLR 0.113413
Epoch 43 | Batch 30/100 | Loss 2.594114
InnerLR 0.887375
FineTuningLR 0.113625
Epoch 43 | Batch 40/100 | Loss 2.613521
InnerLR 0.887057
FineTuningLR 0.113944
Epoch 43 | Batch 50/100 | Loss 2.616886
InnerLR 0.886842
FineTuningLR 0.114158
Epoch 43 | Batch 60/100 | Loss 2.622092
InnerLR 0.886521
FineTuningLR 0.114479
Epoch 43 | Batch 70/100 | Loss 2.649912
InnerLR 0.886308
FineTuningLR 0.114692
Epoch 43 | Batch 80/100 | Loss 2.655681
InnerLR 0.885990
FineTuningLR 0.115010
Epoch 43 | Batch 90/100 | Loss 2.638683
InnerLR 0.885776
FineTuningLR 0.115224
100 Accuracy = 29.59% +- 1.67%
Epoch 43: 29.59
best model! save...
Epoch 44 | Batch 0/100 | Loss 2.722512
InnerLR 0.885455
FineTuningLR 0.115545
Epoch 44 | Batch 10/100 | Loss 2.861372
InnerLR 0.885242
FineTuningLR 0.115758
Epoch 44 | Batch 20/100 | Loss 2.747774
InnerLR 0.884923
FineTuningLR 0.116077
Epoch 44 | Batch 30/100 | Loss 2.717074
InnerLR 0.884708
FineTuningLR 0.116292
Epoch 44 | Batch 40/100 | Loss 2.614069
InnerLR 0.884384
FineTuningLR 0.116616
Epoch 44 | Batch 50/100 | Loss 2.563668
InnerLR 0.884168
FineTuningLR 0.116832
Epoch 44 | Batch 60/100 | Loss 2.582893
InnerLR 0.883839
FineTuningLR 0.117161
Epoch 44 | Batch 70/100 | Loss 2.567098
InnerLR 0.883622
FineTuningLR 0.117378
Epoch 44 | Batch 80/100 | Loss 2.575715
InnerLR 0.883296
FineTuningLR 0.117704
Epoch 44 | Batch 90/100 | Loss 2.568845
InnerLR 0.883079
FineTuningLR 0.117921
100 Accuracy = 27.59% +- 1.43%
Epoch 44: 27.59
Epoch 45 | Batch 0/100 | Loss 2.008718
InnerLR 0.882754
FineTuningLR 0.118246
Epoch 45 | Batch 10/100 | Loss 2.498561
InnerLR 0.882537
FineTuningLR 0.118463
Epoch 45 | Batch 20/100 | Loss 2.527858
InnerLR 0.882213
FineTuningLR 0.118787
Epoch 45 | Batch 30/100 | Loss 2.561225
InnerLR 0.881997
FineTuningLR 0.119003
Epoch 45 | Batch 40/100 | Loss 2.520108
InnerLR 0.881674
FineTuningLR 0.119326
Epoch 45 | Batch 50/100 | Loss 2.550456
InnerLR 0.881458
FineTuningLR 0.119542
Epoch 45 | Batch 60/100 | Loss 2.567825
InnerLR 0.881138
FineTuningLR 0.119862
Epoch 45 | Batch 70/100 | Loss 2.579426
InnerLR 0.880924
FineTuningLR 0.120076
Epoch 45 | Batch 80/100 | Loss 2.557336
InnerLR 0.880601
FineTuningLR 0.120399
Epoch 45 | Batch 90/100 | Loss 2.569930
InnerLR 0.880386
FineTuningLR 0.120614
100 Accuracy = 28.73% +- 1.58%
Epoch 45: 28.73
Epoch 46 | Batch 0/100 | Loss 2.923126
InnerLR 0.880064
FineTuningLR 0.120936
Epoch 46 | Batch 10/100 | Loss 2.628250
InnerLR 0.879852
FineTuningLR 0.121148
Epoch 46 | Batch 20/100 | Loss 2.581728
InnerLR 0.879535
FineTuningLR 0.121465
Epoch 46 | Batch 30/100 | Loss 2.540378
InnerLR 0.879321
FineTuningLR 0.121679
Epoch 46 | Batch 40/100 | Loss 2.581046
InnerLR 0.879003
FineTuningLR 0.121997
Epoch 46 | Batch 50/100 | Loss 2.531638
InnerLR 0.878791
FineTuningLR 0.122210
Epoch 46 | Batch 60/100 | Loss 2.541914
InnerLR 0.878467
FineTuningLR 0.122533
Epoch 46 | Batch 70/100 | Loss 2.576224
InnerLR 0.878253
FineTuningLR 0.122748
Epoch 46 | Batch 80/100 | Loss 2.584154
InnerLR 0.877933
FineTuningLR 0.123067
Epoch 46 | Batch 90/100 | Loss 2.582599
InnerLR 0.877719
FineTuningLR 0.123281
100 Accuracy = 27.96% +- 1.59%
Epoch 46: 27.96
Epoch 47 | Batch 0/100 | Loss 1.989838
InnerLR 0.877398
FineTuningLR 0.123602
Epoch 47 | Batch 10/100 | Loss 2.488093
InnerLR 0.877183
FineTuningLR 0.123817
Epoch 47 | Batch 20/100 | Loss 2.489216
InnerLR 0.876859
FineTuningLR 0.124141
Epoch 47 | Batch 30/100 | Loss 2.517299
InnerLR 0.876642
FineTuningLR 0.124358
Epoch 47 | Batch 40/100 | Loss 2.495461
InnerLR 0.876316
FineTuningLR 0.124684
Epoch 47 | Batch 50/100 | Loss 2.523795
InnerLR 0.876098
FineTuningLR 0.124902
Epoch 47 | Batch 60/100 | Loss 2.474502
InnerLR 0.875772
FineTuningLR 0.125228
Epoch 47 | Batch 70/100 | Loss 2.514939
InnerLR 0.875555
FineTuningLR 0.125445
Epoch 47 | Batch 80/100 | Loss 2.530924
InnerLR 0.875230
FineTuningLR 0.125770
Epoch 47 | Batch 90/100 | Loss 2.532660
InnerLR 0.875013
FineTuningLR 0.125987
100 Accuracy = 28.85% +- 1.54%
Epoch 47: 28.85
Epoch 48 | Batch 0/100 | Loss 3.206244
InnerLR 0.874688
FineTuningLR 0.126312
Epoch 48 | Batch 10/100 | Loss 2.498303
InnerLR 0.874474
FineTuningLR 0.126526
Epoch 48 | Batch 20/100 | Loss 2.596688
InnerLR 0.874152
FineTuningLR 0.126848
Epoch 48 | Batch 30/100 | Loss 2.533343
InnerLR 0.873937
FineTuningLR 0.127063
Epoch 48 | Batch 40/100 | Loss 2.517729
InnerLR 0.873616
FineTuningLR 0.127384
Epoch 48 | Batch 50/100 | Loss 2.523862
InnerLR 0.873400
FineTuningLR 0.127600
Epoch 48 | Batch 60/100 | Loss 2.549723
InnerLR 0.873080
FineTuningLR 0.127920
Epoch 48 | Batch 70/100 | Loss 2.521458
InnerLR 0.872867
FineTuningLR 0.128134
Epoch 48 | Batch 80/100 | Loss 2.504154
InnerLR 0.872547
FineTuningLR 0.128453
Epoch 48 | Batch 90/100 | Loss 2.486568
InnerLR 0.872334
FineTuningLR 0.128666
100 Accuracy = 27.20% +- 1.41%
Epoch 48: 27.20
Epoch 49 | Batch 0/100 | Loss 2.040623
InnerLR 0.872013
FineTuningLR 0.128987
Epoch 49 | Batch 10/100 | Loss 2.584830
InnerLR 0.871800
FineTuningLR 0.129200
Epoch 49 | Batch 20/100 | Loss 2.534522
InnerLR 0.871479
FineTuningLR 0.129521
Epoch 49 | Batch 30/100 | Loss 2.535873
InnerLR 0.871263
FineTuningLR 0.129737
Epoch 49 | Batch 40/100 | Loss 2.524265
InnerLR 0.870941
FineTuningLR 0.130058
Epoch 49 | Batch 50/100 | Loss 2.562407
InnerLR 0.870728
FineTuningLR 0.130272
Epoch 49 | Batch 60/100 | Loss 2.542898
InnerLR 0.870408
FineTuningLR 0.130592
Epoch 49 | Batch 70/100 | Loss 2.532768
InnerLR 0.870194
FineTuningLR 0.130806
Epoch 49 | Batch 80/100 | Loss 2.525368
InnerLR 0.869871
FineTuningLR 0.131129
Epoch 49 | Batch 90/100 | Loss 2.530026
InnerLR 0.869655
FineTuningLR 0.131345
100 Accuracy = 29.56% +- 1.78%
Epoch 49: 29.56
Epoch 50 | Batch 0/100 | Loss 2.755208
InnerLR 0.869330
FineTuningLR 0.131669
Epoch 50 | Batch 10/100 | Loss 2.235461
InnerLR 0.869114
FineTuningLR 0.131886
Epoch 50 | Batch 20/100 | Loss 2.396329
InnerLR 0.868790
FineTuningLR 0.132210
Epoch 50 | Batch 30/100 | Loss 2.445652
InnerLR 0.868573
FineTuningLR 0.132427
Epoch 50 | Batch 40/100 | Loss 2.471013
InnerLR 0.868248
FineTuningLR 0.132752
Epoch 50 | Batch 50/100 | Loss 2.472474
InnerLR 0.868030
FineTuningLR 0.132969
Epoch 50 | Batch 60/100 | Loss 2.460424
InnerLR 0.867706
FineTuningLR 0.133294
Epoch 50 | Batch 70/100 | Loss 2.447137
InnerLR 0.867490
FineTuningLR 0.133510
Epoch 50 | Batch 80/100 | Loss 2.428635
InnerLR 0.867164
FineTuningLR 0.133836
Epoch 50 | Batch 90/100 | Loss 2.432021
InnerLR 0.866945
FineTuningLR 0.134055
100 Accuracy = 29.23% +- 1.45%
Epoch 50: 29.23
Epoch 51 | Batch 0/100 | Loss 2.035474
InnerLR 0.866617
FineTuningLR 0.134383
Epoch 51 | Batch 10/100 | Loss 2.286179
InnerLR 0.866399
FineTuningLR 0.134601
Epoch 51 | Batch 20/100 | Loss 2.272184
InnerLR 0.866071
FineTuningLR 0.134929
Epoch 51 | Batch 30/100 | Loss 2.319014
InnerLR 0.865854
FineTuningLR 0.135146
Epoch 51 | Batch 40/100 | Loss 2.334218
InnerLR 0.865529
FineTuningLR 0.135471
Epoch 51 | Batch 50/100 | Loss 2.378911
InnerLR 0.865312
FineTuningLR 0.135688
Epoch 51 | Batch 60/100 | Loss 2.403073
InnerLR 0.864986
FineTuningLR 0.136014
Epoch 51 | Batch 70/100 | Loss 2.384848
InnerLR 0.864769
FineTuningLR 0.136231
Epoch 51 | Batch 80/100 | Loss 2.384393
InnerLR 0.864443
FineTuningLR 0.136557
Epoch 51 | Batch 90/100 | Loss 2.390610
InnerLR 0.864227
FineTuningLR 0.136773
100 Accuracy = 28.55% +- 1.69%
Epoch 51: 28.55
Epoch 52 | Batch 0/100 | Loss 2.334474
InnerLR 0.863904
FineTuningLR 0.137096
Epoch 52 | Batch 10/100 | Loss 2.300460
InnerLR 0.863686
FineTuningLR 0.137314
Epoch 52 | Batch 20/100 | Loss 2.367258
InnerLR 0.863363
FineTuningLR 0.137637
Epoch 52 | Batch 30/100 | Loss 2.381592
InnerLR 0.863149
FineTuningLR 0.137851
Epoch 52 | Batch 40/100 | Loss 2.404780
InnerLR 0.862826
FineTuningLR 0.138174
Epoch 52 | Batch 50/100 | Loss 2.413467
InnerLR 0.862612
FineTuningLR 0.138388
Epoch 52 | Batch 60/100 | Loss 2.411239
InnerLR 0.862288
FineTuningLR 0.138712
Epoch 52 | Batch 70/100 | Loss 2.442258
InnerLR 0.862073
FineTuningLR 0.138927
Epoch 52 | Batch 80/100 | Loss 2.458150
InnerLR 0.861748
FineTuningLR 0.139252
Epoch 52 | Batch 90/100 | Loss 2.462976
InnerLR 0.861532
FineTuningLR 0.139468
100 Accuracy = 28.88% +- 1.63%
Epoch 52: 28.88
Epoch 53 | Batch 0/100 | Loss 2.055851
InnerLR 0.861207
FineTuningLR 0.139793
Epoch 53 | Batch 10/100 | Loss 2.514712
InnerLR 0.860989
FineTuningLR 0.140011
Epoch 53 | Batch 20/100 | Loss 2.534602
InnerLR 0.860662
FineTuningLR 0.140338
Epoch 53 | Batch 30/100 | Loss 2.489472
InnerLR 0.860443
FineTuningLR 0.140557
Epoch 53 | Batch 40/100 | Loss 2.463711
InnerLR 0.860117
FineTuningLR 0.140883
Epoch 53 | Batch 50/100 | Loss 2.427969
InnerLR 0.859899
FineTuningLR 0.141101
Epoch 53 | Batch 60/100 | Loss 2.429645
InnerLR 0.859571
FineTuningLR 0.141429
Epoch 53 | Batch 70/100 | Loss 2.436675
InnerLR 0.859351
FineTuningLR 0.141649
Epoch 53 | Batch 80/100 | Loss 2.430136
InnerLR 0.859022
FineTuningLR 0.141978
Epoch 53 | Batch 90/100 | Loss 2.420059
InnerLR 0.858805
FineTuningLR 0.142195
100 Accuracy = 28.43% +- 1.46%
Epoch 53: 28.43
Epoch 54 | Batch 0/100 | Loss 2.442760
InnerLR 0.858477
FineTuningLR 0.142523
Epoch 54 | Batch 10/100 | Loss 2.443548
InnerLR 0.858257
FineTuningLR 0.142743
Epoch 54 | Batch 20/100 | Loss 2.481238
InnerLR 0.857928
FineTuningLR 0.143072
Epoch 54 | Batch 30/100 | Loss 2.470098
InnerLR 0.857709
FineTuningLR 0.143291
Epoch 54 | Batch 40/100 | Loss 2.501896
InnerLR 0.857379
FineTuningLR 0.143621
Epoch 54 | Batch 50/100 | Loss 2.500102
InnerLR 0.857161
FineTuningLR 0.143839
Epoch 54 | Batch 60/100 | Loss 2.494944
InnerLR 0.856833
FineTuningLR 0.144167
Epoch 54 | Batch 70/100 | Loss 2.499219
InnerLR 0.856615
FineTuningLR 0.144385
Epoch 54 | Batch 80/100 | Loss 2.486824
InnerLR 0.856288
FineTuningLR 0.144713
Epoch 54 | Batch 90/100 | Loss 2.491486
InnerLR 0.856068
FineTuningLR 0.144932
100 Accuracy = 29.71% +- 1.66%
Epoch 54: 29.71
best model! save...
Epoch 55 | Batch 0/100 | Loss 2.711644
InnerLR 0.855739
FineTuningLR 0.145262
Epoch 55 | Batch 10/100 | Loss 2.447435
InnerLR 0.855519
FineTuningLR 0.145481
Epoch 55 | Batch 20/100 | Loss 2.420430
InnerLR 0.855193
FineTuningLR 0.145807
Epoch 55 | Batch 30/100 | Loss 2.460490
InnerLR 0.854976
FineTuningLR 0.146024
Epoch 55 | Batch 40/100 | Loss 2.470551
InnerLR 0.854652
FineTuningLR 0.146348
Epoch 55 | Batch 50/100 | Loss 2.465011
InnerLR 0.854437
FineTuningLR 0.146563
Epoch 55 | Batch 60/100 | Loss 2.465779
InnerLR 0.854113
FineTuningLR 0.146887
Epoch 55 | Batch 70/100 | Loss 2.468634
InnerLR 0.853899
FineTuningLR 0.147101
Epoch 55 | Batch 80/100 | Loss 2.464272
InnerLR 0.853575
FineTuningLR 0.147425
Epoch 55 | Batch 90/100 | Loss 2.489902
InnerLR 0.853358
FineTuningLR 0.147642
100 Accuracy = 28.92% +- 1.53%
Epoch 55: 28.92
Epoch 56 | Batch 0/100 | Loss 2.416558
InnerLR 0.853029
FineTuningLR 0.147971
Epoch 56 | Batch 10/100 | Loss 2.502759
InnerLR 0.852810
FineTuningLR 0.148190
Epoch 56 | Batch 20/100 | Loss 2.433869
InnerLR 0.852484
FineTuningLR 0.148516
Epoch 56 | Batch 30/100 | Loss 2.391550
InnerLR 0.852266
FineTuningLR 0.148734
Epoch 56 | Batch 40/100 | Loss 2.365744
InnerLR 0.851938
FineTuningLR 0.149062
Epoch 56 | Batch 50/100 | Loss 2.348375
InnerLR 0.851718
FineTuningLR 0.149282
Epoch 56 | Batch 60/100 | Loss 2.339292
InnerLR 0.851389
FineTuningLR 0.149611
Epoch 56 | Batch 70/100 | Loss 2.318365
InnerLR 0.851170
FineTuningLR 0.149831
Epoch 56 | Batch 80/100 | Loss 2.325789
InnerLR 0.850839
FineTuningLR 0.150162
Epoch 56 | Batch 90/100 | Loss 2.333447
InnerLR 0.850618
FineTuningLR 0.150382
100 Accuracy = 29.35% +- 1.55%
Epoch 56: 29.35
Epoch 57 | Batch 0/100 | Loss 2.697180
InnerLR 0.850288
FineTuningLR 0.150712
Epoch 57 | Batch 10/100 | Loss 2.572341
InnerLR 0.850067
FineTuningLR 0.150933
Epoch 57 | Batch 20/100 | Loss 2.468515
InnerLR 0.849736
FineTuningLR 0.151264
Epoch 57 | Batch 30/100 | Loss 2.398915
InnerLR 0.849514
FineTuningLR 0.151486
Epoch 57 | Batch 40/100 | Loss 2.424679
InnerLR 0.849181
FineTuningLR 0.151819
Epoch 57 | Batch 50/100 | Loss 2.431198
InnerLR 0.848962
FineTuningLR 0.152038
Epoch 57 | Batch 60/100 | Loss 2.423263
InnerLR 0.848635
FineTuningLR 0.152365
Epoch 57 | Batch 70/100 | Loss 2.431746
InnerLR 0.848418
FineTuningLR 0.152582
Epoch 57 | Batch 80/100 | Loss 2.409531
InnerLR 0.848094
FineTuningLR 0.152906
Epoch 57 | Batch 90/100 | Loss 2.428277
InnerLR 0.847877
FineTuningLR 0.153123
100 Accuracy = 27.93% +- 1.55%
Epoch 57: 27.93
Epoch 58 | Batch 0/100 | Loss 1.913170
InnerLR 0.847554
FineTuningLR 0.153447
Epoch 58 | Batch 10/100 | Loss 2.233340
InnerLR 0.847337
FineTuningLR 0.153663
Epoch 58 | Batch 20/100 | Loss 2.334364
InnerLR 0.847010
FineTuningLR 0.153990
Epoch 58 | Batch 30/100 | Loss 2.335112
InnerLR 0.846793
FineTuningLR 0.154207
Epoch 58 | Batch 40/100 | Loss 2.345939
InnerLR 0.846466
FineTuningLR 0.154534
Epoch 58 | Batch 50/100 | Loss 2.307646
InnerLR 0.846246
FineTuningLR 0.154755
Epoch 58 | Batch 60/100 | Loss 2.342935
InnerLR 0.845914
FineTuningLR 0.155086
Epoch 58 | Batch 70/100 | Loss 2.386967
InnerLR 0.845693
FineTuningLR 0.155307
Epoch 58 | Batch 80/100 | Loss 2.390573
InnerLR 0.845362
FineTuningLR 0.155638
Epoch 58 | Batch 90/100 | Loss 2.399284
InnerLR 0.845142
FineTuningLR 0.155858
100 Accuracy = 29.84% +- 1.67%
Epoch 58: 29.84
best model! save...
Epoch 59 | Batch 0/100 | Loss 1.939761
InnerLR 0.844815
FineTuningLR 0.156185
Epoch 59 | Batch 10/100 | Loss 2.394476
InnerLR 0.844597
FineTuningLR 0.156404
Epoch 59 | Batch 20/100 | Loss 2.430327
InnerLR 0.844270
FineTuningLR 0.156730
Epoch 59 | Batch 30/100 | Loss 2.439074
InnerLR 0.844052
FineTuningLR 0.156948
Epoch 59 | Batch 40/100 | Loss 2.431800
InnerLR 0.843729
FineTuningLR 0.157271
Epoch 59 | Batch 50/100 | Loss 2.458708
InnerLR 0.843514
FineTuningLR 0.157486
Epoch 59 | Batch 60/100 | Loss 2.452188
InnerLR 0.843190
FineTuningLR 0.157810
Epoch 59 | Batch 70/100 | Loss 2.433431
InnerLR 0.842973
FineTuningLR 0.158027
Epoch 59 | Batch 80/100 | Loss 2.417539
InnerLR 0.842650
FineTuningLR 0.158350
Epoch 59 | Batch 90/100 | Loss 2.406951
InnerLR 0.842433
FineTuningLR 0.158567
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 30.55% +- 1.61%
Epoch 59: 30.55
best model! save...
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_1_lr_0.0001_latent_space_dim_8_weight_decay_1e-08_num_adaptation_steps_5/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_lr_0.0001_latent_space_dim_8_weight_decay_1e-08_num_adaptation_steps_5/tabula_muris/leo_FCNet/20231209_054852
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 31.04% +- 0.67%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_lr_0.0001_latent_space_dim_8_weight_decay_1e-08_num_adaptation_steps_5/tabula_muris/leo_FCNet/20231209_054852
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 29.54% +- 0.62%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_lr_0.0001_latent_space_dim_8_weight_decay_1e-08_num_adaptation_steps_5/tabula_muris/leo_FCNet/20231209_054852
600 Accuracy = 29.46% +- 0.62%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_1_lr_0.0001_latent_space_dim_8_weight_decay_1e-08_num_adaptation_steps_5/results.txt
+-------+--------------------+-------------------+
| split |      acc_mean      |      acc_std      |
+-------+--------------------+-------------------+
| train | 31.037777777777773 |  8.41982111771509 |
|  val  | 29.54222222222222  | 7.764167138722909 |
|  test | 29.45777777777778  | 7.760636349115314 |
+-------+--------------------+-------------------+
