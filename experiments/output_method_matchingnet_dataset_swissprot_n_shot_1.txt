/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
dataset:
  type: classification
  simple_cls:
    _target_: datasets.prot.swissprot.SPSimpleDataset
  set_cls:
    n_way: 5
    n_support: 1
    n_query: 15
    _target_: datasets.prot.swissprot.SPSetDataset
  name: swissprot
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 512
  - 512
train_classes: 7195
n_way: 5
n_shot: 1
n_query: 15
method:
  name: matchingnet
  train_batch: null
  val_batch: null
  fast_weight: false
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 1
    _target_: methods.matchingnet.MatchingNet
model: FCNet
mode: train
exp:
  name: method_matchingnet_dataset_swissprot_n_shot_1
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.001
checkpoint:
  dir: checkpoints/method_matchingnet_dataset_swissprot_n_shot_1/swissprot/matchingnet_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

  EXISTS: go-basic.obo
go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)

**WARNING: NO VERSION LINE FOUND IN GAF FILE. USING:
!gaf-version: 2.2
[2023-12-09 01:40:21,361][root][ERROR] - Failed to validate header as GAF v2.2:
[]
HMS:0:00:07.207589 310,057 annotations READ: ./data/swissprot/filtered_goa_uniprot_all_noiea.gaf 
25933 IDs in loaded association branch, BP

**WARNING: NO VERSION LINE FOUND IN GAF FILE. USING:
!gaf-version: 2.2
[2023-12-09 01:42:10,730][root][ERROR] - Failed to validate header as GAF v2.2:
[]
HMS:0:00:07.234344 310,057 annotations READ: ./data/swissprot/filtered_goa_uniprot_all_noiea.gaf 
25933 IDs in loaded association branch, BP
Model Architecture:
MatchingNet(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear(in_features=1280, out_features=512, bias=True)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (loss_fn): NLLLoss()
  (FCE): FullyContextualEmbedding(
    (lstmcell): LSTMCell(1024, 512)
    (softmax): Softmax(dim=None)
  )
  (G_encoder): LSTM(512, 512, batch_first=True, bidirectional=True)
  (relu): ReLU()
  (softmax): Softmax(dim=None)
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
Epoch 0 | Batch 0/100 | Loss 2.048462
Epoch 0 | Batch 10/100 | Loss 3.208108
Epoch 0 | Batch 20/100 | Loss 3.917692
Epoch 0 | Batch 30/100 | Loss 3.496753
Epoch 0 | Batch 40/100 | Loss 3.283541
Epoch 0 | Batch 50/100 | Loss 3.224080
Epoch 0 | Batch 60/100 | Loss 3.099422
Epoch 0 | Batch 70/100 | Loss 3.027145
Epoch 0 | Batch 80/100 | Loss 2.902762
Epoch 0 | Batch 90/100 | Loss 2.779913
100 Test Acc = 52.47% +- 2.14%
Epoch 0: 52.47
best model! save...
Epoch 1 | Batch 0/100 | Loss 2.241699
Epoch 1 | Batch 10/100 | Loss 1.932778
Epoch 1 | Batch 20/100 | Loss 1.902704
Epoch 1 | Batch 30/100 | Loss 1.619181
Epoch 1 | Batch 40/100 | Loss 1.618192
Epoch 1 | Batch 50/100 | Loss 1.575207
Epoch 1 | Batch 60/100 | Loss 1.558409
Epoch 1 | Batch 70/100 | Loss 1.549629
Epoch 1 | Batch 80/100 | Loss 1.543063
Epoch 1 | Batch 90/100 | Loss 1.492066
100 Test Acc = 53.68% +- 2.67%
Epoch 1: 53.68
best model! save...
Epoch 2 | Batch 0/100 | Loss 0.476960
Epoch 2 | Batch 10/100 | Loss 1.218213
Epoch 2 | Batch 20/100 | Loss 1.235625
Epoch 2 | Batch 30/100 | Loss 1.220334
Epoch 2 | Batch 40/100 | Loss 1.242449
Epoch 2 | Batch 50/100 | Loss 1.232700
Epoch 2 | Batch 60/100 | Loss 1.223873
Epoch 2 | Batch 70/100 | Loss 1.229003
Epoch 2 | Batch 80/100 | Loss 1.238858
Epoch 2 | Batch 90/100 | Loss 1.247810
100 Test Acc = 52.84% +- 2.39%
Epoch 2: 52.84
Epoch 3 | Batch 0/100 | Loss 1.198516
Epoch 3 | Batch 10/100 | Loss 1.304479
Epoch 3 | Batch 20/100 | Loss 1.233816
Epoch 3 | Batch 30/100 | Loss 1.223644
Epoch 3 | Batch 40/100 | Loss 1.186404
Epoch 3 | Batch 50/100 | Loss 1.158061
Epoch 3 | Batch 60/100 | Loss 1.121311
Epoch 3 | Batch 70/100 | Loss 1.109640
Epoch 3 | Batch 80/100 | Loss 1.100280
Epoch 3 | Batch 90/100 | Loss 1.086034
100 Test Acc = 57.69% +- 2.42%
Epoch 3: 57.69
best model! save...
Epoch 4 | Batch 0/100 | Loss 1.247392
Epoch 4 | Batch 10/100 | Loss 0.962350
Epoch 4 | Batch 20/100 | Loss 1.009138
Epoch 4 | Batch 30/100 | Loss 0.949048
Epoch 4 | Batch 40/100 | Loss 0.947536
Epoch 4 | Batch 50/100 | Loss 0.970600
Epoch 4 | Batch 60/100 | Loss 0.975416
Epoch 4 | Batch 70/100 | Loss 0.945125
Epoch 4 | Batch 80/100 | Loss 0.943366
Epoch 4 | Batch 90/100 | Loss 0.932339
100 Test Acc = 53.76% +- 2.74%
Epoch 4: 53.76
Epoch 5 | Batch 0/100 | Loss 1.732844
Epoch 5 | Batch 10/100 | Loss 0.892105
Epoch 5 | Batch 20/100 | Loss 0.771968
Epoch 5 | Batch 30/100 | Loss 0.798594
Epoch 5 | Batch 40/100 | Loss 0.803432
Epoch 5 | Batch 50/100 | Loss 0.812757
Epoch 5 | Batch 60/100 | Loss 0.816493
Epoch 5 | Batch 70/100 | Loss 0.758312
Epoch 5 | Batch 80/100 | Loss 0.770867
Epoch 5 | Batch 90/100 | Loss 0.806564
100 Test Acc = 52.87% +- 2.34%
Epoch 5: 52.87
Epoch 6 | Batch 0/100 | Loss 0.458947
Epoch 6 | Batch 10/100 | Loss 0.851732
Epoch 6 | Batch 20/100 | Loss 0.753380
Epoch 6 | Batch 30/100 | Loss 0.719156
Epoch 6 | Batch 40/100 | Loss 0.815635
Epoch 6 | Batch 50/100 | Loss 0.791519
Epoch 6 | Batch 60/100 | Loss 0.799798
Epoch 6 | Batch 70/100 | Loss 0.768709
Epoch 6 | Batch 80/100 | Loss 0.769073
Epoch 6 | Batch 90/100 | Loss 0.775450
100 Test Acc = 57.27% +- 2.37%
Epoch 6: 57.27
Epoch 7 | Batch 0/100 | Loss 1.567159
Epoch 7 | Batch 10/100 | Loss 0.804337
Epoch 7 | Batch 20/100 | Loss 0.718739
Epoch 7 | Batch 30/100 | Loss 0.657955
Epoch 7 | Batch 40/100 | Loss 0.636539
Epoch 7 | Batch 50/100 | Loss 0.716454
Epoch 7 | Batch 60/100 | Loss 0.742846
Epoch 7 | Batch 70/100 | Loss 0.734540
Epoch 7 | Batch 80/100 | Loss 0.731411
Epoch 7 | Batch 90/100 | Loss 0.708392
100 Test Acc = 53.76% +- 2.43%
Epoch 7: 53.76
Epoch 8 | Batch 0/100 | Loss 0.135270
Epoch 8 | Batch 10/100 | Loss 0.572344
Epoch 8 | Batch 20/100 | Loss 0.659201
Epoch 8 | Batch 30/100 | Loss 0.713692
Epoch 8 | Batch 40/100 | Loss 0.665634
Epoch 8 | Batch 50/100 | Loss 0.671484
Epoch 8 | Batch 60/100 | Loss 0.675144
Epoch 8 | Batch 70/100 | Loss 0.664497
Epoch 8 | Batch 80/100 | Loss 0.658520
Epoch 8 | Batch 90/100 | Loss 0.656454
100 Test Acc = 53.53% +- 2.49%
Epoch 8: 53.53
Epoch 9 | Batch 0/100 | Loss 0.931010
Epoch 9 | Batch 10/100 | Loss 0.710284
Epoch 9 | Batch 20/100 | Loss 0.790624
Epoch 9 | Batch 30/100 | Loss 0.691393
Epoch 9 | Batch 40/100 | Loss 0.655840
Epoch 9 | Batch 50/100 | Loss 0.629671
Epoch 9 | Batch 60/100 | Loss 0.625709
Epoch 9 | Batch 70/100 | Loss 0.612373
Epoch 9 | Batch 80/100 | Loss 0.606004
Epoch 9 | Batch 90/100 | Loss 0.605165
100 Test Acc = 55.64% +- 2.10%
Epoch 9: 55.64
Epoch 10 | Batch 0/100 | Loss 0.768763
Epoch 10 | Batch 10/100 | Loss 0.546032
Epoch 10 | Batch 20/100 | Loss 0.566627
Epoch 10 | Batch 30/100 | Loss 0.591316
Epoch 10 | Batch 40/100 | Loss 0.577927
Epoch 10 | Batch 50/100 | Loss 0.551707
Epoch 10 | Batch 60/100 | Loss 0.554693
Epoch 10 | Batch 70/100 | Loss 0.536977
Epoch 10 | Batch 80/100 | Loss 0.537782
Epoch 10 | Batch 90/100 | Loss 0.527787
100 Test Acc = 53.53% +- 2.14%
Epoch 10: 53.53
Epoch 11 | Batch 0/100 | Loss 0.713483
Epoch 11 | Batch 10/100 | Loss 0.609009
Epoch 11 | Batch 20/100 | Loss 0.639385
Epoch 11 | Batch 30/100 | Loss 0.600845
Epoch 11 | Batch 40/100 | Loss 0.546613
Epoch 11 | Batch 50/100 | Loss 0.525562
Epoch 11 | Batch 60/100 | Loss 0.523149
Epoch 11 | Batch 70/100 | Loss 0.538288
Epoch 11 | Batch 80/100 | Loss 0.530612
Epoch 11 | Batch 90/100 | Loss 0.531922
100 Test Acc = 55.01% +- 2.20%
Epoch 11: 55.01
Epoch 12 | Batch 0/100 | Loss 0.952131
Epoch 12 | Batch 10/100 | Loss 0.582314
Epoch 12 | Batch 20/100 | Loss 0.460800
Epoch 12 | Batch 30/100 | Loss 0.509658
Epoch 12 | Batch 40/100 | Loss 0.460566
Epoch 12 | Batch 50/100 | Loss 0.452669
Epoch 12 | Batch 60/100 | Loss 0.457006
Epoch 12 | Batch 70/100 | Loss 0.489530
Epoch 12 | Batch 80/100 | Loss 0.500314
Epoch 12 | Batch 90/100 | Loss 0.502213
100 Test Acc = 57.60% +- 2.33%
Epoch 12: 57.60
Epoch 13 | Batch 0/100 | Loss 0.500905
Epoch 13 | Batch 10/100 | Loss 0.557203
Epoch 13 | Batch 20/100 | Loss 0.454143
Epoch 13 | Batch 30/100 | Loss 0.485742
Epoch 13 | Batch 40/100 | Loss 0.523535
Epoch 13 | Batch 50/100 | Loss 0.503933
Epoch 13 | Batch 60/100 | Loss 0.499054
Epoch 13 | Batch 70/100 | Loss 0.499281
Epoch 13 | Batch 80/100 | Loss 0.523110
Epoch 13 | Batch 90/100 | Loss 0.530455
100 Test Acc = 56.51% +- 2.50%
Epoch 13: 56.51
Epoch 14 | Batch 0/100 | Loss 0.425575
Epoch 14 | Batch 10/100 | Loss 0.507287
Epoch 14 | Batch 20/100 | Loss 0.432396
Epoch 14 | Batch 30/100 | Loss 0.470424
Epoch 14 | Batch 40/100 | Loss 0.486316
Epoch 14 | Batch 50/100 | Loss 0.483221
Epoch 14 | Batch 60/100 | Loss 0.489496
Epoch 14 | Batch 70/100 | Loss 0.498602
Epoch 14 | Batch 80/100 | Loss 0.524254
Epoch 14 | Batch 90/100 | Loss 0.517521
100 Test Acc = 54.53% +- 2.77%
Epoch 14: 54.53
Epoch 15 | Batch 0/100 | Loss 0.835418
Epoch 15 | Batch 10/100 | Loss 0.377799
Epoch 15 | Batch 20/100 | Loss 0.443525
Epoch 15 | Batch 30/100 | Loss 0.464629
Epoch 15 | Batch 40/100 | Loss 0.417168
Epoch 15 | Batch 50/100 | Loss 0.412851
Epoch 15 | Batch 60/100 | Loss 0.414409
Epoch 15 | Batch 70/100 | Loss 0.404703
Epoch 15 | Batch 80/100 | Loss 0.421578
Epoch 15 | Batch 90/100 | Loss 0.412681
100 Test Acc = 56.92% +- 2.69%
Epoch 15: 56.92
Epoch 16 | Batch 0/100 | Loss 0.322485
Epoch 16 | Batch 10/100 | Loss 0.335598
Epoch 16 | Batch 20/100 | Loss 0.465056
Epoch 16 | Batch 30/100 | Loss 0.425192
Epoch 16 | Batch 40/100 | Loss 0.440047
Epoch 16 | Batch 50/100 | Loss 0.445689
Epoch 16 | Batch 60/100 | Loss 0.413483
Epoch 16 | Batch 70/100 | Loss 0.420561
Epoch 16 | Batch 80/100 | Loss 0.421924
Epoch 16 | Batch 90/100 | Loss 0.447158
100 Test Acc = 53.84% +- 2.33%
Epoch 16: 53.84
Epoch 17 | Batch 0/100 | Loss 1.040897
Epoch 17 | Batch 10/100 | Loss 0.556639
Epoch 17 | Batch 20/100 | Loss 0.529624
Epoch 17 | Batch 30/100 | Loss 0.544078
Epoch 17 | Batch 40/100 | Loss 0.479348
Epoch 17 | Batch 50/100 | Loss 0.465839
Epoch 17 | Batch 60/100 | Loss 0.463694
Epoch 17 | Batch 70/100 | Loss 0.456190
Epoch 17 | Batch 80/100 | Loss 0.467110
Epoch 17 | Batch 90/100 | Loss 0.455529
100 Test Acc = 53.88% +- 2.58%
Epoch 17: 53.88
Epoch 18 | Batch 0/100 | Loss 0.141692
Epoch 18 | Batch 10/100 | Loss 0.405817
Epoch 18 | Batch 20/100 | Loss 0.450646
Epoch 18 | Batch 30/100 | Loss 0.462208
Epoch 18 | Batch 40/100 | Loss 0.479890
Epoch 18 | Batch 50/100 | Loss 0.447993
Epoch 18 | Batch 60/100 | Loss 0.445077
Epoch 18 | Batch 70/100 | Loss 0.439420
Epoch 18 | Batch 80/100 | Loss 0.465593
Epoch 18 | Batch 90/100 | Loss 0.456614
100 Test Acc = 52.01% +- 2.54%
Epoch 18: 52.01
Epoch 19 | Batch 0/100 | Loss 0.133023
Epoch 19 | Batch 10/100 | Loss 0.323184
Epoch 19 | Batch 20/100 | Loss 0.319864
Epoch 19 | Batch 30/100 | Loss 0.344436
Epoch 19 | Batch 40/100 | Loss 0.372396
Epoch 19 | Batch 50/100 | Loss 0.370271
Epoch 19 | Batch 60/100 | Loss 0.355559
Epoch 19 | Batch 70/100 | Loss 0.367029
Epoch 19 | Batch 80/100 | Loss 0.365525
Epoch 19 | Batch 90/100 | Loss 0.363136
100 Test Acc = 51.69% +- 2.34%
Epoch 19: 51.69
Epoch 20 | Batch 0/100 | Loss 0.858372
Epoch 20 | Batch 10/100 | Loss 0.454951
Epoch 20 | Batch 20/100 | Loss 0.471378
Epoch 20 | Batch 30/100 | Loss 0.488702
Epoch 20 | Batch 40/100 | Loss 0.479768
Epoch 20 | Batch 50/100 | Loss 0.478167
Epoch 20 | Batch 60/100 | Loss 0.486733
Epoch 20 | Batch 70/100 | Loss 0.486633
Epoch 20 | Batch 80/100 | Loss 0.476773
Epoch 20 | Batch 90/100 | Loss 0.473465
100 Test Acc = 57.15% +- 2.32%
Epoch 20: 57.15
Epoch 21 | Batch 0/100 | Loss 0.039652
Epoch 21 | Batch 10/100 | Loss 0.388473
Epoch 21 | Batch 20/100 | Loss 0.399609
Epoch 21 | Batch 30/100 | Loss 0.424316
Epoch 21 | Batch 40/100 | Loss 0.402600
Epoch 21 | Batch 50/100 | Loss 0.402496
Epoch 21 | Batch 60/100 | Loss 0.413251
Epoch 21 | Batch 70/100 | Loss 0.421660
Epoch 21 | Batch 80/100 | Loss 0.410797
Epoch 21 | Batch 90/100 | Loss 0.393958
100 Test Acc = 54.31% +- 2.66%
Epoch 21: 54.31
Epoch 22 | Batch 0/100 | Loss 0.525271
Epoch 22 | Batch 10/100 | Loss 0.408149
Epoch 22 | Batch 20/100 | Loss 0.357452
Epoch 22 | Batch 30/100 | Loss 0.327538
Epoch 22 | Batch 40/100 | Loss 0.339313
Epoch 22 | Batch 50/100 | Loss 0.346065
Epoch 22 | Batch 60/100 | Loss 0.373544
Epoch 22 | Batch 70/100 | Loss 0.399754
Epoch 22 | Batch 80/100 | Loss 0.396921
Epoch 22 | Batch 90/100 | Loss 0.385131
100 Test Acc = 55.35% +- 2.54%
Epoch 22: 55.35
Epoch 23 | Batch 0/100 | Loss 0.245185
Epoch 23 | Batch 10/100 | Loss 0.338493
Epoch 23 | Batch 20/100 | Loss 0.359043
Epoch 23 | Batch 30/100 | Loss 0.476663
Epoch 23 | Batch 40/100 | Loss 0.529810
Epoch 23 | Batch 50/100 | Loss 0.485580
Epoch 23 | Batch 60/100 | Loss 0.485140
Epoch 23 | Batch 70/100 | Loss 0.511697
Epoch 23 | Batch 80/100 | Loss 0.489837
Epoch 23 | Batch 90/100 | Loss 0.468932
100 Test Acc = 55.53% +- 2.49%
Epoch 23: 55.53
Epoch 24 | Batch 0/100 | Loss 2.010254
Epoch 24 | Batch 10/100 | Loss 0.547863
Epoch 24 | Batch 20/100 | Loss 0.551118
Epoch 24 | Batch 30/100 | Loss 0.501542
Epoch 24 | Batch 40/100 | Loss 0.489560
Epoch 24 | Batch 50/100 | Loss 0.449982
Epoch 24 | Batch 60/100 | Loss 0.450326
Epoch 24 | Batch 70/100 | Loss 0.428864
Epoch 24 | Batch 80/100 | Loss 0.413073
Epoch 24 | Batch 90/100 | Loss 0.415830
100 Test Acc = 54.83% +- 2.44%
Epoch 24: 54.83
Epoch 25 | Batch 0/100 | Loss 0.779587
Epoch 25 | Batch 10/100 | Loss 0.347421
Epoch 25 | Batch 20/100 | Loss 0.328334
Epoch 25 | Batch 30/100 | Loss 0.387799
Epoch 25 | Batch 40/100 | Loss 0.408246
Epoch 25 | Batch 50/100 | Loss 0.406219
Epoch 25 | Batch 60/100 | Loss 0.406517
Epoch 25 | Batch 70/100 | Loss 0.392615
Epoch 25 | Batch 80/100 | Loss 0.398317
Epoch 25 | Batch 90/100 | Loss 0.386530
100 Test Acc = 52.64% +- 2.76%
Epoch 25: 52.64
Epoch 26 | Batch 0/100 | Loss 0.419741
Epoch 26 | Batch 10/100 | Loss 0.481014
Epoch 26 | Batch 20/100 | Loss 0.441120
Epoch 26 | Batch 30/100 | Loss 0.391404
Epoch 26 | Batch 40/100 | Loss 0.409605
Epoch 26 | Batch 50/100 | Loss 0.415669
Epoch 26 | Batch 60/100 | Loss 0.385892
Epoch 26 | Batch 70/100 | Loss 0.367044
Epoch 26 | Batch 80/100 | Loss 0.348455
Epoch 26 | Batch 90/100 | Loss 0.342326
100 Test Acc = 52.95% +- 2.40%
Epoch 26: 52.95
Epoch 27 | Batch 0/100 | Loss 0.236199
Epoch 27 | Batch 10/100 | Loss 0.227692
Epoch 27 | Batch 20/100 | Loss 0.238508
Epoch 27 | Batch 30/100 | Loss 0.269114
Epoch 27 | Batch 40/100 | Loss 0.283636
Epoch 27 | Batch 50/100 | Loss 0.310063
Epoch 27 | Batch 60/100 | Loss 0.330271
Epoch 27 | Batch 70/100 | Loss 0.312821
Epoch 27 | Batch 80/100 | Loss 0.294913
Epoch 27 | Batch 90/100 | Loss 0.290541
100 Test Acc = 54.89% +- 2.63%
Epoch 27: 54.89
Epoch 28 | Batch 0/100 | Loss 0.193133
Epoch 28 | Batch 10/100 | Loss 0.340087
Epoch 28 | Batch 20/100 | Loss 0.337455
Epoch 28 | Batch 30/100 | Loss 0.325954
Epoch 28 | Batch 40/100 | Loss 0.337565
Epoch 28 | Batch 50/100 | Loss 0.411434
Epoch 28 | Batch 60/100 | Loss 0.396958
Epoch 28 | Batch 70/100 | Loss 0.378219
Epoch 28 | Batch 80/100 | Loss 0.389833
Epoch 28 | Batch 90/100 | Loss 0.387495
100 Test Acc = 53.99% +- 2.42%
Epoch 28: 53.99
Epoch 29 | Batch 0/100 | Loss 0.448920
Epoch 29 | Batch 10/100 | Loss 0.242864
Epoch 29 | Batch 20/100 | Loss 0.250137
Epoch 29 | Batch 30/100 | Loss 0.334944
Epoch 29 | Batch 40/100 | Loss 0.329353
Epoch 29 | Batch 50/100 | Loss 0.300353
Epoch 29 | Batch 60/100 | Loss 0.273875
Epoch 29 | Batch 70/100 | Loss 0.285803
Epoch 29 | Batch 80/100 | Loss 0.269363
Epoch 29 | Batch 90/100 | Loss 0.277829
100 Test Acc = 54.51% +- 2.63%
Epoch 29: 54.51
Epoch 30 | Batch 0/100 | Loss 0.053244
Epoch 30 | Batch 10/100 | Loss 0.339015
Epoch 30 | Batch 20/100 | Loss 0.309515
Epoch 30 | Batch 30/100 | Loss 0.298216
Epoch 30 | Batch 40/100 | Loss 0.280308
Epoch 30 | Batch 50/100 | Loss 0.266210
Epoch 30 | Batch 60/100 | Loss 0.264415
Epoch 30 | Batch 70/100 | Loss 0.279270
Epoch 30 | Batch 80/100 | Loss 0.299915
Epoch 30 | Batch 90/100 | Loss 0.304589
100 Test Acc = 52.97% +- 2.44%
Epoch 30: 52.97
Epoch 31 | Batch 0/100 | Loss 0.109582
Epoch 31 | Batch 10/100 | Loss 0.337313
Epoch 31 | Batch 20/100 | Loss 0.263477
Epoch 31 | Batch 30/100 | Loss 0.356302
Epoch 31 | Batch 40/100 | Loss 0.356325
Epoch 31 | Batch 50/100 | Loss 0.350075
Epoch 31 | Batch 60/100 | Loss 0.355850
Epoch 31 | Batch 70/100 | Loss 0.341195
Epoch 31 | Batch 80/100 | Loss 0.374910
Epoch 31 | Batch 90/100 | Loss 0.361925
100 Test Acc = 55.03% +- 2.61%
Epoch 31: 55.03
Epoch 32 | Batch 0/100 | Loss 0.095841
Epoch 32 | Batch 10/100 | Loss 0.268390
Epoch 32 | Batch 20/100 | Loss 0.257197
Epoch 32 | Batch 30/100 | Loss 0.252787
Epoch 32 | Batch 40/100 | Loss 0.219324
Epoch 32 | Batch 50/100 | Loss 0.205207
Epoch 32 | Batch 60/100 | Loss 0.214842
Epoch 32 | Batch 70/100 | Loss 0.221892
Epoch 32 | Batch 80/100 | Loss 0.253207
Epoch 32 | Batch 90/100 | Loss 0.271679
100 Test Acc = 56.37% +- 2.63%
Epoch 32: 56.37
Epoch 33 | Batch 0/100 | Loss 0.386582
Epoch 33 | Batch 10/100 | Loss 0.327461
Epoch 33 | Batch 20/100 | Loss 0.321789
Epoch 33 | Batch 30/100 | Loss 0.338741
Epoch 33 | Batch 40/100 | Loss 0.354265
Epoch 33 | Batch 50/100 | Loss 0.365977
Epoch 33 | Batch 60/100 | Loss 0.351696
Epoch 33 | Batch 70/100 | Loss 0.354038
Epoch 33 | Batch 80/100 | Loss 0.366170
Epoch 33 | Batch 90/100 | Loss 0.379666
100 Test Acc = 52.12% +- 2.75%
Epoch 33: 52.12
Epoch 34 | Batch 0/100 | Loss 0.102898
Epoch 34 | Batch 10/100 | Loss 0.227893
Epoch 34 | Batch 20/100 | Loss 0.204388
Epoch 34 | Batch 30/100 | Loss 0.211389
Epoch 34 | Batch 40/100 | Loss 0.217767
Epoch 34 | Batch 50/100 | Loss 0.245864
Epoch 34 | Batch 60/100 | Loss 0.264547
Epoch 34 | Batch 70/100 | Loss 0.256200
Epoch 34 | Batch 80/100 | Loss 0.290094
Epoch 34 | Batch 90/100 | Loss 0.282712
100 Test Acc = 55.29% +- 2.35%
Epoch 34: 55.29
Epoch 35 | Batch 0/100 | Loss 0.114448
Epoch 35 | Batch 10/100 | Loss 0.429684
Epoch 35 | Batch 20/100 | Loss 0.358736
Epoch 35 | Batch 30/100 | Loss 0.294432
Epoch 35 | Batch 40/100 | Loss 0.278677
Epoch 35 | Batch 50/100 | Loss 0.292048
Epoch 35 | Batch 60/100 | Loss 0.291003
Epoch 35 | Batch 70/100 | Loss 0.289303
Epoch 35 | Batch 80/100 | Loss 0.291816
Epoch 35 | Batch 90/100 | Loss 0.289695
100 Test Acc = 54.07% +- 2.37%
Epoch 35: 54.07
Epoch 36 | Batch 0/100 | Loss 0.302171
Epoch 36 | Batch 10/100 | Loss 0.374528
Epoch 36 | Batch 20/100 | Loss 0.453666
Epoch 36 | Batch 30/100 | Loss 0.494771
Epoch 36 | Batch 40/100 | Loss 0.425554
Epoch 36 | Batch 50/100 | Loss 0.399681
Epoch 36 | Batch 60/100 | Loss 0.405376
Epoch 36 | Batch 70/100 | Loss 0.399918
Epoch 36 | Batch 80/100 | Loss 0.383773
Epoch 36 | Batch 90/100 | Loss 0.380992
100 Test Acc = 50.79% +- 2.34%
Epoch 36: 50.79
Epoch 37 | Batch 0/100 | Loss 0.310966
Epoch 37 | Batch 10/100 | Loss 0.334876
Epoch 37 | Batch 20/100 | Loss 0.302991
Epoch 37 | Batch 30/100 | Loss 0.313594
Epoch 37 | Batch 40/100 | Loss 0.281612
Epoch 37 | Batch 50/100 | Loss 0.270906
Epoch 37 | Batch 60/100 | Loss 0.267840
Epoch 37 | Batch 70/100 | Loss 0.268720
Epoch 37 | Batch 80/100 | Loss 0.271534
Epoch 37 | Batch 90/100 | Loss 0.270504
100 Test Acc = 53.68% +- 2.50%
Epoch 37: 53.68
Epoch 38 | Batch 0/100 | Loss 0.100583
Epoch 38 | Batch 10/100 | Loss 0.292355
Epoch 38 | Batch 20/100 | Loss 0.320274
Epoch 38 | Batch 30/100 | Loss 0.346884
Epoch 38 | Batch 40/100 | Loss 0.350117
Epoch 38 | Batch 50/100 | Loss 0.336357
Epoch 38 | Batch 60/100 | Loss 0.322585
Epoch 38 | Batch 70/100 | Loss 0.337211
Epoch 38 | Batch 80/100 | Loss 0.330739
Epoch 38 | Batch 90/100 | Loss 0.320041
100 Test Acc = 53.71% +- 2.58%
Epoch 38: 53.71
Epoch 39 | Batch 0/100 | Loss 0.114835
Epoch 39 | Batch 10/100 | Loss 0.322282
Epoch 39 | Batch 20/100 | Loss 0.353722
Epoch 39 | Batch 30/100 | Loss 0.366708
Epoch 39 | Batch 40/100 | Loss 0.316494
Epoch 39 | Batch 50/100 | Loss 0.288803
Epoch 39 | Batch 60/100 | Loss 0.291206
Epoch 39 | Batch 70/100 | Loss 0.297109
Epoch 39 | Batch 80/100 | Loss 0.292717
Epoch 39 | Batch 90/100 | Loss 0.283962
100 Test Acc = 54.51% +- 2.57%
Epoch 39: 54.51
Epoch 40 | Batch 0/100 | Loss 0.137139
Epoch 40 | Batch 10/100 | Loss 0.268561
Epoch 40 | Batch 20/100 | Loss 0.259161
Epoch 40 | Batch 30/100 | Loss 0.285548
Epoch 40 | Batch 40/100 | Loss 0.319505
Epoch 40 | Batch 50/100 | Loss 0.316928
Epoch 40 | Batch 60/100 | Loss 0.298862
Epoch 40 | Batch 70/100 | Loss 0.324389
Epoch 40 | Batch 80/100 | Loss 0.312296
Epoch 40 | Batch 90/100 | Loss 0.316290
100 Test Acc = 51.61% +- 2.67%
Epoch 40: 51.61
Epoch 41 | Batch 0/100 | Loss 0.178378
Epoch 41 | Batch 10/100 | Loss 0.267730
Epoch 41 | Batch 20/100 | Loss 0.260392
Epoch 41 | Batch 30/100 | Loss 0.286083
Epoch 41 | Batch 40/100 | Loss 0.274783
Epoch 41 | Batch 50/100 | Loss 0.258533
Epoch 41 | Batch 60/100 | Loss 0.254233
Epoch 41 | Batch 70/100 | Loss 0.248041
Epoch 41 | Batch 80/100 | Loss 0.248211
Epoch 41 | Batch 90/100 | Loss 0.246408
100 Test Acc = 53.45% +- 2.48%
Epoch 41: 53.45
Epoch 42 | Batch 0/100 | Loss 0.132772
Epoch 42 | Batch 10/100 | Loss 0.268236
Epoch 42 | Batch 20/100 | Loss 0.338095
Epoch 42 | Batch 30/100 | Loss 0.316217
Epoch 42 | Batch 40/100 | Loss 0.354978
Epoch 42 | Batch 50/100 | Loss 0.360709
Epoch 42 | Batch 60/100 | Loss 0.349998
Epoch 42 | Batch 70/100 | Loss 0.338670
Epoch 42 | Batch 80/100 | Loss 0.323441
Epoch 42 | Batch 90/100 | Loss 0.322269
100 Test Acc = 54.84% +- 2.71%
Epoch 42: 54.84
Epoch 43 | Batch 0/100 | Loss 0.178483
Epoch 43 | Batch 10/100 | Loss 0.217639
Epoch 43 | Batch 20/100 | Loss 0.183938
Epoch 43 | Batch 30/100 | Loss 0.185771
Epoch 43 | Batch 40/100 | Loss 0.213725
Epoch 43 | Batch 50/100 | Loss 0.208983
Epoch 43 | Batch 60/100 | Loss 0.195207
Epoch 43 | Batch 70/100 | Loss 0.190795
Epoch 43 | Batch 80/100 | Loss 0.218958
Epoch 43 | Batch 90/100 | Loss 0.224818
100 Test Acc = 53.13% +- 2.62%
Epoch 43: 53.13
Epoch 44 | Batch 0/100 | Loss 0.009251
Epoch 44 | Batch 10/100 | Loss 0.159587
Epoch 44 | Batch 20/100 | Loss 0.205694
Epoch 44 | Batch 30/100 | Loss 0.217021
Epoch 44 | Batch 40/100 | Loss 0.191024
Epoch 44 | Batch 50/100 | Loss 0.187778
Epoch 44 | Batch 60/100 | Loss 0.191043
Epoch 44 | Batch 70/100 | Loss 0.194752
Epoch 44 | Batch 80/100 | Loss 0.186145
Epoch 44 | Batch 90/100 | Loss 0.200635
100 Test Acc = 53.35% +- 2.58%
Epoch 44: 53.35
Epoch 45 | Batch 0/100 | Loss 0.048306
Epoch 45 | Batch 10/100 | Loss 0.131966
Epoch 45 | Batch 20/100 | Loss 0.197157
Epoch 45 | Batch 30/100 | Loss 0.178932
Epoch 45 | Batch 40/100 | Loss 0.215804
Epoch 45 | Batch 50/100 | Loss 0.216662
Epoch 45 | Batch 60/100 | Loss 0.234133
Epoch 45 | Batch 70/100 | Loss 0.236719
Epoch 45 | Batch 80/100 | Loss 0.247132
Epoch 45 | Batch 90/100 | Loss 0.244461
100 Test Acc = 55.39% +- 2.58%
Epoch 45: 55.39
Epoch 46 | Batch 0/100 | Loss 0.097279
Epoch 46 | Batch 10/100 | Loss 0.169654
Epoch 46 | Batch 20/100 | Loss 0.204720
Epoch 46 | Batch 30/100 | Loss 0.234001
Epoch 46 | Batch 40/100 | Loss 0.242675
Epoch 46 | Batch 50/100 | Loss 0.253351
Epoch 46 | Batch 60/100 | Loss 0.275866
Epoch 46 | Batch 70/100 | Loss 0.261485
Epoch 46 | Batch 80/100 | Loss 0.258767
Epoch 46 | Batch 90/100 | Loss 0.252627
100 Test Acc = 53.23% +- 2.42%
Epoch 46: 53.23
Epoch 47 | Batch 0/100 | Loss 0.199644
Epoch 47 | Batch 10/100 | Loss 0.162935
Epoch 47 | Batch 20/100 | Loss 0.170605
Epoch 47 | Batch 30/100 | Loss 0.189656
Epoch 47 | Batch 40/100 | Loss 0.165583
Epoch 47 | Batch 50/100 | Loss 0.187615
Epoch 47 | Batch 60/100 | Loss 0.198787
Epoch 47 | Batch 70/100 | Loss 0.203755
Epoch 47 | Batch 80/100 | Loss 0.195560
Epoch 47 | Batch 90/100 | Loss 0.198441
100 Test Acc = 53.04% +- 2.49%
Epoch 47: 53.04
Epoch 48 | Batch 0/100 | Loss 0.166191
Epoch 48 | Batch 10/100 | Loss 0.188271
Epoch 48 | Batch 20/100 | Loss 0.236109
Epoch 48 | Batch 30/100 | Loss 0.277976
Epoch 48 | Batch 40/100 | Loss 0.259297
Epoch 48 | Batch 50/100 | Loss 0.255527
Epoch 48 | Batch 60/100 | Loss 0.292361
Epoch 48 | Batch 70/100 | Loss 0.306367
Epoch 48 | Batch 80/100 | Loss 0.296229
Epoch 48 | Batch 90/100 | Loss 0.277969
100 Test Acc = 53.85% +- 2.61%
Epoch 48: 53.85
Epoch 49 | Batch 0/100 | Loss 0.339855
Epoch 49 | Batch 10/100 | Loss 0.228105
Epoch 49 | Batch 20/100 | Loss 0.223078
Epoch 49 | Batch 30/100 | Loss 0.226620
Epoch 49 | Batch 40/100 | Loss 0.219188
Epoch 49 | Batch 50/100 | Loss 0.238057
Epoch 49 | Batch 60/100 | Loss 0.229965
Epoch 49 | Batch 70/100 | Loss 0.258075
Epoch 49 | Batch 80/100 | Loss 0.250120
Epoch 49 | Batch 90/100 | Loss 0.262370
100 Test Acc = 55.96% +- 2.59%
Epoch 49: 55.96
Epoch 50 | Batch 0/100 | Loss 0.109318
Epoch 50 | Batch 10/100 | Loss 0.302139
Epoch 50 | Batch 20/100 | Loss 0.359895
Epoch 50 | Batch 30/100 | Loss 0.333633
Epoch 50 | Batch 40/100 | Loss 0.297753
Epoch 50 | Batch 50/100 | Loss 0.271333
Epoch 50 | Batch 60/100 | Loss 0.292598
Epoch 50 | Batch 70/100 | Loss 0.284031
Epoch 50 | Batch 80/100 | Loss 0.265308
Epoch 50 | Batch 90/100 | Loss 0.252263
100 Test Acc = 51.47% +- 2.60%
Epoch 50: 51.47
Epoch 51 | Batch 0/100 | Loss 0.049033
Epoch 51 | Batch 10/100 | Loss 0.168962
Epoch 51 | Batch 20/100 | Loss 0.227285
Epoch 51 | Batch 30/100 | Loss 0.190208
Epoch 51 | Batch 40/100 | Loss 0.228325
Epoch 51 | Batch 50/100 | Loss 0.215070
Epoch 51 | Batch 60/100 | Loss 0.226590
Epoch 51 | Batch 70/100 | Loss 0.237180
Epoch 51 | Batch 80/100 | Loss 0.230892
Epoch 51 | Batch 90/100 | Loss 0.237683
100 Test Acc = 51.63% +- 2.46%
Epoch 51: 51.63
Epoch 52 | Batch 0/100 | Loss 0.110598
Epoch 52 | Batch 10/100 | Loss 0.184615
Epoch 52 | Batch 20/100 | Loss 0.174918
Epoch 52 | Batch 30/100 | Loss 0.169939
Epoch 52 | Batch 40/100 | Loss 0.170977
Epoch 52 | Batch 50/100 | Loss 0.180485
Epoch 52 | Batch 60/100 | Loss 0.184161
Epoch 52 | Batch 70/100 | Loss 0.179409
Epoch 52 | Batch 80/100 | Loss 0.189186
Epoch 52 | Batch 90/100 | Loss 0.183916
100 Test Acc = 53.75% +- 2.44%
Epoch 52: 53.75
Epoch 53 | Batch 0/100 | Loss 0.374440
Epoch 53 | Batch 10/100 | Loss 0.253515
Epoch 53 | Batch 20/100 | Loss 0.225741
Epoch 53 | Batch 30/100 | Loss 0.226606
Epoch 53 | Batch 40/100 | Loss 0.215517
Epoch 53 | Batch 50/100 | Loss 0.235419
Epoch 53 | Batch 60/100 | Loss 0.236443
Epoch 53 | Batch 70/100 | Loss 0.235299
Epoch 53 | Batch 80/100 | Loss 0.237053
Epoch 53 | Batch 90/100 | Loss 0.228708
100 Test Acc = 52.96% +- 2.47%
Epoch 53: 52.96
Epoch 54 | Batch 0/100 | Loss 0.312346
Epoch 54 | Batch 10/100 | Loss 0.286558
Epoch 54 | Batch 20/100 | Loss 0.230662
Epoch 54 | Batch 30/100 | Loss 0.213265
Epoch 54 | Batch 40/100 | Loss 0.314413
Epoch 54 | Batch 50/100 | Loss 0.269619
Epoch 54 | Batch 60/100 | Loss 0.268066
Epoch 54 | Batch 70/100 | Loss 0.255877
Epoch 54 | Batch 80/100 | Loss 0.256373
Epoch 54 | Batch 90/100 | Loss 0.263523
100 Test Acc = 55.47% +- 2.69%
Epoch 54: 55.47
Epoch 55 | Batch 0/100 | Loss 0.019537
Epoch 55 | Batch 10/100 | Loss 0.229218
Epoch 55 | Batch 20/100 | Loss 0.294215
Epoch 55 | Batch 30/100 | Loss 0.339021
Epoch 55 | Batch 40/100 | Loss 0.293249
Epoch 55 | Batch 50/100 | Loss 0.276137
Epoch 55 | Batch 60/100 | Loss 0.285250
Epoch 55 | Batch 70/100 | Loss 0.271910
Epoch 55 | Batch 80/100 | Loss 0.263163
Epoch 55 | Batch 90/100 | Loss 0.262349
100 Test Acc = 54.35% +- 2.57%
Epoch 55: 54.35
Epoch 56 | Batch 0/100 | Loss 0.026617
Epoch 56 | Batch 10/100 | Loss 0.205617
Epoch 56 | Batch 20/100 | Loss 0.222683
Epoch 56 | Batch 30/100 | Loss 0.235686
Epoch 56 | Batch 40/100 | Loss 0.210841
Epoch 56 | Batch 50/100 | Loss 0.212671
Epoch 56 | Batch 60/100 | Loss 0.194460
Epoch 56 | Batch 70/100 | Loss 0.199709
Epoch 56 | Batch 80/100 | Loss 0.216236
Epoch 56 | Batch 90/100 | Loss 0.219007
100 Test Acc = 54.49% +- 2.49%
Epoch 56: 54.49
Epoch 57 | Batch 0/100 | Loss 0.067460
Epoch 57 | Batch 10/100 | Loss 0.224670
Epoch 57 | Batch 20/100 | Loss 0.174198
Epoch 57 | Batch 30/100 | Loss 0.190009
Epoch 57 | Batch 40/100 | Loss 0.177715
Epoch 57 | Batch 50/100 | Loss 0.180774
Epoch 57 | Batch 60/100 | Loss 0.185667
Epoch 57 | Batch 70/100 | Loss 0.184844
Epoch 57 | Batch 80/100 | Loss 0.188846
Epoch 57 | Batch 90/100 | Loss 0.188862
100 Test Acc = 54.73% +- 2.42%
Epoch 57: 54.73
Epoch 58 | Batch 0/100 | Loss 1.002471
Epoch 58 | Batch 10/100 | Loss 0.177326
Epoch 58 | Batch 20/100 | Loss 0.226468
Epoch 58 | Batch 30/100 | Loss 0.194430
Epoch 58 | Batch 40/100 | Loss 0.237339
Epoch 58 | Batch 50/100 | Loss 0.231294
Epoch 58 | Batch 60/100 | Loss 0.202682
Epoch 58 | Batch 70/100 | Loss 0.217606
Epoch 58 | Batch 80/100 | Loss 0.211771
Epoch 58 | Batch 90/100 | Loss 0.219816
100 Test Acc = 55.29% +- 2.36%
Epoch 58: 55.29
Epoch 59 | Batch 0/100 | Loss 0.069345
Epoch 59 | Batch 10/100 | Loss 0.145982
Epoch 59 | Batch 20/100 | Loss 0.173273
Epoch 59 | Batch 30/100 | Loss 0.212471
Epoch 59 | Batch 40/100 | Loss 0.238027
Epoch 59 | Batch 50/100 | Loss 0.240031
Epoch 59 | Batch 60/100 | Loss 0.236675
Epoch 59 | Batch 70/100 | Loss 0.229946
Epoch 59 | Batch 80/100 | Loss 0.234359
Epoch 59 | Batch 90/100 | Loss 0.221560
100 Test Acc = 58.39% +- 2.40%
Epoch 59: 58.39
best model! save...
Checkpoint directory: checkpoints/method_matchingnet_dataset_swissprot_n_shot_1/swissprot/matchingnet_FCNet

**WARNING: NO VERSION LINE FOUND IN GAF FILE. USING:
!gaf-version: 2.2
[2023-12-09 01:45:28,995][root][ERROR] - Failed to validate header as GAF v2.2:
[]
HMS:0:00:07.255945 310,057 annotations READ: ./data/swissprot/filtered_goa_uniprot_all_noiea.gaf 
25933 IDs in loaded association branch, BP
Using checkpoint dir: checkpoints/method_matchingnet_dataset_swissprot_n_shot_1/swissprot/matchingnet_FCNet/20231209_014250
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
600 Test Acc = 92.84% +- 0.62%

**WARNING: NO VERSION LINE FOUND IN GAF FILE. USING:
!gaf-version: 2.2
[2023-12-09 01:47:21,790][root][ERROR] - Failed to validate header as GAF v2.2:
[]
HMS:0:00:06.977517 310,057 annotations READ: ./data/swissprot/filtered_goa_uniprot_all_noiea.gaf 
25933 IDs in loaded association branch, BP
Using checkpoint dir: checkpoints/method_matchingnet_dataset_swissprot_n_shot_1/swissprot/matchingnet_FCNet/20231209_014250
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
600 Test Acc = 54.66% +- 1.06%

**WARNING: NO VERSION LINE FOUND IN GAF FILE. USING:
!gaf-version: 2.2
[2023-12-09 01:48:07,773][root][ERROR] - Failed to validate header as GAF v2.2:
[]
HMS:0:00:06.844482 310,057 annotations READ: ./data/swissprot/filtered_goa_uniprot_all_noiea.gaf 
25933 IDs in loaded association branch, BP
Using checkpoint dir: checkpoints/method_matchingnet_dataset_swissprot_n_shot_1/swissprot/matchingnet_FCNet/20231209_014250
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
600 Test Acc = 54.80% +- 0.95%
Results logged to ./checkpoints/method_matchingnet_dataset_swissprot_n_shot_1/results.txt
+-------+--------------------+-------------------+
| split |      acc_mean      |      acc_std      |
+-------+--------------------+-------------------+
| train |       92.84        | 7.787522783986645 |
|  val  | 54.662222222222226 | 13.29862073977023 |
|  test | 54.80222222222221  | 11.85302565946563 |
+-------+--------------------+-------------------+
