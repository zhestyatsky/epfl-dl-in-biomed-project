/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 1
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 1
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 1
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 0.5
    finetuning_lr_init: 0.05
    num_adaptation_steps: 5
    kl_coef: 0.01
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 0.1
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 32
    enable_finetuning_loop: true
  n_task: 4
  latent_space_dim: 32
  leo_inner_lr_init: 0.5
  leo_finetuning_lr_init: 0.05
  num_adaptation_steps: 5
  kl_coef: 0.01
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 0.1
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-06
  optimize_backbone: false
  pretrained_backbone_weights_path: pretrained_weights/tabula_muris_baseline_model.tar
  enable_finetuning_loop: true
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.001
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Using pretrained backbone from pretrained_weights/tabula_muris_baseline_model.tar.
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=32, bias=False)
    (relation_net): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=False)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=64, bias=False)
      (3): ReLU()
      (4): Linear(in_features=64, out_features=64, bias=False)
    )
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=32, out_features=130, bias=False)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 1e-06

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Epoch 0 | Batch 0/100 | Loss 5.089219
InnerLR 0.500000
FineTuningLR 0.050000
Epoch 0 | Batch 10/100 | Loss 5.033438
InnerLR 0.502000
FineTuningLR 0.052000
Epoch 0 | Batch 20/100 | Loss 5.588529
InnerLR 0.505000
FineTuningLR 0.055000
Epoch 0 | Batch 30/100 | Loss 5.637398
InnerLR 0.507000
FineTuningLR 0.057000
Epoch 0 | Batch 40/100 | Loss 5.723864
InnerLR 0.510000
FineTuningLR 0.060000
Epoch 0 | Batch 50/100 | Loss 5.555181
InnerLR 0.512000
FineTuningLR 0.062000
Epoch 0 | Batch 60/100 | Loss 5.388324
InnerLR 0.514748
FineTuningLR 0.065000
Epoch 0 | Batch 70/100 | Loss 5.419846
InnerLR 0.515871
FineTuningLR 0.067000
Epoch 0 | Batch 80/100 | Loss 5.412252
InnerLR 0.517905
FineTuningLR 0.070000
Epoch 0 | Batch 90/100 | Loss 5.369795
InnerLR 0.519429
FineTuningLR 0.072000
100 Accuracy = 49.09% +- 2.58%
Epoch 0: 49.09
best model! save...
Epoch 1 | Batch 0/100 | Loss 3.256386
InnerLR 0.521893
FineTuningLR 0.075000
Epoch 1 | Batch 10/100 | Loss 5.114139
InnerLR 0.523625
FineTuningLR 0.077000
Epoch 1 | Batch 20/100 | Loss 4.525094
InnerLR 0.525922
FineTuningLR 0.080000
Epoch 1 | Batch 30/100 | Loss 4.397661
InnerLR 0.527448
FineTuningLR 0.082000
Epoch 1 | Batch 40/100 | Loss 4.357667
InnerLR 0.529905
FineTuningLR 0.085000
Epoch 1 | Batch 50/100 | Loss 4.227701
InnerLR 0.531630
FineTuningLR 0.087000
Epoch 1 | Batch 60/100 | Loss 4.069190
InnerLR 0.533927
FineTuningLR 0.090000
Epoch 1 | Batch 70/100 | Loss 4.069147
InnerLR 0.535454
FineTuningLR 0.092000
Epoch 1 | Batch 80/100 | Loss 3.888375
InnerLR 0.537362
FineTuningLR 0.095000
Epoch 1 | Batch 90/100 | Loss 3.826076
InnerLR 0.538610
FineTuningLR 0.097004
100 Accuracy = 52.08% +- 2.23%
Epoch 1: 52.08
best model! save...
Epoch 2 | Batch 0/100 | Loss 3.200109
InnerLR 0.540492
FineTuningLR 0.100013
Epoch 2 | Batch 10/100 | Loss 2.432718
InnerLR 0.541922
FineTuningLR 0.102018
Epoch 2 | Batch 20/100 | Loss 2.618152
InnerLR 0.544265
FineTuningLR 0.105022
Epoch 2 | Batch 30/100 | Loss 2.833672
InnerLR 0.545929
FineTuningLR 0.107024
Epoch 2 | Batch 40/100 | Loss 2.780173
InnerLR 0.547417
FineTuningLR 0.110025
Epoch 2 | Batch 50/100 | Loss 2.588085
InnerLR 0.547910
FineTuningLR 0.112026
Epoch 2 | Batch 60/100 | Loss 2.481563
InnerLR 0.548970
FineTuningLR 0.115026
Epoch 2 | Batch 70/100 | Loss 2.332187
InnerLR 0.549158
FineTuningLR 0.117026
Epoch 2 | Batch 80/100 | Loss 2.250461
InnerLR 0.548801
FineTuningLR 0.119882
Epoch 2 | Batch 90/100 | Loss 2.132715
InnerLR 0.548386
FineTuningLR 0.121585
100 Accuracy = 60.88% +- 2.35%
Epoch 2: 60.88
best model! save...
Epoch 3 | Batch 0/100 | Loss 2.243570
InnerLR 0.548016
FineTuningLR 0.124238
Epoch 3 | Batch 10/100 | Loss 1.583661
InnerLR 0.547740
FineTuningLR 0.126057
Epoch 3 | Batch 20/100 | Loss 1.264636
InnerLR 0.547856
FineTuningLR 0.128845
Epoch 3 | Batch 30/100 | Loss 1.212255
InnerLR 0.548003
FineTuningLR 0.130734
Epoch 3 | Batch 40/100 | Loss 1.153877
InnerLR 0.548120
FineTuningLR 0.133603
Epoch 3 | Batch 50/100 | Loss 1.061092
InnerLR 0.548025
FineTuningLR 0.135533
Epoch 3 | Batch 60/100 | Loss 0.990285
InnerLR 0.548043
FineTuningLR 0.138464
Epoch 3 | Batch 70/100 | Loss 0.949204
InnerLR 0.547911
FineTuningLR 0.140445
Epoch 3 | Batch 80/100 | Loss 0.930085
InnerLR 0.547811
FineTuningLR 0.142881
Epoch 3 | Batch 90/100 | Loss 0.914541
InnerLR 0.547733
FineTuningLR 0.144589
100 Accuracy = 64.79% +- 3.02%
Epoch 3: 64.79
best model! save...
Epoch 4 | Batch 0/100 | Loss 0.462805
InnerLR 0.547590
FineTuningLR 0.146710
Epoch 4 | Batch 10/100 | Loss 0.470489
InnerLR 0.547363
FineTuningLR 0.148058
Epoch 4 | Batch 20/100 | Loss 0.457761
InnerLR 0.547697
FineTuningLR 0.149537
Epoch 4 | Batch 30/100 | Loss 0.477262
InnerLR 0.548338
FineTuningLR 0.150405
Epoch 4 | Batch 40/100 | Loss 0.512116
InnerLR 0.549444
FineTuningLR 0.152157
Epoch 4 | Batch 50/100 | Loss 0.502454
InnerLR 0.549998
FineTuningLR 0.153534
Epoch 4 | Batch 60/100 | Loss 0.511998
InnerLR 0.550064
FineTuningLR 0.155335
Epoch 4 | Batch 70/100 | Loss 0.533784
InnerLR 0.549659
FineTuningLR 0.156537
Epoch 4 | Batch 80/100 | Loss 0.525432
InnerLR 0.548492
FineTuningLR 0.158353
Epoch 4 | Batch 90/100 | Loss 0.535552
InnerLR 0.548011
FineTuningLR 0.159741
100 Accuracy = 70.69% +- 2.32%
Epoch 4: 70.69
best model! save...
Epoch 5 | Batch 0/100 | Loss 0.577896
InnerLR 0.547769
FineTuningLR 0.161293
Epoch 5 | Batch 10/100 | Loss 0.486004
InnerLR 0.547688
FineTuningLR 0.161867
Epoch 5 | Batch 20/100 | Loss 0.505264
InnerLR 0.546891
FineTuningLR 0.162835
Epoch 5 | Batch 30/100 | Loss 0.529027
InnerLR 0.546599
FineTuningLR 0.163481
Epoch 5 | Batch 40/100 | Loss 0.511625
InnerLR 0.546228
FineTuningLR 0.164379
Epoch 5 | Batch 50/100 | Loss 0.522387
InnerLR 0.545797
FineTuningLR 0.164822
Epoch 5 | Batch 60/100 | Loss 0.506964
InnerLR 0.544596
FineTuningLR 0.165638
Epoch 5 | Batch 70/100 | Loss 0.497198
InnerLR 0.543506
FineTuningLR 0.166401
Epoch 5 | Batch 80/100 | Loss 0.489604
InnerLR 0.542485
FineTuningLR 0.167587
Epoch 5 | Batch 90/100 | Loss 0.483271
InnerLR 0.541603
FineTuningLR 0.168540
100 Accuracy = 74.65% +- 2.75%
Epoch 5: 74.65
best model! save...
Epoch 6 | Batch 0/100 | Loss 0.356817
InnerLR 0.540854
FineTuningLR 0.169808
Epoch 6 | Batch 10/100 | Loss 0.437746
InnerLR 0.540468
FineTuningLR 0.170988
Epoch 6 | Batch 20/100 | Loss 0.422967
InnerLR 0.539278
FineTuningLR 0.172787
Epoch 6 | Batch 30/100 | Loss 0.417401
InnerLR 0.538175
FineTuningLR 0.174086
Epoch 6 | Batch 40/100 | Loss 0.421486
InnerLR 0.536750
FineTuningLR 0.176264
Epoch 6 | Batch 50/100 | Loss 0.448117
InnerLR 0.535924
FineTuningLR 0.177382
Epoch 6 | Batch 60/100 | Loss 0.467260
InnerLR 0.535263
FineTuningLR 0.179227
Epoch 6 | Batch 70/100 | Loss 0.473720
InnerLR 0.534472
FineTuningLR 0.180374
Epoch 6 | Batch 80/100 | Loss 0.468945
InnerLR 0.533053
FineTuningLR 0.182349
Epoch 6 | Batch 90/100 | Loss 0.459479
InnerLR 0.532134
FineTuningLR 0.183843
100 Accuracy = 74.43% +- 2.49%
Epoch 6: 74.43
Epoch 7 | Batch 0/100 | Loss 0.563286
InnerLR 0.530988
FineTuningLR 0.185897
Epoch 7 | Batch 10/100 | Loss 0.482755
InnerLR 0.530396
FineTuningLR 0.186726
Epoch 7 | Batch 20/100 | Loss 0.403015
InnerLR 0.529833
FineTuningLR 0.187190
Epoch 7 | Batch 30/100 | Loss 0.414905
InnerLR 0.530008
FineTuningLR 0.187792
Epoch 7 | Batch 40/100 | Loss 0.399825
InnerLR 0.530058
FineTuningLR 0.189134
Epoch 7 | Batch 50/100 | Loss 0.382393
InnerLR 0.530370
FineTuningLR 0.190223
Epoch 7 | Batch 60/100 | Loss 0.370492
InnerLR 0.530790
FineTuningLR 0.192117
Epoch 7 | Batch 70/100 | Loss 0.361125
InnerLR 0.530806
FineTuningLR 0.192781
Epoch 7 | Batch 80/100 | Loss 0.353746
InnerLR 0.531129
FineTuningLR 0.193945
Epoch 7 | Batch 90/100 | Loss 0.356066
InnerLR 0.531407
FineTuningLR 0.194382
100 Accuracy = 72.33% +- 2.62%
Epoch 7: 72.33
Epoch 8 | Batch 0/100 | Loss 0.954288
InnerLR 0.531644
FineTuningLR 0.195144
Epoch 8 | Batch 10/100 | Loss 0.467649
InnerLR 0.531684
FineTuningLR 0.195633
Epoch 8 | Batch 20/100 | Loss 0.433945
InnerLR 0.531018
FineTuningLR 0.196617
Epoch 8 | Batch 30/100 | Loss 0.401686
InnerLR 0.530382
FineTuningLR 0.197669
Epoch 8 | Batch 40/100 | Loss 0.387767
InnerLR 0.530157
FineTuningLR 0.199119
Epoch 8 | Batch 50/100 | Loss 0.368614
InnerLR 0.530257
FineTuningLR 0.200423
Epoch 8 | Batch 60/100 | Loss 0.346667
InnerLR 0.530343
FineTuningLR 0.202271
Epoch 8 | Batch 70/100 | Loss 0.341462
InnerLR 0.530875
FineTuningLR 0.203190
Epoch 8 | Batch 80/100 | Loss 0.334858
InnerLR 0.531160
FineTuningLR 0.204979
Epoch 8 | Batch 90/100 | Loss 0.340055
InnerLR 0.530854
FineTuningLR 0.206362
100 Accuracy = 74.04% +- 2.66%
Epoch 8: 74.04
Epoch 9 | Batch 0/100 | Loss 0.559501
InnerLR 0.531019
FineTuningLR 0.208262
Epoch 9 | Batch 10/100 | Loss 0.491286
InnerLR 0.531429
FineTuningLR 0.209173
Epoch 9 | Batch 20/100 | Loss 0.373963
InnerLR 0.531675
FineTuningLR 0.210517
Epoch 9 | Batch 30/100 | Loss 0.377460
InnerLR 0.532053
FineTuningLR 0.211483
Epoch 9 | Batch 40/100 | Loss 0.375629
InnerLR 0.531807
FineTuningLR 0.212300
Epoch 9 | Batch 50/100 | Loss 0.378407
InnerLR 0.531552
FineTuningLR 0.212288
Epoch 9 | Batch 60/100 | Loss 0.363338
InnerLR 0.531970
FineTuningLR 0.212320
Epoch 9 | Batch 70/100 | Loss 0.356190
InnerLR 0.532370
FineTuningLR 0.212734
Epoch 9 | Batch 80/100 | Loss 0.343745
InnerLR 0.532366
FineTuningLR 0.213860
Epoch 9 | Batch 90/100 | Loss 0.335715
InnerLR 0.532177
FineTuningLR 0.214940
100 Accuracy = 76.44% +- 2.65%
Epoch 9: 76.44
best model! save...
Epoch 10 | Batch 0/100 | Loss 0.154499
InnerLR 0.532387
FineTuningLR 0.216872
Epoch 10 | Batch 10/100 | Loss 0.374169
InnerLR 0.532767
FineTuningLR 0.218328
Epoch 10 | Batch 20/100 | Loss 0.329994
InnerLR 0.533022
FineTuningLR 0.220722
Epoch 10 | Batch 30/100 | Loss 0.375547
InnerLR 0.532934
FineTuningLR 0.222074
Epoch 10 | Batch 40/100 | Loss 0.352793
InnerLR 0.532596
FineTuningLR 0.224337
Epoch 10 | Batch 50/100 | Loss 0.340607
InnerLR 0.532392
FineTuningLR 0.225814
Epoch 10 | Batch 60/100 | Loss 0.338343
InnerLR 0.532435
FineTuningLR 0.227347
Epoch 10 | Batch 70/100 | Loss 0.330588
InnerLR 0.532339
FineTuningLR 0.228241
Epoch 10 | Batch 80/100 | Loss 0.334285
InnerLR 0.532133
FineTuningLR 0.229828
Epoch 10 | Batch 90/100 | Loss 0.329998
InnerLR 0.531790
FineTuningLR 0.230857
100 Accuracy = 76.17% +- 2.28%
Epoch 10: 76.17
Epoch 11 | Batch 0/100 | Loss 0.311721
InnerLR 0.531426
FineTuningLR 0.232165
Epoch 11 | Batch 10/100 | Loss 0.409836
InnerLR 0.531394
FineTuningLR 0.233084
Epoch 11 | Batch 20/100 | Loss 0.357448
InnerLR 0.531083
FineTuningLR 0.234500
Epoch 11 | Batch 30/100 | Loss 0.317972
InnerLR 0.531129
FineTuningLR 0.235319
Epoch 11 | Batch 40/100 | Loss 0.306652
InnerLR 0.531241
FineTuningLR 0.236865
Epoch 11 | Batch 50/100 | Loss 0.320921
InnerLR 0.530963
FineTuningLR 0.237531
Epoch 11 | Batch 60/100 | Loss 0.320386
InnerLR 0.530761
FineTuningLR 0.238876
Epoch 11 | Batch 70/100 | Loss 0.322919
InnerLR 0.530331
FineTuningLR 0.239380
Epoch 11 | Batch 80/100 | Loss 0.324570
InnerLR 0.529960
FineTuningLR 0.240198
Epoch 11 | Batch 90/100 | Loss 0.337079
InnerLR 0.529621
FineTuningLR 0.240992
100 Accuracy = 76.60% +- 2.56%
Epoch 11: 76.60
best model! save...
Epoch 12 | Batch 0/100 | Loss 0.169301
InnerLR 0.529241
FineTuningLR 0.241494
Epoch 12 | Batch 10/100 | Loss 0.300417
InnerLR 0.529195
FineTuningLR 0.242103
Epoch 12 | Batch 20/100 | Loss 0.290775
InnerLR 0.528628
FineTuningLR 0.242757
Epoch 12 | Batch 30/100 | Loss 0.285620
InnerLR 0.528622
FineTuningLR 0.243171
Epoch 12 | Batch 40/100 | Loss 0.296482
InnerLR 0.529244
FineTuningLR 0.243929
Epoch 12 | Batch 50/100 | Loss 0.289364
InnerLR 0.529370
FineTuningLR 0.244459
Epoch 12 | Batch 60/100 | Loss 0.296822
InnerLR 0.529180
FineTuningLR 0.245609
Epoch 12 | Batch 70/100 | Loss 0.290484
InnerLR 0.529259
FineTuningLR 0.246761
Epoch 12 | Batch 80/100 | Loss 0.297251
InnerLR 0.529873
FineTuningLR 0.248262
Epoch 12 | Batch 90/100 | Loss 0.299004
InnerLR 0.529980
FineTuningLR 0.249214
100 Accuracy = 77.52% +- 2.50%
Epoch 12: 77.52
best model! save...
Epoch 13 | Batch 0/100 | Loss 0.152119
InnerLR 0.529781
FineTuningLR 0.250686
Epoch 13 | Batch 10/100 | Loss 0.327112
InnerLR 0.529803
FineTuningLR 0.251739
Epoch 13 | Batch 20/100 | Loss 0.336768
InnerLR 0.529429
FineTuningLR 0.252655
Epoch 13 | Batch 30/100 | Loss 0.302858
InnerLR 0.529134
FineTuningLR 0.253081
Epoch 13 | Batch 40/100 | Loss 0.309042
InnerLR 0.528652
FineTuningLR 0.253840
Epoch 13 | Batch 50/100 | Loss 0.304685
InnerLR 0.528286
FineTuningLR 0.254567
Epoch 13 | Batch 60/100 | Loss 0.297735
InnerLR 0.527994
FineTuningLR 0.255683
Epoch 13 | Batch 70/100 | Loss 0.297418
InnerLR 0.528030
FineTuningLR 0.256079
Epoch 13 | Batch 80/100 | Loss 0.301912
InnerLR 0.527794
FineTuningLR 0.256452
Epoch 13 | Batch 90/100 | Loss 0.307974
InnerLR 0.527537
FineTuningLR 0.256794
100 Accuracy = 77.67% +- 2.38%
Epoch 13: 77.67
best model! save...
Epoch 14 | Batch 0/100 | Loss 0.195627
InnerLR 0.527124
FineTuningLR 0.257603
Epoch 14 | Batch 10/100 | Loss 0.239936
InnerLR 0.527405
FineTuningLR 0.258100
Epoch 14 | Batch 20/100 | Loss 0.268595
InnerLR 0.527919
FineTuningLR 0.258488
Epoch 14 | Batch 30/100 | Loss 0.259723
InnerLR 0.527819
FineTuningLR 0.259098
Epoch 14 | Batch 40/100 | Loss 0.263013
InnerLR 0.527759
FineTuningLR 0.259944
Epoch 14 | Batch 50/100 | Loss 0.272628
InnerLR 0.528117
FineTuningLR 0.260652
Epoch 14 | Batch 60/100 | Loss 0.293409
InnerLR 0.528108
FineTuningLR 0.261397
Epoch 14 | Batch 70/100 | Loss 0.291551
InnerLR 0.527878
FineTuningLR 0.262196
Epoch 14 | Batch 80/100 | Loss 0.287047
InnerLR 0.527626
FineTuningLR 0.263180
Epoch 14 | Batch 90/100 | Loss 0.295360
InnerLR 0.527226
FineTuningLR 0.263945
100 Accuracy = 78.76% +- 2.42%
Epoch 14: 78.76
best model! save...
Epoch 15 | Batch 0/100 | Loss 0.448342
InnerLR 0.526251
FineTuningLR 0.264356
Epoch 15 | Batch 10/100 | Loss 0.302659
InnerLR 0.525515
FineTuningLR 0.264906
Epoch 15 | Batch 20/100 | Loss 0.346461
InnerLR 0.523959
FineTuningLR 0.265629
Epoch 15 | Batch 30/100 | Loss 0.311907
InnerLR 0.522965
FineTuningLR 0.265692
Epoch 15 | Batch 40/100 | Loss 0.286624
InnerLR 0.522226
FineTuningLR 0.266580
Epoch 15 | Batch 50/100 | Loss 0.328788
InnerLR 0.522080
FineTuningLR 0.267139
Epoch 15 | Batch 60/100 | Loss 0.337986
InnerLR 0.521875
FineTuningLR 0.267932
Epoch 15 | Batch 70/100 | Loss 0.331673
InnerLR 0.522120
FineTuningLR 0.268283
Epoch 15 | Batch 80/100 | Loss 0.323561
InnerLR 0.521921
FineTuningLR 0.269438
Epoch 15 | Batch 90/100 | Loss 0.314518
InnerLR 0.521727
FineTuningLR 0.270320
100 Accuracy = 77.52% +- 2.51%
Epoch 15: 77.52
Epoch 16 | Batch 0/100 | Loss 0.536765
InnerLR 0.521812
FineTuningLR 0.270746
Epoch 16 | Batch 10/100 | Loss 0.277725
InnerLR 0.521402
FineTuningLR 0.270966
Epoch 16 | Batch 20/100 | Loss 0.319404
InnerLR 0.521432
FineTuningLR 0.271831
Epoch 16 | Batch 30/100 | Loss 0.309991
InnerLR 0.521815
FineTuningLR 0.272737
Epoch 16 | Batch 40/100 | Loss 0.285332
InnerLR 0.522500
FineTuningLR 0.274020
Epoch 16 | Batch 50/100 | Loss 0.276306
InnerLR 0.523087
FineTuningLR 0.275052
Epoch 16 | Batch 60/100 | Loss 0.272012
InnerLR 0.524545
FineTuningLR 0.276395
Epoch 16 | Batch 70/100 | Loss 0.271307
InnerLR 0.525510
FineTuningLR 0.277302
Epoch 16 | Batch 80/100 | Loss 0.271796
InnerLR 0.526866
FineTuningLR 0.278248
Epoch 16 | Batch 90/100 | Loss 0.271190
InnerLR 0.527559
FineTuningLR 0.278774
100 Accuracy = 78.35% +- 2.57%
Epoch 16: 78.35
Epoch 17 | Batch 0/100 | Loss 0.150621
InnerLR 0.527898
FineTuningLR 0.279492
Epoch 17 | Batch 10/100 | Loss 0.239767
InnerLR 0.528198
FineTuningLR 0.279960
Epoch 17 | Batch 20/100 | Loss 0.219817
InnerLR 0.528498
FineTuningLR 0.281154
Epoch 17 | Batch 30/100 | Loss 0.218231
InnerLR 0.528470
FineTuningLR 0.281890
Epoch 17 | Batch 40/100 | Loss 0.245261
InnerLR 0.528436
FineTuningLR 0.282964
Epoch 17 | Batch 50/100 | Loss 0.261998
InnerLR 0.528757
FineTuningLR 0.283285
Epoch 17 | Batch 60/100 | Loss 0.275806
InnerLR 0.529262
FineTuningLR 0.284270
Epoch 17 | Batch 70/100 | Loss 0.291561
InnerLR 0.529158
FineTuningLR 0.285278
Epoch 17 | Batch 80/100 | Loss 0.287158
InnerLR 0.529217
FineTuningLR 0.286309
Epoch 17 | Batch 90/100 | Loss 0.285476
InnerLR 0.529447
FineTuningLR 0.287290
100 Accuracy = 78.39% +- 2.75%
Epoch 17: 78.39
Epoch 18 | Batch 0/100 | Loss 0.124863
InnerLR 0.529922
FineTuningLR 0.288642
Epoch 18 | Batch 10/100 | Loss 0.248744
InnerLR 0.530370
FineTuningLR 0.289812
Epoch 18 | Batch 20/100 | Loss 0.272624
InnerLR 0.530424
FineTuningLR 0.290960
Epoch 18 | Batch 30/100 | Loss 0.255690
InnerLR 0.530827
FineTuningLR 0.291884
Epoch 18 | Batch 40/100 | Loss 0.268239
InnerLR 0.531523
FineTuningLR 0.293314
Epoch 18 | Batch 50/100 | Loss 0.275265
InnerLR 0.531638
FineTuningLR 0.294384
Epoch 18 | Batch 60/100 | Loss 0.268308
InnerLR 0.531339
FineTuningLR 0.295908
Epoch 18 | Batch 70/100 | Loss 0.269527
InnerLR 0.531169
FineTuningLR 0.297175
Epoch 18 | Batch 80/100 | Loss 0.278911
InnerLR 0.530830
FineTuningLR 0.298730
Epoch 18 | Batch 90/100 | Loss 0.288029
InnerLR 0.530292
FineTuningLR 0.299504
100 Accuracy = 80.32% +- 2.44%
Epoch 18: 80.32
best model! save...
Epoch 19 | Batch 0/100 | Loss 0.234771
InnerLR 0.529415
FineTuningLR 0.300537
Epoch 19 | Batch 10/100 | Loss 0.246169
InnerLR 0.528989
FineTuningLR 0.301272
Epoch 19 | Batch 20/100 | Loss 0.248432
InnerLR 0.529114
FineTuningLR 0.302601
Epoch 19 | Batch 30/100 | Loss 0.288707
InnerLR 0.529685
FineTuningLR 0.303130
Epoch 19 | Batch 40/100 | Loss 0.295839
InnerLR 0.530499
FineTuningLR 0.303597
Epoch 19 | Batch 50/100 | Loss 0.298945
InnerLR 0.531404
FineTuningLR 0.303384
Epoch 19 | Batch 60/100 | Loss 0.299472
InnerLR 0.532775
FineTuningLR 0.302663
Epoch 19 | Batch 70/100 | Loss 0.318092
InnerLR 0.533447
FineTuningLR 0.302075
Epoch 19 | Batch 80/100 | Loss 0.305905
InnerLR 0.534220
FineTuningLR 0.300843
Epoch 19 | Batch 90/100 | Loss 0.298231
InnerLR 0.534839
FineTuningLR 0.300258
100 Accuracy = 79.53% +- 2.36%
Epoch 19: 79.53
Epoch 20 | Batch 0/100 | Loss 0.116515
InnerLR 0.535510
FineTuningLR 0.299976
Epoch 20 | Batch 10/100 | Loss 0.289848
InnerLR 0.535693
FineTuningLR 0.300003
Epoch 20 | Batch 20/100 | Loss 0.315608
InnerLR 0.535709
FineTuningLR 0.300143
Epoch 20 | Batch 30/100 | Loss 0.299549
InnerLR 0.535645
FineTuningLR 0.300065
Epoch 20 | Batch 40/100 | Loss 0.290210
InnerLR 0.535328
FineTuningLR 0.299866
Epoch 20 | Batch 50/100 | Loss 0.290566
InnerLR 0.535087
FineTuningLR 0.300037
Epoch 20 | Batch 60/100 | Loss 0.280957
InnerLR 0.534964
FineTuningLR 0.300339
Epoch 20 | Batch 70/100 | Loss 0.270191
InnerLR 0.535325
FineTuningLR 0.300254
Epoch 20 | Batch 80/100 | Loss 0.270460
InnerLR 0.536349
FineTuningLR 0.300034
Epoch 20 | Batch 90/100 | Loss 0.272344
InnerLR 0.536640
FineTuningLR 0.299879
100 Accuracy = 77.91% +- 2.53%
Epoch 20: 77.91
Epoch 21 | Batch 0/100 | Loss 0.143243
InnerLR 0.536788
FineTuningLR 0.299466
Epoch 21 | Batch 10/100 | Loss 0.398768
InnerLR 0.536744
FineTuningLR 0.298802
Epoch 21 | Batch 20/100 | Loss 0.366029
InnerLR 0.536938
FineTuningLR 0.297737
Epoch 21 | Batch 30/100 | Loss 0.317890
InnerLR 0.537186
FineTuningLR 0.296788
Epoch 21 | Batch 40/100 | Loss 0.295460
InnerLR 0.537432
FineTuningLR 0.295420
Epoch 21 | Batch 50/100 | Loss 0.296288
InnerLR 0.537651
FineTuningLR 0.294825
Epoch 21 | Batch 60/100 | Loss 0.299885
InnerLR 0.537355
FineTuningLR 0.294537
Epoch 21 | Batch 70/100 | Loss 0.290680
InnerLR 0.537269
FineTuningLR 0.294179
Epoch 21 | Batch 80/100 | Loss 0.289358
InnerLR 0.537622
FineTuningLR 0.294124
Epoch 21 | Batch 90/100 | Loss 0.292344
InnerLR 0.537637
FineTuningLR 0.294552
100 Accuracy = 78.85% +- 2.10%
Epoch 21: 78.85
Epoch 22 | Batch 0/100 | Loss 0.284822
InnerLR 0.537184
FineTuningLR 0.295244
Epoch 22 | Batch 10/100 | Loss 0.273715
InnerLR 0.537165
FineTuningLR 0.295255
Epoch 22 | Batch 20/100 | Loss 0.226944
InnerLR 0.537388
FineTuningLR 0.295686
Epoch 22 | Batch 30/100 | Loss 0.219908
InnerLR 0.537131
FineTuningLR 0.296359
Epoch 22 | Batch 40/100 | Loss 0.210983
InnerLR 0.536400
FineTuningLR 0.297230
Epoch 22 | Batch 50/100 | Loss 0.219729
InnerLR 0.535970
FineTuningLR 0.297771
Epoch 22 | Batch 60/100 | Loss 0.217659
InnerLR 0.535240
FineTuningLR 0.298529
Epoch 22 | Batch 70/100 | Loss 0.234125
InnerLR 0.534575
FineTuningLR 0.299105
Epoch 22 | Batch 80/100 | Loss 0.234971
InnerLR 0.533179
FineTuningLR 0.300251
Epoch 22 | Batch 90/100 | Loss 0.241040
InnerLR 0.532257
FineTuningLR 0.301211
100 Accuracy = 79.27% +- 2.50%
Epoch 22: 79.27
Epoch 23 | Batch 0/100 | Loss 0.144205
InnerLR 0.531436
FineTuningLR 0.301846
Epoch 23 | Batch 10/100 | Loss 0.237398
InnerLR 0.531072
FineTuningLR 0.302588
Epoch 23 | Batch 20/100 | Loss 0.230272
InnerLR 0.531216
FineTuningLR 0.303673
Epoch 23 | Batch 30/100 | Loss 0.244330
InnerLR 0.531111
FineTuningLR 0.304364
Epoch 23 | Batch 40/100 | Loss 0.242228
InnerLR 0.531029
FineTuningLR 0.305651
Epoch 23 | Batch 50/100 | Loss 0.246950
InnerLR 0.531036
FineTuningLR 0.306816
Epoch 23 | Batch 60/100 | Loss 0.250628
InnerLR 0.531485
FineTuningLR 0.308914
Epoch 23 | Batch 70/100 | Loss 0.264240
InnerLR 0.531600
FineTuningLR 0.310112
Epoch 23 | Batch 80/100 | Loss 0.276906
InnerLR 0.531782
FineTuningLR 0.312257
Epoch 23 | Batch 90/100 | Loss 0.267938
InnerLR 0.532108
FineTuningLR 0.313610
100 Accuracy = 79.85% +- 2.57%
Epoch 23: 79.85
Epoch 24 | Batch 0/100 | Loss 0.283505
InnerLR 0.532128
FineTuningLR 0.314738
Epoch 24 | Batch 10/100 | Loss 0.261403
InnerLR 0.532174
FineTuningLR 0.315237
Epoch 24 | Batch 20/100 | Loss 0.241514
InnerLR 0.532639
FineTuningLR 0.315477
Epoch 24 | Batch 30/100 | Loss 0.250293
InnerLR 0.533116
FineTuningLR 0.315270
Epoch 24 | Batch 40/100 | Loss 0.255913
InnerLR 0.533843
FineTuningLR 0.314842
Epoch 24 | Batch 50/100 | Loss 0.249162
InnerLR 0.534152
FineTuningLR 0.314421
Epoch 24 | Batch 60/100 | Loss 0.257536
InnerLR 0.534779
FineTuningLR 0.313907
Epoch 24 | Batch 70/100 | Loss 0.251569
InnerLR 0.534830
FineTuningLR 0.313876
Epoch 24 | Batch 80/100 | Loss 0.263644
InnerLR 0.535034
FineTuningLR 0.314122
Epoch 24 | Batch 90/100 | Loss 0.265169
InnerLR 0.534953
FineTuningLR 0.313878
100 Accuracy = 78.77% +- 2.56%
Epoch 24: 78.77
Epoch 25 | Batch 0/100 | Loss 0.817983
InnerLR 0.534869
FineTuningLR 0.313765
Epoch 25 | Batch 10/100 | Loss 0.328870
InnerLR 0.534592
FineTuningLR 0.314010
Epoch 25 | Batch 20/100 | Loss 0.286989
InnerLR 0.534475
FineTuningLR 0.314598
Epoch 25 | Batch 30/100 | Loss 0.264715
InnerLR 0.534814
FineTuningLR 0.314750
Epoch 25 | Batch 40/100 | Loss 0.306130
InnerLR 0.534580
FineTuningLR 0.315073
Epoch 25 | Batch 50/100 | Loss 0.297614
InnerLR 0.533841
FineTuningLR 0.315342
Epoch 25 | Batch 60/100 | Loss 0.302153
InnerLR 0.532129
FineTuningLR 0.315498
Epoch 25 | Batch 70/100 | Loss 0.286361
InnerLR 0.530824
FineTuningLR 0.315352
Epoch 25 | Batch 80/100 | Loss 0.272210
InnerLR 0.529515
FineTuningLR 0.314997
Epoch 25 | Batch 90/100 | Loss 0.262695
InnerLR 0.529101
FineTuningLR 0.314840
100 Accuracy = 80.12% +- 2.62%
Epoch 25: 80.12
Epoch 26 | Batch 0/100 | Loss 0.246023
InnerLR 0.528518
FineTuningLR 0.314188
Epoch 26 | Batch 10/100 | Loss 0.298872
InnerLR 0.528398
FineTuningLR 0.313608
Epoch 26 | Batch 20/100 | Loss 0.271531
InnerLR 0.527799
FineTuningLR 0.313702
Epoch 26 | Batch 30/100 | Loss 0.289987
InnerLR 0.527190
FineTuningLR 0.313870
Epoch 26 | Batch 40/100 | Loss 0.292056
InnerLR 0.526852
FineTuningLR 0.313898
Epoch 26 | Batch 50/100 | Loss 0.296190
InnerLR 0.526625
FineTuningLR 0.313881
Epoch 26 | Batch 60/100 | Loss 0.286526
InnerLR 0.526370
FineTuningLR 0.314128
Epoch 26 | Batch 70/100 | Loss 0.283901
InnerLR 0.526297
FineTuningLR 0.314267
Epoch 26 | Batch 80/100 | Loss 0.284113
InnerLR 0.526299
FineTuningLR 0.314818
Epoch 26 | Batch 90/100 | Loss 0.277667
InnerLR 0.526074
FineTuningLR 0.314955
100 Accuracy = 78.68% +- 2.50%
Epoch 26: 78.68
Epoch 27 | Batch 0/100 | Loss 0.189368
InnerLR 0.526155
FineTuningLR 0.315550
Epoch 27 | Batch 10/100 | Loss 0.285021
InnerLR 0.526497
FineTuningLR 0.315679
Epoch 27 | Batch 20/100 | Loss 0.280748
InnerLR 0.526573
FineTuningLR 0.315677
Epoch 27 | Batch 30/100 | Loss 0.244372
InnerLR 0.527085
FineTuningLR 0.315646
Epoch 27 | Batch 40/100 | Loss 0.246062
InnerLR 0.528631
FineTuningLR 0.315730
Epoch 27 | Batch 50/100 | Loss 0.234049
InnerLR 0.529955
FineTuningLR 0.315777
Epoch 27 | Batch 60/100 | Loss 0.245906
InnerLR 0.531630
FineTuningLR 0.315744
Epoch 27 | Batch 70/100 | Loss 0.256020
InnerLR 0.531995
FineTuningLR 0.315949
Epoch 27 | Batch 80/100 | Loss 0.252170
InnerLR 0.532336
FineTuningLR 0.316619
Epoch 27 | Batch 90/100 | Loss 0.258664
InnerLR 0.532352
FineTuningLR 0.317077
100 Accuracy = 78.00% +- 2.66%
Epoch 27: 78.00
Epoch 28 | Batch 0/100 | Loss 0.191889
InnerLR 0.532340
FineTuningLR 0.317104
Epoch 28 | Batch 10/100 | Loss 0.259048
InnerLR 0.532318
FineTuningLR 0.317034
Epoch 28 | Batch 20/100 | Loss 0.277012
InnerLR 0.532580
FineTuningLR 0.316991
Epoch 28 | Batch 30/100 | Loss 0.268169
InnerLR 0.532722
FineTuningLR 0.316882
Epoch 28 | Batch 40/100 | Loss 0.273475
InnerLR 0.533095
FineTuningLR 0.317190
Epoch 28 | Batch 50/100 | Loss 0.278445
InnerLR 0.533179
FineTuningLR 0.317775
Epoch 28 | Batch 60/100 | Loss 0.263891
InnerLR 0.533161
FineTuningLR 0.318399
Epoch 28 | Batch 70/100 | Loss 0.259476
InnerLR 0.533384
FineTuningLR 0.318815
Epoch 28 | Batch 80/100 | Loss 0.281756
InnerLR 0.533622
FineTuningLR 0.318991
Epoch 28 | Batch 90/100 | Loss 0.268310
InnerLR 0.533740
FineTuningLR 0.318906
100 Accuracy = 78.76% +- 2.30%
Epoch 28: 78.76
Epoch 29 | Batch 0/100 | Loss 0.243851
InnerLR 0.534019
FineTuningLR 0.319137
Epoch 29 | Batch 10/100 | Loss 0.265996
InnerLR 0.533727
FineTuningLR 0.319211
Epoch 29 | Batch 20/100 | Loss 0.220823
InnerLR 0.532897
FineTuningLR 0.319167
Epoch 29 | Batch 30/100 | Loss 0.229032
InnerLR 0.532590
FineTuningLR 0.319157
Epoch 29 | Batch 40/100 | Loss 0.257614
InnerLR 0.531680
FineTuningLR 0.319421
Epoch 29 | Batch 50/100 | Loss 0.243990
InnerLR 0.531311
FineTuningLR 0.319744
Epoch 29 | Batch 60/100 | Loss 0.239508
InnerLR 0.531094
FineTuningLR 0.320671
Epoch 29 | Batch 70/100 | Loss 0.252772
InnerLR 0.530977
FineTuningLR 0.320740
Epoch 29 | Batch 80/100 | Loss 0.260233
InnerLR 0.530949
FineTuningLR 0.320515
Epoch 29 | Batch 90/100 | Loss 0.266730
InnerLR 0.530940
FineTuningLR 0.320365
100 Accuracy = 79.88% +- 2.36%
Epoch 29: 79.88
Epoch 30 | Batch 0/100 | Loss 0.169119
InnerLR 0.530609
FineTuningLR 0.320373
Epoch 30 | Batch 10/100 | Loss 0.387987
InnerLR 0.530663
FineTuningLR 0.320032
Epoch 30 | Batch 20/100 | Loss 0.365882
InnerLR 0.530789
FineTuningLR 0.319349
Epoch 30 | Batch 30/100 | Loss 0.311868
InnerLR 0.530715
FineTuningLR 0.318967
Epoch 30 | Batch 40/100 | Loss 0.293281
InnerLR 0.530488
FineTuningLR 0.319210
Epoch 30 | Batch 50/100 | Loss 0.279129
InnerLR 0.530128
FineTuningLR 0.319650
Epoch 30 | Batch 60/100 | Loss 0.269334
InnerLR 0.530077
FineTuningLR 0.320117
Epoch 30 | Batch 70/100 | Loss 0.274016
InnerLR 0.530005
FineTuningLR 0.320259
Epoch 30 | Batch 80/100 | Loss 0.264299
InnerLR 0.529467
FineTuningLR 0.320524
Epoch 30 | Batch 90/100 | Loss 0.268507
InnerLR 0.529076
FineTuningLR 0.320435
100 Accuracy = 81.37% +- 2.24%
Epoch 30: 81.37
best model! save...
Epoch 31 | Batch 0/100 | Loss 0.923321
InnerLR 0.528109
FineTuningLR 0.320755
Epoch 31 | Batch 10/100 | Loss 0.349459
InnerLR 0.527430
FineTuningLR 0.320775
Epoch 31 | Batch 20/100 | Loss 0.296013
InnerLR 0.526298
FineTuningLR 0.320019
Epoch 31 | Batch 30/100 | Loss 0.284832
InnerLR 0.525843
FineTuningLR 0.319772
Epoch 31 | Batch 40/100 | Loss 0.285990
InnerLR 0.525151
FineTuningLR 0.319353
Epoch 31 | Batch 50/100 | Loss 0.269983
InnerLR 0.524776
FineTuningLR 0.319254
Epoch 31 | Batch 60/100 | Loss 0.267154
InnerLR 0.524571
FineTuningLR 0.319212
Epoch 31 | Batch 70/100 | Loss 0.261188
InnerLR 0.524839
FineTuningLR 0.319353
Epoch 31 | Batch 80/100 | Loss 0.258792
InnerLR 0.525211
FineTuningLR 0.319210
Epoch 31 | Batch 90/100 | Loss 0.274697
InnerLR 0.525405
FineTuningLR 0.319446
100 Accuracy = 78.27% +- 2.33%
Epoch 31: 78.27
Epoch 32 | Batch 0/100 | Loss 0.241592
InnerLR 0.525518
FineTuningLR 0.320401
Epoch 32 | Batch 10/100 | Loss 0.227963
InnerLR 0.525497
FineTuningLR 0.321241
Epoch 32 | Batch 20/100 | Loss 0.230223
InnerLR 0.525592
FineTuningLR 0.322096
Epoch 32 | Batch 30/100 | Loss 0.247338
InnerLR 0.525317
FineTuningLR 0.322332
Epoch 32 | Batch 40/100 | Loss 0.246226
InnerLR 0.525555
FineTuningLR 0.322261
Epoch 32 | Batch 50/100 | Loss 0.249001
InnerLR 0.526215
FineTuningLR 0.322021
Epoch 32 | Batch 60/100 | Loss 0.245596
InnerLR 0.527660
FineTuningLR 0.322089
Epoch 32 | Batch 70/100 | Loss 0.254294
InnerLR 0.528918
FineTuningLR 0.322428
Epoch 32 | Batch 80/100 | Loss 0.256219
InnerLR 0.530044
FineTuningLR 0.323139
Epoch 32 | Batch 90/100 | Loss 0.278277
InnerLR 0.530121
FineTuningLR 0.323328
100 Accuracy = 81.37% +- 2.14%
Epoch 32: 81.37
Epoch 33 | Batch 0/100 | Loss 0.105076
InnerLR 0.530404
FineTuningLR 0.323845
Epoch 33 | Batch 10/100 | Loss 0.271450
InnerLR 0.530659
FineTuningLR 0.324164
Epoch 33 | Batch 20/100 | Loss 0.248100
InnerLR 0.531602
FineTuningLR 0.324599
Epoch 33 | Batch 30/100 | Loss 0.255663
InnerLR 0.532089
FineTuningLR 0.324612
Epoch 33 | Batch 40/100 | Loss 0.259851
InnerLR 0.532087
FineTuningLR 0.324857
Epoch 33 | Batch 50/100 | Loss 0.262078
InnerLR 0.531530
FineTuningLR 0.325180
Epoch 33 | Batch 60/100 | Loss 0.258592
InnerLR 0.530605
FineTuningLR 0.326259
Epoch 33 | Batch 70/100 | Loss 0.255376
InnerLR 0.530325
FineTuningLR 0.327241
Epoch 33 | Batch 80/100 | Loss 0.249332
InnerLR 0.529924
FineTuningLR 0.328161
Epoch 33 | Batch 90/100 | Loss 0.250321
InnerLR 0.529911
FineTuningLR 0.328313
100 Accuracy = 80.81% +- 2.27%
Epoch 33: 80.81
Epoch 34 | Batch 0/100 | Loss 0.108452
InnerLR 0.529880
FineTuningLR 0.328358
Epoch 34 | Batch 10/100 | Loss 0.174425
InnerLR 0.530033
FineTuningLR 0.328487
Epoch 34 | Batch 20/100 | Loss 0.194826
InnerLR 0.529546
FineTuningLR 0.328818
Epoch 34 | Batch 30/100 | Loss 0.183919
InnerLR 0.529366
FineTuningLR 0.329486
Epoch 34 | Batch 40/100 | Loss 0.224039
InnerLR 0.529149
FineTuningLR 0.329727
Epoch 34 | Batch 50/100 | Loss 0.217367
InnerLR 0.528930
FineTuningLR 0.329638
Epoch 34 | Batch 60/100 | Loss 0.233494
InnerLR 0.529148
FineTuningLR 0.328822
Epoch 34 | Batch 70/100 | Loss 0.243838
InnerLR 0.528998
FineTuningLR 0.328384
Epoch 34 | Batch 80/100 | Loss 0.237337
InnerLR 0.529090
FineTuningLR 0.327608
Epoch 34 | Batch 90/100 | Loss 0.236913
InnerLR 0.529393
FineTuningLR 0.327286
100 Accuracy = 80.31% +- 2.55%
Epoch 34: 80.31
Epoch 35 | Batch 0/100 | Loss 0.176908
InnerLR 0.529862
FineTuningLR 0.326543
Epoch 35 | Batch 10/100 | Loss 0.165988
InnerLR 0.529659
FineTuningLR 0.326147
Epoch 35 | Batch 20/100 | Loss 0.208382
InnerLR 0.529771
FineTuningLR 0.325560
Epoch 35 | Batch 30/100 | Loss 0.240509
InnerLR 0.530319
FineTuningLR 0.325287
Epoch 35 | Batch 40/100 | Loss 0.252676
InnerLR 0.530896
FineTuningLR 0.324666
Epoch 35 | Batch 50/100 | Loss 0.260485
InnerLR 0.531297
FineTuningLR 0.323957
Epoch 35 | Batch 60/100 | Loss 0.257248
InnerLR 0.532229
FineTuningLR 0.323128
Epoch 35 | Batch 70/100 | Loss 0.252705
InnerLR 0.533302
FineTuningLR 0.322722
Epoch 35 | Batch 80/100 | Loss 0.254500
InnerLR 0.534344
FineTuningLR 0.322124
Epoch 35 | Batch 90/100 | Loss 0.261236
InnerLR 0.534731
FineTuningLR 0.321414
100 Accuracy = 78.68% +- 2.73%
Epoch 35: 78.68
Epoch 36 | Batch 0/100 | Loss 0.151785
InnerLR 0.535319
FineTuningLR 0.319732
Epoch 36 | Batch 10/100 | Loss 0.159538
InnerLR 0.535840
FineTuningLR 0.318805
Epoch 36 | Batch 20/100 | Loss 0.175746
InnerLR 0.535984
FineTuningLR 0.317785
Epoch 36 | Batch 30/100 | Loss 0.214829
InnerLR 0.535656
FineTuningLR 0.317666
Epoch 36 | Batch 40/100 | Loss 0.210270
InnerLR 0.535103
FineTuningLR 0.317245
Epoch 36 | Batch 50/100 | Loss 0.233738
InnerLR 0.534917
FineTuningLR 0.316739
Epoch 36 | Batch 60/100 | Loss 0.233173
InnerLR 0.534831
FineTuningLR 0.315652
Epoch 36 | Batch 70/100 | Loss 0.237842
InnerLR 0.535025
FineTuningLR 0.315011
Epoch 36 | Batch 80/100 | Loss 0.237986
InnerLR 0.534452
FineTuningLR 0.314638
Epoch 36 | Batch 90/100 | Loss 0.236901
InnerLR 0.533846
FineTuningLR 0.314423
100 Accuracy = 78.21% +- 2.53%
Epoch 36: 78.21
Epoch 37 | Batch 0/100 | Loss 0.596087
InnerLR 0.532922
FineTuningLR 0.314250
Epoch 37 | Batch 10/100 | Loss 0.240147
InnerLR 0.532187
FineTuningLR 0.313867
Epoch 37 | Batch 20/100 | Loss 0.218648
InnerLR 0.531682
FineTuningLR 0.313505
Epoch 37 | Batch 30/100 | Loss 0.230121
InnerLR 0.531220
FineTuningLR 0.313472
Epoch 37 | Batch 40/100 | Loss 0.223248
InnerLR 0.530512
FineTuningLR 0.313348
Epoch 37 | Batch 50/100 | Loss 0.215410
InnerLR 0.529875
FineTuningLR 0.313405
Epoch 37 | Batch 60/100 | Loss 0.220065
InnerLR 0.529379
FineTuningLR 0.313386
Epoch 37 | Batch 70/100 | Loss 0.221055
InnerLR 0.529112
FineTuningLR 0.313695
Epoch 37 | Batch 80/100 | Loss 0.220954
InnerLR 0.528383
FineTuningLR 0.314507
Epoch 37 | Batch 90/100 | Loss 0.219753
InnerLR 0.527979
FineTuningLR 0.315039
100 Accuracy = 79.59% +- 2.37%
Epoch 37: 79.59
Epoch 38 | Batch 0/100 | Loss 0.152586
InnerLR 0.527953
FineTuningLR 0.315208
Epoch 38 | Batch 10/100 | Loss 0.234903
InnerLR 0.528411
FineTuningLR 0.314890
Epoch 38 | Batch 20/100 | Loss 0.240828
InnerLR 0.529110
FineTuningLR 0.314166
Epoch 38 | Batch 30/100 | Loss 0.236444
InnerLR 0.529403
FineTuningLR 0.313922
Epoch 38 | Batch 40/100 | Loss 0.219573
InnerLR 0.529648
FineTuningLR 0.313228
Epoch 38 | Batch 50/100 | Loss 0.213445
InnerLR 0.529751
FineTuningLR 0.313043
Epoch 38 | Batch 60/100 | Loss 0.217149
InnerLR 0.530005
FineTuningLR 0.313620
Epoch 38 | Batch 70/100 | Loss 0.207767
InnerLR 0.530349
FineTuningLR 0.314395
Epoch 38 | Batch 80/100 | Loss 0.217838
InnerLR 0.530960
FineTuningLR 0.315464
Epoch 38 | Batch 90/100 | Loss 0.225904
InnerLR 0.530953
FineTuningLR 0.315885
100 Accuracy = 79.17% +- 2.52%
Epoch 38: 79.17
Epoch 39 | Batch 0/100 | Loss 0.267042
InnerLR 0.531257
FineTuningLR 0.316566
Epoch 39 | Batch 10/100 | Loss 0.207427
InnerLR 0.531770
FineTuningLR 0.316801
Epoch 39 | Batch 20/100 | Loss 0.213435
InnerLR 0.533064
FineTuningLR 0.316833
Epoch 39 | Batch 30/100 | Loss 0.229315
InnerLR 0.533630
FineTuningLR 0.316431
Epoch 39 | Batch 40/100 | Loss 0.222249
InnerLR 0.534202
FineTuningLR 0.315246
Epoch 39 | Batch 50/100 | Loss 0.218352
InnerLR 0.534533
FineTuningLR 0.314241
Epoch 39 | Batch 60/100 | Loss 0.214854
InnerLR 0.535358
FineTuningLR 0.313223
Epoch 39 | Batch 70/100 | Loss 0.213923
InnerLR 0.536047
FineTuningLR 0.312577
Epoch 39 | Batch 80/100 | Loss 0.210245
InnerLR 0.537348
FineTuningLR 0.312566
Epoch 39 | Batch 90/100 | Loss 0.218213
InnerLR 0.538116
FineTuningLR 0.312811
100 Accuracy = 79.16% +- 2.18%
Epoch 39: 79.16
Epoch 40 | Batch 0/100 | Loss 0.172695
InnerLR 0.539147
FineTuningLR 0.313487
Epoch 40 | Batch 10/100 | Loss 0.364325
InnerLR 0.539171
FineTuningLR 0.314085
Epoch 40 | Batch 20/100 | Loss 0.332001
InnerLR 0.538862
FineTuningLR 0.314485
Epoch 40 | Batch 30/100 | Loss 0.289506
InnerLR 0.538615
FineTuningLR 0.314440
Epoch 40 | Batch 40/100 | Loss 0.266394
InnerLR 0.538011
FineTuningLR 0.314546
Epoch 40 | Batch 50/100 | Loss 0.330564
InnerLR 0.538076
FineTuningLR 0.314750
Epoch 40 | Batch 60/100 | Loss 0.336202
InnerLR 0.538371
FineTuningLR 0.314239
Epoch 40 | Batch 70/100 | Loss 0.319445
InnerLR 0.538690
FineTuningLR 0.313998
Epoch 40 | Batch 80/100 | Loss 0.312011
InnerLR 0.539063
FineTuningLR 0.314469
Epoch 40 | Batch 90/100 | Loss 0.302528
InnerLR 0.539016
FineTuningLR 0.315266
100 Accuracy = 80.31% +- 2.26%
Epoch 40: 80.31
Epoch 41 | Batch 0/100 | Loss 0.185131
InnerLR 0.539330
FineTuningLR 0.316766
Epoch 41 | Batch 10/100 | Loss 0.214179
InnerLR 0.539486
FineTuningLR 0.317774
Epoch 41 | Batch 20/100 | Loss 0.236360
InnerLR 0.539382
FineTuningLR 0.318980
Epoch 41 | Batch 30/100 | Loss 0.231861
InnerLR 0.539552
FineTuningLR 0.319826
Epoch 41 | Batch 40/100 | Loss 0.217342
InnerLR 0.540193
FineTuningLR 0.320637
Epoch 41 | Batch 50/100 | Loss 0.213621
InnerLR 0.540820
FineTuningLR 0.321170
Epoch 41 | Batch 60/100 | Loss 0.207780
InnerLR 0.541236
FineTuningLR 0.321909
Epoch 41 | Batch 70/100 | Loss 0.238710
InnerLR 0.541381
FineTuningLR 0.322217
Epoch 41 | Batch 80/100 | Loss 0.253163
InnerLR 0.541749
FineTuningLR 0.321861
Epoch 41 | Batch 90/100 | Loss 0.250828
InnerLR 0.541802
FineTuningLR 0.321640
100 Accuracy = 80.19% +- 2.33%
Epoch 41: 80.19
Epoch 42 | Batch 0/100 | Loss 0.189559
InnerLR 0.541819
FineTuningLR 0.321413
Epoch 42 | Batch 10/100 | Loss 0.210088
InnerLR 0.541736
FineTuningLR 0.321407
Epoch 42 | Batch 20/100 | Loss 0.263665
InnerLR 0.541566
FineTuningLR 0.321762
Epoch 42 | Batch 30/100 | Loss 0.239862
InnerLR 0.541799
FineTuningLR 0.322134
Epoch 42 | Batch 40/100 | Loss 0.224614
InnerLR 0.542503
FineTuningLR 0.322617
Epoch 42 | Batch 50/100 | Loss 0.223064
InnerLR 0.543238
FineTuningLR 0.322519
Epoch 42 | Batch 60/100 | Loss 0.220969
InnerLR 0.544264
FineTuningLR 0.322169
Epoch 42 | Batch 70/100 | Loss 0.225481
InnerLR 0.544875
FineTuningLR 0.321576
Epoch 42 | Batch 80/100 | Loss 0.223336
InnerLR 0.545932
FineTuningLR 0.320419
Epoch 42 | Batch 90/100 | Loss 0.223989
InnerLR 0.546540
FineTuningLR 0.319567
100 Accuracy = 79.32% +- 2.56%
Epoch 42: 79.32
Epoch 43 | Batch 0/100 | Loss 0.386974
InnerLR 0.547596
FineTuningLR 0.318987
Epoch 43 | Batch 10/100 | Loss 0.252241
InnerLR 0.547973
FineTuningLR 0.318623
Epoch 43 | Batch 20/100 | Loss 0.260696
InnerLR 0.548483
FineTuningLR 0.317808
Epoch 43 | Batch 30/100 | Loss 0.264043
InnerLR 0.549145
FineTuningLR 0.317274
Epoch 43 | Batch 40/100 | Loss 0.248877
InnerLR 0.549593
FineTuningLR 0.316636
Epoch 43 | Batch 50/100 | Loss 0.245362
InnerLR 0.550138
FineTuningLR 0.316487
Epoch 43 | Batch 60/100 | Loss 0.237048
InnerLR 0.550958
FineTuningLR 0.316690
Epoch 43 | Batch 70/100 | Loss 0.227890
InnerLR 0.551474
FineTuningLR 0.316952
Epoch 43 | Batch 80/100 | Loss 0.229224
InnerLR 0.552149
FineTuningLR 0.316942
Epoch 43 | Batch 90/100 | Loss 0.227257
InnerLR 0.552443
FineTuningLR 0.316893
100 Accuracy = 79.00% +- 2.46%
Epoch 43: 79.00
Epoch 44 | Batch 0/100 | Loss 0.107916
InnerLR 0.552876
FineTuningLR 0.316847
Epoch 44 | Batch 10/100 | Loss 0.141092
InnerLR 0.553394
FineTuningLR 0.317119
Epoch 44 | Batch 20/100 | Loss 0.262409
InnerLR 0.553793
FineTuningLR 0.317462
Epoch 44 | Batch 30/100 | Loss 0.256214
InnerLR 0.553400
FineTuningLR 0.317667
Epoch 44 | Batch 40/100 | Loss 0.249175
InnerLR 0.552979
FineTuningLR 0.317868
Epoch 44 | Batch 50/100 | Loss 0.252996
InnerLR 0.552941
FineTuningLR 0.317458
Epoch 44 | Batch 60/100 | Loss 0.241969
InnerLR 0.552760
FineTuningLR 0.317382
Epoch 44 | Batch 70/100 | Loss 0.235229
InnerLR 0.552097
FineTuningLR 0.317583
Epoch 44 | Batch 80/100 | Loss 0.231818
InnerLR 0.551577
FineTuningLR 0.317586
Epoch 44 | Batch 90/100 | Loss 0.229471
InnerLR 0.551406
FineTuningLR 0.317659
100 Accuracy = 80.47% +- 2.31%
Epoch 44: 80.47
Epoch 45 | Batch 0/100 | Loss 0.105567
InnerLR 0.551593
FineTuningLR 0.318092
Epoch 45 | Batch 10/100 | Loss 0.165357
InnerLR 0.552125
FineTuningLR 0.318112
Epoch 45 | Batch 20/100 | Loss 0.214588
InnerLR 0.552961
FineTuningLR 0.318033
Epoch 45 | Batch 30/100 | Loss 0.222507
InnerLR 0.553148
FineTuningLR 0.317825
Epoch 45 | Batch 40/100 | Loss 0.221637
InnerLR 0.553629
FineTuningLR 0.317227
Epoch 45 | Batch 50/100 | Loss 0.225840
InnerLR 0.554164
FineTuningLR 0.316888
Epoch 45 | Batch 60/100 | Loss 0.220174
InnerLR 0.554524
FineTuningLR 0.316893
Epoch 45 | Batch 70/100 | Loss 0.221877
InnerLR 0.555130
FineTuningLR 0.316868
Epoch 45 | Batch 80/100 | Loss 0.216489
InnerLR 0.556128
FineTuningLR 0.316544
Epoch 45 | Batch 90/100 | Loss 0.210263
InnerLR 0.556556
FineTuningLR 0.316240
100 Accuracy = 81.71% +- 2.53%
Epoch 45: 81.71
best model! save...
Epoch 46 | Batch 0/100 | Loss 0.313020
InnerLR 0.557215
FineTuningLR 0.315780
Epoch 46 | Batch 10/100 | Loss 0.237598
InnerLR 0.557652
FineTuningLR 0.315672
Epoch 46 | Batch 20/100 | Loss 0.225528
InnerLR 0.558867
FineTuningLR 0.315149
Epoch 46 | Batch 30/100 | Loss 0.220136
InnerLR 0.559876
FineTuningLR 0.315011
Epoch 46 | Batch 40/100 | Loss 0.234771
InnerLR 0.560562
FineTuningLR 0.315097
Epoch 46 | Batch 50/100 | Loss 0.264033
InnerLR 0.560855
FineTuningLR 0.315343
Epoch 46 | Batch 60/100 | Loss 0.251200
InnerLR 0.561089
FineTuningLR 0.315509
Epoch 46 | Batch 70/100 | Loss 0.248854
InnerLR 0.561509
FineTuningLR 0.315741
Epoch 46 | Batch 80/100 | Loss 0.244461
InnerLR 0.561570
FineTuningLR 0.315798
Epoch 46 | Batch 90/100 | Loss 0.243066
InnerLR 0.561540
FineTuningLR 0.315824
100 Accuracy = 79.04% +- 2.19%
Epoch 46: 79.04
Epoch 47 | Batch 0/100 | Loss 0.085787
InnerLR 0.561505
FineTuningLR 0.315499
Epoch 47 | Batch 10/100 | Loss 0.241928
InnerLR 0.561518
FineTuningLR 0.315027
Epoch 47 | Batch 20/100 | Loss 0.240591
InnerLR 0.561454
FineTuningLR 0.314598
Epoch 47 | Batch 30/100 | Loss 0.229243
InnerLR 0.561735
FineTuningLR 0.314850
Epoch 47 | Batch 40/100 | Loss 0.236452
InnerLR 0.561397
FineTuningLR 0.315620
Epoch 47 | Batch 50/100 | Loss 0.230871
InnerLR 0.561386
FineTuningLR 0.315788
Epoch 47 | Batch 60/100 | Loss 0.227987
InnerLR 0.561871
FineTuningLR 0.316424
Epoch 47 | Batch 70/100 | Loss 0.233347
InnerLR 0.562105
FineTuningLR 0.316487
Epoch 47 | Batch 80/100 | Loss 0.239299
InnerLR 0.562200
FineTuningLR 0.316006
Epoch 47 | Batch 90/100 | Loss 0.236700
InnerLR 0.562290
FineTuningLR 0.315529
100 Accuracy = 78.81% +- 3.10%
Epoch 47: 78.81
Epoch 48 | Batch 0/100 | Loss 0.658911
InnerLR 0.561672
FineTuningLR 0.315090
Epoch 48 | Batch 10/100 | Loss 0.271356
InnerLR 0.561075
FineTuningLR 0.314978
Epoch 48 | Batch 20/100 | Loss 0.315268
InnerLR 0.560098
FineTuningLR 0.314735
Epoch 48 | Batch 30/100 | Loss 0.315092
InnerLR 0.559746
FineTuningLR 0.314745
Epoch 48 | Batch 40/100 | Loss 0.306013
InnerLR 0.559503
FineTuningLR 0.314459
Epoch 48 | Batch 50/100 | Loss 0.274052
InnerLR 0.559264
FineTuningLR 0.314309
Epoch 48 | Batch 60/100 | Loss 0.266675
InnerLR 0.558882
FineTuningLR 0.314499
Epoch 48 | Batch 70/100 | Loss 0.260861
InnerLR 0.558599
FineTuningLR 0.314453
Epoch 48 | Batch 80/100 | Loss 0.258058
InnerLR 0.558954
FineTuningLR 0.313964
Epoch 48 | Batch 90/100 | Loss 0.261189
InnerLR 0.559441
FineTuningLR 0.313741
100 Accuracy = 81.33% +- 1.99%
Epoch 48: 81.33
Epoch 49 | Batch 0/100 | Loss 0.112350
InnerLR 0.559386
FineTuningLR 0.313172
Epoch 49 | Batch 10/100 | Loss 0.170697
InnerLR 0.559296
FineTuningLR 0.312700
Epoch 49 | Batch 20/100 | Loss 0.184064
InnerLR 0.559763
FineTuningLR 0.312076
Epoch 49 | Batch 30/100 | Loss 0.210340
InnerLR 0.559770
FineTuningLR 0.312106
Epoch 49 | Batch 40/100 | Loss 0.214411
InnerLR 0.558986
FineTuningLR 0.312364
Epoch 49 | Batch 50/100 | Loss 0.224545
InnerLR 0.558554
FineTuningLR 0.312102
Epoch 49 | Batch 60/100 | Loss 0.225986
InnerLR 0.558327
FineTuningLR 0.311448
Epoch 49 | Batch 70/100 | Loss 0.215466
InnerLR 0.558102
FineTuningLR 0.311171
Epoch 49 | Batch 80/100 | Loss 0.211384
InnerLR 0.558198
FineTuningLR 0.310262
Epoch 49 | Batch 90/100 | Loss 0.210617
InnerLR 0.558617
FineTuningLR 0.309324
100 Accuracy = 79.87% +- 2.40%
Epoch 49: 79.87
Epoch 50 | Batch 0/100 | Loss 0.070439
InnerLR 0.559243
FineTuningLR 0.307867
Epoch 50 | Batch 10/100 | Loss 0.179959
InnerLR 0.559727
FineTuningLR 0.307470
Epoch 50 | Batch 20/100 | Loss 0.253853
InnerLR 0.559911
FineTuningLR 0.307127
Epoch 50 | Batch 30/100 | Loss 0.250087
InnerLR 0.560178
FineTuningLR 0.306834
Epoch 50 | Batch 40/100 | Loss 0.237007
InnerLR 0.560567
FineTuningLR 0.306463
Epoch 50 | Batch 50/100 | Loss 0.234835
InnerLR 0.560590
FineTuningLR 0.306545
Epoch 50 | Batch 60/100 | Loss 0.239449
InnerLR 0.560428
FineTuningLR 0.306084
Epoch 50 | Batch 70/100 | Loss 0.238356
InnerLR 0.560792
FineTuningLR 0.305557
Epoch 50 | Batch 80/100 | Loss 0.241717
InnerLR 0.560914
FineTuningLR 0.305397
Epoch 50 | Batch 90/100 | Loss 0.241217
InnerLR 0.560930
FineTuningLR 0.305396
100 Accuracy = 79.12% +- 2.53%
Epoch 50: 79.12
Epoch 51 | Batch 0/100 | Loss 0.080560
InnerLR 0.560741
FineTuningLR 0.305805
Epoch 51 | Batch 10/100 | Loss 0.171185
InnerLR 0.560685
FineTuningLR 0.306382
Epoch 51 | Batch 20/100 | Loss 0.188877
InnerLR 0.560599
FineTuningLR 0.306757
Epoch 51 | Batch 30/100 | Loss 0.173816
InnerLR 0.560496
FineTuningLR 0.306971
Epoch 51 | Batch 40/100 | Loss 0.187998
InnerLR 0.560769
FineTuningLR 0.307325
Epoch 51 | Batch 50/100 | Loss 0.179050
InnerLR 0.560779
FineTuningLR 0.307601
Epoch 51 | Batch 60/100 | Loss 0.178465
InnerLR 0.560562
FineTuningLR 0.307970
Epoch 51 | Batch 70/100 | Loss 0.188397
InnerLR 0.560360
FineTuningLR 0.308244
Epoch 51 | Batch 80/100 | Loss 0.196180
InnerLR 0.559610
FineTuningLR 0.308971
Epoch 51 | Batch 90/100 | Loss 0.210715
InnerLR 0.558734
FineTuningLR 0.309118
100 Accuracy = 77.96% +- 2.45%
Epoch 51: 77.96
Epoch 52 | Batch 0/100 | Loss 0.105494
InnerLR 0.557777
FineTuningLR 0.308983
Epoch 52 | Batch 10/100 | Loss 0.147565
InnerLR 0.557348
FineTuningLR 0.309190
Epoch 52 | Batch 20/100 | Loss 0.181393
InnerLR 0.557038
FineTuningLR 0.309452
Epoch 52 | Batch 30/100 | Loss 0.202719
InnerLR 0.556940
FineTuningLR 0.309679
Epoch 52 | Batch 40/100 | Loss 0.221563
InnerLR 0.556638
FineTuningLR 0.309838
Epoch 52 | Batch 50/100 | Loss 0.214034
InnerLR 0.556779
FineTuningLR 0.310151
Epoch 52 | Batch 60/100 | Loss 0.229684
InnerLR 0.557102
FineTuningLR 0.310247
Epoch 52 | Batch 70/100 | Loss 0.234632
InnerLR 0.557214
FineTuningLR 0.310702
Epoch 52 | Batch 80/100 | Loss 0.233064
InnerLR 0.557148
FineTuningLR 0.311857
Epoch 52 | Batch 90/100 | Loss 0.236844
InnerLR 0.557225
FineTuningLR 0.312617
100 Accuracy = 80.32% +- 2.18%
Epoch 52: 80.32
Epoch 53 | Batch 0/100 | Loss 0.226471
InnerLR 0.557152
FineTuningLR 0.313367
Epoch 53 | Batch 10/100 | Loss 0.226497
InnerLR 0.557180
FineTuningLR 0.313597
Epoch 53 | Batch 20/100 | Loss 0.233427
InnerLR 0.557735
FineTuningLR 0.313991
Epoch 53 | Batch 30/100 | Loss 0.257761
InnerLR 0.558273
FineTuningLR 0.313755
Epoch 53 | Batch 40/100 | Loss 0.254923
InnerLR 0.558593
FineTuningLR 0.313206
Epoch 53 | Batch 50/100 | Loss 0.274059
InnerLR 0.558792
FineTuningLR 0.312763
Epoch 53 | Batch 60/100 | Loss 0.261702
InnerLR 0.558976
FineTuningLR 0.311808
Epoch 53 | Batch 70/100 | Loss 0.257480
InnerLR 0.558971
FineTuningLR 0.311757
Epoch 53 | Batch 80/100 | Loss 0.267662
InnerLR 0.558762
FineTuningLR 0.312286
Epoch 53 | Batch 90/100 | Loss 0.262550
InnerLR 0.559021
FineTuningLR 0.312722
100 Accuracy = 79.73% +- 2.40%
Epoch 53: 79.73
Epoch 54 | Batch 0/100 | Loss 0.062173
InnerLR 0.559535
FineTuningLR 0.313477
Epoch 54 | Batch 10/100 | Loss 0.243654
InnerLR 0.559715
FineTuningLR 0.313781
Epoch 54 | Batch 20/100 | Loss 0.266725
InnerLR 0.559596
FineTuningLR 0.313704
Epoch 54 | Batch 30/100 | Loss 0.252218
InnerLR 0.559718
FineTuningLR 0.313193
Epoch 54 | Batch 40/100 | Loss 0.247407
InnerLR 0.560553
FineTuningLR 0.312401
Epoch 54 | Batch 50/100 | Loss 0.252002
InnerLR 0.560830
FineTuningLR 0.312070
Epoch 54 | Batch 60/100 | Loss 0.244940
InnerLR 0.560690
FineTuningLR 0.311472
Epoch 54 | Batch 70/100 | Loss 0.235721
InnerLR 0.560672
FineTuningLR 0.311229
Epoch 54 | Batch 80/100 | Loss 0.232221
InnerLR 0.560351
FineTuningLR 0.311275
Epoch 54 | Batch 90/100 | Loss 0.235545
InnerLR 0.560101
FineTuningLR 0.311424
100 Accuracy = 79.56% +- 2.37%
Epoch 54: 79.56
Epoch 55 | Batch 0/100 | Loss 0.475237
InnerLR 0.559845
FineTuningLR 0.311380
Epoch 55 | Batch 10/100 | Loss 0.255505
InnerLR 0.559986
FineTuningLR 0.311391
Epoch 55 | Batch 20/100 | Loss 0.211233
InnerLR 0.560019
FineTuningLR 0.310717
Epoch 55 | Batch 30/100 | Loss 0.199804
InnerLR 0.560477
FineTuningLR 0.310278
Epoch 55 | Batch 40/100 | Loss 0.211847
InnerLR 0.561047
FineTuningLR 0.310110
Epoch 55 | Batch 50/100 | Loss 0.224699
InnerLR 0.561290
FineTuningLR 0.309816
Epoch 55 | Batch 60/100 | Loss 0.227505
InnerLR 0.561103
FineTuningLR 0.309544
Epoch 55 | Batch 70/100 | Loss 0.233315
InnerLR 0.560529
FineTuningLR 0.309541
Epoch 55 | Batch 80/100 | Loss 0.228729
InnerLR 0.559545
FineTuningLR 0.309494
Epoch 55 | Batch 90/100 | Loss 0.224086
InnerLR 0.559054
FineTuningLR 0.309998
100 Accuracy = 80.64% +- 2.35%
Epoch 55: 80.64
Epoch 56 | Batch 0/100 | Loss 0.328821
InnerLR 0.558329
FineTuningLR 0.310789
Epoch 56 | Batch 10/100 | Loss 0.301782
InnerLR 0.557643
FineTuningLR 0.311067
Epoch 56 | Batch 20/100 | Loss 0.281077
InnerLR 0.556722
FineTuningLR 0.311142
Epoch 56 | Batch 30/100 | Loss 0.270403
InnerLR 0.556512
FineTuningLR 0.311413
Epoch 56 | Batch 40/100 | Loss 0.259841
InnerLR 0.556452
FineTuningLR 0.311601
Epoch 56 | Batch 50/100 | Loss 0.233903
InnerLR 0.556512
FineTuningLR 0.311878
Epoch 56 | Batch 60/100 | Loss 0.232503
InnerLR 0.556598
FineTuningLR 0.312508
Epoch 56 | Batch 70/100 | Loss 0.229473
InnerLR 0.556144
FineTuningLR 0.313061
Epoch 56 | Batch 80/100 | Loss 0.220744
InnerLR 0.555914
FineTuningLR 0.314293
Epoch 56 | Batch 90/100 | Loss 0.219125
InnerLR 0.556096
FineTuningLR 0.314792
100 Accuracy = 79.04% +- 2.50%
Epoch 56: 79.04
Epoch 57 | Batch 0/100 | Loss 0.201020
InnerLR 0.555678
FineTuningLR 0.315549
Epoch 57 | Batch 10/100 | Loss 0.175072
InnerLR 0.555109
FineTuningLR 0.315938
Epoch 57 | Batch 20/100 | Loss 0.201271
InnerLR 0.554213
FineTuningLR 0.316469
Epoch 57 | Batch 30/100 | Loss 0.188803
InnerLR 0.554084
FineTuningLR 0.316687
Epoch 57 | Batch 40/100 | Loss 0.173878
InnerLR 0.554109
FineTuningLR 0.317232
Epoch 57 | Batch 50/100 | Loss 0.224397
InnerLR 0.554507
FineTuningLR 0.317146
Epoch 57 | Batch 60/100 | Loss 0.213562
InnerLR 0.554976
FineTuningLR 0.317111
Epoch 57 | Batch 70/100 | Loss 0.211140
InnerLR 0.555682
FineTuningLR 0.316711
Epoch 57 | Batch 80/100 | Loss 0.214533
InnerLR 0.556729
FineTuningLR 0.316158
Epoch 57 | Batch 90/100 | Loss 0.213955
InnerLR 0.557404
FineTuningLR 0.315590
100 Accuracy = 79.01% +- 2.53%
Epoch 57: 79.01
Epoch 58 | Batch 0/100 | Loss 0.266902
InnerLR 0.558072
FineTuningLR 0.314895
Epoch 58 | Batch 10/100 | Loss 0.180655
InnerLR 0.558610
FineTuningLR 0.315038
Epoch 58 | Batch 20/100 | Loss 0.151461
InnerLR 0.559051
FineTuningLR 0.315779
Epoch 58 | Batch 30/100 | Loss 0.208344
InnerLR 0.558956
FineTuningLR 0.316351
Epoch 58 | Batch 40/100 | Loss 0.212054
InnerLR 0.558288
FineTuningLR 0.317469
Epoch 58 | Batch 50/100 | Loss 0.218839
InnerLR 0.557502
FineTuningLR 0.317963
Epoch 58 | Batch 60/100 | Loss 0.210110
InnerLR 0.556276
FineTuningLR 0.318463
Epoch 58 | Batch 70/100 | Loss 0.235162
InnerLR 0.555736
FineTuningLR 0.318520
Epoch 58 | Batch 80/100 | Loss 0.238787
InnerLR 0.555635
FineTuningLR 0.318440
Epoch 58 | Batch 90/100 | Loss 0.230566
InnerLR 0.555685
FineTuningLR 0.318297
100 Accuracy = 80.60% +- 2.44%
Epoch 58: 80.60
Epoch 59 | Batch 0/100 | Loss 0.060466
InnerLR 0.555924
FineTuningLR 0.318112
Epoch 59 | Batch 10/100 | Loss 0.159694
InnerLR 0.556310
FineTuningLR 0.317441
Epoch 59 | Batch 20/100 | Loss 0.184429
InnerLR 0.556843
FineTuningLR 0.315930
Epoch 59 | Batch 30/100 | Loss 0.219647
InnerLR 0.557608
FineTuningLR 0.314912
Epoch 59 | Batch 40/100 | Loss 0.231694
InnerLR 0.558725
FineTuningLR 0.313634
Epoch 59 | Batch 50/100 | Loss 0.227076
InnerLR 0.558760
FineTuningLR 0.312637
Epoch 59 | Batch 60/100 | Loss 0.217670
InnerLR 0.558324
FineTuningLR 0.311584
Epoch 59 | Batch 70/100 | Loss 0.218852
InnerLR 0.558326
FineTuningLR 0.311113
Epoch 59 | Batch 80/100 | Loss 0.208069
InnerLR 0.558411
FineTuningLR 0.311025
Epoch 59 | Batch 90/100 | Loss 0.215343
InnerLR 0.558840
FineTuningLR 0.311397
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 81.01% +- 2.28%
Epoch 59: 81.01
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/tabula_muris/leo_FCNet/20231212_121203
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 96.46% +- 0.39%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/tabula_muris/leo_FCNet/20231212_121203
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 79.42% +- 0.97%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/tabula_muris/leo_FCNet/20231212_121203
600 Accuracy = 76.74% +- 0.96%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_1_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/results.txt
+-------+-------------------+--------------------+
| split |      acc_mean     |      acc_std       |
+-------+-------------------+--------------------+
| train | 96.46222222222222 | 4.918263268700337  |
|  val  | 79.41777777777779 | 12.120334102879843 |
|  test | 76.74444444444445 |  12.0354979072967  |
+-------+-------------------+--------------------+
