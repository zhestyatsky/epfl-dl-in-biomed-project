/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 1
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 1
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 1
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 0.5
    finetuning_lr_init: 0.05
    num_adaptation_steps: 5
    kl_coef: 0.01
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 0.1
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 32
    enable_finetuning_loop: true
  n_task: 4
  latent_space_dim: 32
  leo_inner_lr_init: 0.5
  leo_finetuning_lr_init: 0.05
  num_adaptation_steps: 5
  kl_coef: 0.01
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 0.1
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-06
  optimize_backbone: false
  pretrained_backbone_weights_path: pretrained_weights/tabula_muris_baseline_model.tar
  enable_finetuning_loop: true
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_1_latent_space_dim_32_lr_0.0003
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.0003
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.0003
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_32_lr_0.0003/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Using pretrained backbone from pretrained_weights/tabula_muris_baseline_model.tar.
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=32, bias=False)
    (relation_net): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=False)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=64, bias=False)
      (3): ReLU()
      (4): Linear(in_features=64, out_features=64, bias=False)
    )
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=32, out_features=130, bias=False)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 1e-06

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 0
)
Epoch 0 | Batch 0/100 | Loss 5.089219
InnerLR 0.500000
FineTuningLR 0.050000
Epoch 0 | Batch 10/100 | Loss 5.059041
InnerLR 0.500600
FineTuningLR 0.050600
Epoch 0 | Batch 20/100 | Loss 5.646142
InnerLR 0.501500
FineTuningLR 0.051500
Epoch 0 | Batch 30/100 | Loss 5.774651
InnerLR 0.502100
FineTuningLR 0.052100
Epoch 0 | Batch 40/100 | Loss 5.898590
InnerLR 0.503000
FineTuningLR 0.053000
Epoch 0 | Batch 50/100 | Loss 5.766168
InnerLR 0.503600
FineTuningLR 0.053600
Epoch 0 | Batch 60/100 | Loss 5.649359
InnerLR 0.504424
FineTuningLR 0.054500
Epoch 0 | Batch 70/100 | Loss 5.732821
InnerLR 0.504900
FineTuningLR 0.055100
Epoch 0 | Batch 80/100 | Loss 5.787131
InnerLR 0.505662
FineTuningLR 0.056000
Epoch 0 | Batch 90/100 | Loss 5.807061
InnerLR 0.506195
FineTuningLR 0.056600
100 Accuracy = 46.60% +- 2.60%
Epoch 0: 46.60
best model! save...
Epoch 1 | Batch 0/100 | Loss 3.462563
InnerLR 0.507019
FineTuningLR 0.057500
Epoch 1 | Batch 10/100 | Loss 6.024031
InnerLR 0.507580
FineTuningLR 0.058100
Epoch 1 | Batch 20/100 | Loss 5.346380
InnerLR 0.508437
FineTuningLR 0.059000
Epoch 1 | Batch 30/100 | Loss 5.502560
InnerLR 0.509015
FineTuningLR 0.059600
Epoch 1 | Batch 40/100 | Loss 5.511475
InnerLR 0.509890
FineTuningLR 0.060500
Epoch 1 | Batch 50/100 | Loss 5.413750
InnerLR 0.510477
FineTuningLR 0.061100
Epoch 1 | Batch 60/100 | Loss 5.314692
InnerLR 0.511363
FineTuningLR 0.062000
Epoch 1 | Batch 70/100 | Loss 5.379727
InnerLR 0.511840
FineTuningLR 0.062600
Epoch 1 | Batch 80/100 | Loss 5.237570
InnerLR 0.512598
FineTuningLR 0.063500
Epoch 1 | Batch 90/100 | Loss 5.170873
InnerLR 0.513126
FineTuningLR 0.064100
100 Accuracy = 46.12% +- 2.30%
Epoch 1: 46.12
Epoch 2 | Batch 0/100 | Loss 4.821245
InnerLR 0.513943
FineTuningLR 0.065000
Epoch 2 | Batch 10/100 | Loss 4.648268
InnerLR 0.514386
FineTuningLR 0.065600
Epoch 2 | Batch 20/100 | Loss 5.096838
InnerLR 0.515104
FineTuningLR 0.066500
Epoch 2 | Batch 30/100 | Loss 5.335791
InnerLR 0.515612
FineTuningLR 0.067100
Epoch 2 | Batch 40/100 | Loss 5.388250
InnerLR 0.516405
FineTuningLR 0.068000
Epoch 2 | Batch 50/100 | Loss 5.297998
InnerLR 0.516950
FineTuningLR 0.068600
Epoch 2 | Batch 60/100 | Loss 5.212488
InnerLR 0.517787
FineTuningLR 0.069500
Epoch 2 | Batch 70/100 | Loss 5.067184
InnerLR 0.518295
FineTuningLR 0.070100
Epoch 2 | Batch 80/100 | Loss 4.978648
InnerLR 0.518849
FineTuningLR 0.071000
Epoch 2 | Batch 90/100 | Loss 4.862214
InnerLR 0.519272
FineTuningLR 0.071600
100 Accuracy = 49.09% +- 2.41%
Epoch 2: 49.09
best model! save...
Epoch 3 | Batch 0/100 | Loss 6.248816
InnerLR 0.519967
FineTuningLR 0.072500
Epoch 3 | Batch 10/100 | Loss 4.928997
InnerLR 0.520463
FineTuningLR 0.073100
Epoch 3 | Batch 20/100 | Loss 4.581761
InnerLR 0.521242
FineTuningLR 0.074000
Epoch 3 | Batch 30/100 | Loss 4.670593
InnerLR 0.521666
FineTuningLR 0.074600
Epoch 3 | Batch 40/100 | Loss 4.614114
InnerLR 0.522363
FineTuningLR 0.075500
Epoch 3 | Batch 50/100 | Loss 4.571170
InnerLR 0.522860
FineTuningLR 0.076100
Epoch 3 | Batch 60/100 | Loss 4.455820
InnerLR 0.523526
FineTuningLR 0.077000
Epoch 3 | Batch 70/100 | Loss 4.366666
InnerLR 0.523972
FineTuningLR 0.077600
Epoch 3 | Batch 80/100 | Loss 4.330522
InnerLR 0.524650
FineTuningLR 0.078508
Epoch 3 | Batch 90/100 | Loss 4.364041
InnerLR 0.525084
FineTuningLR 0.079122
100 Accuracy = 47.79% +- 2.79%
Epoch 3: 47.79
Epoch 4 | Batch 0/100 | Loss 1.823339
InnerLR 0.525793
FineTuningLR 0.080038
Epoch 4 | Batch 10/100 | Loss 2.649296
InnerLR 0.526296
FineTuningLR 0.080645
Epoch 4 | Batch 20/100 | Loss 2.846417
InnerLR 0.527085
FineTuningLR 0.081553
Epoch 4 | Batch 30/100 | Loss 3.042255
InnerLR 0.527628
FineTuningLR 0.082157
Epoch 4 | Batch 40/100 | Loss 3.242675
InnerLR 0.528463
FineTuningLR 0.083060
Epoch 4 | Batch 50/100 | Loss 3.149002
InnerLR 0.529025
FineTuningLR 0.083666
Epoch 4 | Batch 60/100 | Loss 3.259593
InnerLR 0.529874
FineTuningLR 0.084578
Epoch 4 | Batch 70/100 | Loss 3.358575
InnerLR 0.530334
FineTuningLR 0.085183
Epoch 4 | Batch 80/100 | Loss 3.358640
InnerLR 0.531025
FineTuningLR 0.086096
Epoch 4 | Batch 90/100 | Loss 3.389915
InnerLR 0.531403
FineTuningLR 0.086712
100 Accuracy = 53.59% +- 2.32%
Epoch 4: 53.59
best model! save...
Epoch 5 | Batch 0/100 | Loss 2.490338
InnerLR 0.531975
FineTuningLR 0.087632
Epoch 5 | Batch 10/100 | Loss 3.658204
InnerLR 0.532348
FineTuningLR 0.088242
Epoch 5 | Batch 20/100 | Loss 3.377899
InnerLR 0.532909
FineTuningLR 0.089151
Epoch 5 | Batch 30/100 | Loss 3.488651
InnerLR 0.533162
FineTuningLR 0.089755
Epoch 5 | Batch 40/100 | Loss 3.354194
InnerLR 0.533420
FineTuningLR 0.090658
Epoch 5 | Batch 50/100 | Loss 3.322113
InnerLR 0.533633
FineTuningLR 0.091259
Epoch 5 | Batch 60/100 | Loss 3.300672
InnerLR 0.533731
FineTuningLR 0.092158
Epoch 5 | Batch 70/100 | Loss 3.224291
InnerLR 0.533827
FineTuningLR 0.092757
Epoch 5 | Batch 80/100 | Loss 3.125903
InnerLR 0.533845
FineTuningLR 0.093654
Epoch 5 | Batch 90/100 | Loss 3.074059
InnerLR 0.533923
FineTuningLR 0.094252
100 Accuracy = 53.33% +- 2.42%
Epoch 5: 53.33
Epoch 6 | Batch 0/100 | Loss 1.601701
InnerLR 0.534000
FineTuningLR 0.095151
Epoch 6 | Batch 10/100 | Loss 2.793761
InnerLR 0.534113
FineTuningLR 0.095753
Epoch 6 | Batch 20/100 | Loss 2.605899
InnerLR 0.534451
FineTuningLR 0.096654
Epoch 6 | Batch 30/100 | Loss 2.499479
InnerLR 0.534764
FineTuningLR 0.097254
Epoch 6 | Batch 40/100 | Loss 2.524804
InnerLR 0.535320
FineTuningLR 0.098161
Epoch 6 | Batch 50/100 | Loss 2.566397
InnerLR 0.535666
FineTuningLR 0.098775
Epoch 6 | Batch 60/100 | Loss 2.538217
InnerLR 0.536081
FineTuningLR 0.099689
Epoch 6 | Batch 70/100 | Loss 2.477741
InnerLR 0.536340
FineTuningLR 0.100295
Epoch 6 | Batch 80/100 | Loss 2.499297
InnerLR 0.536605
FineTuningLR 0.101200
Epoch 6 | Batch 90/100 | Loss 2.496454
InnerLR 0.536882
FineTuningLR 0.101801
100 Accuracy = 56.89% +- 2.48%
Epoch 6: 56.89
best model! save...
Epoch 7 | Batch 0/100 | Loss 2.271490
InnerLR 0.537247
FineTuningLR 0.102701
Epoch 7 | Batch 10/100 | Loss 1.734203
InnerLR 0.537514
FineTuningLR 0.103300
Epoch 7 | Batch 20/100 | Loss 1.743085
InnerLR 0.537893
FineTuningLR 0.104197
Epoch 7 | Batch 30/100 | Loss 1.798330
InnerLR 0.538088
FineTuningLR 0.104800
Epoch 7 | Batch 40/100 | Loss 1.755555
InnerLR 0.538328
FineTuningLR 0.105703
Epoch 7 | Batch 50/100 | Loss 1.724323
InnerLR 0.538383
FineTuningLR 0.106302
Epoch 7 | Batch 60/100 | Loss 1.672524
InnerLR 0.538303
FineTuningLR 0.107205
Epoch 7 | Batch 70/100 | Loss 1.645287
InnerLR 0.538311
FineTuningLR 0.107807
Epoch 7 | Batch 80/100 | Loss 1.594068
InnerLR 0.538340
FineTuningLR 0.108735
Epoch 7 | Batch 90/100 | Loss 1.560178
InnerLR 0.538435
FineTuningLR 0.109348
100 Accuracy = 56.89% +- 2.54%
Epoch 7: 56.89
Epoch 8 | Batch 0/100 | Loss 2.135861
InnerLR 0.538512
FineTuningLR 0.110261
Epoch 8 | Batch 10/100 | Loss 1.431129
InnerLR 0.538518
FineTuningLR 0.110866
Epoch 8 | Batch 20/100 | Loss 1.399043
InnerLR 0.538375
FineTuningLR 0.111769
Epoch 8 | Batch 30/100 | Loss 1.271833
InnerLR 0.538381
FineTuningLR 0.112387
Epoch 8 | Batch 40/100 | Loss 1.259116
InnerLR 0.538433
FineTuningLR 0.113304
Epoch 8 | Batch 50/100 | Loss 1.193738
InnerLR 0.538601
FineTuningLR 0.113912
Epoch 8 | Batch 60/100 | Loss 1.156164
InnerLR 0.538735
FineTuningLR 0.114839
Epoch 8 | Batch 70/100 | Loss 1.130599
InnerLR 0.538860
FineTuningLR 0.115457
Epoch 8 | Batch 80/100 | Loss 1.128704
InnerLR 0.538932
FineTuningLR 0.116375
Epoch 8 | Batch 90/100 | Loss 1.129574
InnerLR 0.538961
FineTuningLR 0.116983
100 Accuracy = 60.52% +- 2.63%
Epoch 8: 60.52
best model! save...
Epoch 9 | Batch 0/100 | Loss 0.836246
InnerLR 0.539028
FineTuningLR 0.117888
Epoch 9 | Batch 10/100 | Loss 1.277948
InnerLR 0.538981
FineTuningLR 0.118490
Epoch 9 | Batch 20/100 | Loss 1.066867
InnerLR 0.539116
FineTuningLR 0.119402
Epoch 9 | Batch 30/100 | Loss 1.038019
InnerLR 0.539145
FineTuningLR 0.120011
Epoch 9 | Batch 40/100 | Loss 1.069425
InnerLR 0.539029
FineTuningLR 0.120918
Epoch 9 | Batch 50/100 | Loss 1.032206
InnerLR 0.538900
FineTuningLR 0.121519
Epoch 9 | Batch 60/100 | Loss 0.975790
InnerLR 0.538835
FineTuningLR 0.122426
Epoch 9 | Batch 70/100 | Loss 0.930645
InnerLR 0.538707
FineTuningLR 0.123036
Epoch 9 | Batch 80/100 | Loss 0.892750
InnerLR 0.538469
FineTuningLR 0.123987
Epoch 9 | Batch 90/100 | Loss 0.865242
InnerLR 0.538371
FineTuningLR 0.124510
100 Accuracy = 64.04% +- 2.61%
Epoch 9: 64.04
best model! save...
Epoch 10 | Batch 0/100 | Loss 0.426883
InnerLR 0.538217
FineTuningLR 0.125324
Epoch 10 | Batch 10/100 | Loss 0.795447
InnerLR 0.538094
FineTuningLR 0.125884
Epoch 10 | Batch 20/100 | Loss 0.783550
InnerLR 0.537741
FineTuningLR 0.126734
Epoch 10 | Batch 30/100 | Loss 0.912648
InnerLR 0.537418
FineTuningLR 0.127247
Epoch 10 | Batch 40/100 | Loss 0.856178
InnerLR 0.536854
FineTuningLR 0.127978
Epoch 10 | Batch 50/100 | Loss 0.827766
InnerLR 0.536626
FineTuningLR 0.128501
Epoch 10 | Batch 60/100 | Loss 0.806572
InnerLR 0.536570
FineTuningLR 0.129311
Epoch 10 | Batch 70/100 | Loss 0.780910
InnerLR 0.536514
FineTuningLR 0.129814
Epoch 10 | Batch 80/100 | Loss 0.764620
InnerLR 0.536299
FineTuningLR 0.130522
Epoch 10 | Batch 90/100 | Loss 0.752109
InnerLR 0.536120
FineTuningLR 0.130910
100 Accuracy = 65.79% +- 2.29%
Epoch 10: 65.79
best model! save...
Epoch 11 | Batch 0/100 | Loss 0.611549
InnerLR 0.535967
FineTuningLR 0.131573
Epoch 11 | Batch 10/100 | Loss 0.773128
InnerLR 0.535807
FineTuningLR 0.131978
Epoch 11 | Batch 20/100 | Loss 0.691764
InnerLR 0.535444
FineTuningLR 0.132557
Epoch 11 | Batch 30/100 | Loss 0.615670
InnerLR 0.535164
FineTuningLR 0.133012
Epoch 11 | Batch 40/100 | Loss 0.592284
InnerLR 0.534818
FineTuningLR 0.133774
Epoch 11 | Batch 50/100 | Loss 0.615099
InnerLR 0.534602
FineTuningLR 0.134307
Epoch 11 | Batch 60/100 | Loss 0.616967
InnerLR 0.534385
FineTuningLR 0.135064
Epoch 11 | Batch 70/100 | Loss 0.619272
InnerLR 0.534131
FineTuningLR 0.135407
Epoch 11 | Batch 80/100 | Loss 0.619814
InnerLR 0.533646
FineTuningLR 0.136019
Epoch 11 | Batch 90/100 | Loss 0.623921
InnerLR 0.533261
FineTuningLR 0.136473
100 Accuracy = 68.28% +- 2.78%
Epoch 11: 68.28
best model! save...
Epoch 12 | Batch 0/100 | Loss 0.331209
InnerLR 0.532577
FineTuningLR 0.137079
Epoch 12 | Batch 10/100 | Loss 0.460436
InnerLR 0.532263
FineTuningLR 0.137526
Epoch 12 | Batch 20/100 | Loss 0.525234
InnerLR 0.531818
FineTuningLR 0.138251
Epoch 12 | Batch 30/100 | Loss 0.532692
InnerLR 0.531564
FineTuningLR 0.138771
Epoch 12 | Batch 40/100 | Loss 0.524687
InnerLR 0.531366
FineTuningLR 0.139582
Epoch 12 | Batch 50/100 | Loss 0.522897
InnerLR 0.531275
FineTuningLR 0.140147
Epoch 12 | Batch 60/100 | Loss 0.573092
InnerLR 0.531261
FineTuningLR 0.140848
Epoch 12 | Batch 70/100 | Loss 0.556611
InnerLR 0.531325
FineTuningLR 0.141158
Epoch 12 | Batch 80/100 | Loss 0.564822
InnerLR 0.531453
FineTuningLR 0.141593
Epoch 12 | Batch 90/100 | Loss 0.552557
InnerLR 0.531605
FineTuningLR 0.141878
100 Accuracy = 70.28% +- 2.81%
Epoch 12: 70.28
best model! save...
Epoch 13 | Batch 0/100 | Loss 0.254112
InnerLR 0.531568
FineTuningLR 0.142296
Epoch 13 | Batch 10/100 | Loss 0.544134
InnerLR 0.531520
FineTuningLR 0.142615
Epoch 13 | Batch 20/100 | Loss 0.561919
InnerLR 0.531419
FineTuningLR 0.142916
Epoch 13 | Batch 30/100 | Loss 0.507326
InnerLR 0.531341
FineTuningLR 0.143062
Epoch 13 | Batch 40/100 | Loss 0.508531
InnerLR 0.531110
FineTuningLR 0.143417
Epoch 13 | Batch 50/100 | Loss 0.513587
InnerLR 0.530935
FineTuningLR 0.143715
Epoch 13 | Batch 60/100 | Loss 0.492105
InnerLR 0.530809
FineTuningLR 0.144285
Epoch 13 | Batch 70/100 | Loss 0.483644
InnerLR 0.530834
FineTuningLR 0.144730
Epoch 13 | Batch 80/100 | Loss 0.485915
InnerLR 0.530870
FineTuningLR 0.145463
Epoch 13 | Batch 90/100 | Loss 0.496293
InnerLR 0.530862
FineTuningLR 0.145975
100 Accuracy = 71.57% +- 2.52%
Epoch 13: 71.57
best model! save...
Epoch 14 | Batch 0/100 | Loss 0.387320
InnerLR 0.530924
FineTuningLR 0.146609
Epoch 14 | Batch 10/100 | Loss 0.333347
InnerLR 0.530964
FineTuningLR 0.147069
Epoch 14 | Batch 20/100 | Loss 0.411740
InnerLR 0.531012
FineTuningLR 0.147824
Epoch 14 | Batch 30/100 | Loss 0.401569
InnerLR 0.530906
FineTuningLR 0.148352
Epoch 14 | Batch 40/100 | Loss 0.411112
InnerLR 0.530735
FineTuningLR 0.149195
Epoch 14 | Batch 50/100 | Loss 0.430156
InnerLR 0.530638
FineTuningLR 0.149761
Epoch 14 | Batch 60/100 | Loss 0.464923
InnerLR 0.530405
FineTuningLR 0.150536
Epoch 14 | Batch 70/100 | Loss 0.464551
InnerLR 0.530230
FineTuningLR 0.151055
Epoch 14 | Batch 80/100 | Loss 0.455357
InnerLR 0.530179
FineTuningLR 0.151855
Epoch 14 | Batch 90/100 | Loss 0.461186
InnerLR 0.530044
FineTuningLR 0.152230
100 Accuracy = 73.52% +- 2.66%
Epoch 14: 73.52
best model! save...
Epoch 15 | Batch 0/100 | Loss 0.710715
InnerLR 0.529738
FineTuningLR 0.152678
Epoch 15 | Batch 10/100 | Loss 0.535173
InnerLR 0.529512
FineTuningLR 0.153011
Epoch 15 | Batch 20/100 | Loss 0.500096
InnerLR 0.529060
FineTuningLR 0.153496
Epoch 15 | Batch 30/100 | Loss 0.448697
InnerLR 0.528737
FineTuningLR 0.153871
Epoch 15 | Batch 40/100 | Loss 0.430233
InnerLR 0.528463
FineTuningLR 0.154554
Epoch 15 | Batch 50/100 | Loss 0.476152
InnerLR 0.528354
FineTuningLR 0.155066
Epoch 15 | Batch 60/100 | Loss 0.486519
InnerLR 0.528085
FineTuningLR 0.155893
Epoch 15 | Batch 70/100 | Loss 0.476078
InnerLR 0.527887
FineTuningLR 0.156488
Epoch 15 | Batch 80/100 | Loss 0.470334
InnerLR 0.527611
FineTuningLR 0.157374
Epoch 15 | Batch 90/100 | Loss 0.457469
InnerLR 0.527380
FineTuningLR 0.157858
100 Accuracy = 71.59% +- 2.89%
Epoch 15: 71.59
Epoch 16 | Batch 0/100 | Loss 0.483959
InnerLR 0.527004
FineTuningLR 0.158493
Epoch 16 | Batch 10/100 | Loss 0.424402
InnerLR 0.526794
FineTuningLR 0.158804
Epoch 16 | Batch 20/100 | Loss 0.443104
InnerLR 0.526571
FineTuningLR 0.159397
Epoch 16 | Batch 30/100 | Loss 0.436997
InnerLR 0.526404
FineTuningLR 0.159837
Epoch 16 | Batch 40/100 | Loss 0.406796
InnerLR 0.526237
FineTuningLR 0.160477
Epoch 16 | Batch 50/100 | Loss 0.398813
InnerLR 0.526207
FineTuningLR 0.160878
Epoch 16 | Batch 60/100 | Loss 0.397778
InnerLR 0.526156
FineTuningLR 0.161541
Epoch 16 | Batch 70/100 | Loss 0.392194
InnerLR 0.526096
FineTuningLR 0.161974
Epoch 16 | Batch 80/100 | Loss 0.387792
InnerLR 0.526073
FineTuningLR 0.162618
Epoch 16 | Batch 90/100 | Loss 0.391017
InnerLR 0.525972
FineTuningLR 0.163087
100 Accuracy = 73.67% +- 2.73%
Epoch 16: 73.67
best model! save...
Epoch 17 | Batch 0/100 | Loss 0.227114
InnerLR 0.525713
FineTuningLR 0.163833
Epoch 17 | Batch 10/100 | Loss 0.363346
InnerLR 0.525553
FineTuningLR 0.164350
Epoch 17 | Batch 20/100 | Loss 0.336787
InnerLR 0.525414
FineTuningLR 0.165117
Epoch 17 | Batch 30/100 | Loss 0.336834
InnerLR 0.525341
FineTuningLR 0.165584
Epoch 17 | Batch 40/100 | Loss 0.360708
InnerLR 0.525150
FineTuningLR 0.166345
Epoch 17 | Batch 50/100 | Loss 0.385788
InnerLR 0.524975
FineTuningLR 0.166763
Epoch 17 | Batch 60/100 | Loss 0.388525
InnerLR 0.524569
FineTuningLR 0.167444
Epoch 17 | Batch 70/100 | Loss 0.410531
InnerLR 0.524338
FineTuningLR 0.167868
Epoch 17 | Batch 80/100 | Loss 0.405330
InnerLR 0.523918
FineTuningLR 0.168269
Epoch 17 | Batch 90/100 | Loss 0.407937
InnerLR 0.523661
FineTuningLR 0.168412
100 Accuracy = 74.28% +- 2.68%
Epoch 17: 74.28
best model! save...
Epoch 18 | Batch 0/100 | Loss 0.251888
InnerLR 0.523444
FineTuningLR 0.168554
Epoch 18 | Batch 10/100 | Loss 0.357783
InnerLR 0.523365
FineTuningLR 0.168780
Epoch 18 | Batch 20/100 | Loss 0.383618
InnerLR 0.523186
FineTuningLR 0.169057
Epoch 18 | Batch 30/100 | Loss 0.360829
InnerLR 0.523145
FineTuningLR 0.169177
Epoch 18 | Batch 40/100 | Loss 0.373490
InnerLR 0.523103
FineTuningLR 0.169341
Epoch 18 | Batch 50/100 | Loss 0.377717
InnerLR 0.523028
FineTuningLR 0.169536
Epoch 18 | Batch 60/100 | Loss 0.366161
InnerLR 0.522912
FineTuningLR 0.170001
Epoch 18 | Batch 70/100 | Loss 0.368400
InnerLR 0.522778
FineTuningLR 0.170392
Epoch 18 | Batch 80/100 | Loss 0.379496
InnerLR 0.522452
FineTuningLR 0.171061
Epoch 18 | Batch 90/100 | Loss 0.386995
InnerLR 0.522163
FineTuningLR 0.171549
100 Accuracy = 76.11% +- 2.54%
Epoch 18: 76.11
best model! save...
Epoch 19 | Batch 0/100 | Loss 0.279382
InnerLR 0.521640
FineTuningLR 0.172057
Epoch 19 | Batch 10/100 | Loss 0.341376
InnerLR 0.521261
FineTuningLR 0.172437
Epoch 19 | Batch 20/100 | Loss 0.338184
InnerLR 0.520683
FineTuningLR 0.173080
Epoch 19 | Batch 30/100 | Loss 0.367221
InnerLR 0.520383
FineTuningLR 0.173547
Epoch 19 | Batch 40/100 | Loss 0.375867
InnerLR 0.520017
FineTuningLR 0.174131
Epoch 19 | Batch 50/100 | Loss 0.360817
InnerLR 0.519851
FineTuningLR 0.174528
Epoch 19 | Batch 60/100 | Loss 0.364319
InnerLR 0.519737
FineTuningLR 0.175012
Epoch 19 | Batch 70/100 | Loss 0.378332
InnerLR 0.519586
FineTuningLR 0.175313
Epoch 19 | Batch 80/100 | Loss 0.376630
InnerLR 0.519196
FineTuningLR 0.175674
Epoch 19 | Batch 90/100 | Loss 0.370289
InnerLR 0.518970
FineTuningLR 0.175851
100 Accuracy = 76.89% +- 2.47%
Epoch 19: 76.89
best model! save...
Epoch 20 | Batch 0/100 | Loss 0.180956
InnerLR 0.518491
FineTuningLR 0.176087
Epoch 20 | Batch 10/100 | Loss 0.382453
InnerLR 0.518098
FineTuningLR 0.176132
Epoch 20 | Batch 20/100 | Loss 0.396465
InnerLR 0.517455
FineTuningLR 0.176212
Epoch 20 | Batch 30/100 | Loss 0.374223
InnerLR 0.517009
FineTuningLR 0.176407
Epoch 20 | Batch 40/100 | Loss 0.365836
InnerLR 0.516637
FineTuningLR 0.176799
Epoch 20 | Batch 50/100 | Loss 0.358995
InnerLR 0.516443
FineTuningLR 0.177152
Epoch 20 | Batch 60/100 | Loss 0.348662
InnerLR 0.516169
FineTuningLR 0.177772
Epoch 20 | Batch 70/100 | Loss 0.338778
InnerLR 0.515964
FineTuningLR 0.178227
Epoch 20 | Batch 80/100 | Loss 0.346720
InnerLR 0.515802
FineTuningLR 0.178895
Epoch 20 | Batch 90/100 | Loss 0.348599
InnerLR 0.515607
FineTuningLR 0.179301
100 Accuracy = 75.83% +- 2.62%
Epoch 20: 75.83
Epoch 21 | Batch 0/100 | Loss 0.221160
InnerLR 0.515436
FineTuningLR 0.179874
Epoch 21 | Batch 10/100 | Loss 0.492046
InnerLR 0.515244
FineTuningLR 0.180095
Epoch 21 | Batch 20/100 | Loss 0.450461
InnerLR 0.515192
FineTuningLR 0.180364
Epoch 21 | Batch 30/100 | Loss 0.396513
InnerLR 0.515130
FineTuningLR 0.180509
Epoch 21 | Batch 40/100 | Loss 0.385761
InnerLR 0.514812
FineTuningLR 0.180686
Epoch 21 | Batch 50/100 | Loss 0.383669
InnerLR 0.514555
FineTuningLR 0.180792
Epoch 21 | Batch 60/100 | Loss 0.388438
InnerLR 0.514103
FineTuningLR 0.181075
Epoch 21 | Batch 70/100 | Loss 0.386031
InnerLR 0.513826
FineTuningLR 0.181357
Epoch 21 | Batch 80/100 | Loss 0.382369
InnerLR 0.513319
FineTuningLR 0.181898
Epoch 21 | Batch 90/100 | Loss 0.390557
InnerLR 0.512940
FineTuningLR 0.182321
100 Accuracy = 75.41% +- 2.23%
Epoch 21: 75.41
Epoch 22 | Batch 0/100 | Loss 0.524261
InnerLR 0.512298
FineTuningLR 0.182908
Epoch 22 | Batch 10/100 | Loss 0.354689
InnerLR 0.511841
FineTuningLR 0.183319
Epoch 22 | Batch 20/100 | Loss 0.302824
InnerLR 0.511394
FineTuningLR 0.183846
Epoch 22 | Batch 30/100 | Loss 0.292223
InnerLR 0.511043
FineTuningLR 0.184102
Epoch 22 | Batch 40/100 | Loss 0.279772
InnerLR 0.510586
FineTuningLR 0.184578
Epoch 22 | Batch 50/100 | Loss 0.291138
InnerLR 0.510330
FineTuningLR 0.184852
Epoch 22 | Batch 60/100 | Loss 0.287407
InnerLR 0.510088
FineTuningLR 0.185357
Epoch 22 | Batch 70/100 | Loss 0.305900
InnerLR 0.509929
FineTuningLR 0.185749
Epoch 22 | Batch 80/100 | Loss 0.310089
InnerLR 0.509655
FineTuningLR 0.186417
Epoch 22 | Batch 90/100 | Loss 0.314845
InnerLR 0.509406
FineTuningLR 0.186849
100 Accuracy = 74.99% +- 2.63%
Epoch 22: 74.99
Epoch 23 | Batch 0/100 | Loss 0.268848
InnerLR 0.509039
FineTuningLR 0.187319
Epoch 23 | Batch 10/100 | Loss 0.313089
InnerLR 0.508849
FineTuningLR 0.187467
Epoch 23 | Batch 20/100 | Loss 0.302762
InnerLR 0.508572
FineTuningLR 0.187737
Epoch 23 | Batch 30/100 | Loss 0.311619
InnerLR 0.508365
FineTuningLR 0.188002
Epoch 23 | Batch 40/100 | Loss 0.321988
InnerLR 0.508180
FineTuningLR 0.188411
Epoch 23 | Batch 50/100 | Loss 0.324907
InnerLR 0.507999
FineTuningLR 0.188624
Epoch 23 | Batch 60/100 | Loss 0.331136
InnerLR 0.507785
FineTuningLR 0.189089
Epoch 23 | Batch 70/100 | Loss 0.328971
InnerLR 0.507545
FineTuningLR 0.189471
Epoch 23 | Batch 80/100 | Loss 0.340367
InnerLR 0.507188
FineTuningLR 0.190142
Epoch 23 | Batch 90/100 | Loss 0.336472
InnerLR 0.506962
FineTuningLR 0.190635
100 Accuracy = 76.57% +- 2.92%
Epoch 23: 76.57
Epoch 24 | Batch 0/100 | Loss 0.352438
InnerLR 0.506484
FineTuningLR 0.191247
Epoch 24 | Batch 10/100 | Loss 0.365834
InnerLR 0.506203
FineTuningLR 0.191700
Epoch 24 | Batch 20/100 | Loss 0.335700
InnerLR 0.505868
FineTuningLR 0.192444
Epoch 24 | Batch 30/100 | Loss 0.350340
InnerLR 0.505687
FineTuningLR 0.192965
Epoch 24 | Batch 40/100 | Loss 0.355156
InnerLR 0.505301
FineTuningLR 0.193778
Epoch 24 | Batch 50/100 | Loss 0.340789
InnerLR 0.504948
FineTuningLR 0.194317
Epoch 24 | Batch 60/100 | Loss 0.337727
InnerLR 0.504306
FineTuningLR 0.195064
Epoch 24 | Batch 70/100 | Loss 0.333750
InnerLR 0.503895
FineTuningLR 0.195509
Epoch 24 | Batch 80/100 | Loss 0.337875
InnerLR 0.503481
FineTuningLR 0.196094
Epoch 24 | Batch 90/100 | Loss 0.341147
InnerLR 0.503140
FineTuningLR 0.196389
100 Accuracy = 76.41% +- 2.81%
Epoch 24: 76.41
Epoch 25 | Batch 0/100 | Loss 0.571376
InnerLR 0.502597
FineTuningLR 0.196855
Epoch 25 | Batch 10/100 | Loss 0.379927
InnerLR 0.502368
FineTuningLR 0.197228
Epoch 25 | Batch 20/100 | Loss 0.347834
InnerLR 0.502002
FineTuningLR 0.197908
Epoch 25 | Batch 30/100 | Loss 0.325791
InnerLR 0.501683
FineTuningLR 0.198395
Epoch 25 | Batch 40/100 | Loss 0.362858
InnerLR 0.501086
FineTuningLR 0.198847
Epoch 25 | Batch 50/100 | Loss 0.357176
InnerLR 0.500628
FineTuningLR 0.199030
Epoch 25 | Batch 60/100 | Loss 0.356400
InnerLR 0.499893
FineTuningLR 0.199338
Epoch 25 | Batch 70/100 | Loss 0.342726
InnerLR 0.499430
FineTuningLR 0.199599
Epoch 25 | Batch 80/100 | Loss 0.330811
InnerLR 0.498976
FineTuningLR 0.200132
Epoch 25 | Batch 90/100 | Loss 0.322706
InnerLR 0.498748
FineTuningLR 0.200573
100 Accuracy = 78.09% +- 2.74%
Epoch 25: 78.09
best model! save...
Epoch 26 | Batch 0/100 | Loss 0.182304
InnerLR 0.498530
FineTuningLR 0.201121
Epoch 26 | Batch 10/100 | Loss 0.354770
InnerLR 0.498425
FineTuningLR 0.201458
Epoch 26 | Batch 20/100 | Loss 0.325812
InnerLR 0.498096
FineTuningLR 0.201979
Epoch 26 | Batch 30/100 | Loss 0.355775
InnerLR 0.497791
FineTuningLR 0.202385
Epoch 26 | Batch 40/100 | Loss 0.351614
InnerLR 0.497283
FineTuningLR 0.202875
Epoch 26 | Batch 50/100 | Loss 0.348880
InnerLR 0.496943
FineTuningLR 0.203091
Epoch 26 | Batch 60/100 | Loss 0.338597
InnerLR 0.496584
FineTuningLR 0.203492
Epoch 26 | Batch 70/100 | Loss 0.339213
InnerLR 0.496350
FineTuningLR 0.203838
Epoch 26 | Batch 80/100 | Loss 0.338344
InnerLR 0.496212
FineTuningLR 0.204451
Epoch 26 | Batch 90/100 | Loss 0.332568
InnerLR 0.496176
FineTuningLR 0.204909
100 Accuracy = 77.00% +- 2.61%
Epoch 26: 77.00
Epoch 27 | Batch 0/100 | Loss 0.177670
InnerLR 0.496099
FineTuningLR 0.205669
Epoch 27 | Batch 10/100 | Loss 0.317886
InnerLR 0.496209
FineTuningLR 0.206089
Epoch 27 | Batch 20/100 | Loss 0.334523
InnerLR 0.496225
FineTuningLR 0.206715
Epoch 27 | Batch 30/100 | Loss 0.301423
InnerLR 0.496298
FineTuningLR 0.207065
Epoch 27 | Batch 40/100 | Loss 0.309695
InnerLR 0.496330
FineTuningLR 0.207610
Epoch 27 | Batch 50/100 | Loss 0.300689
InnerLR 0.496322
FineTuningLR 0.207974
Epoch 27 | Batch 60/100 | Loss 0.304894
InnerLR 0.496214
FineTuningLR 0.208434
Epoch 27 | Batch 70/100 | Loss 0.319937
InnerLR 0.496166
FineTuningLR 0.208803
Epoch 27 | Batch 80/100 | Loss 0.313223
InnerLR 0.496017
FineTuningLR 0.209396
Epoch 27 | Batch 90/100 | Loss 0.316445
InnerLR 0.495857
FineTuningLR 0.209783
100 Accuracy = 74.12% +- 2.74%
Epoch 27: 74.12
Epoch 28 | Batch 0/100 | Loss 0.266899
InnerLR 0.495641
FineTuningLR 0.210034
Epoch 28 | Batch 10/100 | Loss 0.320766
InnerLR 0.495403
FineTuningLR 0.210235
Epoch 28 | Batch 20/100 | Loss 0.325618
InnerLR 0.495210
FineTuningLR 0.210470
Epoch 28 | Batch 30/100 | Loss 0.315142
InnerLR 0.495022
FineTuningLR 0.210581
Epoch 28 | Batch 40/100 | Loss 0.342530
InnerLR 0.494570
FineTuningLR 0.210723
Epoch 28 | Batch 50/100 | Loss 0.347043
InnerLR 0.494285
FineTuningLR 0.210802
Epoch 28 | Batch 60/100 | Loss 0.327585
InnerLR 0.493844
FineTuningLR 0.210947
Epoch 28 | Batch 70/100 | Loss 0.323379
InnerLR 0.493598
FineTuningLR 0.211186
Epoch 28 | Batch 80/100 | Loss 0.339198
InnerLR 0.493301
FineTuningLR 0.211599
Epoch 28 | Batch 90/100 | Loss 0.328972
InnerLR 0.493216
FineTuningLR 0.211816
100 Accuracy = 77.53% +- 2.33%
Epoch 28: 77.53
Epoch 29 | Batch 0/100 | Loss 0.364678
InnerLR 0.493070
FineTuningLR 0.212264
Epoch 29 | Batch 10/100 | Loss 0.291587
InnerLR 0.492995
FineTuningLR 0.212647
Epoch 29 | Batch 20/100 | Loss 0.244969
InnerLR 0.492856
FineTuningLR 0.213310
Epoch 29 | Batch 30/100 | Loss 0.257003
InnerLR 0.492812
FineTuningLR 0.213669
Epoch 29 | Batch 40/100 | Loss 0.277991
InnerLR 0.492550
FineTuningLR 0.214286
Epoch 29 | Batch 50/100 | Loss 0.273192
InnerLR 0.492304
FineTuningLR 0.214666
Epoch 29 | Batch 60/100 | Loss 0.272558
InnerLR 0.492149
FineTuningLR 0.215081
Epoch 29 | Batch 70/100 | Loss 0.281496
InnerLR 0.492082
FineTuningLR 0.215303
Epoch 29 | Batch 80/100 | Loss 0.286134
InnerLR 0.492024
FineTuningLR 0.215490
Epoch 29 | Batch 90/100 | Loss 0.295405
InnerLR 0.492011
FineTuningLR 0.215613
100 Accuracy = 77.32% +- 2.45%
Epoch 29: 77.32
Epoch 30 | Batch 0/100 | Loss 0.152279
InnerLR 0.491910
FineTuningLR 0.215890
Epoch 30 | Batch 10/100 | Loss 0.390041
InnerLR 0.491739
FineTuningLR 0.216170
Epoch 30 | Batch 20/100 | Loss 0.402001
InnerLR 0.491437
FineTuningLR 0.216484
Epoch 30 | Batch 30/100 | Loss 0.353800
InnerLR 0.491243
FineTuningLR 0.216751
Epoch 30 | Batch 40/100 | Loss 0.339585
InnerLR 0.490869
FineTuningLR 0.217203
Epoch 30 | Batch 50/100 | Loss 0.322750
InnerLR 0.490655
FineTuningLR 0.217507
Epoch 30 | Batch 60/100 | Loss 0.313895
InnerLR 0.490460
FineTuningLR 0.217891
Epoch 30 | Batch 70/100 | Loss 0.319297
InnerLR 0.490351
FineTuningLR 0.218055
Epoch 30 | Batch 80/100 | Loss 0.310751
InnerLR 0.490105
FineTuningLR 0.218270
Epoch 30 | Batch 90/100 | Loss 0.310413
InnerLR 0.490027
FineTuningLR 0.218385
100 Accuracy = 79.75% +- 2.41%
Epoch 30: 79.75
best model! save...
Epoch 31 | Batch 0/100 | Loss 0.802262
InnerLR 0.489993
FineTuningLR 0.218581
Epoch 31 | Batch 10/100 | Loss 0.390747
InnerLR 0.489983
FineTuningLR 0.218700
Epoch 31 | Batch 20/100 | Loss 0.344381
InnerLR 0.489879
FineTuningLR 0.218961
Epoch 31 | Batch 30/100 | Loss 0.337265
InnerLR 0.489885
FineTuningLR 0.219100
Epoch 31 | Batch 40/100 | Loss 0.333918
InnerLR 0.489737
FineTuningLR 0.219325
Epoch 31 | Batch 50/100 | Loss 0.315227
InnerLR 0.489674
FineTuningLR 0.219388
Epoch 31 | Batch 60/100 | Loss 0.312244
InnerLR 0.489579
FineTuningLR 0.219533
Epoch 31 | Batch 70/100 | Loss 0.306416
InnerLR 0.489565
FineTuningLR 0.219741
Epoch 31 | Batch 80/100 | Loss 0.301291
InnerLR 0.489433
FineTuningLR 0.220025
Epoch 31 | Batch 90/100 | Loss 0.312381
InnerLR 0.489322
FineTuningLR 0.220241
100 Accuracy = 76.55% +- 2.33%
Epoch 31: 76.55
Epoch 32 | Batch 0/100 | Loss 0.253079
InnerLR 0.489198
FineTuningLR 0.220715
Epoch 32 | Batch 10/100 | Loss 0.241898
InnerLR 0.489246
FineTuningLR 0.221096
Epoch 32 | Batch 20/100 | Loss 0.271852
InnerLR 0.489341
FineTuningLR 0.221636
Epoch 32 | Batch 30/100 | Loss 0.288406
InnerLR 0.489250
FineTuningLR 0.222020
Epoch 32 | Batch 40/100 | Loss 0.288246
InnerLR 0.489208
FineTuningLR 0.222514
Epoch 32 | Batch 50/100 | Loss 0.296474
InnerLR 0.489207
FineTuningLR 0.222716
Epoch 32 | Batch 60/100 | Loss 0.285273
InnerLR 0.489255
FineTuningLR 0.223072
Epoch 32 | Batch 70/100 | Loss 0.288989
InnerLR 0.489399
FineTuningLR 0.223330
Epoch 32 | Batch 80/100 | Loss 0.288908
InnerLR 0.489498
FineTuningLR 0.223490
Epoch 32 | Batch 90/100 | Loss 0.309261
InnerLR 0.489441
FineTuningLR 0.223548
100 Accuracy = 79.52% +- 2.34%
Epoch 32: 79.52
Epoch 33 | Batch 0/100 | Loss 0.206644
InnerLR 0.489207
FineTuningLR 0.223600
Epoch 33 | Batch 10/100 | Loss 0.356960
InnerLR 0.489051
FineTuningLR 0.223633
Epoch 33 | Batch 20/100 | Loss 0.324585
InnerLR 0.488865
FineTuningLR 0.223589
Epoch 33 | Batch 30/100 | Loss 0.317590
InnerLR 0.488855
FineTuningLR 0.223620
Epoch 33 | Batch 40/100 | Loss 0.315622
InnerLR 0.488743
FineTuningLR 0.223636
Epoch 33 | Batch 50/100 | Loss 0.311516
InnerLR 0.488584
FineTuningLR 0.223623
Epoch 33 | Batch 60/100 | Loss 0.307127
InnerLR 0.488340
FineTuningLR 0.223611
Epoch 33 | Batch 70/100 | Loss 0.306450
InnerLR 0.488244
FineTuningLR 0.223579
Epoch 33 | Batch 80/100 | Loss 0.298696
InnerLR 0.488132
FineTuningLR 0.223607
Epoch 33 | Batch 90/100 | Loss 0.298599
InnerLR 0.488068
FineTuningLR 0.223606
100 Accuracy = 78.97% +- 2.48%
Epoch 33: 78.97
Epoch 34 | Batch 0/100 | Loss 0.165695
InnerLR 0.487984
FineTuningLR 0.223541
Epoch 34 | Batch 10/100 | Loss 0.218591
InnerLR 0.488028
FineTuningLR 0.223609
Epoch 34 | Batch 20/100 | Loss 0.228463
InnerLR 0.487978
FineTuningLR 0.223891
Epoch 34 | Batch 30/100 | Loss 0.218508
InnerLR 0.487956
FineTuningLR 0.224173
Epoch 34 | Batch 40/100 | Loss 0.250960
InnerLR 0.487919
FineTuningLR 0.224465
Epoch 34 | Batch 50/100 | Loss 0.246119
InnerLR 0.487933
FineTuningLR 0.224557
Epoch 34 | Batch 60/100 | Loss 0.258656
InnerLR 0.488125
FineTuningLR 0.224828
Epoch 34 | Batch 70/100 | Loss 0.266510
InnerLR 0.488303
FineTuningLR 0.224979
Epoch 34 | Batch 80/100 | Loss 0.262068
InnerLR 0.488503
FineTuningLR 0.225269
Epoch 34 | Batch 90/100 | Loss 0.264052
InnerLR 0.488595
FineTuningLR 0.225358
100 Accuracy = 79.04% +- 2.42%
Epoch 34: 79.04
Epoch 35 | Batch 0/100 | Loss 0.223085
InnerLR 0.488789
FineTuningLR 0.225591
Epoch 35 | Batch 10/100 | Loss 0.207588
InnerLR 0.488967
FineTuningLR 0.225863
Epoch 35 | Batch 20/100 | Loss 0.248962
InnerLR 0.489099
FineTuningLR 0.226371
Epoch 35 | Batch 30/100 | Loss 0.255885
InnerLR 0.489133
FineTuningLR 0.226704
Epoch 35 | Batch 40/100 | Loss 0.279907
InnerLR 0.489087
FineTuningLR 0.227259
Epoch 35 | Batch 50/100 | Loss 0.285360
InnerLR 0.488955
FineTuningLR 0.227561
Epoch 35 | Batch 60/100 | Loss 0.286132
InnerLR 0.488894
FineTuningLR 0.228083
Epoch 35 | Batch 70/100 | Loss 0.284310
InnerLR 0.489039
FineTuningLR 0.228433
Epoch 35 | Batch 80/100 | Loss 0.283237
InnerLR 0.489126
FineTuningLR 0.228826
Epoch 35 | Batch 90/100 | Loss 0.293098
InnerLR 0.489131
FineTuningLR 0.228907
100 Accuracy = 77.61% +- 2.57%
Epoch 35: 77.61
Epoch 36 | Batch 0/100 | Loss 0.203746
InnerLR 0.488879
FineTuningLR 0.229021
Epoch 36 | Batch 10/100 | Loss 0.179269
InnerLR 0.488761
FineTuningLR 0.229151
Epoch 36 | Batch 20/100 | Loss 0.192058
InnerLR 0.488698
FineTuningLR 0.229409
Epoch 36 | Batch 30/100 | Loss 0.235823
InnerLR 0.488715
FineTuningLR 0.229641
Epoch 36 | Batch 40/100 | Loss 0.234116
InnerLR 0.488829
FineTuningLR 0.229921
Epoch 36 | Batch 50/100 | Loss 0.262844
InnerLR 0.488899
FineTuningLR 0.229992
Epoch 36 | Batch 60/100 | Loss 0.265110
InnerLR 0.488990
FineTuningLR 0.229880
Epoch 36 | Batch 70/100 | Loss 0.267270
InnerLR 0.489094
FineTuningLR 0.229761
Epoch 36 | Batch 80/100 | Loss 0.268659
InnerLR 0.488985
FineTuningLR 0.229783
Epoch 36 | Batch 90/100 | Loss 0.265159
InnerLR 0.488839
FineTuningLR 0.229804
100 Accuracy = 77.43% +- 2.55%
Epoch 36: 77.43
Epoch 37 | Batch 0/100 | Loss 0.419157
InnerLR 0.488584
FineTuningLR 0.229996
Epoch 37 | Batch 10/100 | Loss 0.280843
InnerLR 0.488392
FineTuningLR 0.230215
Epoch 37 | Batch 20/100 | Loss 0.266772
InnerLR 0.488254
FineTuningLR 0.230600
Epoch 37 | Batch 30/100 | Loss 0.267567
InnerLR 0.488157
FineTuningLR 0.230963
Epoch 37 | Batch 40/100 | Loss 0.262330
InnerLR 0.487976
FineTuningLR 0.231449
Epoch 37 | Batch 50/100 | Loss 0.253686
InnerLR 0.487899
FineTuningLR 0.231702
Epoch 37 | Batch 60/100 | Loss 0.262294
InnerLR 0.487782
FineTuningLR 0.231919
Epoch 37 | Batch 70/100 | Loss 0.264417
InnerLR 0.487646
FineTuningLR 0.232102
Epoch 37 | Batch 80/100 | Loss 0.260750
InnerLR 0.487378
FineTuningLR 0.232529
Epoch 37 | Batch 90/100 | Loss 0.259074
InnerLR 0.487165
FineTuningLR 0.232763
100 Accuracy = 78.21% +- 2.47%
Epoch 37: 78.21
Epoch 38 | Batch 0/100 | Loss 0.214856
InnerLR 0.486960
FineTuningLR 0.233013
Epoch 38 | Batch 10/100 | Loss 0.268801
InnerLR 0.486920
FineTuningLR 0.233081
Epoch 38 | Batch 20/100 | Loss 0.284461
InnerLR 0.486951
FineTuningLR 0.233168
Epoch 38 | Batch 30/100 | Loss 0.260308
InnerLR 0.487010
FineTuningLR 0.233183
Epoch 38 | Batch 40/100 | Loss 0.248411
InnerLR 0.487108
FineTuningLR 0.233259
Epoch 38 | Batch 50/100 | Loss 0.242360
InnerLR 0.487167
FineTuningLR 0.233290
Epoch 38 | Batch 60/100 | Loss 0.244402
InnerLR 0.487228
FineTuningLR 0.233457
Epoch 38 | Batch 70/100 | Loss 0.240492
InnerLR 0.487245
FineTuningLR 0.233678
Epoch 38 | Batch 80/100 | Loss 0.252908
InnerLR 0.487200
FineTuningLR 0.234109
Epoch 38 | Batch 90/100 | Loss 0.260137
InnerLR 0.487199
FineTuningLR 0.234221
100 Accuracy = 77.61% +- 2.58%
Epoch 38: 77.61
Epoch 39 | Batch 0/100 | Loss 0.197879
InnerLR 0.487209
FineTuningLR 0.234281
Epoch 39 | Batch 10/100 | Loss 0.219523
InnerLR 0.487245
FineTuningLR 0.234260
Epoch 39 | Batch 20/100 | Loss 0.223545
InnerLR 0.487316
FineTuningLR 0.234215
Epoch 39 | Batch 30/100 | Loss 0.239660
InnerLR 0.487325
FineTuningLR 0.234135
Epoch 39 | Batch 40/100 | Loss 0.243614
InnerLR 0.487316
FineTuningLR 0.234078
Epoch 39 | Batch 50/100 | Loss 0.248426
InnerLR 0.487245
FineTuningLR 0.234096
Epoch 39 | Batch 60/100 | Loss 0.244009
InnerLR 0.487247
FineTuningLR 0.234281
Epoch 39 | Batch 70/100 | Loss 0.244908
InnerLR 0.487291
FineTuningLR 0.234445
Epoch 39 | Batch 80/100 | Loss 0.240602
InnerLR 0.487385
FineTuningLR 0.234797
Epoch 39 | Batch 90/100 | Loss 0.246975
InnerLR 0.487403
FineTuningLR 0.235063
100 Accuracy = 77.88% +- 2.33%
Epoch 39: 77.88
Epoch 40 | Batch 0/100 | Loss 0.153443
InnerLR 0.487306
FineTuningLR 0.235609
Epoch 40 | Batch 10/100 | Loss 0.340305
InnerLR 0.487191
FineTuningLR 0.235977
Epoch 40 | Batch 20/100 | Loss 0.331803
InnerLR 0.486989
FineTuningLR 0.236611
Epoch 40 | Batch 30/100 | Loss 0.293721
InnerLR 0.486808
FineTuningLR 0.237083
Epoch 40 | Batch 40/100 | Loss 0.274670
InnerLR 0.486400
FineTuningLR 0.237837
Epoch 40 | Batch 50/100 | Loss 0.343214
InnerLR 0.486143
FineTuningLR 0.238182
Epoch 40 | Batch 60/100 | Loss 0.354117
InnerLR 0.485757
FineTuningLR 0.238530
Epoch 40 | Batch 70/100 | Loss 0.342381
InnerLR 0.485554
FineTuningLR 0.238577
Epoch 40 | Batch 80/100 | Loss 0.338081
InnerLR 0.485459
FineTuningLR 0.238744
Epoch 40 | Batch 90/100 | Loss 0.328184
InnerLR 0.485454
FineTuningLR 0.238946
100 Accuracy = 79.37% +- 2.44%
Epoch 40: 79.37
Epoch 41 | Batch 0/100 | Loss 0.220062
InnerLR 0.485582
FineTuningLR 0.239353
Epoch 41 | Batch 10/100 | Loss 0.249188
InnerLR 0.485623
FineTuningLR 0.239630
Epoch 41 | Batch 20/100 | Loss 0.300079
InnerLR 0.485571
FineTuningLR 0.240086
Epoch 41 | Batch 30/100 | Loss 0.284145
InnerLR 0.485615
FineTuningLR 0.240440
Epoch 41 | Batch 40/100 | Loss 0.262977
InnerLR 0.485610
FineTuningLR 0.240928
Epoch 41 | Batch 50/100 | Loss 0.256345
InnerLR 0.485717
FineTuningLR 0.241239
Epoch 41 | Batch 60/100 | Loss 0.243034
InnerLR 0.485930
FineTuningLR 0.241742
Epoch 41 | Batch 70/100 | Loss 0.268799
InnerLR 0.486025
FineTuningLR 0.242027
Epoch 41 | Batch 80/100 | Loss 0.280435
InnerLR 0.486254
FineTuningLR 0.242144
Epoch 41 | Batch 90/100 | Loss 0.278589
InnerLR 0.486381
FineTuningLR 0.242161
100 Accuracy = 78.44% +- 2.28%
Epoch 41: 78.44
Epoch 42 | Batch 0/100 | Loss 0.218122
InnerLR 0.486525
FineTuningLR 0.241966
Epoch 42 | Batch 10/100 | Loss 0.253136
InnerLR 0.486566
FineTuningLR 0.241903
Epoch 42 | Batch 20/100 | Loss 0.273815
InnerLR 0.486533
FineTuningLR 0.241972
Epoch 42 | Batch 30/100 | Loss 0.261266
InnerLR 0.486470
FineTuningLR 0.242073
Epoch 42 | Batch 40/100 | Loss 0.241261
InnerLR 0.486397
FineTuningLR 0.242342
Epoch 42 | Batch 50/100 | Loss 0.242203
InnerLR 0.486448
FineTuningLR 0.242609
Epoch 42 | Batch 60/100 | Loss 0.242838
InnerLR 0.486301
FineTuningLR 0.242960
Epoch 42 | Batch 70/100 | Loss 0.242685
InnerLR 0.486214
FineTuningLR 0.243136
Epoch 42 | Batch 80/100 | Loss 0.238360
InnerLR 0.486243
FineTuningLR 0.243336
Epoch 42 | Batch 90/100 | Loss 0.240255
InnerLR 0.486139
FineTuningLR 0.243536
100 Accuracy = 78.17% +- 2.60%
Epoch 42: 78.17
Epoch 43 | Batch 0/100 | Loss 0.449309
InnerLR 0.485981
FineTuningLR 0.243851
Epoch 43 | Batch 10/100 | Loss 0.271767
InnerLR 0.485903
FineTuningLR 0.243972
Epoch 43 | Batch 20/100 | Loss 0.296021
InnerLR 0.485835
FineTuningLR 0.244355
Epoch 43 | Batch 30/100 | Loss 0.299241
InnerLR 0.485818
FineTuningLR 0.244691
Epoch 43 | Batch 40/100 | Loss 0.289112
InnerLR 0.485833
FineTuningLR 0.245285
Epoch 43 | Batch 50/100 | Loss 0.287316
InnerLR 0.485827
FineTuningLR 0.245547
Epoch 43 | Batch 60/100 | Loss 0.273325
InnerLR 0.486031
FineTuningLR 0.245932
Epoch 43 | Batch 70/100 | Loss 0.266298
InnerLR 0.486226
FineTuningLR 0.246229
Epoch 43 | Batch 80/100 | Loss 0.268366
InnerLR 0.486485
FineTuningLR 0.246476
Epoch 43 | Batch 90/100 | Loss 0.267101
InnerLR 0.486623
FineTuningLR 0.246543
100 Accuracy = 78.03% +- 2.50%
Epoch 43: 78.03
Epoch 44 | Batch 0/100 | Loss 0.210817
InnerLR 0.486716
FineTuningLR 0.246788
Epoch 44 | Batch 10/100 | Loss 0.195463
InnerLR 0.486746
FineTuningLR 0.246945
Epoch 44 | Batch 20/100 | Loss 0.316087
InnerLR 0.486849
FineTuningLR 0.247040
Epoch 44 | Batch 30/100 | Loss 0.300917
InnerLR 0.486819
FineTuningLR 0.247139
Epoch 44 | Batch 40/100 | Loss 0.289336
InnerLR 0.486900
FineTuningLR 0.247247
Epoch 44 | Batch 50/100 | Loss 0.285968
InnerLR 0.486831
FineTuningLR 0.247252
Epoch 44 | Batch 60/100 | Loss 0.276071
InnerLR 0.486688
FineTuningLR 0.247361
Epoch 44 | Batch 70/100 | Loss 0.266930
InnerLR 0.486623
FineTuningLR 0.247355
Epoch 44 | Batch 80/100 | Loss 0.265226
InnerLR 0.486726
FineTuningLR 0.247401
Epoch 44 | Batch 90/100 | Loss 0.266826
InnerLR 0.486735
FineTuningLR 0.247450
100 Accuracy = 79.03% +- 2.45%
Epoch 44: 79.03
Epoch 45 | Batch 0/100 | Loss 0.102333
InnerLR 0.486719
FineTuningLR 0.247741
Epoch 45 | Batch 10/100 | Loss 0.218971
InnerLR 0.486818
FineTuningLR 0.247872
Epoch 45 | Batch 20/100 | Loss 0.247819
InnerLR 0.486968
FineTuningLR 0.248146
Epoch 45 | Batch 30/100 | Loss 0.250334
InnerLR 0.486960
FineTuningLR 0.248417
Epoch 45 | Batch 40/100 | Loss 0.258018
InnerLR 0.487009
FineTuningLR 0.248928
Epoch 45 | Batch 50/100 | Loss 0.255697
InnerLR 0.486990
FineTuningLR 0.249133
Epoch 45 | Batch 60/100 | Loss 0.253667
InnerLR 0.486970
FineTuningLR 0.249366
Epoch 45 | Batch 70/100 | Loss 0.256592
InnerLR 0.486973
FineTuningLR 0.249482
Epoch 45 | Batch 80/100 | Loss 0.248417
InnerLR 0.487059
FineTuningLR 0.249653
Epoch 45 | Batch 90/100 | Loss 0.241957
InnerLR 0.487094
FineTuningLR 0.249634
100 Accuracy = 80.91% +- 2.51%
Epoch 45: 80.91
best model! save...
Epoch 46 | Batch 0/100 | Loss 0.303491
InnerLR 0.487238
FineTuningLR 0.249623
Epoch 46 | Batch 10/100 | Loss 0.244681
InnerLR 0.487411
FineTuningLR 0.249707
Epoch 46 | Batch 20/100 | Loss 0.239136
InnerLR 0.487515
FineTuningLR 0.249783
Epoch 46 | Batch 30/100 | Loss 0.246670
InnerLR 0.487573
FineTuningLR 0.249916
Epoch 46 | Batch 40/100 | Loss 0.268743
InnerLR 0.487483
FineTuningLR 0.250189
Epoch 46 | Batch 50/100 | Loss 0.302530
InnerLR 0.487335
FineTuningLR 0.250390
Epoch 46 | Batch 60/100 | Loss 0.286647
InnerLR 0.487096
FineTuningLR 0.250601
Epoch 46 | Batch 70/100 | Loss 0.282636
InnerLR 0.487020
FineTuningLR 0.250802
Epoch 46 | Batch 80/100 | Loss 0.277121
InnerLR 0.486971
FineTuningLR 0.250923
Epoch 46 | Batch 90/100 | Loss 0.275877
InnerLR 0.486866
FineTuningLR 0.251079
100 Accuracy = 77.73% +- 2.29%
Epoch 46: 77.73
Epoch 47 | Batch 0/100 | Loss 0.127455
InnerLR 0.486578
FineTuningLR 0.251448
Epoch 47 | Batch 10/100 | Loss 0.240761
InnerLR 0.486499
FineTuningLR 0.251627
Epoch 47 | Batch 20/100 | Loss 0.260096
InnerLR 0.486284
FineTuningLR 0.251932
Epoch 47 | Batch 30/100 | Loss 0.246193
InnerLR 0.486216
FineTuningLR 0.252221
Epoch 47 | Batch 40/100 | Loss 0.253687
InnerLR 0.486009
FineTuningLR 0.252567
Epoch 47 | Batch 50/100 | Loss 0.248892
InnerLR 0.485921
FineTuningLR 0.252702
Epoch 47 | Batch 60/100 | Loss 0.249753
InnerLR 0.485763
FineTuningLR 0.252883
Epoch 47 | Batch 70/100 | Loss 0.253097
InnerLR 0.485687
FineTuningLR 0.252980
Epoch 47 | Batch 80/100 | Loss 0.258287
InnerLR 0.485614
FineTuningLR 0.253119
Epoch 47 | Batch 90/100 | Loss 0.258999
InnerLR 0.485516
FineTuningLR 0.253196
100 Accuracy = 77.61% +- 2.96%
Epoch 47: 77.61
Epoch 48 | Batch 0/100 | Loss 0.889378
InnerLR 0.485236
FineTuningLR 0.253234
Epoch 48 | Batch 10/100 | Loss 0.301809
InnerLR 0.484941
FineTuningLR 0.253286
Epoch 48 | Batch 20/100 | Loss 0.323504
InnerLR 0.484334
FineTuningLR 0.253370
Epoch 48 | Batch 30/100 | Loss 0.313803
InnerLR 0.484017
FineTuningLR 0.253444
Epoch 48 | Batch 40/100 | Loss 0.322339
InnerLR 0.483604
FineTuningLR 0.253572
Epoch 48 | Batch 50/100 | Loss 0.292606
InnerLR 0.483399
FineTuningLR 0.253730
Epoch 48 | Batch 60/100 | Loss 0.288637
InnerLR 0.483195
FineTuningLR 0.254033
Epoch 48 | Batch 70/100 | Loss 0.285881
InnerLR 0.483017
FineTuningLR 0.254309
Epoch 48 | Batch 80/100 | Loss 0.284008
InnerLR 0.482799
FineTuningLR 0.254499
Epoch 48 | Batch 90/100 | Loss 0.282684
InnerLR 0.482696
FineTuningLR 0.254636
100 Accuracy = 80.48% +- 2.00%
Epoch 48: 80.48
Epoch 49 | Batch 0/100 | Loss 0.135113
InnerLR 0.482416
FineTuningLR 0.254781
Epoch 49 | Batch 10/100 | Loss 0.182613
InnerLR 0.482255
FineTuningLR 0.254884
Epoch 49 | Batch 20/100 | Loss 0.197530
InnerLR 0.482078
FineTuningLR 0.255198
Epoch 49 | Batch 30/100 | Loss 0.234945
InnerLR 0.481873
FineTuningLR 0.255460
Epoch 49 | Batch 40/100 | Loss 0.240819
InnerLR 0.481489
FineTuningLR 0.255579
Epoch 49 | Batch 50/100 | Loss 0.247428
InnerLR 0.481420
FineTuningLR 0.255523
Epoch 49 | Batch 60/100 | Loss 0.241286
InnerLR 0.481505
FineTuningLR 0.255594
Epoch 49 | Batch 70/100 | Loss 0.234369
InnerLR 0.481560
FineTuningLR 0.255706
Epoch 49 | Batch 80/100 | Loss 0.229378
InnerLR 0.481596
FineTuningLR 0.255955
Epoch 49 | Batch 90/100 | Loss 0.226476
InnerLR 0.481681
FineTuningLR 0.256208
100 Accuracy = 79.43% +- 2.35%
Epoch 49: 79.43
Epoch 50 | Batch 0/100 | Loss 0.126243
InnerLR 0.481759
FineTuningLR 0.256385
Epoch 50 | Batch 10/100 | Loss 0.197748
InnerLR 0.481743
FineTuningLR 0.256590
Epoch 50 | Batch 20/100 | Loss 0.245515
InnerLR 0.481588
FineTuningLR 0.256930
Epoch 50 | Batch 30/100 | Loss 0.249172
InnerLR 0.481561
FineTuningLR 0.257026
Epoch 50 | Batch 40/100 | Loss 0.236745
InnerLR 0.481605
FineTuningLR 0.257095
Epoch 50 | Batch 50/100 | Loss 0.245907
InnerLR 0.481629
FineTuningLR 0.257302
Epoch 50 | Batch 60/100 | Loss 0.251573
InnerLR 0.481595
FineTuningLR 0.257432
Epoch 50 | Batch 70/100 | Loss 0.254840
InnerLR 0.481601
FineTuningLR 0.257385
Epoch 50 | Batch 80/100 | Loss 0.256026
InnerLR 0.481467
FineTuningLR 0.257306
Epoch 50 | Batch 90/100 | Loss 0.262117
InnerLR 0.481408
FineTuningLR 0.257204
100 Accuracy = 77.53% +- 2.74%
Epoch 50: 77.53
Epoch 51 | Batch 0/100 | Loss 0.120421
InnerLR 0.481228
FineTuningLR 0.257151
Epoch 51 | Batch 10/100 | Loss 0.228220
InnerLR 0.481227
FineTuningLR 0.257123
Epoch 51 | Batch 20/100 | Loss 0.253191
InnerLR 0.481284
FineTuningLR 0.256954
Epoch 51 | Batch 30/100 | Loss 0.231926
InnerLR 0.481315
FineTuningLR 0.256920
Epoch 51 | Batch 40/100 | Loss 0.241711
InnerLR 0.481256
FineTuningLR 0.256946
Epoch 51 | Batch 50/100 | Loss 0.232843
InnerLR 0.481147
FineTuningLR 0.257080
Epoch 51 | Batch 60/100 | Loss 0.221207
InnerLR 0.481174
FineTuningLR 0.257351
Epoch 51 | Batch 70/100 | Loss 0.224193
InnerLR 0.481186
FineTuningLR 0.257563
Epoch 51 | Batch 80/100 | Loss 0.227593
InnerLR 0.481221
FineTuningLR 0.257978
Epoch 51 | Batch 90/100 | Loss 0.240995
InnerLR 0.481181
FineTuningLR 0.258116
100 Accuracy = 77.29% +- 2.42%
Epoch 51: 77.29
Epoch 52 | Batch 0/100 | Loss 0.138356
InnerLR 0.481055
FineTuningLR 0.258244
Epoch 52 | Batch 10/100 | Loss 0.173091
InnerLR 0.481060
FineTuningLR 0.258241
Epoch 52 | Batch 20/100 | Loss 0.221857
InnerLR 0.481057
FineTuningLR 0.258328
Epoch 52 | Batch 30/100 | Loss 0.231520
InnerLR 0.480918
FineTuningLR 0.258432
Epoch 52 | Batch 40/100 | Loss 0.246029
InnerLR 0.480715
FineTuningLR 0.258578
Epoch 52 | Batch 50/100 | Loss 0.241786
InnerLR 0.480687
FineTuningLR 0.258683
Epoch 52 | Batch 60/100 | Loss 0.249303
InnerLR 0.480689
FineTuningLR 0.258899
Epoch 52 | Batch 70/100 | Loss 0.252949
InnerLR 0.480714
FineTuningLR 0.259133
Epoch 52 | Batch 80/100 | Loss 0.253887
InnerLR 0.480590
FineTuningLR 0.259440
Epoch 52 | Batch 90/100 | Loss 0.255196
InnerLR 0.480615
FineTuningLR 0.259519
100 Accuracy = 79.40% +- 2.14%
Epoch 52: 79.40
Epoch 53 | Batch 0/100 | Loss 0.439066
InnerLR 0.480802
FineTuningLR 0.259591
Epoch 53 | Batch 10/100 | Loss 0.281710
InnerLR 0.480773
FineTuningLR 0.259507
Epoch 53 | Batch 20/100 | Loss 0.272838
InnerLR 0.480737
FineTuningLR 0.259376
Epoch 53 | Batch 30/100 | Loss 0.288990
InnerLR 0.480734
FineTuningLR 0.259297
Epoch 53 | Batch 40/100 | Loss 0.272852
InnerLR 0.480755
FineTuningLR 0.259222
Epoch 53 | Batch 50/100 | Loss 0.289356
InnerLR 0.480769
FineTuningLR 0.259253
Epoch 53 | Batch 60/100 | Loss 0.274996
InnerLR 0.480862
FineTuningLR 0.259214
Epoch 53 | Batch 70/100 | Loss 0.275956
InnerLR 0.480897
FineTuningLR 0.259173
Epoch 53 | Batch 80/100 | Loss 0.285365
InnerLR 0.480826
FineTuningLR 0.259288
Epoch 53 | Batch 90/100 | Loss 0.279689
InnerLR 0.480887
FineTuningLR 0.259422
100 Accuracy = 78.91% +- 2.47%
Epoch 53: 78.91
Epoch 54 | Batch 0/100 | Loss 0.095533
InnerLR 0.481070
FineTuningLR 0.259621
Epoch 54 | Batch 10/100 | Loss 0.251452
InnerLR 0.481119
FineTuningLR 0.259746
Epoch 54 | Batch 20/100 | Loss 0.266571
InnerLR 0.481011
FineTuningLR 0.259926
Epoch 54 | Batch 30/100 | Loss 0.259522
InnerLR 0.480945
FineTuningLR 0.260041
Epoch 54 | Batch 40/100 | Loss 0.258258
InnerLR 0.481053
FineTuningLR 0.260321
Epoch 54 | Batch 50/100 | Loss 0.267383
InnerLR 0.481133
FineTuningLR 0.260519
Epoch 54 | Batch 60/100 | Loss 0.262493
InnerLR 0.481155
FineTuningLR 0.260742
Epoch 54 | Batch 70/100 | Loss 0.256206
InnerLR 0.481183
FineTuningLR 0.260936
Epoch 54 | Batch 80/100 | Loss 0.249576
InnerLR 0.481308
FineTuningLR 0.261241
Epoch 54 | Batch 90/100 | Loss 0.251797
InnerLR 0.481254
FineTuningLR 0.261420
100 Accuracy = 79.05% +- 2.50%
Epoch 54: 79.05
Epoch 55 | Batch 0/100 | Loss 0.531366
InnerLR 0.481043
FineTuningLR 0.261609
Epoch 55 | Batch 10/100 | Loss 0.312016
InnerLR 0.481046
FineTuningLR 0.261725
Epoch 55 | Batch 20/100 | Loss 0.257570
InnerLR 0.480960
FineTuningLR 0.261838
Epoch 55 | Batch 30/100 | Loss 0.240743
InnerLR 0.480880
FineTuningLR 0.262046
Epoch 55 | Batch 40/100 | Loss 0.238038
InnerLR 0.480888
FineTuningLR 0.262450
Epoch 55 | Batch 50/100 | Loss 0.238273
InnerLR 0.480947
FineTuningLR 0.262648
Epoch 55 | Batch 60/100 | Loss 0.247389
InnerLR 0.481031
FineTuningLR 0.262849
Epoch 55 | Batch 70/100 | Loss 0.249521
InnerLR 0.481135
FineTuningLR 0.262805
Epoch 55 | Batch 80/100 | Loss 0.243079
InnerLR 0.481297
FineTuningLR 0.262886
Epoch 55 | Batch 90/100 | Loss 0.243666
InnerLR 0.481383
FineTuningLR 0.262995
100 Accuracy = 79.73% +- 2.43%
Epoch 55: 79.73
Epoch 56 | Batch 0/100 | Loss 0.528912
InnerLR 0.481339
FineTuningLR 0.263097
Epoch 56 | Batch 10/100 | Loss 0.393739
InnerLR 0.481160
FineTuningLR 0.263079
Epoch 56 | Batch 20/100 | Loss 0.327636
InnerLR 0.481021
FineTuningLR 0.262958
Epoch 56 | Batch 30/100 | Loss 0.311197
InnerLR 0.481087
FineTuningLR 0.262833
Epoch 56 | Batch 40/100 | Loss 0.299961
InnerLR 0.481154
FineTuningLR 0.262640
Epoch 56 | Batch 50/100 | Loss 0.270295
InnerLR 0.481117
FineTuningLR 0.262470
Epoch 56 | Batch 60/100 | Loss 0.266615
InnerLR 0.481004
FineTuningLR 0.262339
Epoch 56 | Batch 70/100 | Loss 0.260417
InnerLR 0.480777
FineTuningLR 0.262248
Epoch 56 | Batch 80/100 | Loss 0.251365
InnerLR 0.480407
FineTuningLR 0.262185
Epoch 56 | Batch 90/100 | Loss 0.247444
InnerLR 0.480307
FineTuningLR 0.262308
100 Accuracy = 78.56% +- 2.65%
Epoch 56: 78.56
Epoch 57 | Batch 0/100 | Loss 0.253251
InnerLR 0.480097
FineTuningLR 0.262442
Epoch 57 | Batch 10/100 | Loss 0.198007
InnerLR 0.480091
FineTuningLR 0.262475
Epoch 57 | Batch 20/100 | Loss 0.221264
InnerLR 0.480180
FineTuningLR 0.262753
Epoch 57 | Batch 30/100 | Loss 0.209441
InnerLR 0.480242
FineTuningLR 0.262911
Epoch 57 | Batch 40/100 | Loss 0.196238
InnerLR 0.480336
FineTuningLR 0.263197
Epoch 57 | Batch 50/100 | Loss 0.232682
InnerLR 0.480540
FineTuningLR 0.263317
Epoch 57 | Batch 60/100 | Loss 0.222921
InnerLR 0.480838
FineTuningLR 0.263603
Epoch 57 | Batch 70/100 | Loss 0.216009
InnerLR 0.480994
FineTuningLR 0.263851
Epoch 57 | Batch 80/100 | Loss 0.218794
InnerLR 0.481187
FineTuningLR 0.264167
Epoch 57 | Batch 90/100 | Loss 0.219034
InnerLR 0.481356
FineTuningLR 0.264175
100 Accuracy = 78.40% +- 2.62%
Epoch 57: 78.40
Epoch 58 | Batch 0/100 | Loss 0.339565
InnerLR 0.481616
FineTuningLR 0.264060
Epoch 58 | Batch 10/100 | Loss 0.258235
InnerLR 0.481842
FineTuningLR 0.263982
Epoch 58 | Batch 20/100 | Loss 0.200025
InnerLR 0.482326
FineTuningLR 0.264054
Epoch 58 | Batch 30/100 | Loss 0.226120
InnerLR 0.482611
FineTuningLR 0.264224
Epoch 58 | Batch 40/100 | Loss 0.228180
InnerLR 0.482707
FineTuningLR 0.264452
Epoch 58 | Batch 50/100 | Loss 0.238752
InnerLR 0.482794
FineTuningLR 0.264450
Epoch 58 | Batch 60/100 | Loss 0.228420
InnerLR 0.482922
FineTuningLR 0.264587
Epoch 58 | Batch 70/100 | Loss 0.243334
InnerLR 0.482906
FineTuningLR 0.264712
Epoch 58 | Batch 80/100 | Loss 0.244435
InnerLR 0.482870
FineTuningLR 0.264814
Epoch 58 | Batch 90/100 | Loss 0.234897
InnerLR 0.482849
FineTuningLR 0.264900
100 Accuracy = 80.51% +- 2.33%
Epoch 58: 80.51
Epoch 59 | Batch 0/100 | Loss 0.088781
InnerLR 0.482819
FineTuningLR 0.264828
Epoch 59 | Batch 10/100 | Loss 0.180266
InnerLR 0.482841
FineTuningLR 0.264681
Epoch 59 | Batch 20/100 | Loss 0.206745
InnerLR 0.483042
FineTuningLR 0.264508
Epoch 59 | Batch 30/100 | Loss 0.219194
InnerLR 0.483262
FineTuningLR 0.264301
Epoch 59 | Batch 40/100 | Loss 0.231246
InnerLR 0.483606
FineTuningLR 0.263866
Epoch 59 | Batch 50/100 | Loss 0.234301
InnerLR 0.483643
FineTuningLR 0.263610
Epoch 59 | Batch 60/100 | Loss 0.226940
InnerLR 0.483636
FineTuningLR 0.263314
Epoch 59 | Batch 70/100 | Loss 0.233087
InnerLR 0.483754
FineTuningLR 0.263225
Epoch 59 | Batch 80/100 | Loss 0.223364
InnerLR 0.483999
FineTuningLR 0.263273
Epoch 59 | Batch 90/100 | Loss 0.230821
InnerLR 0.484273
FineTuningLR 0.263307
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 80.49% +- 2.31%
Epoch 59: 80.49
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_32_lr_0.0003/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_32_lr_0.0003/tabula_muris/leo_FCNet/20231211_165827
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 96.18% +- 0.40%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_32_lr_0.0003/tabula_muris/leo_FCNet/20231211_165827
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 78.16% +- 0.99%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_32_lr_0.0003/tabula_muris/leo_FCNet/20231211_165827
600 Accuracy = 71.33% +- 1.03%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_32_lr_0.0003/results.txt
+-------+-------------------+--------------------+
| split |      acc_mean     |      acc_std       |
+-------+-------------------+--------------------+
| train | 96.18444444444445 | 5.0153891568911915 |
|  val  | 78.16444444444446 | 12.32941359133405  |
|  test | 71.33333333333333 | 12.850133303819302 |
+-------+-------------------+--------------------+
