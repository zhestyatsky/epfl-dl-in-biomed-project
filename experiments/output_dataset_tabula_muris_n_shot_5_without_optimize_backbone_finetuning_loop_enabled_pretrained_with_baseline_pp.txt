/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 5
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 5
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 5
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 0.5
    finetuning_lr_init: 0.05
    num_adaptation_steps: 5
    kl_coef: 0.01
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 0.1
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 32
    enable_finetuning_loop: true
  n_task: 4
  latent_space_dim: 32
  leo_inner_lr_init: 0.5
  leo_finetuning_lr_init: 0.05
  num_adaptation_steps: 5
  kl_coef: 0.01
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 0.1
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-06
  optimize_backbone: false
  pretrained_backbone_weights_path: pretrained_weights/tabula_muris_baseline_pp_model.tar
  enable_finetuning_loop: true
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_5_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.001
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_5_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Using pretrained backbone from pretrained_weights/tabula_muris_baseline_pp_model.tar.
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=32, bias=False)
    (relation_net): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=False)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=64, bias=False)
      (3): ReLU()
      (4): Linear(in_features=64, out_features=64, bias=False)
    )
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=32, out_features=130, bias=False)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 1e-06

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Epoch 0 | Batch 0/100 | Loss 5.150723
InnerLR 0.500000
FineTuningLR 0.050000
Epoch 0 | Batch 10/100 | Loss 4.352119
InnerLR 0.502000
FineTuningLR 0.052000
Epoch 0 | Batch 20/100 | Loss 4.020089
InnerLR 0.505000
FineTuningLR 0.055000
Epoch 0 | Batch 30/100 | Loss 3.872759
InnerLR 0.507000
FineTuningLR 0.057000
Epoch 0 | Batch 40/100 | Loss 3.806627
InnerLR 0.510000
FineTuningLR 0.060000
Epoch 0 | Batch 50/100 | Loss 3.687975
InnerLR 0.512000
FineTuningLR 0.062000
Epoch 0 | Batch 60/100 | Loss 3.651826
InnerLR 0.515000
FineTuningLR 0.065000
Epoch 0 | Batch 70/100 | Loss 3.524159
InnerLR 0.517000
FineTuningLR 0.067000
Epoch 0 | Batch 80/100 | Loss 3.457342
InnerLR 0.520000
FineTuningLR 0.070000
Epoch 0 | Batch 90/100 | Loss 3.366046
InnerLR 0.522000
FineTuningLR 0.072000
100 Accuracy = 48.36% +- 2.44%
Epoch 0: 48.36
best model! save...
Epoch 1 | Batch 0/100 | Loss 3.059147
InnerLR 0.525000
FineTuningLR 0.075000
Epoch 1 | Batch 10/100 | Loss 2.956462
InnerLR 0.527000
FineTuningLR 0.077000
Epoch 1 | Batch 20/100 | Loss 2.540588
InnerLR 0.530000
FineTuningLR 0.080000
Epoch 1 | Batch 30/100 | Loss 2.387173
InnerLR 0.532000
FineTuningLR 0.082000
Epoch 1 | Batch 40/100 | Loss 2.250524
InnerLR 0.535000
FineTuningLR 0.085000
Epoch 1 | Batch 50/100 | Loss 2.076498
InnerLR 0.537000
FineTuningLR 0.087000
Epoch 1 | Batch 60/100 | Loss 1.976156
InnerLR 0.539999
FineTuningLR 0.090000
Epoch 1 | Batch 70/100 | Loss 1.866793
InnerLR 0.541999
FineTuningLR 0.092000
Epoch 1 | Batch 80/100 | Loss 1.761983
InnerLR 0.544999
FineTuningLR 0.095000
Epoch 1 | Batch 90/100 | Loss 1.678605
InnerLR 0.546999
FineTuningLR 0.097000
100 Accuracy = 68.43% +- 2.56%
Epoch 1: 68.43
best model! save...
Epoch 2 | Batch 0/100 | Loss 1.284311
InnerLR 0.549999
FineTuningLR 0.100000
Epoch 2 | Batch 10/100 | Loss 0.832275
InnerLR 0.551999
FineTuningLR 0.102000
Epoch 2 | Batch 20/100 | Loss 0.794766
InnerLR 0.554999
FineTuningLR 0.105000
Epoch 2 | Batch 30/100 | Loss 0.765462
InnerLR 0.556999
FineTuningLR 0.107000
Epoch 2 | Batch 40/100 | Loss 0.757529
InnerLR 0.559999
FineTuningLR 0.110000
Epoch 2 | Batch 50/100 | Loss 0.748169
InnerLR 0.561999
FineTuningLR 0.112000
Epoch 2 | Batch 60/100 | Loss 0.712645
InnerLR 0.564999
FineTuningLR 0.115000
Epoch 2 | Batch 70/100 | Loss 0.697258
InnerLR 0.566999
FineTuningLR 0.117000
Epoch 2 | Batch 80/100 | Loss 0.683667
InnerLR 0.569999
FineTuningLR 0.120000
Epoch 2 | Batch 90/100 | Loss 0.663606
InnerLR 0.571999
FineTuningLR 0.122000
100 Accuracy = 77.65% +- 2.10%
Epoch 2: 77.65
best model! save...
Epoch 3 | Batch 0/100 | Loss 0.205747
InnerLR 0.574999
FineTuningLR 0.125000
Epoch 3 | Batch 10/100 | Loss 0.409183
InnerLR 0.576999
FineTuningLR 0.127000
Epoch 3 | Batch 20/100 | Loss 0.423546
InnerLR 0.579999
FineTuningLR 0.130000
Epoch 3 | Batch 30/100 | Loss 0.420865
InnerLR 0.581999
FineTuningLR 0.132000
Epoch 3 | Batch 40/100 | Loss 0.442578
InnerLR 0.584995
FineTuningLR 0.135004
Epoch 3 | Batch 50/100 | Loss 0.446904
InnerLR 0.586992
FineTuningLR 0.137007
Epoch 3 | Batch 60/100 | Loss 0.436941
InnerLR 0.589990
FineTuningLR 0.140009
Epoch 3 | Batch 70/100 | Loss 0.436934
InnerLR 0.591989
FineTuningLR 0.142010
Epoch 3 | Batch 80/100 | Loss 0.438038
InnerLR 0.594988
FineTuningLR 0.145011
Epoch 3 | Batch 90/100 | Loss 0.440265
InnerLR 0.596987
FineTuningLR 0.147012
100 Accuracy = 79.64% +- 2.00%
Epoch 3: 79.64
best model! save...
Epoch 4 | Batch 0/100 | Loss 0.497404
InnerLR 0.599987
FineTuningLR 0.150012
Epoch 4 | Batch 10/100 | Loss 0.431514
InnerLR 0.601987
FineTuningLR 0.152012
Epoch 4 | Batch 20/100 | Loss 0.421519
InnerLR 0.604987
FineTuningLR 0.155012
Epoch 4 | Batch 30/100 | Loss 0.426011
InnerLR 0.606987
FineTuningLR 0.157012
Epoch 4 | Batch 40/100 | Loss 0.437139
InnerLR 0.609987
FineTuningLR 0.160012
Epoch 4 | Batch 50/100 | Loss 0.419022
InnerLR 0.611987
FineTuningLR 0.162012
Epoch 4 | Batch 60/100 | Loss 0.415830
InnerLR 0.614975
FineTuningLR 0.165023
Epoch 4 | Batch 70/100 | Loss 0.408626
InnerLR 0.616970
FineTuningLR 0.167028
Epoch 4 | Batch 80/100 | Loss 0.414231
InnerLR 0.619963
FineTuningLR 0.170034
Epoch 4 | Batch 90/100 | Loss 0.416085
InnerLR 0.621960
FineTuningLR 0.172037
100 Accuracy = 81.67% +- 2.02%
Epoch 4: 81.67
best model! save...
Epoch 5 | Batch 0/100 | Loss 0.392170
InnerLR 0.624826
FineTuningLR 0.175073
Epoch 5 | Batch 10/100 | Loss 0.372488
InnerLR 0.626602
FineTuningLR 0.177130
Epoch 5 | Batch 20/100 | Loss 0.365994
InnerLR 0.629346
FineTuningLR 0.180194
Epoch 5 | Batch 30/100 | Loss 0.372078
InnerLR 0.631217
FineTuningLR 0.182225
Epoch 5 | Batch 40/100 | Loss 0.359402
InnerLR 0.634070
FineTuningLR 0.185257
Epoch 5 | Batch 50/100 | Loss 0.348984
InnerLR 0.635997
FineTuningLR 0.187273
Epoch 5 | Batch 60/100 | Loss 0.352066
InnerLR 0.638915
FineTuningLR 0.190288
Epoch 5 | Batch 70/100 | Loss 0.345838
InnerLR 0.640870
FineTuningLR 0.192298
Epoch 5 | Batch 80/100 | Loss 0.331980
InnerLR 0.643821
FineTuningLR 0.195308
Epoch 5 | Batch 90/100 | Loss 0.341094
InnerLR 0.645813
FineTuningLR 0.197291
100 Accuracy = 81.23% +- 1.72%
Epoch 5: 81.23
Epoch 6 | Batch 0/100 | Loss 0.354082
InnerLR 0.648828
FineTuningLR 0.200244
Epoch 6 | Batch 10/100 | Loss 0.316936
InnerLR 0.650836
FineTuningLR 0.202219
Epoch 6 | Batch 20/100 | Loss 0.331115
InnerLR 0.653816
FineTuningLR 0.204674
Epoch 6 | Batch 30/100 | Loss 0.345961
InnerLR 0.655797
FineTuningLR 0.206402
Epoch 6 | Batch 40/100 | Loss 0.331064
InnerLR 0.658778
FineTuningLR 0.209086
Epoch 6 | Batch 50/100 | Loss 0.329572
InnerLR 0.660770
FineTuningLR 0.210923
Epoch 6 | Batch 60/100 | Loss 0.329127
InnerLR 0.663763
FineTuningLR 0.213732
Epoch 6 | Batch 70/100 | Loss 0.349374
InnerLR 0.665630
FineTuningLR 0.215714
Epoch 6 | Batch 80/100 | Loss 0.334863
InnerLR 0.668431
FineTuningLR 0.218729
Epoch 6 | Batch 90/100 | Loss 0.330457
InnerLR 0.670328
FineTuningLR 0.220737
100 Accuracy = 81.89% +- 2.15%
Epoch 6: 81.89
best model! save...
Epoch 7 | Batch 0/100 | Loss 0.500021
InnerLR 0.673215
FineTuningLR 0.223742
Epoch 7 | Batch 10/100 | Loss 0.287271
InnerLR 0.675160
FineTuningLR 0.225741
Epoch 7 | Batch 20/100 | Loss 0.290055
InnerLR 0.678044
FineTuningLR 0.228777
Epoch 7 | Batch 30/100 | Loss 0.279115
InnerLR 0.679971
FineTuningLR 0.230804
Epoch 7 | Batch 40/100 | Loss 0.277771
InnerLR 0.682893
FineTuningLR 0.233830
Epoch 7 | Batch 50/100 | Loss 0.281824
InnerLR 0.684852
FineTuningLR 0.235844
Epoch 7 | Batch 60/100 | Loss 0.290325
InnerLR 0.687871
FineTuningLR 0.238737
Epoch 7 | Batch 70/100 | Loss 0.291842
InnerLR 0.689904
FineTuningLR 0.240642
Epoch 7 | Batch 80/100 | Loss 0.288629
InnerLR 0.692946
FineTuningLR 0.243529
Epoch 7 | Batch 90/100 | Loss 0.296006
InnerLR 0.694951
FineTuningLR 0.245484
100 Accuracy = 82.32% +- 1.92%
Epoch 7: 82.32
best model! save...
Epoch 8 | Batch 0/100 | Loss 0.245776
InnerLR 0.697966
FineTuningLR 0.247945
Epoch 8 | Batch 10/100 | Loss 0.252543
InnerLR 0.699964
FineTuningLR 0.249679
Epoch 8 | Batch 20/100 | Loss 0.285161
InnerLR 0.702912
FineTuningLR 0.252401
Epoch 8 | Batch 30/100 | Loss 0.274631
InnerLR 0.704862
FineTuningLR 0.254275
Epoch 8 | Batch 40/100 | Loss 0.276398
InnerLR 0.707751
FineTuningLR 0.257175
Epoch 8 | Batch 50/100 | Loss 0.267337
InnerLR 0.709587
FineTuningLR 0.259182
Epoch 8 | Batch 60/100 | Loss 0.271516
InnerLR 0.712405
FineTuningLR 0.262185
Epoch 8 | Batch 70/100 | Loss 0.263822
InnerLR 0.714249
FineTuningLR 0.264228
Epoch 8 | Batch 80/100 | Loss 0.268246
InnerLR 0.716544
FineTuningLR 0.267306
Epoch 8 | Batch 90/100 | Loss 0.268183
InnerLR 0.717884
FineTuningLR 0.269375
100 Accuracy = 83.39% +- 1.80%
Epoch 8: 83.39
best model! save...
Epoch 9 | Batch 0/100 | Loss 0.228004
InnerLR 0.720131
FineTuningLR 0.272445
Epoch 9 | Batch 10/100 | Loss 0.271621
InnerLR 0.721753
FineTuningLR 0.274475
Epoch 9 | Batch 20/100 | Loss 0.303259
InnerLR 0.724281
FineTuningLR 0.277536
Epoch 9 | Batch 30/100 | Loss 0.293599
InnerLR 0.725963
FineTuningLR 0.279623
Epoch 9 | Batch 40/100 | Loss 0.280265
InnerLR 0.728555
FineTuningLR 0.282382
Epoch 9 | Batch 50/100 | Loss 0.285675
InnerLR 0.730286
FineTuningLR 0.284175
Epoch 9 | Batch 60/100 | Loss 0.286843
InnerLR 0.732702
FineTuningLR 0.287077
Epoch 9 | Batch 70/100 | Loss 0.288324
InnerLR 0.734397
FineTuningLR 0.289032
Epoch 9 | Batch 80/100 | Loss 0.286002
InnerLR 0.736921
FineTuningLR 0.292021
Epoch 9 | Batch 90/100 | Loss 0.283908
InnerLR 0.738544
FineTuningLR 0.294053
100 Accuracy = 82.87% +- 1.96%
Epoch 9: 82.87
Epoch 10 | Batch 0/100 | Loss 0.131401
InnerLR 0.741061
FineTuningLR 0.297112
Epoch 10 | Batch 10/100 | Loss 0.180494
InnerLR 0.742654
FineTuningLR 0.299239
Epoch 10 | Batch 20/100 | Loss 0.256102
InnerLR 0.745105
FineTuningLR 0.302394
Epoch 10 | Batch 30/100 | Loss 0.254614
InnerLR 0.746817
FineTuningLR 0.304465
Epoch 10 | Batch 40/100 | Loss 0.266240
InnerLR 0.749256
FineTuningLR 0.307647
Epoch 10 | Batch 50/100 | Loss 0.271480
InnerLR 0.750893
FineTuningLR 0.309773
Epoch 10 | Batch 60/100 | Loss 0.266014
InnerLR 0.753446
FineTuningLR 0.312936
Epoch 10 | Batch 70/100 | Loss 0.256782
InnerLR 0.755191
FineTuningLR 0.315034
Epoch 10 | Batch 80/100 | Loss 0.255288
InnerLR 0.757662
FineTuningLR 0.318280
Epoch 10 | Batch 90/100 | Loss 0.249936
InnerLR 0.759284
FineTuningLR 0.320465
100 Accuracy = 82.13% +- 1.99%
Epoch 10: 82.13
Epoch 11 | Batch 0/100 | Loss 0.146043
InnerLR 0.761844
FineTuningLR 0.323682
Epoch 11 | Batch 10/100 | Loss 0.301066
InnerLR 0.763379
FineTuningLR 0.325886
Epoch 11 | Batch 20/100 | Loss 0.273341
InnerLR 0.765655
FineTuningLR 0.328542
Epoch 11 | Batch 30/100 | Loss 0.273581
InnerLR 0.767157
FineTuningLR 0.330088
Epoch 11 | Batch 40/100 | Loss 0.264483
InnerLR 0.769647
FineTuningLR 0.332426
Epoch 11 | Batch 50/100 | Loss 0.260762
InnerLR 0.771144
FineTuningLR 0.334018
Epoch 11 | Batch 60/100 | Loss 0.255374
InnerLR 0.773533
FineTuningLR 0.336566
Epoch 11 | Batch 70/100 | Loss 0.244261
InnerLR 0.775213
FineTuningLR 0.338295
Epoch 11 | Batch 80/100 | Loss 0.245525
InnerLR 0.777686
FineTuningLR 0.341027
Epoch 11 | Batch 90/100 | Loss 0.243138
InnerLR 0.779271
FineTuningLR 0.342976
100 Accuracy = 83.47% +- 1.77%
Epoch 11: 83.47
best model! save...
Epoch 12 | Batch 0/100 | Loss 0.380278
InnerLR 0.781479
FineTuningLR 0.345835
Epoch 12 | Batch 10/100 | Loss 0.264533
InnerLR 0.782991
FineTuningLR 0.347808
Epoch 12 | Batch 20/100 | Loss 0.225901
InnerLR 0.785444
FineTuningLR 0.350682
Epoch 12 | Batch 30/100 | Loss 0.222443
InnerLR 0.786861
FineTuningLR 0.352668
Epoch 12 | Batch 40/100 | Loss 0.218808
InnerLR 0.789040
FineTuningLR 0.355245
Epoch 12 | Batch 50/100 | Loss 0.231604
InnerLR 0.790537
FineTuningLR 0.357084
Epoch 12 | Batch 60/100 | Loss 0.230983
InnerLR 0.792863
FineTuningLR 0.359934
Epoch 12 | Batch 70/100 | Loss 0.221488
InnerLR 0.794315
FineTuningLR 0.361952
Epoch 12 | Batch 80/100 | Loss 0.222365
InnerLR 0.796595
FineTuningLR 0.364911
Epoch 12 | Batch 90/100 | Loss 0.216916
InnerLR 0.798044
FineTuningLR 0.366773
100 Accuracy = 83.00% +- 1.78%
Epoch 12: 83.00
Epoch 13 | Batch 0/100 | Loss 0.298398
InnerLR 0.800156
FineTuningLR 0.369731
Epoch 13 | Batch 10/100 | Loss 0.201224
InnerLR 0.801490
FineTuningLR 0.371806
Epoch 13 | Batch 20/100 | Loss 0.233717
InnerLR 0.803596
FineTuningLR 0.374946
Epoch 13 | Batch 30/100 | Loss 0.221400
InnerLR 0.805167
FineTuningLR 0.376997
Epoch 13 | Batch 40/100 | Loss 0.218822
InnerLR 0.807741
FineTuningLR 0.380001
Epoch 13 | Batch 50/100 | Loss 0.218580
InnerLR 0.809330
FineTuningLR 0.382084
Epoch 13 | Batch 60/100 | Loss 0.216442
InnerLR 0.811686
FineTuningLR 0.385250
Epoch 13 | Batch 70/100 | Loss 0.219541
InnerLR 0.813166
FineTuningLR 0.387046
Epoch 13 | Batch 80/100 | Loss 0.212429
InnerLR 0.815481
FineTuningLR 0.389856
Epoch 13 | Batch 90/100 | Loss 0.207632
InnerLR 0.816894
FineTuningLR 0.391842
100 Accuracy = 82.61% +- 2.20%
Epoch 13: 82.61
Epoch 14 | Batch 0/100 | Loss 0.132470
InnerLR 0.818811
FineTuningLR 0.394815
Epoch 14 | Batch 10/100 | Loss 0.235809
InnerLR 0.820227
FineTuningLR 0.396786
Epoch 14 | Batch 20/100 | Loss 0.245593
InnerLR 0.822122
FineTuningLR 0.399902
Epoch 14 | Batch 30/100 | Loss 0.250714
InnerLR 0.823466
FineTuningLR 0.401782
Epoch 14 | Batch 40/100 | Loss 0.236724
InnerLR 0.825548
FineTuningLR 0.404343
Epoch 14 | Batch 50/100 | Loss 0.223479
InnerLR 0.826845
FineTuningLR 0.406018
Epoch 14 | Batch 60/100 | Loss 0.220130
InnerLR 0.828694
FineTuningLR 0.408707
Epoch 14 | Batch 70/100 | Loss 0.214437
InnerLR 0.829792
FineTuningLR 0.410233
Epoch 14 | Batch 80/100 | Loss 0.214881
InnerLR 0.831686
FineTuningLR 0.412380
Epoch 14 | Batch 90/100 | Loss 0.210147
InnerLR 0.832942
FineTuningLR 0.413973
100 Accuracy = 84.04% +- 2.04%
Epoch 14: 84.04
best model! save...
Epoch 15 | Batch 0/100 | Loss 0.237223
InnerLR 0.834875
FineTuningLR 0.416398
Epoch 15 | Batch 10/100 | Loss 0.240678
InnerLR 0.836125
FineTuningLR 0.417954
Epoch 15 | Batch 20/100 | Loss 0.228972
InnerLR 0.838094
FineTuningLR 0.419787
Epoch 15 | Batch 30/100 | Loss 0.221171
InnerLR 0.839318
FineTuningLR 0.421163
Epoch 15 | Batch 40/100 | Loss 0.226002
InnerLR 0.841044
FineTuningLR 0.422820
Epoch 15 | Batch 50/100 | Loss 0.234971
InnerLR 0.842170
FineTuningLR 0.423579
Epoch 15 | Batch 60/100 | Loss 0.235521
InnerLR 0.843993
FineTuningLR 0.424811
Epoch 15 | Batch 70/100 | Loss 0.223515
InnerLR 0.845276
FineTuningLR 0.425538
Epoch 15 | Batch 80/100 | Loss 0.219929
InnerLR 0.847410
FineTuningLR 0.427011
Epoch 15 | Batch 90/100 | Loss 0.217780
InnerLR 0.848915
FineTuningLR 0.427823
100 Accuracy = 85.12% +- 1.88%
Epoch 15: 85.12
best model! save...
Epoch 16 | Batch 0/100 | Loss 0.301925
InnerLR 0.851052
FineTuningLR 0.429200
Epoch 16 | Batch 10/100 | Loss 0.195699
InnerLR 0.852203
FineTuningLR 0.430389
Epoch 16 | Batch 20/100 | Loss 0.213593
InnerLR 0.854122
FineTuningLR 0.432517
Epoch 16 | Batch 30/100 | Loss 0.211660
InnerLR 0.855339
FineTuningLR 0.433958
Epoch 16 | Batch 40/100 | Loss 0.202227
InnerLR 0.857345
FineTuningLR 0.436182
Epoch 16 | Batch 50/100 | Loss 0.200405
InnerLR 0.858726
FineTuningLR 0.437819
Epoch 16 | Batch 60/100 | Loss 0.208641
InnerLR 0.860960
FineTuningLR 0.440255
Epoch 16 | Batch 70/100 | Loss 0.205773
InnerLR 0.862595
FineTuningLR 0.441313
Epoch 16 | Batch 80/100 | Loss 0.207235
InnerLR 0.864894
FineTuningLR 0.442403
Epoch 16 | Batch 90/100 | Loss 0.206174
InnerLR 0.866308
FineTuningLR 0.443266
100 Accuracy = 83.31% +- 1.95%
Epoch 16: 83.31
Epoch 17 | Batch 0/100 | Loss 0.126813
InnerLR 0.868287
FineTuningLR 0.444836
Epoch 17 | Batch 10/100 | Loss 0.172573
InnerLR 0.869645
FineTuningLR 0.445884
Epoch 17 | Batch 20/100 | Loss 0.191835
InnerLR 0.871569
FineTuningLR 0.447831
Epoch 17 | Batch 30/100 | Loss 0.197145
InnerLR 0.872694
FineTuningLR 0.449291
Epoch 17 | Batch 40/100 | Loss 0.207556
InnerLR 0.873977
FineTuningLR 0.451212
Epoch 17 | Batch 50/100 | Loss 0.206557
InnerLR 0.874699
FineTuningLR 0.452339
Epoch 17 | Batch 60/100 | Loss 0.208220
InnerLR 0.875647
FineTuningLR 0.453402
Epoch 17 | Batch 70/100 | Loss 0.205836
InnerLR 0.876423
FineTuningLR 0.454372
Epoch 17 | Batch 80/100 | Loss 0.200110
InnerLR 0.877894
FineTuningLR 0.456012
Epoch 17 | Batch 90/100 | Loss 0.204384
InnerLR 0.878907
FineTuningLR 0.456534
100 Accuracy = 83.88% +- 1.84%
Epoch 17: 83.88
Epoch 18 | Batch 0/100 | Loss 0.208063
InnerLR 0.880357
FineTuningLR 0.457439
Epoch 18 | Batch 10/100 | Loss 0.203404
InnerLR 0.881503
FineTuningLR 0.457990
Epoch 18 | Batch 20/100 | Loss 0.206163
InnerLR 0.883221
FineTuningLR 0.459463
Epoch 18 | Batch 30/100 | Loss 0.219317
InnerLR 0.884161
FineTuningLR 0.460118
Epoch 18 | Batch 40/100 | Loss 0.207320
InnerLR 0.885387
FineTuningLR 0.460986
Epoch 18 | Batch 50/100 | Loss 0.203631
InnerLR 0.886093
FineTuningLR 0.461904
Epoch 18 | Batch 60/100 | Loss 0.193469
InnerLR 0.887025
FineTuningLR 0.463505
Epoch 18 | Batch 70/100 | Loss 0.192546
InnerLR 0.887813
FineTuningLR 0.464411
Epoch 18 | Batch 80/100 | Loss 0.192459
InnerLR 0.889154
FineTuningLR 0.465743
Epoch 18 | Batch 90/100 | Loss 0.188533
InnerLR 0.890141
FineTuningLR 0.466813
100 Accuracy = 82.20% +- 2.04%
Epoch 18: 82.20
Epoch 19 | Batch 0/100 | Loss 0.330281
InnerLR 0.891126
FineTuningLR 0.468247
Epoch 19 | Batch 10/100 | Loss 0.194746
InnerLR 0.891893
FineTuningLR 0.469413
Epoch 19 | Batch 20/100 | Loss 0.200347
InnerLR 0.893473
FineTuningLR 0.471372
Epoch 19 | Batch 30/100 | Loss 0.209106
InnerLR 0.894717
FineTuningLR 0.472849
Epoch 19 | Batch 40/100 | Loss 0.212696
InnerLR 0.896454
FineTuningLR 0.475182
Epoch 19 | Batch 50/100 | Loss 0.215151
InnerLR 0.897604
FineTuningLR 0.476586
Epoch 19 | Batch 60/100 | Loss 0.207592
InnerLR 0.899492
FineTuningLR 0.478922
Epoch 19 | Batch 70/100 | Loss 0.207711
InnerLR 0.900636
FineTuningLR 0.480522
Epoch 19 | Batch 80/100 | Loss 0.211115
InnerLR 0.902198
FineTuningLR 0.483048
Epoch 19 | Batch 90/100 | Loss 0.204158
InnerLR 0.902919
FineTuningLR 0.484413
100 Accuracy = 83.05% +- 1.84%
Epoch 19: 83.05
Epoch 20 | Batch 0/100 | Loss 0.271257
InnerLR 0.904286
FineTuningLR 0.486588
Epoch 20 | Batch 10/100 | Loss 0.240720
InnerLR 0.905328
FineTuningLR 0.487940
Epoch 20 | Batch 20/100 | Loss 0.243547
InnerLR 0.906817
FineTuningLR 0.489391
Epoch 20 | Batch 30/100 | Loss 0.222046
InnerLR 0.907850
FineTuningLR 0.490275
Epoch 20 | Batch 40/100 | Loss 0.217855
InnerLR 0.909452
FineTuningLR 0.491170
Epoch 20 | Batch 50/100 | Loss 0.211621
InnerLR 0.910589
FineTuningLR 0.491851
Epoch 20 | Batch 60/100 | Loss 0.205294
InnerLR 0.912397
FineTuningLR 0.493303
Epoch 20 | Batch 70/100 | Loss 0.204264
InnerLR 0.913818
FineTuningLR 0.494420
Epoch 20 | Batch 80/100 | Loss 0.197741
InnerLR 0.915920
FineTuningLR 0.496289
Epoch 20 | Batch 90/100 | Loss 0.196898
InnerLR 0.917285
FineTuningLR 0.496916
100 Accuracy = 84.56% +- 1.85%
Epoch 20: 84.56
Epoch 21 | Batch 0/100 | Loss 0.075699
InnerLR 0.919143
FineTuningLR 0.497738
Epoch 21 | Batch 10/100 | Loss 0.267897
InnerLR 0.920366
FineTuningLR 0.498261
Epoch 21 | Batch 20/100 | Loss 0.254869
InnerLR 0.922162
FineTuningLR 0.499120
Epoch 21 | Batch 30/100 | Loss 0.257716
InnerLR 0.923411
FineTuningLR 0.499919
Epoch 21 | Batch 40/100 | Loss 0.237629
InnerLR 0.925047
FineTuningLR 0.500740
Epoch 21 | Batch 50/100 | Loss 0.241709
InnerLR 0.926112
FineTuningLR 0.501577
Epoch 21 | Batch 60/100 | Loss 0.237888
InnerLR 0.928120
FineTuningLR 0.502962
Epoch 21 | Batch 70/100 | Loss 0.236206
InnerLR 0.929268
FineTuningLR 0.503623
Epoch 21 | Batch 80/100 | Loss 0.230485
InnerLR 0.930437
FineTuningLR 0.504750
Epoch 21 | Batch 90/100 | Loss 0.232423
InnerLR 0.931358
FineTuningLR 0.505715
100 Accuracy = 83.72% +- 2.00%
Epoch 21: 83.72
Epoch 22 | Batch 0/100 | Loss 0.101750
InnerLR 0.932723
FineTuningLR 0.506981
Epoch 22 | Batch 10/100 | Loss 0.256748
InnerLR 0.933640
FineTuningLR 0.508113
Epoch 22 | Batch 20/100 | Loss 0.240127
InnerLR 0.935360
FineTuningLR 0.509898
Epoch 22 | Batch 30/100 | Loss 0.219810
InnerLR 0.936613
FineTuningLR 0.510755
Epoch 22 | Batch 40/100 | Loss 0.217634
InnerLR 0.938372
FineTuningLR 0.512435
Epoch 22 | Batch 50/100 | Loss 0.210237
InnerLR 0.939586
FineTuningLR 0.513779
Epoch 22 | Batch 60/100 | Loss 0.202186
InnerLR 0.941208
FineTuningLR 0.515488
Epoch 22 | Batch 70/100 | Loss 0.203424
InnerLR 0.942154
FineTuningLR 0.516922
Epoch 22 | Batch 80/100 | Loss 0.204503
InnerLR 0.943648
FineTuningLR 0.519189
Epoch 22 | Batch 90/100 | Loss 0.198432
InnerLR 0.944732
FineTuningLR 0.520409
100 Accuracy = 84.03% +- 1.80%
Epoch 22: 84.03
Epoch 23 | Batch 0/100 | Loss 0.222561
InnerLR 0.946425
FineTuningLR 0.522267
Epoch 23 | Batch 10/100 | Loss 0.171847
InnerLR 0.947648
FineTuningLR 0.523440
Epoch 23 | Batch 20/100 | Loss 0.160480
InnerLR 0.949415
FineTuningLR 0.525214
Epoch 23 | Batch 30/100 | Loss 0.163209
InnerLR 0.950599
FineTuningLR 0.526543
Epoch 23 | Batch 40/100 | Loss 0.169195
InnerLR 0.952231
FineTuningLR 0.528404
Epoch 23 | Batch 50/100 | Loss 0.175549
InnerLR 0.953026
FineTuningLR 0.529846
Epoch 23 | Batch 60/100 | Loss 0.174867
InnerLR 0.954237
FineTuningLR 0.531889
Epoch 23 | Batch 70/100 | Loss 0.178444
InnerLR 0.955103
FineTuningLR 0.533305
Epoch 23 | Batch 80/100 | Loss 0.177043
InnerLR 0.956411
FineTuningLR 0.534755
Epoch 23 | Batch 90/100 | Loss 0.177945
InnerLR 0.957299
FineTuningLR 0.535570
100 Accuracy = 84.84% +- 1.76%
Epoch 23: 84.84
Epoch 24 | Batch 0/100 | Loss 0.084881
InnerLR 0.958978
FineTuningLR 0.536953
Epoch 24 | Batch 10/100 | Loss 0.216352
InnerLR 0.959954
FineTuningLR 0.537852
Epoch 24 | Batch 20/100 | Loss 0.202956
InnerLR 0.961356
FineTuningLR 0.539588
Epoch 24 | Batch 30/100 | Loss 0.189616
InnerLR 0.962648
FineTuningLR 0.540698
Epoch 24 | Batch 40/100 | Loss 0.180630
InnerLR 0.964465
FineTuningLR 0.542456
Epoch 24 | Batch 50/100 | Loss 0.179665
InnerLR 0.965638
FineTuningLR 0.543860
Epoch 24 | Batch 60/100 | Loss 0.184978
InnerLR 0.967342
FineTuningLR 0.545568
Epoch 24 | Batch 70/100 | Loss 0.182206
InnerLR 0.968456
FineTuningLR 0.546580
Epoch 24 | Batch 80/100 | Loss 0.177179
InnerLR 0.970176
FineTuningLR 0.548237
Epoch 24 | Batch 90/100 | Loss 0.177428
InnerLR 0.971328
FineTuningLR 0.549564
100 Accuracy = 83.71% +- 1.71%
Epoch 24: 83.71
Epoch 25 | Batch 0/100 | Loss 0.063664
InnerLR 0.973304
FineTuningLR 0.550776
Epoch 25 | Batch 10/100 | Loss 0.182401
InnerLR 0.974522
FineTuningLR 0.551346
Epoch 25 | Batch 20/100 | Loss 0.157206
InnerLR 0.976465
FineTuningLR 0.552155
Epoch 25 | Batch 30/100 | Loss 0.164427
InnerLR 0.977649
FineTuningLR 0.552751
Epoch 25 | Batch 40/100 | Loss 0.173382
InnerLR 0.979407
FineTuningLR 0.553490
Epoch 25 | Batch 50/100 | Loss 0.172616
InnerLR 0.980686
FineTuningLR 0.554042
Epoch 25 | Batch 60/100 | Loss 0.185230
InnerLR 0.982168
FineTuningLR 0.555156
Epoch 25 | Batch 70/100 | Loss 0.180023
InnerLR 0.983225
FineTuningLR 0.555924
Epoch 25 | Batch 80/100 | Loss 0.178683
InnerLR 0.984871
FineTuningLR 0.557387
Epoch 25 | Batch 90/100 | Loss 0.183274
InnerLR 0.985889
FineTuningLR 0.558484
100 Accuracy = 84.49% +- 1.85%
Epoch 25: 84.49
Epoch 26 | Batch 0/100 | Loss 0.199973
InnerLR 0.987621
FineTuningLR 0.560078
Epoch 26 | Batch 10/100 | Loss 0.173706
InnerLR 0.988854
FineTuningLR 0.561072
Epoch 26 | Batch 20/100 | Loss 0.179856
InnerLR 0.990469
FineTuningLR 0.562596
Epoch 26 | Batch 30/100 | Loss 0.182085
InnerLR 0.991488
FineTuningLR 0.563823
Epoch 26 | Batch 40/100 | Loss 0.176341
InnerLR 0.993203
FineTuningLR 0.565003
Epoch 26 | Batch 50/100 | Loss 0.174564
InnerLR 0.994248
FineTuningLR 0.565837
Epoch 26 | Batch 60/100 | Loss 0.172775
InnerLR 0.995955
FineTuningLR 0.566695
Epoch 26 | Batch 70/100 | Loss 0.179548
InnerLR 0.997160
FineTuningLR 0.567301
Epoch 26 | Batch 80/100 | Loss 0.179177
InnerLR 0.998913
FineTuningLR 0.568457
Epoch 26 | Batch 90/100 | Loss 0.176969
InnerLR 0.999963
FineTuningLR 0.569136
100 Accuracy = 83.47% +- 1.76%
Epoch 26: 83.47
Epoch 27 | Batch 0/100 | Loss 0.079718
InnerLR 1.001450
FineTuningLR 0.570539
Epoch 27 | Batch 10/100 | Loss 0.150194
InnerLR 1.002459
FineTuningLR 0.571709
Epoch 27 | Batch 20/100 | Loss 0.175162
InnerLR 1.004033
FineTuningLR 0.573105
Epoch 27 | Batch 30/100 | Loss 0.171547
InnerLR 1.005148
FineTuningLR 0.573787
Epoch 27 | Batch 40/100 | Loss 0.167299
InnerLR 1.006778
FineTuningLR 0.574652
Epoch 27 | Batch 50/100 | Loss 0.167510
InnerLR 1.007920
FineTuningLR 0.575486
Epoch 27 | Batch 60/100 | Loss 0.167456
InnerLR 1.009869
FineTuningLR 0.576389
Epoch 27 | Batch 70/100 | Loss 0.168122
InnerLR 1.010853
FineTuningLR 0.576956
Epoch 27 | Batch 80/100 | Loss 0.172035
InnerLR 1.012195
FineTuningLR 0.577695
Epoch 27 | Batch 90/100 | Loss 0.171790
InnerLR 1.013146
FineTuningLR 0.578395
100 Accuracy = 83.11% +- 1.86%
Epoch 27: 83.11
Epoch 28 | Batch 0/100 | Loss 0.108333
InnerLR 1.014095
FineTuningLR 0.579440
Epoch 28 | Batch 10/100 | Loss 0.196786
InnerLR 1.014850
FineTuningLR 0.580113
Epoch 28 | Batch 20/100 | Loss 0.228101
InnerLR 1.016160
FineTuningLR 0.581110
Epoch 28 | Batch 30/100 | Loss 0.201098
InnerLR 1.016971
FineTuningLR 0.582035
Epoch 28 | Batch 40/100 | Loss 0.206661
InnerLR 1.018006
FineTuningLR 0.583717
Epoch 28 | Batch 50/100 | Loss 0.189008
InnerLR 1.018502
FineTuningLR 0.584871
Epoch 28 | Batch 60/100 | Loss 0.181680
InnerLR 1.019623
FineTuningLR 0.586393
Epoch 28 | Batch 70/100 | Loss 0.184624
InnerLR 1.020662
FineTuningLR 0.587345
Epoch 28 | Batch 80/100 | Loss 0.176001
InnerLR 1.022746
FineTuningLR 0.588325
Epoch 28 | Batch 90/100 | Loss 0.185858
InnerLR 1.024251
FineTuningLR 0.588754
100 Accuracy = 84.29% +- 1.89%
Epoch 28: 84.29
Epoch 29 | Batch 0/100 | Loss 0.054708
InnerLR 1.026617
FineTuningLR 0.589395
Epoch 29 | Batch 10/100 | Loss 0.180649
InnerLR 1.028326
FineTuningLR 0.589943
Epoch 29 | Batch 20/100 | Loss 0.198681
InnerLR 1.030855
FineTuningLR 0.590791
Epoch 29 | Batch 30/100 | Loss 0.207713
InnerLR 1.032477
FineTuningLR 0.591140
Epoch 29 | Batch 40/100 | Loss 0.191898
InnerLR 1.034754
FineTuningLR 0.591466
Epoch 29 | Batch 50/100 | Loss 0.179543
InnerLR 1.036183
FineTuningLR 0.592107
Epoch 29 | Batch 60/100 | Loss 0.177325
InnerLR 1.038041
FineTuningLR 0.592931
Epoch 29 | Batch 70/100 | Loss 0.173769
InnerLR 1.039123
FineTuningLR 0.593696
Epoch 29 | Batch 80/100 | Loss 0.177059
InnerLR 1.040808
FineTuningLR 0.594286
Epoch 29 | Batch 90/100 | Loss 0.174273
InnerLR 1.042158
FineTuningLR 0.594522
100 Accuracy = 84.03% +- 1.63%
Epoch 29: 84.03
Epoch 30 | Batch 0/100 | Loss 0.240790
InnerLR 1.044170
FineTuningLR 0.595097
Epoch 30 | Batch 10/100 | Loss 0.209967
InnerLR 1.045457
FineTuningLR 0.595466
Epoch 30 | Batch 20/100 | Loss 0.212371
InnerLR 1.047033
FineTuningLR 0.596038
Epoch 30 | Batch 30/100 | Loss 0.188953
InnerLR 1.047989
FineTuningLR 0.596439
Epoch 30 | Batch 40/100 | Loss 0.192650
InnerLR 1.049310
FineTuningLR 0.596721
Epoch 30 | Batch 50/100 | Loss 0.194045
InnerLR 1.050248
FineTuningLR 0.596906
Epoch 30 | Batch 60/100 | Loss 0.188689
InnerLR 1.051829
FineTuningLR 0.597441
Epoch 30 | Batch 70/100 | Loss 0.187539
InnerLR 1.052928
FineTuningLR 0.598096
Epoch 30 | Batch 80/100 | Loss 0.189474
InnerLR 1.054639
FineTuningLR 0.598907
Epoch 30 | Batch 90/100 | Loss 0.182656
InnerLR 1.055953
FineTuningLR 0.599311
100 Accuracy = 83.79% +- 1.68%
Epoch 30: 83.79
Epoch 31 | Batch 0/100 | Loss 0.054810
InnerLR 1.057947
FineTuningLR 0.599694
Epoch 31 | Batch 10/100 | Loss 0.127629
InnerLR 1.058948
FineTuningLR 0.599858
Epoch 31 | Batch 20/100 | Loss 0.149063
InnerLR 1.060040
FineTuningLR 0.599970
Epoch 31 | Batch 30/100 | Loss 0.157721
InnerLR 1.060746
FineTuningLR 0.600026
Epoch 31 | Batch 40/100 | Loss 0.145488
InnerLR 1.061879
FineTuningLR 0.600070
Epoch 31 | Batch 50/100 | Loss 0.148845
InnerLR 1.062826
FineTuningLR 0.600464
Epoch 31 | Batch 60/100 | Loss 0.148538
InnerLR 1.064228
FineTuningLR 0.601525
Epoch 31 | Batch 70/100 | Loss 0.155544
InnerLR 1.065255
FineTuningLR 0.602375
Epoch 31 | Batch 80/100 | Loss 0.160393
InnerLR 1.067267
FineTuningLR 0.603208
Epoch 31 | Batch 90/100 | Loss 0.157326
InnerLR 1.068540
FineTuningLR 0.603879
100 Accuracy = 82.89% +- 1.99%
Epoch 31: 82.89
Epoch 32 | Batch 0/100 | Loss 0.225303
InnerLR 1.070476
FineTuningLR 0.604678
Epoch 32 | Batch 10/100 | Loss 0.137260
InnerLR 1.071612
FineTuningLR 0.605197
Epoch 32 | Batch 20/100 | Loss 0.165006
InnerLR 1.073512
FineTuningLR 0.605708
Epoch 32 | Batch 30/100 | Loss 0.167702
InnerLR 1.074803
FineTuningLR 0.605689
Epoch 32 | Batch 40/100 | Loss 0.169731
InnerLR 1.076874
FineTuningLR 0.605828
Epoch 32 | Batch 50/100 | Loss 0.169721
InnerLR 1.078279
FineTuningLR 0.605633
Epoch 32 | Batch 60/100 | Loss 0.170518
InnerLR 1.080268
FineTuningLR 0.605881
Epoch 32 | Batch 70/100 | Loss 0.168913
InnerLR 1.081383
FineTuningLR 0.606416
Epoch 32 | Batch 80/100 | Loss 0.160813
InnerLR 1.083159
FineTuningLR 0.607320
Epoch 32 | Batch 90/100 | Loss 0.164617
InnerLR 1.084441
FineTuningLR 0.608123
100 Accuracy = 85.57% +- 1.76%
Epoch 32: 85.57
best model! save...
Epoch 33 | Batch 0/100 | Loss 0.322308
InnerLR 1.085553
FineTuningLR 0.608964
Epoch 33 | Batch 10/100 | Loss 0.149685
InnerLR 1.085991
FineTuningLR 0.609559
Epoch 33 | Batch 20/100 | Loss 0.160201
InnerLR 1.086634
FineTuningLR 0.610231
Epoch 33 | Batch 30/100 | Loss 0.162227
InnerLR 1.086668
FineTuningLR 0.610482
Epoch 33 | Batch 40/100 | Loss 0.164632
InnerLR 1.086863
FineTuningLR 0.610959
Epoch 33 | Batch 50/100 | Loss 0.165667
InnerLR 1.086938
FineTuningLR 0.611486
Epoch 33 | Batch 60/100 | Loss 0.157615
InnerLR 1.087082
FineTuningLR 0.612370
Epoch 33 | Batch 70/100 | Loss 0.162517
InnerLR 1.087381
FineTuningLR 0.613071
Epoch 33 | Batch 80/100 | Loss 0.165472
InnerLR 1.088164
FineTuningLR 0.614078
Epoch 33 | Batch 90/100 | Loss 0.164196
InnerLR 1.088745
FineTuningLR 0.614505
100 Accuracy = 83.95% +- 1.73%
Epoch 33: 83.95
Epoch 34 | Batch 0/100 | Loss 0.269280
InnerLR 1.089534
FineTuningLR 0.615365
Epoch 34 | Batch 10/100 | Loss 0.193354
InnerLR 1.090351
FineTuningLR 0.615990
Epoch 34 | Batch 20/100 | Loss 0.210426
InnerLR 1.091800
FineTuningLR 0.616951
Epoch 34 | Batch 30/100 | Loss 0.210315
InnerLR 1.092792
FineTuningLR 0.617229
Epoch 34 | Batch 40/100 | Loss 0.188145
InnerLR 1.094322
FineTuningLR 0.617736
Epoch 34 | Batch 50/100 | Loss 0.173455
InnerLR 1.095175
FineTuningLR 0.618019
Epoch 34 | Batch 60/100 | Loss 0.173387
InnerLR 1.096603
FineTuningLR 0.618086
Epoch 34 | Batch 70/100 | Loss 0.165730
InnerLR 1.097471
FineTuningLR 0.618099
Epoch 34 | Batch 80/100 | Loss 0.158870
InnerLR 1.098678
FineTuningLR 0.618594
Epoch 34 | Batch 90/100 | Loss 0.161644
InnerLR 1.099538
FineTuningLR 0.618941
100 Accuracy = 84.55% +- 1.97%
Epoch 34: 84.55
Epoch 35 | Batch 0/100 | Loss 0.116129
InnerLR 1.100532
FineTuningLR 0.619384
Epoch 35 | Batch 10/100 | Loss 0.146630
InnerLR 1.101292
FineTuningLR 0.619945
Epoch 35 | Batch 20/100 | Loss 0.145939
InnerLR 1.102672
FineTuningLR 0.621133
Epoch 35 | Batch 30/100 | Loss 0.157697
InnerLR 1.103399
FineTuningLR 0.622027
Epoch 35 | Batch 40/100 | Loss 0.162037
InnerLR 1.104423
FineTuningLR 0.623358
Epoch 35 | Batch 50/100 | Loss 0.156627
InnerLR 1.104813
FineTuningLR 0.624261
Epoch 35 | Batch 60/100 | Loss 0.154038
InnerLR 1.105295
FineTuningLR 0.625802
Epoch 35 | Batch 70/100 | Loss 0.156120
InnerLR 1.105792
FineTuningLR 0.627186
Epoch 35 | Batch 80/100 | Loss 0.157360
InnerLR 1.106780
FineTuningLR 0.629090
Epoch 35 | Batch 90/100 | Loss 0.156667
InnerLR 1.107603
FineTuningLR 0.630018
100 Accuracy = 83.47% +- 1.80%
Epoch 35: 83.47
Epoch 36 | Batch 0/100 | Loss 0.237857
InnerLR 1.108627
FineTuningLR 0.630718
Epoch 36 | Batch 10/100 | Loss 0.186172
InnerLR 1.108982
FineTuningLR 0.631250
Epoch 36 | Batch 20/100 | Loss 0.201217
InnerLR 1.109900
FineTuningLR 0.631691
Epoch 36 | Batch 30/100 | Loss 0.186529
InnerLR 1.110598
FineTuningLR 0.631551
Epoch 36 | Batch 40/100 | Loss 0.183215
InnerLR 1.111537
FineTuningLR 0.631275
Epoch 36 | Batch 50/100 | Loss 0.187219
InnerLR 1.111943
FineTuningLR 0.631168
Epoch 36 | Batch 60/100 | Loss 0.179581
InnerLR 1.112562
FineTuningLR 0.631530
Epoch 36 | Batch 70/100 | Loss 0.181016
InnerLR 1.112953
FineTuningLR 0.632175
Epoch 36 | Batch 80/100 | Loss 0.175937
InnerLR 1.113718
FineTuningLR 0.633709
Epoch 36 | Batch 90/100 | Loss 0.172600
InnerLR 1.114479
FineTuningLR 0.634754
100 Accuracy = 84.19% +- 1.82%
Epoch 36: 84.19
Epoch 37 | Batch 0/100 | Loss 0.063232
InnerLR 1.115302
FineTuningLR 0.635788
Epoch 37 | Batch 10/100 | Loss 0.181003
InnerLR 1.115714
FineTuningLR 0.635812
Epoch 37 | Batch 20/100 | Loss 0.188272
InnerLR 1.116314
FineTuningLR 0.635904
Epoch 37 | Batch 30/100 | Loss 0.176464
InnerLR 1.116935
FineTuningLR 0.635894
Epoch 37 | Batch 40/100 | Loss 0.173922
InnerLR 1.118140
FineTuningLR 0.636240
Epoch 37 | Batch 50/100 | Loss 0.174499
InnerLR 1.118954
FineTuningLR 0.636795
Epoch 37 | Batch 60/100 | Loss 0.176988
InnerLR 1.120593
FineTuningLR 0.637720
Epoch 37 | Batch 70/100 | Loss 0.173931
InnerLR 1.121562
FineTuningLR 0.638228
Epoch 37 | Batch 80/100 | Loss 0.172125
InnerLR 1.122815
FineTuningLR 0.638603
Epoch 37 | Batch 90/100 | Loss 0.170272
InnerLR 1.123527
FineTuningLR 0.638648
100 Accuracy = 84.52% +- 1.74%
Epoch 37: 84.52
Epoch 38 | Batch 0/100 | Loss 0.542370
InnerLR 1.124324
FineTuningLR 0.639298
Epoch 38 | Batch 10/100 | Loss 0.177274
InnerLR 1.125116
FineTuningLR 0.639515
Epoch 38 | Batch 20/100 | Loss 0.169117
InnerLR 1.126109
FineTuningLR 0.639946
Epoch 38 | Batch 30/100 | Loss 0.155349
InnerLR 1.126869
FineTuningLR 0.640421
Epoch 38 | Batch 40/100 | Loss 0.158258
InnerLR 1.128160
FineTuningLR 0.641311
Epoch 38 | Batch 50/100 | Loss 0.155325
InnerLR 1.128956
FineTuningLR 0.642199
Epoch 38 | Batch 60/100 | Loss 0.147754
InnerLR 1.130073
FineTuningLR 0.643350
Epoch 38 | Batch 70/100 | Loss 0.156829
InnerLR 1.130756
FineTuningLR 0.643713
Epoch 38 | Batch 80/100 | Loss 0.167343
InnerLR 1.131212
FineTuningLR 0.643716
Epoch 38 | Batch 90/100 | Loss 0.172469
InnerLR 1.131106
FineTuningLR 0.643872
100 Accuracy = 83.91% +- 1.74%
Epoch 38: 83.91
Epoch 39 | Batch 0/100 | Loss 0.213554
InnerLR 1.131400
FineTuningLR 0.643781
Epoch 39 | Batch 10/100 | Loss 0.143169
InnerLR 1.131896
FineTuningLR 0.643640
Epoch 39 | Batch 20/100 | Loss 0.137811
InnerLR 1.132873
FineTuningLR 0.643418
Epoch 39 | Batch 30/100 | Loss 0.155516
InnerLR 1.133745
FineTuningLR 0.643543
Epoch 39 | Batch 40/100 | Loss 0.153747
InnerLR 1.134486
FineTuningLR 0.643421
Epoch 39 | Batch 50/100 | Loss 0.157559
InnerLR 1.134800
FineTuningLR 0.643678
Epoch 39 | Batch 60/100 | Loss 0.157259
InnerLR 1.135386
FineTuningLR 0.644101
Epoch 39 | Batch 70/100 | Loss 0.162417
InnerLR 1.135528
FineTuningLR 0.644598
Epoch 39 | Batch 80/100 | Loss 0.162252
InnerLR 1.135881
FineTuningLR 0.645232
Epoch 39 | Batch 90/100 | Loss 0.161785
InnerLR 1.136255
FineTuningLR 0.645625
100 Accuracy = 82.61% +- 2.05%
Epoch 39: 82.61
Epoch 40 | Batch 0/100 | Loss 0.377059
InnerLR 1.137165
FineTuningLR 0.646655
Epoch 40 | Batch 10/100 | Loss 0.126787
InnerLR 1.137897
FineTuningLR 0.647467
Epoch 40 | Batch 20/100 | Loss 0.160846
InnerLR 1.139166
FineTuningLR 0.648983
Epoch 40 | Batch 30/100 | Loss 0.167698
InnerLR 1.140043
FineTuningLR 0.649917
Epoch 40 | Batch 40/100 | Loss 0.157781
InnerLR 1.140982
FineTuningLR 0.651336
Epoch 40 | Batch 50/100 | Loss 0.162249
InnerLR 1.141806
FineTuningLR 0.652194
Epoch 40 | Batch 60/100 | Loss 0.165243
InnerLR 1.142962
FineTuningLR 0.653799
Epoch 40 | Batch 70/100 | Loss 0.166600
InnerLR 1.143801
FineTuningLR 0.654426
Epoch 40 | Batch 80/100 | Loss 0.168149
InnerLR 1.145269
FineTuningLR 0.655013
Epoch 40 | Batch 90/100 | Loss 0.164687
InnerLR 1.145883
FineTuningLR 0.655398
100 Accuracy = 82.99% +- 1.91%
Epoch 40: 82.99
Epoch 41 | Batch 0/100 | Loss 0.129394
InnerLR 1.146858
FineTuningLR 0.656222
Epoch 41 | Batch 10/100 | Loss 0.091982
InnerLR 1.147494
FineTuningLR 0.656600
Epoch 41 | Batch 20/100 | Loss 0.133564
InnerLR 1.148480
FineTuningLR 0.656955
Epoch 41 | Batch 30/100 | Loss 0.154074
InnerLR 1.149368
FineTuningLR 0.656989
Epoch 41 | Batch 40/100 | Loss 0.158040
InnerLR 1.151020
FineTuningLR 0.657330
Epoch 41 | Batch 50/100 | Loss 0.154560
InnerLR 1.151826
FineTuningLR 0.657421
Epoch 41 | Batch 60/100 | Loss 0.155516
InnerLR 1.153410
FineTuningLR 0.657504
Epoch 41 | Batch 70/100 | Loss 0.148202
InnerLR 1.154336
FineTuningLR 0.657966
Epoch 41 | Batch 80/100 | Loss 0.151032
InnerLR 1.155839
FineTuningLR 0.659043
Epoch 41 | Batch 90/100 | Loss 0.153668
InnerLR 1.156957
FineTuningLR 0.659977
100 Accuracy = 84.68% +- 1.75%
Epoch 41: 84.68
Epoch 42 | Batch 0/100 | Loss 0.301225
InnerLR 1.158607
FineTuningLR 0.661222
Epoch 42 | Batch 10/100 | Loss 0.165380
InnerLR 1.159224
FineTuningLR 0.661554
Epoch 42 | Batch 20/100 | Loss 0.156298
InnerLR 1.159771
FineTuningLR 0.662500
Epoch 42 | Batch 30/100 | Loss 0.150131
InnerLR 1.160242
FineTuningLR 0.662665
Epoch 42 | Batch 40/100 | Loss 0.158603
InnerLR 1.161334
FineTuningLR 0.662879
Epoch 42 | Batch 50/100 | Loss 0.169706
InnerLR 1.162573
FineTuningLR 0.662841
Epoch 42 | Batch 60/100 | Loss 0.169659
InnerLR 1.163864
FineTuningLR 0.662919
Epoch 42 | Batch 70/100 | Loss 0.162358
InnerLR 1.164902
FineTuningLR 0.662910
Epoch 42 | Batch 80/100 | Loss 0.164602
InnerLR 1.166420
FineTuningLR 0.662746
Epoch 42 | Batch 90/100 | Loss 0.160459
InnerLR 1.167311
FineTuningLR 0.662570
100 Accuracy = 83.52% +- 1.94%
Epoch 42: 83.52
Epoch 43 | Batch 0/100 | Loss 0.179443
InnerLR 1.168632
FineTuningLR 0.662374
Epoch 43 | Batch 10/100 | Loss 0.164918
InnerLR 1.169374
FineTuningLR 0.662291
Epoch 43 | Batch 20/100 | Loss 0.203205
InnerLR 1.170655
FineTuningLR 0.661581
Epoch 43 | Batch 30/100 | Loss 0.199649
InnerLR 1.171533
FineTuningLR 0.660776
Epoch 43 | Batch 40/100 | Loss 0.195966
InnerLR 1.172923
FineTuningLR 0.659692
Epoch 43 | Batch 50/100 | Loss 0.187449
InnerLR 1.173806
FineTuningLR 0.658821
Epoch 43 | Batch 60/100 | Loss 0.183914
InnerLR 1.174885
FineTuningLR 0.657733
Epoch 43 | Batch 70/100 | Loss 0.181522
InnerLR 1.175580
FineTuningLR 0.657269
Epoch 43 | Batch 80/100 | Loss 0.178802
InnerLR 1.176106
FineTuningLR 0.657059
Epoch 43 | Batch 90/100 | Loss 0.179484
InnerLR 1.176254
FineTuningLR 0.657073
100 Accuracy = 85.35% +- 1.69%
Epoch 43: 85.35
Epoch 44 | Batch 0/100 | Loss 0.218076
InnerLR 1.176477
FineTuningLR 0.657011
Epoch 44 | Batch 10/100 | Loss 0.187421
InnerLR 1.176646
FineTuningLR 0.657139
Epoch 44 | Batch 20/100 | Loss 0.150314
InnerLR 1.176373
FineTuningLR 0.657608
Epoch 44 | Batch 30/100 | Loss 0.142240
InnerLR 1.176164
FineTuningLR 0.658045
Epoch 44 | Batch 40/100 | Loss 0.154738
InnerLR 1.175975
FineTuningLR 0.658107
Epoch 44 | Batch 50/100 | Loss 0.156059
InnerLR 1.175837
FineTuningLR 0.658103
Epoch 44 | Batch 60/100 | Loss 0.160400
InnerLR 1.176063
FineTuningLR 0.657949
Epoch 44 | Batch 70/100 | Loss 0.163632
InnerLR 1.176668
FineTuningLR 0.658026
Epoch 44 | Batch 80/100 | Loss 0.170563
InnerLR 1.177984
FineTuningLR 0.658617
Epoch 44 | Batch 90/100 | Loss 0.169372
InnerLR 1.178635
FineTuningLR 0.659511
100 Accuracy = 84.72% +- 1.95%
Epoch 44: 84.72
Epoch 45 | Batch 0/100 | Loss 0.108693
InnerLR 1.179831
FineTuningLR 0.661108
Epoch 45 | Batch 10/100 | Loss 0.168987
InnerLR 1.180766
FineTuningLR 0.662357
Epoch 45 | Batch 20/100 | Loss 0.167447
InnerLR 1.182291
FineTuningLR 0.664020
Epoch 45 | Batch 30/100 | Loss 0.156236
InnerLR 1.183363
FineTuningLR 0.664835
Epoch 45 | Batch 40/100 | Loss 0.160850
InnerLR 1.184754
FineTuningLR 0.666224
Epoch 45 | Batch 50/100 | Loss 0.162007
InnerLR 1.185736
FineTuningLR 0.666856
Epoch 45 | Batch 60/100 | Loss 0.168197
InnerLR 1.186838
FineTuningLR 0.667425
Epoch 45 | Batch 70/100 | Loss 0.170538
InnerLR 1.187777
FineTuningLR 0.667982
Epoch 45 | Batch 80/100 | Loss 0.172085
InnerLR 1.189489
FineTuningLR 0.668599
Epoch 45 | Batch 90/100 | Loss 0.171374
InnerLR 1.190424
FineTuningLR 0.668688
100 Accuracy = 83.24% +- 1.94%
Epoch 45: 83.24
Epoch 46 | Batch 0/100 | Loss 0.088016
InnerLR 1.191922
FineTuningLR 0.669021
Epoch 46 | Batch 10/100 | Loss 0.141262
InnerLR 1.192933
FineTuningLR 0.669447
Epoch 46 | Batch 20/100 | Loss 0.142663
InnerLR 1.194633
FineTuningLR 0.669859
Epoch 46 | Batch 30/100 | Loss 0.136657
InnerLR 1.195840
FineTuningLR 0.670039
Epoch 46 | Batch 40/100 | Loss 0.163633
InnerLR 1.197638
FineTuningLR 0.670744
Epoch 46 | Batch 50/100 | Loss 0.160892
InnerLR 1.198603
FineTuningLR 0.671053
Epoch 46 | Batch 60/100 | Loss 0.163080
InnerLR 1.200271
FineTuningLR 0.671442
Epoch 46 | Batch 70/100 | Loss 0.164515
InnerLR 1.201367
FineTuningLR 0.671793
Epoch 46 | Batch 80/100 | Loss 0.168014
InnerLR 1.202887
FineTuningLR 0.671856
Epoch 46 | Batch 90/100 | Loss 0.168734
InnerLR 1.203992
FineTuningLR 0.671871
100 Accuracy = 85.08% +- 1.67%
Epoch 46: 85.08
Epoch 47 | Batch 0/100 | Loss 0.231906
InnerLR 1.205935
FineTuningLR 0.671853
Epoch 47 | Batch 10/100 | Loss 0.254132
InnerLR 1.206699
FineTuningLR 0.671690
Epoch 47 | Batch 20/100 | Loss 0.214970
InnerLR 1.207481
FineTuningLR 0.671704
Epoch 47 | Batch 30/100 | Loss 0.184626
InnerLR 1.207822
FineTuningLR 0.672127
Epoch 47 | Batch 40/100 | Loss 0.164388
InnerLR 1.208619
FineTuningLR 0.672340
Epoch 47 | Batch 50/100 | Loss 0.164976
InnerLR 1.209263
FineTuningLR 0.672212
Epoch 47 | Batch 60/100 | Loss 0.163464
InnerLR 1.210851
FineTuningLR 0.671824
Epoch 47 | Batch 70/100 | Loss 0.164652
InnerLR 1.211649
FineTuningLR 0.671337
Epoch 47 | Batch 80/100 | Loss 0.167369
InnerLR 1.212125
FineTuningLR 0.670816
Epoch 47 | Batch 90/100 | Loss 0.169684
InnerLR 1.212182
FineTuningLR 0.670776
100 Accuracy = 85.48% +- 1.69%
Epoch 47: 85.48
Epoch 48 | Batch 0/100 | Loss 0.118685
InnerLR 1.212394
FineTuningLR 0.671309
Epoch 48 | Batch 10/100 | Loss 0.157484
InnerLR 1.212737
FineTuningLR 0.671742
Epoch 48 | Batch 20/100 | Loss 0.170793
InnerLR 1.213524
FineTuningLR 0.672071
Epoch 48 | Batch 30/100 | Loss 0.164473
InnerLR 1.214010
FineTuningLR 0.672534
Epoch 48 | Batch 40/100 | Loss 0.158953
InnerLR 1.214574
FineTuningLR 0.672905
Epoch 48 | Batch 50/100 | Loss 0.151625
InnerLR 1.215259
FineTuningLR 0.672939
Epoch 48 | Batch 60/100 | Loss 0.154647
InnerLR 1.216334
FineTuningLR 0.673145
Epoch 48 | Batch 70/100 | Loss 0.152231
InnerLR 1.217181
FineTuningLR 0.673416
Epoch 48 | Batch 80/100 | Loss 0.152547
InnerLR 1.218422
FineTuningLR 0.674055
Epoch 48 | Batch 90/100 | Loss 0.151510
InnerLR 1.219220
FineTuningLR 0.674345
100 Accuracy = 83.44% +- 1.71%
Epoch 48: 83.44
Epoch 49 | Batch 0/100 | Loss 0.184807
InnerLR 1.220563
FineTuningLR 0.674996
Epoch 49 | Batch 10/100 | Loss 0.127649
InnerLR 1.221543
FineTuningLR 0.675510
Epoch 49 | Batch 20/100 | Loss 0.147233
InnerLR 1.222952
FineTuningLR 0.676182
Epoch 49 | Batch 30/100 | Loss 0.136136
InnerLR 1.223733
FineTuningLR 0.676900
Epoch 49 | Batch 40/100 | Loss 0.156009
InnerLR 1.224851
FineTuningLR 0.677146
Epoch 49 | Batch 50/100 | Loss 0.158614
InnerLR 1.225315
FineTuningLR 0.677265
Epoch 49 | Batch 60/100 | Loss 0.155961
InnerLR 1.226013
FineTuningLR 0.677743
Epoch 49 | Batch 70/100 | Loss 0.152644
InnerLR 1.226577
FineTuningLR 0.678246
Epoch 49 | Batch 80/100 | Loss 0.154357
InnerLR 1.227279
FineTuningLR 0.679539
Epoch 49 | Batch 90/100 | Loss 0.155461
InnerLR 1.227568
FineTuningLR 0.680190
100 Accuracy = 84.37% +- 1.83%
Epoch 49: 84.37
Epoch 50 | Batch 0/100 | Loss 0.169238
InnerLR 1.227596
FineTuningLR 0.680463
Epoch 50 | Batch 10/100 | Loss 0.106968
InnerLR 1.227856
FineTuningLR 0.680931
Epoch 50 | Batch 20/100 | Loss 0.165152
InnerLR 1.228392
FineTuningLR 0.681934
Epoch 50 | Batch 30/100 | Loss 0.147828
InnerLR 1.228618
FineTuningLR 0.682579
Epoch 50 | Batch 40/100 | Loss 0.164796
InnerLR 1.229209
FineTuningLR 0.683531
Epoch 50 | Batch 50/100 | Loss 0.156891
InnerLR 1.229886
FineTuningLR 0.684327
Epoch 50 | Batch 60/100 | Loss 0.156538
InnerLR 1.230931
FineTuningLR 0.685272
Epoch 50 | Batch 70/100 | Loss 0.160049
InnerLR 1.231624
FineTuningLR 0.685748
Epoch 50 | Batch 80/100 | Loss 0.162170
InnerLR 1.232273
FineTuningLR 0.686041
Epoch 50 | Batch 90/100 | Loss 0.157382
InnerLR 1.233000
FineTuningLR 0.685953
100 Accuracy = 84.96% +- 1.69%
Epoch 50: 84.96
Epoch 51 | Batch 0/100 | Loss 0.180271
InnerLR 1.234562
FineTuningLR 0.685991
Epoch 51 | Batch 10/100 | Loss 0.146482
InnerLR 1.235348
FineTuningLR 0.685926
Epoch 51 | Batch 20/100 | Loss 0.156449
InnerLR 1.236261
FineTuningLR 0.685667
Epoch 51 | Batch 30/100 | Loss 0.149208
InnerLR 1.236935
FineTuningLR 0.685583
Epoch 51 | Batch 40/100 | Loss 0.153876
InnerLR 1.238107
FineTuningLR 0.685325
Epoch 51 | Batch 50/100 | Loss 0.161799
InnerLR 1.238837
FineTuningLR 0.685070
Epoch 51 | Batch 60/100 | Loss 0.156536
InnerLR 1.240340
FineTuningLR 0.685019
Epoch 51 | Batch 70/100 | Loss 0.157347
InnerLR 1.241285
FineTuningLR 0.684798
Epoch 51 | Batch 80/100 | Loss 0.156575
InnerLR 1.243276
FineTuningLR 0.684519
Epoch 51 | Batch 90/100 | Loss 0.155499
InnerLR 1.244688
FineTuningLR 0.684527
100 Accuracy = 85.19% +- 1.73%
Epoch 51: 85.19
Epoch 52 | Batch 0/100 | Loss 0.133831
InnerLR 1.246467
FineTuningLR 0.684924
Epoch 52 | Batch 10/100 | Loss 0.133573
InnerLR 1.247203
FineTuningLR 0.685645
Epoch 52 | Batch 20/100 | Loss 0.134587
InnerLR 1.248641
FineTuningLR 0.686803
Epoch 52 | Batch 30/100 | Loss 0.140237
InnerLR 1.249458
FineTuningLR 0.687570
Epoch 52 | Batch 40/100 | Loss 0.129152
InnerLR 1.250629
FineTuningLR 0.688706
Epoch 52 | Batch 50/100 | Loss 0.126883
InnerLR 1.251703
FineTuningLR 0.689282
Epoch 52 | Batch 60/100 | Loss 0.155143
InnerLR 1.253263
FineTuningLR 0.690090
Epoch 52 | Batch 70/100 | Loss 0.154919
InnerLR 1.254265
FineTuningLR 0.690680
Epoch 52 | Batch 80/100 | Loss 0.156299
InnerLR 1.255652
FineTuningLR 0.690766
Epoch 52 | Batch 90/100 | Loss 0.161912
InnerLR 1.256935
FineTuningLR 0.690873
100 Accuracy = 82.63% +- 1.89%
Epoch 52: 82.63
Epoch 53 | Batch 0/100 | Loss 0.066126
InnerLR 1.259042
FineTuningLR 0.690838
Epoch 53 | Batch 10/100 | Loss 0.169786
InnerLR 1.260011
FineTuningLR 0.690767
Epoch 53 | Batch 20/100 | Loss 0.157005
InnerLR 1.261330
FineTuningLR 0.690856
Epoch 53 | Batch 30/100 | Loss 0.157141
InnerLR 1.262149
FineTuningLR 0.691113
Epoch 53 | Batch 40/100 | Loss 0.158935
InnerLR 1.263695
FineTuningLR 0.691349
Epoch 53 | Batch 50/100 | Loss 0.157094
InnerLR 1.264471
FineTuningLR 0.691440
Epoch 53 | Batch 60/100 | Loss 0.156876
InnerLR 1.265752
FineTuningLR 0.691944
Epoch 53 | Batch 70/100 | Loss 0.150587
InnerLR 1.266597
FineTuningLR 0.691943
Epoch 53 | Batch 80/100 | Loss 0.166092
InnerLR 1.268074
FineTuningLR 0.691746
Epoch 53 | Batch 90/100 | Loss 0.165346
InnerLR 1.268771
FineTuningLR 0.691504
100 Accuracy = 83.68% +- 1.85%
Epoch 53: 83.68
Epoch 54 | Batch 0/100 | Loss 0.113038
InnerLR 1.269284
FineTuningLR 0.691477
Epoch 54 | Batch 10/100 | Loss 0.168767
InnerLR 1.269084
FineTuningLR 0.691614
Epoch 54 | Batch 20/100 | Loss 0.149114
InnerLR 1.268698
FineTuningLR 0.692041
Epoch 54 | Batch 30/100 | Loss 0.142937
InnerLR 1.268560
FineTuningLR 0.692054
Epoch 54 | Batch 40/100 | Loss 0.144837
InnerLR 1.268607
FineTuningLR 0.692301
Epoch 54 | Batch 50/100 | Loss 0.134703
InnerLR 1.268821
FineTuningLR 0.692401
Epoch 54 | Batch 60/100 | Loss 0.135905
InnerLR 1.269140
FineTuningLR 0.692625
Epoch 54 | Batch 70/100 | Loss 0.134653
InnerLR 1.269603
FineTuningLR 0.692559
Epoch 54 | Batch 80/100 | Loss 0.137661
InnerLR 1.270360
FineTuningLR 0.692583
Epoch 54 | Batch 90/100 | Loss 0.141499
InnerLR 1.270883
FineTuningLR 0.692766
100 Accuracy = 84.09% +- 1.69%
Epoch 54: 84.09
Epoch 55 | Batch 0/100 | Loss 0.112771
InnerLR 1.271562
FineTuningLR 0.693283
Epoch 55 | Batch 10/100 | Loss 0.157668
InnerLR 1.272202
FineTuningLR 0.693772
Epoch 55 | Batch 20/100 | Loss 0.169603
InnerLR 1.272754
FineTuningLR 0.694059
Epoch 55 | Batch 30/100 | Loss 0.168899
InnerLR 1.273105
FineTuningLR 0.694481
Epoch 55 | Batch 40/100 | Loss 0.167160
InnerLR 1.274057
FineTuningLR 0.695305
Epoch 55 | Batch 50/100 | Loss 0.166567
InnerLR 1.275157
FineTuningLR 0.696006
Epoch 55 | Batch 60/100 | Loss 0.158661
InnerLR 1.277049
FineTuningLR 0.697218
Epoch 55 | Batch 70/100 | Loss 0.160739
InnerLR 1.278517
FineTuningLR 0.697766
Epoch 55 | Batch 80/100 | Loss 0.157243
InnerLR 1.280575
FineTuningLR 0.698299
Epoch 55 | Batch 90/100 | Loss 0.152998
InnerLR 1.281784
FineTuningLR 0.698672
100 Accuracy = 83.61% +- 1.91%
Epoch 55: 83.61
Epoch 56 | Batch 0/100 | Loss 0.039291
InnerLR 1.283328
FineTuningLR 0.699538
Epoch 56 | Batch 10/100 | Loss 0.185164
InnerLR 1.284515
FineTuningLR 0.700060
Epoch 56 | Batch 20/100 | Loss 0.158645
InnerLR 1.286178
FineTuningLR 0.700604
Epoch 56 | Batch 30/100 | Loss 0.167192
InnerLR 1.286900
FineTuningLR 0.700944
Epoch 56 | Batch 40/100 | Loss 0.172233
InnerLR 1.287494
FineTuningLR 0.701361
Epoch 56 | Batch 50/100 | Loss 0.185213
InnerLR 1.287789
FineTuningLR 0.701942
Epoch 56 | Batch 60/100 | Loss 0.174929
InnerLR 1.288179
FineTuningLR 0.702758
Epoch 56 | Batch 70/100 | Loss 0.173470
InnerLR 1.288665
FineTuningLR 0.703284
Epoch 56 | Batch 80/100 | Loss 0.166457
InnerLR 1.289154
FineTuningLR 0.703873
Epoch 56 | Batch 90/100 | Loss 0.166222
InnerLR 1.289734
FineTuningLR 0.704237
100 Accuracy = 84.41% +- 1.79%
Epoch 56: 84.41
Epoch 57 | Batch 0/100 | Loss 0.136495
InnerLR 1.290322
FineTuningLR 0.704633
Epoch 57 | Batch 10/100 | Loss 0.137273
InnerLR 1.290621
FineTuningLR 0.705217
Epoch 57 | Batch 20/100 | Loss 0.148344
InnerLR 1.291048
FineTuningLR 0.705832
Epoch 57 | Batch 30/100 | Loss 0.138937
InnerLR 1.291623
FineTuningLR 0.706246
Epoch 57 | Batch 40/100 | Loss 0.146613
InnerLR 1.292264
FineTuningLR 0.707152
Epoch 57 | Batch 50/100 | Loss 0.147810
InnerLR 1.292368
FineTuningLR 0.707772
Epoch 57 | Batch 60/100 | Loss 0.156496
InnerLR 1.292334
FineTuningLR 0.708425
Epoch 57 | Batch 70/100 | Loss 0.150388
InnerLR 1.292454
FineTuningLR 0.708827
Epoch 57 | Batch 80/100 | Loss 0.146854
InnerLR 1.292878
FineTuningLR 0.709063
Epoch 57 | Batch 90/100 | Loss 0.144717
InnerLR 1.293281
FineTuningLR 0.709363
100 Accuracy = 85.21% +- 1.80%
Epoch 57: 85.21
Epoch 58 | Batch 0/100 | Loss 0.198336
InnerLR 1.294184
FineTuningLR 0.709404
Epoch 58 | Batch 10/100 | Loss 0.167076
InnerLR 1.295233
FineTuningLR 0.709455
Epoch 58 | Batch 20/100 | Loss 0.147584
InnerLR 1.296810
FineTuningLR 0.709452
Epoch 58 | Batch 30/100 | Loss 0.137002
InnerLR 1.297713
FineTuningLR 0.709586
Epoch 58 | Batch 40/100 | Loss 0.141198
InnerLR 1.298394
FineTuningLR 0.710361
Epoch 58 | Batch 50/100 | Loss 0.136822
InnerLR 1.298754
FineTuningLR 0.710891
Epoch 58 | Batch 60/100 | Loss 0.135707
InnerLR 1.299605
FineTuningLR 0.711475
Epoch 58 | Batch 70/100 | Loss 0.135249
InnerLR 1.299914
FineTuningLR 0.711891
Epoch 58 | Batch 80/100 | Loss 0.135346
InnerLR 1.300504
FineTuningLR 0.711958
Epoch 58 | Batch 90/100 | Loss 0.139387
InnerLR 1.300961
FineTuningLR 0.712063
100 Accuracy = 84.24% +- 1.94%
Epoch 58: 84.24
Epoch 59 | Batch 0/100 | Loss 0.200084
InnerLR 1.301293
FineTuningLR 0.712400
Epoch 59 | Batch 10/100 | Loss 0.126082
InnerLR 1.301521
FineTuningLR 0.712521
Epoch 59 | Batch 20/100 | Loss 0.147033
InnerLR 1.302206
FineTuningLR 0.712508
Epoch 59 | Batch 30/100 | Loss 0.147425
InnerLR 1.302573
FineTuningLR 0.712735
Epoch 59 | Batch 40/100 | Loss 0.149560
InnerLR 1.302854
FineTuningLR 0.713020
Epoch 59 | Batch 50/100 | Loss 0.140227
InnerLR 1.302777
FineTuningLR 0.712895
Epoch 59 | Batch 60/100 | Loss 0.136422
InnerLR 1.303039
FineTuningLR 0.712786
Epoch 59 | Batch 70/100 | Loss 0.138084
InnerLR 1.303439
FineTuningLR 0.712837
Epoch 59 | Batch 80/100 | Loss 0.135160
InnerLR 1.303851
FineTuningLR 0.713131
Epoch 59 | Batch 90/100 | Loss 0.131831
InnerLR 1.304121
FineTuningLR 0.713641
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 85.29% +- 1.74%
Epoch 59: 85.29
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_5_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/tabula_muris/leo_FCNet/20231212_134319
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 98.77% +- 0.16%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/tabula_muris/leo_FCNet/20231212_134319
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 84.03% +- 0.76%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/tabula_muris/leo_FCNet/20231212_134319
600 Accuracy = 80.81% +- 0.68%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_5_without_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline_pp/results.txt
+-------+-------------------+--------------------+
| split |      acc_mean     |      acc_std       |
+-------+-------------------+--------------------+
| train | 98.76888888888891 | 1.9735085007339424 |
|  val  | 84.02666666666667 | 9.507854063293614  |
|  test | 80.81333333333333 | 8.465133719492497  |
+-------+-------------------+--------------------+
