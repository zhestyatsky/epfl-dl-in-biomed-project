/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 5
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 5
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 5
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 0.5
    finetuning_lr_init: 0.05
    num_adaptation_steps: 5
    kl_coef: 0.01
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 0.1
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 16
    enable_finetuning_loop: true
  n_task: 4
  latent_space_dim: 16
  leo_inner_lr_init: 0.5
  leo_finetuning_lr_init: 0.05
  num_adaptation_steps: 5
  kl_coef: 0.01
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 0.1
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-06
  optimize_backbone: false
  pretrained_backbone_weights_path: pretrained_weights/tabula_muris_baseline_model.tar
  enable_finetuning_loop: true
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_5_latent_space_dim_16_lr_0.001
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.001
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_16_lr_0.001/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Using pretrained backbone from pretrained_weights/tabula_muris_baseline_model.tar.
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=16, bias=False)
    (relation_net): Sequential(
      (0): Linear(in_features=32, out_features=32, bias=False)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=False)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=False)
    )
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=16, out_features=130, bias=False)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 1e-06

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Epoch 0 | Batch 0/100 | Loss 6.305812
InnerLR 0.500000
FineTuningLR 0.050000
Epoch 0 | Batch 10/100 | Loss 5.727098
InnerLR 0.502000
FineTuningLR 0.052000
Epoch 0 | Batch 20/100 | Loss 5.320669
InnerLR 0.505000
FineTuningLR 0.055000
Epoch 0 | Batch 30/100 | Loss 5.158715
InnerLR 0.507000
FineTuningLR 0.057000
Epoch 0 | Batch 40/100 | Loss 5.029577
InnerLR 0.510000
FineTuningLR 0.060000
Epoch 0 | Batch 50/100 | Loss 4.907532
InnerLR 0.512000
FineTuningLR 0.062000
Epoch 0 | Batch 60/100 | Loss 4.756804
InnerLR 0.514748
FineTuningLR 0.065000
Epoch 0 | Batch 70/100 | Loss 4.661916
InnerLR 0.516333
FineTuningLR 0.067000
Epoch 0 | Batch 80/100 | Loss 4.641823
InnerLR 0.518875
FineTuningLR 0.070000
Epoch 0 | Batch 90/100 | Loss 4.464486
InnerLR 0.520649
FineTuningLR 0.072000
100 Accuracy = 60.72% +- 2.34%
Epoch 0: 60.72
best model! save...
Epoch 1 | Batch 0/100 | Loss 2.119514
InnerLR 0.523396
FineTuningLR 0.075000
Epoch 1 | Batch 10/100 | Loss 3.034182
InnerLR 0.525269
FineTuningLR 0.077000
Epoch 1 | Batch 20/100 | Loss 3.122575
InnerLR 0.528124
FineTuningLR 0.080000
Epoch 1 | Batch 30/100 | Loss 3.140084
InnerLR 0.530051
FineTuningLR 0.082000
Epoch 1 | Batch 40/100 | Loss 3.050579
InnerLR 0.532967
FineTuningLR 0.085000
Epoch 1 | Batch 50/100 | Loss 2.981143
InnerLR 0.534925
FineTuningLR 0.087000
Epoch 1 | Batch 60/100 | Loss 2.906015
InnerLR 0.537876
FineTuningLR 0.090000
Epoch 1 | Batch 70/100 | Loss 2.865952
InnerLR 0.539851
FineTuningLR 0.092000
Epoch 1 | Batch 80/100 | Loss 2.791099
InnerLR 0.542822
FineTuningLR 0.095000
Epoch 1 | Batch 90/100 | Loss 2.724013
InnerLR 0.544808
FineTuningLR 0.097000
100 Accuracy = 67.83% +- 2.37%
Epoch 1: 67.83
best model! save...
Epoch 2 | Batch 0/100 | Loss 1.453462
InnerLR 0.547791
FineTuningLR 0.100000
Epoch 2 | Batch 10/100 | Loss 1.941232
InnerLR 0.549782
FineTuningLR 0.102000
Epoch 2 | Batch 20/100 | Loss 1.669443
InnerLR 0.552772
FineTuningLR 0.105000
Epoch 2 | Batch 30/100 | Loss 1.702054
InnerLR 0.554650
FineTuningLR 0.107031
Epoch 2 | Batch 40/100 | Loss 1.596878
InnerLR 0.557362
FineTuningLR 0.110102
Epoch 2 | Batch 50/100 | Loss 1.530760
InnerLR 0.559218
FineTuningLR 0.112135
Epoch 2 | Batch 60/100 | Loss 1.488563
InnerLR 0.562057
FineTuningLR 0.115169
Epoch 2 | Batch 70/100 | Loss 1.441326
InnerLR 0.563977
FineTuningLR 0.117183
Epoch 2 | Batch 80/100 | Loss 1.377209
InnerLR 0.566343
FineTuningLR 0.120196
Epoch 2 | Batch 90/100 | Loss 1.310533
InnerLR 0.568022
FineTuningLR 0.122199
100 Accuracy = 75.75% +- 2.10%
Epoch 2: 75.75
best model! save...
Epoch 3 | Batch 0/100 | Loss 0.639385
InnerLR 0.570562
FineTuningLR 0.125252
Epoch 3 | Batch 10/100 | Loss 0.703180
InnerLR 0.572303
FineTuningLR 0.127291
Epoch 3 | Batch 20/100 | Loss 0.620972
InnerLR 0.574260
FineTuningLR 0.130329
Epoch 3 | Batch 30/100 | Loss 0.564847
InnerLR 0.575280
FineTuningLR 0.132350
Epoch 3 | Batch 40/100 | Loss 0.566149
InnerLR 0.576135
FineTuningLR 0.135451
Epoch 3 | Batch 50/100 | Loss 0.538463
InnerLR 0.576379
FineTuningLR 0.137545
Epoch 3 | Batch 60/100 | Loss 0.529043
InnerLR 0.576405
FineTuningLR 0.140748
Epoch 3 | Batch 70/100 | Loss 0.514494
InnerLR 0.576194
FineTuningLR 0.142870
Epoch 3 | Batch 80/100 | Loss 0.503134
InnerLR 0.576270
FineTuningLR 0.145996
Epoch 3 | Batch 90/100 | Loss 0.491712
InnerLR 0.576439
FineTuningLR 0.148105
100 Accuracy = 81.52% +- 1.80%
Epoch 3: 81.52
best model! save...
Epoch 4 | Batch 0/100 | Loss 0.387182
InnerLR 0.576016
FineTuningLR 0.151272
Epoch 4 | Batch 10/100 | Loss 0.369758
InnerLR 0.575887
FineTuningLR 0.153385
Epoch 4 | Batch 20/100 | Loss 0.376199
InnerLR 0.576205
FineTuningLR 0.156522
Epoch 4 | Batch 30/100 | Loss 0.352268
InnerLR 0.576171
FineTuningLR 0.158675
Epoch 4 | Batch 40/100 | Loss 0.353950
InnerLR 0.575856
FineTuningLR 0.161990
Epoch 4 | Batch 50/100 | Loss 0.344668
InnerLR 0.575893
FineTuningLR 0.164217
Epoch 4 | Batch 60/100 | Loss 0.335345
InnerLR 0.575998
FineTuningLR 0.167645
Epoch 4 | Batch 70/100 | Loss 0.334948
InnerLR 0.576048
FineTuningLR 0.169947
Epoch 4 | Batch 80/100 | Loss 0.328130
InnerLR 0.575517
FineTuningLR 0.173334
Epoch 4 | Batch 90/100 | Loss 0.327702
InnerLR 0.575230
FineTuningLR 0.175537
100 Accuracy = 80.53% +- 1.83%
Epoch 4: 80.53
Epoch 5 | Batch 0/100 | Loss 0.248706
InnerLR 0.574553
FineTuningLR 0.178820
Epoch 5 | Batch 10/100 | Loss 0.273643
InnerLR 0.574398
FineTuningLR 0.180950
Epoch 5 | Batch 20/100 | Loss 0.296255
InnerLR 0.573545
FineTuningLR 0.184100
Epoch 5 | Batch 30/100 | Loss 0.286904
InnerLR 0.573036
FineTuningLR 0.186162
Epoch 5 | Batch 40/100 | Loss 0.302901
InnerLR 0.571707
FineTuningLR 0.189192
Epoch 5 | Batch 50/100 | Loss 0.297263
InnerLR 0.570807
FineTuningLR 0.191221
Epoch 5 | Batch 60/100 | Loss 0.307176
InnerLR 0.569317
FineTuningLR 0.194224
Epoch 5 | Batch 70/100 | Loss 0.304957
InnerLR 0.568403
FineTuningLR 0.196268
Epoch 5 | Batch 80/100 | Loss 0.294020
InnerLR 0.567282
FineTuningLR 0.199361
Epoch 5 | Batch 90/100 | Loss 0.290502
InnerLR 0.566510
FineTuningLR 0.201411
100 Accuracy = 84.88% +- 1.65%
Epoch 5: 84.88
best model! save...
Epoch 6 | Batch 0/100 | Loss 0.303354
InnerLR 0.564911
FineTuningLR 0.204448
Epoch 6 | Batch 10/100 | Loss 0.242907
InnerLR 0.564044
FineTuningLR 0.206490
Epoch 6 | Batch 20/100 | Loss 0.260893
InnerLR 0.562907
FineTuningLR 0.209667
Epoch 6 | Batch 30/100 | Loss 0.271338
InnerLR 0.562200
FineTuningLR 0.211829
Epoch 6 | Batch 40/100 | Loss 0.256590
InnerLR 0.561664
FineTuningLR 0.215065
Epoch 6 | Batch 50/100 | Loss 0.261976
InnerLR 0.561587
FineTuningLR 0.217234
Epoch 6 | Batch 60/100 | Loss 0.266995
InnerLR 0.560971
FineTuningLR 0.220427
Epoch 6 | Batch 70/100 | Loss 0.262004
InnerLR 0.560286
FineTuningLR 0.222541
Epoch 6 | Batch 80/100 | Loss 0.266261
InnerLR 0.559080
FineTuningLR 0.225758
Epoch 6 | Batch 90/100 | Loss 0.266829
InnerLR 0.558059
FineTuningLR 0.227875
100 Accuracy = 84.19% +- 1.90%
Epoch 6: 84.19
Epoch 7 | Batch 0/100 | Loss 0.189645
InnerLR 0.556769
FineTuningLR 0.231007
Epoch 7 | Batch 10/100 | Loss 0.247105
InnerLR 0.556095
FineTuningLR 0.233082
Epoch 7 | Batch 20/100 | Loss 0.258397
InnerLR 0.554572
FineTuningLR 0.236130
Epoch 7 | Batch 30/100 | Loss 0.262035
InnerLR 0.553485
FineTuningLR 0.238200
Epoch 7 | Batch 40/100 | Loss 0.258876
InnerLR 0.552096
FineTuningLR 0.241247
Epoch 7 | Batch 50/100 | Loss 0.261838
InnerLR 0.551211
FineTuningLR 0.243343
Epoch 7 | Batch 60/100 | Loss 0.256566
InnerLR 0.550357
FineTuningLR 0.246521
Epoch 7 | Batch 70/100 | Loss 0.257074
InnerLR 0.549623
FineTuningLR 0.248620
Epoch 7 | Batch 80/100 | Loss 0.256838
InnerLR 0.548874
FineTuningLR 0.251712
Epoch 7 | Batch 90/100 | Loss 0.255631
InnerLR 0.548541
FineTuningLR 0.253320
100 Accuracy = 85.71% +- 1.70%
Epoch 7: 85.71
best model! save...
Epoch 8 | Batch 0/100 | Loss 0.164344
InnerLR 0.547492
FineTuningLR 0.255873
Epoch 8 | Batch 10/100 | Loss 0.255466
InnerLR 0.546682
FineTuningLR 0.257708
Epoch 8 | Batch 20/100 | Loss 0.271984
InnerLR 0.545449
FineTuningLR 0.260572
Epoch 8 | Batch 30/100 | Loss 0.262035
InnerLR 0.544350
FineTuningLR 0.262492
Epoch 8 | Batch 40/100 | Loss 0.260594
InnerLR 0.542584
FineTuningLR 0.265463
Epoch 8 | Batch 50/100 | Loss 0.262176
InnerLR 0.541260
FineTuningLR 0.267456
Epoch 8 | Batch 60/100 | Loss 0.259287
InnerLR 0.539056
FineTuningLR 0.270440
Epoch 8 | Batch 70/100 | Loss 0.249489
InnerLR 0.538036
FineTuningLR 0.272432
Epoch 8 | Batch 80/100 | Loss 0.248647
InnerLR 0.536308
FineTuningLR 0.275395
Epoch 8 | Batch 90/100 | Loss 0.248332
InnerLR 0.535270
FineTuningLR 0.277370
100 Accuracy = 83.83% +- 2.19%
Epoch 8: 83.83
Epoch 9 | Batch 0/100 | Loss 0.159853
InnerLR 0.533765
FineTuningLR 0.280406
Epoch 9 | Batch 10/100 | Loss 0.207261
InnerLR 0.532836
FineTuningLR 0.282459
Epoch 9 | Batch 20/100 | Loss 0.211998
InnerLR 0.531207
FineTuningLR 0.285529
Epoch 9 | Batch 30/100 | Loss 0.212861
InnerLR 0.530678
FineTuningLR 0.287562
Epoch 9 | Batch 40/100 | Loss 0.218454
InnerLR 0.529629
FineTuningLR 0.290565
Epoch 9 | Batch 50/100 | Loss 0.211107
InnerLR 0.528746
FineTuningLR 0.292613
Epoch 9 | Batch 60/100 | Loss 0.227258
InnerLR 0.527555
FineTuningLR 0.295689
Epoch 9 | Batch 70/100 | Loss 0.225272
InnerLR 0.526778
FineTuningLR 0.297785
Epoch 9 | Batch 80/100 | Loss 0.236258
InnerLR 0.525505
FineTuningLR 0.300740
Epoch 9 | Batch 90/100 | Loss 0.237493
InnerLR 0.524392
FineTuningLR 0.302489
100 Accuracy = 85.91% +- 1.72%
Epoch 9: 85.91
best model! save...
Epoch 10 | Batch 0/100 | Loss 0.156964
InnerLR 0.522602
FineTuningLR 0.305170
Epoch 10 | Batch 10/100 | Loss 0.254765
InnerLR 0.521918
FineTuningLR 0.306549
Epoch 10 | Batch 20/100 | Loss 0.230185
InnerLR 0.521903
FineTuningLR 0.308734
Epoch 10 | Batch 30/100 | Loss 0.212363
InnerLR 0.522254
FineTuningLR 0.310272
Epoch 10 | Batch 40/100 | Loss 0.215696
InnerLR 0.522694
FineTuningLR 0.312867
Epoch 10 | Batch 50/100 | Loss 0.220342
InnerLR 0.523236
FineTuningLR 0.314496
Epoch 10 | Batch 60/100 | Loss 0.224230
InnerLR 0.523655
FineTuningLR 0.316852
Epoch 10 | Batch 70/100 | Loss 0.219117
InnerLR 0.523715
FineTuningLR 0.318536
Epoch 10 | Batch 80/100 | Loss 0.221972
InnerLR 0.523276
FineTuningLR 0.321157
Epoch 10 | Batch 90/100 | Loss 0.217413
InnerLR 0.522762
FineTuningLR 0.322928
100 Accuracy = 84.48% +- 1.94%
Epoch 10: 84.48
Epoch 11 | Batch 0/100 | Loss 0.464847
InnerLR 0.522291
FineTuningLR 0.325599
Epoch 11 | Batch 10/100 | Loss 0.213389
InnerLR 0.521699
FineTuningLR 0.327337
Epoch 11 | Batch 20/100 | Loss 0.211095
InnerLR 0.521249
FineTuningLR 0.330005
Epoch 11 | Batch 30/100 | Loss 0.215824
InnerLR 0.520621
FineTuningLR 0.331834
Epoch 11 | Batch 40/100 | Loss 0.199749
InnerLR 0.520117
FineTuningLR 0.334654
Epoch 11 | Batch 50/100 | Loss 0.195179
InnerLR 0.520066
FineTuningLR 0.336592
Epoch 11 | Batch 60/100 | Loss 0.192332
InnerLR 0.519688
FineTuningLR 0.339581
Epoch 11 | Batch 70/100 | Loss 0.189610
InnerLR 0.519718
FineTuningLR 0.341618
Epoch 11 | Batch 80/100 | Loss 0.187093
InnerLR 0.519606
FineTuningLR 0.344682
Epoch 11 | Batch 90/100 | Loss 0.187116
InnerLR 0.520006
FineTuningLR 0.346715
100 Accuracy = 86.03% +- 1.69%
Epoch 11: 86.03
best model! save...
Epoch 12 | Batch 0/100 | Loss 0.227182
InnerLR 0.520585
FineTuningLR 0.349717
Epoch 12 | Batch 10/100 | Loss 0.164268
InnerLR 0.520951
FineTuningLR 0.351690
Epoch 12 | Batch 20/100 | Loss 0.176451
InnerLR 0.521161
FineTuningLR 0.354737
Epoch 12 | Batch 30/100 | Loss 0.178782
InnerLR 0.521485
FineTuningLR 0.356810
Epoch 12 | Batch 40/100 | Loss 0.188383
InnerLR 0.521505
FineTuningLR 0.359914
Epoch 12 | Batch 50/100 | Loss 0.194858
InnerLR 0.521933
FineTuningLR 0.361759
Epoch 12 | Batch 60/100 | Loss 0.198416
InnerLR 0.522905
FineTuningLR 0.363989
Epoch 12 | Batch 70/100 | Loss 0.196930
InnerLR 0.523418
FineTuningLR 0.365523
Epoch 12 | Batch 80/100 | Loss 0.207154
InnerLR 0.523529
FineTuningLR 0.367865
Epoch 12 | Batch 90/100 | Loss 0.202050
InnerLR 0.523603
FineTuningLR 0.369319
100 Accuracy = 86.95% +- 1.86%
Epoch 12: 86.95
best model! save...
Epoch 13 | Batch 0/100 | Loss 0.111648
InnerLR 0.523656
FineTuningLR 0.371534
Epoch 13 | Batch 10/100 | Loss 0.206383
InnerLR 0.523601
FineTuningLR 0.373084
Epoch 13 | Batch 20/100 | Loss 0.202569
InnerLR 0.522862
FineTuningLR 0.375553
Epoch 13 | Batch 30/100 | Loss 0.183550
InnerLR 0.522499
FineTuningLR 0.377325
Epoch 13 | Batch 40/100 | Loss 0.185697
InnerLR 0.521479
FineTuningLR 0.380034
Epoch 13 | Batch 50/100 | Loss 0.186595
InnerLR 0.520433
FineTuningLR 0.381848
Epoch 13 | Batch 60/100 | Loss 0.183605
InnerLR 0.519117
FineTuningLR 0.384667
Epoch 13 | Batch 70/100 | Loss 0.183185
InnerLR 0.518218
FineTuningLR 0.386561
Epoch 13 | Batch 80/100 | Loss 0.185483
InnerLR 0.516974
FineTuningLR 0.388959
Epoch 13 | Batch 90/100 | Loss 0.185452
InnerLR 0.515973
FineTuningLR 0.390656
100 Accuracy = 85.36% +- 1.79%
Epoch 13: 85.36
Epoch 14 | Batch 0/100 | Loss 0.177251
InnerLR 0.514158
FineTuningLR 0.393322
Epoch 14 | Batch 10/100 | Loss 0.167828
InnerLR 0.513226
FineTuningLR 0.395207
Epoch 14 | Batch 20/100 | Loss 0.186119
InnerLR 0.511881
FineTuningLR 0.398048
Epoch 14 | Batch 30/100 | Loss 0.186470
InnerLR 0.511023
FineTuningLR 0.399646
Epoch 14 | Batch 40/100 | Loss 0.184584
InnerLR 0.510311
FineTuningLR 0.402170
Epoch 14 | Batch 50/100 | Loss 0.187551
InnerLR 0.510381
FineTuningLR 0.403420
Epoch 14 | Batch 60/100 | Loss 0.183975
InnerLR 0.510603
FineTuningLR 0.405249
Epoch 14 | Batch 70/100 | Loss 0.188820
InnerLR 0.510785
FineTuningLR 0.406581
Epoch 14 | Batch 80/100 | Loss 0.183225
InnerLR 0.510536
FineTuningLR 0.408794
Epoch 14 | Batch 90/100 | Loss 0.190081
InnerLR 0.510619
FineTuningLR 0.410019
100 Accuracy = 84.48% +- 1.97%
Epoch 14: 84.48
Epoch 15 | Batch 0/100 | Loss 0.121718
InnerLR 0.510085
FineTuningLR 0.411597
Epoch 15 | Batch 10/100 | Loss 0.230398
InnerLR 0.509499
FineTuningLR 0.412691
Epoch 15 | Batch 20/100 | Loss 0.190426
InnerLR 0.508307
FineTuningLR 0.414276
Epoch 15 | Batch 30/100 | Loss 0.190102
InnerLR 0.507722
FineTuningLR 0.415432
Epoch 15 | Batch 40/100 | Loss 0.199539
InnerLR 0.506833
FineTuningLR 0.417341
Epoch 15 | Batch 50/100 | Loss 0.196787
InnerLR 0.505975
FineTuningLR 0.418575
Epoch 15 | Batch 60/100 | Loss 0.192991
InnerLR 0.505204
FineTuningLR 0.420748
Epoch 15 | Batch 70/100 | Loss 0.193938
InnerLR 0.504481
FineTuningLR 0.422083
Epoch 15 | Batch 80/100 | Loss 0.193466
InnerLR 0.503743
FineTuningLR 0.423967
Epoch 15 | Batch 90/100 | Loss 0.195375
InnerLR 0.503380
FineTuningLR 0.425026
100 Accuracy = 86.01% +- 1.91%
Epoch 15: 86.01
Epoch 16 | Batch 0/100 | Loss 0.136850
InnerLR 0.502196
FineTuningLR 0.426820
Epoch 16 | Batch 10/100 | Loss 0.176184
InnerLR 0.501649
FineTuningLR 0.427839
Epoch 16 | Batch 20/100 | Loss 0.179305
InnerLR 0.501028
FineTuningLR 0.429415
Epoch 16 | Batch 30/100 | Loss 0.173075
InnerLR 0.500682
FineTuningLR 0.430601
Epoch 16 | Batch 40/100 | Loss 0.186615
InnerLR 0.499865
FineTuningLR 0.432285
Epoch 16 | Batch 50/100 | Loss 0.186127
InnerLR 0.499169
FineTuningLR 0.433582
Epoch 16 | Batch 60/100 | Loss 0.181876
InnerLR 0.497772
FineTuningLR 0.435777
Epoch 16 | Batch 70/100 | Loss 0.188214
InnerLR 0.497337
FineTuningLR 0.437202
Epoch 16 | Batch 80/100 | Loss 0.188843
InnerLR 0.496776
FineTuningLR 0.439396
Epoch 16 | Batch 90/100 | Loss 0.187311
InnerLR 0.496135
FineTuningLR 0.440649
100 Accuracy = 85.49% +- 1.83%
Epoch 16: 85.49
Epoch 17 | Batch 0/100 | Loss 0.124376
InnerLR 0.495987
FineTuningLR 0.442810
Epoch 17 | Batch 10/100 | Loss 0.194130
InnerLR 0.496138
FineTuningLR 0.444371
Epoch 17 | Batch 20/100 | Loss 0.188913
InnerLR 0.496559
FineTuningLR 0.446407
Epoch 17 | Batch 30/100 | Loss 0.197644
InnerLR 0.496701
FineTuningLR 0.447941
Epoch 17 | Batch 40/100 | Loss 0.206525
InnerLR 0.496483
FineTuningLR 0.449798
Epoch 17 | Batch 50/100 | Loss 0.200514
InnerLR 0.496193
FineTuningLR 0.450603
Epoch 17 | Batch 60/100 | Loss 0.194188
InnerLR 0.496123
FineTuningLR 0.451959
Epoch 17 | Batch 70/100 | Loss 0.186164
InnerLR 0.496246
FineTuningLR 0.453026
Epoch 17 | Batch 80/100 | Loss 0.183869
InnerLR 0.496189
FineTuningLR 0.454893
Epoch 17 | Batch 90/100 | Loss 0.182384
InnerLR 0.496493
FineTuningLR 0.456231
100 Accuracy = 86.33% +- 1.66%
Epoch 17: 86.33
Epoch 18 | Batch 0/100 | Loss 0.132009
InnerLR 0.497076
FineTuningLR 0.457973
Epoch 18 | Batch 10/100 | Loss 0.192484
InnerLR 0.497033
FineTuningLR 0.459373
Epoch 18 | Batch 20/100 | Loss 0.206873
InnerLR 0.496112
FineTuningLR 0.461123
Epoch 18 | Batch 30/100 | Loss 0.185673
InnerLR 0.495101
FineTuningLR 0.462407
Epoch 18 | Batch 40/100 | Loss 0.194187
InnerLR 0.494263
FineTuningLR 0.464280
Epoch 18 | Batch 50/100 | Loss 0.187041
InnerLR 0.493781
FineTuningLR 0.465395
Epoch 18 | Batch 60/100 | Loss 0.195721
InnerLR 0.492911
FineTuningLR 0.466995
Epoch 18 | Batch 70/100 | Loss 0.203976
InnerLR 0.492446
FineTuningLR 0.467847
Epoch 18 | Batch 80/100 | Loss 0.199147
InnerLR 0.492475
FineTuningLR 0.468879
Epoch 18 | Batch 90/100 | Loss 0.198292
InnerLR 0.492088
FineTuningLR 0.469388
100 Accuracy = 83.63% +- 2.00%
Epoch 18: 83.63
Epoch 19 | Batch 0/100 | Loss 0.154762
InnerLR 0.491355
FineTuningLR 0.470294
Epoch 19 | Batch 10/100 | Loss 0.184034
InnerLR 0.490607
FineTuningLR 0.470898
Epoch 19 | Batch 20/100 | Loss 0.200469
InnerLR 0.489499
FineTuningLR 0.472032
Epoch 19 | Batch 30/100 | Loss 0.184401
InnerLR 0.488782
FineTuningLR 0.472917
Epoch 19 | Batch 40/100 | Loss 0.180419
InnerLR 0.487497
FineTuningLR 0.474358
Epoch 19 | Batch 50/100 | Loss 0.178172
InnerLR 0.486384
FineTuningLR 0.475257
Epoch 19 | Batch 60/100 | Loss 0.183933
InnerLR 0.484591
FineTuningLR 0.476820
Epoch 19 | Batch 70/100 | Loss 0.179780
InnerLR 0.483174
FineTuningLR 0.477996
Epoch 19 | Batch 80/100 | Loss 0.177145
InnerLR 0.481625
FineTuningLR 0.479466
Epoch 19 | Batch 90/100 | Loss 0.177193
InnerLR 0.480580
FineTuningLR 0.480588
100 Accuracy = 84.87% +- 1.84%
Epoch 19: 84.87
Epoch 20 | Batch 0/100 | Loss 0.260653
InnerLR 0.479175
FineTuningLR 0.482472
Epoch 20 | Batch 10/100 | Loss 0.273906
InnerLR 0.478505
FineTuningLR 0.483323
Epoch 20 | Batch 20/100 | Loss 0.214004
InnerLR 0.477519
FineTuningLR 0.484734
Epoch 20 | Batch 30/100 | Loss 0.230617
InnerLR 0.477191
FineTuningLR 0.485535
Epoch 20 | Batch 40/100 | Loss 0.258969
InnerLR 0.476643
FineTuningLR 0.486412
Epoch 20 | Batch 50/100 | Loss 0.249365
InnerLR 0.476273
FineTuningLR 0.486728
Epoch 20 | Batch 60/100 | Loss 0.228968
InnerLR 0.475827
FineTuningLR 0.487886
Epoch 20 | Batch 70/100 | Loss 0.216975
InnerLR 0.475434
FineTuningLR 0.488971
Epoch 20 | Batch 80/100 | Loss 0.212018
InnerLR 0.474647
FineTuningLR 0.490953
Epoch 20 | Batch 90/100 | Loss 0.208555
InnerLR 0.473776
FineTuningLR 0.492410
100 Accuracy = 84.61% +- 1.90%
Epoch 20: 84.61
Epoch 21 | Batch 0/100 | Loss 0.661417
InnerLR 0.472754
FineTuningLR 0.494797
Epoch 21 | Batch 10/100 | Loss 0.241640
InnerLR 0.472217
FineTuningLR 0.496485
Epoch 21 | Batch 20/100 | Loss 0.200228
InnerLR 0.471904
FineTuningLR 0.498483
Epoch 21 | Batch 30/100 | Loss 0.234112
InnerLR 0.471840
FineTuningLR 0.499226
Epoch 21 | Batch 40/100 | Loss 0.213010
InnerLR 0.471751
FineTuningLR 0.499991
Epoch 21 | Batch 50/100 | Loss 0.202876
InnerLR 0.471552
FineTuningLR 0.500467
Epoch 21 | Batch 60/100 | Loss 0.209144
InnerLR 0.472129
FineTuningLR 0.500839
Epoch 21 | Batch 70/100 | Loss 0.204268
InnerLR 0.472492
FineTuningLR 0.501144
Epoch 21 | Batch 80/100 | Loss 0.197463
InnerLR 0.473340
FineTuningLR 0.501945
Epoch 21 | Batch 90/100 | Loss 0.190740
InnerLR 0.474044
FineTuningLR 0.502833
100 Accuracy = 82.83% +- 2.07%
Epoch 21: 82.83
Epoch 22 | Batch 0/100 | Loss 0.159651
InnerLR 0.474508
FineTuningLR 0.504317
Epoch 22 | Batch 10/100 | Loss 0.198548
InnerLR 0.474723
FineTuningLR 0.505384
Epoch 22 | Batch 20/100 | Loss 0.266580
InnerLR 0.475095
FineTuningLR 0.505990
Epoch 22 | Batch 30/100 | Loss 0.237260
InnerLR 0.474920
FineTuningLR 0.506190
Epoch 22 | Batch 40/100 | Loss 0.223247
InnerLR 0.474144
FineTuningLR 0.506595
Epoch 22 | Batch 50/100 | Loss 0.222666
InnerLR 0.473633
FineTuningLR 0.506646
Epoch 22 | Batch 60/100 | Loss 0.212473
InnerLR 0.472601
FineTuningLR 0.506687
Epoch 22 | Batch 70/100 | Loss 0.209770
InnerLR 0.471570
FineTuningLR 0.507066
Epoch 22 | Batch 80/100 | Loss 0.211112
InnerLR 0.469579
FineTuningLR 0.508090
Epoch 22 | Batch 90/100 | Loss 0.205763
InnerLR 0.468247
FineTuningLR 0.508844
100 Accuracy = 87.01% +- 1.74%
Epoch 22: 87.01
best model! save...
Epoch 23 | Batch 0/100 | Loss 0.115866
InnerLR 0.466998
FineTuningLR 0.509805
Epoch 23 | Batch 10/100 | Loss 0.193299
InnerLR 0.466329
FineTuningLR 0.510436
Epoch 23 | Batch 20/100 | Loss 0.188005
InnerLR 0.465498
FineTuningLR 0.511213
Epoch 23 | Batch 30/100 | Loss 0.182380
InnerLR 0.464873
FineTuningLR 0.511519
Epoch 23 | Batch 40/100 | Loss 0.185399
InnerLR 0.464339
FineTuningLR 0.512105
Epoch 23 | Batch 50/100 | Loss 0.179706
InnerLR 0.464172
FineTuningLR 0.512629
Epoch 23 | Batch 60/100 | Loss 0.186724
InnerLR 0.464221
FineTuningLR 0.513454
Epoch 23 | Batch 70/100 | Loss 0.181074
InnerLR 0.464072
FineTuningLR 0.513633
Epoch 23 | Batch 80/100 | Loss 0.180966
InnerLR 0.463450
FineTuningLR 0.514493
Epoch 23 | Batch 90/100 | Loss 0.181049
InnerLR 0.463135
FineTuningLR 0.515415
100 Accuracy = 85.83% +- 2.11%
Epoch 23: 85.83
Epoch 24 | Batch 0/100 | Loss 0.925316
InnerLR 0.462530
FineTuningLR 0.516845
Epoch 24 | Batch 10/100 | Loss 0.277062
InnerLR 0.461908
FineTuningLR 0.517599
Epoch 24 | Batch 20/100 | Loss 0.259951
InnerLR 0.461596
FineTuningLR 0.518470
Epoch 24 | Batch 30/100 | Loss 0.229324
InnerLR 0.461632
FineTuningLR 0.519178
Epoch 24 | Batch 40/100 | Loss 0.208963
InnerLR 0.461812
FineTuningLR 0.520146
Epoch 24 | Batch 50/100 | Loss 0.193456
InnerLR 0.461821
FineTuningLR 0.521057
Epoch 24 | Batch 60/100 | Loss 0.190772
InnerLR 0.462242
FineTuningLR 0.522452
Epoch 24 | Batch 70/100 | Loss 0.180773
InnerLR 0.462408
FineTuningLR 0.523570
Epoch 24 | Batch 80/100 | Loss 0.178490
InnerLR 0.463386
FineTuningLR 0.525296
Epoch 24 | Batch 90/100 | Loss 0.179955
InnerLR 0.464426
FineTuningLR 0.525840
100 Accuracy = 84.96% +- 1.88%
Epoch 24: 84.96
Epoch 25 | Batch 0/100 | Loss 0.110312
InnerLR 0.465664
FineTuningLR 0.526778
Epoch 25 | Batch 10/100 | Loss 0.222263
InnerLR 0.466567
FineTuningLR 0.527343
Epoch 25 | Batch 20/100 | Loss 0.193232
InnerLR 0.468119
FineTuningLR 0.527990
Epoch 25 | Batch 30/100 | Loss 0.239397
InnerLR 0.469223
FineTuningLR 0.528622
Epoch 25 | Batch 40/100 | Loss 0.225318
InnerLR 0.470764
FineTuningLR 0.529823
Epoch 25 | Batch 50/100 | Loss 0.219641
InnerLR 0.471204
FineTuningLR 0.530778
Epoch 25 | Batch 60/100 | Loss 0.212627
InnerLR 0.471151
FineTuningLR 0.531599
Epoch 25 | Batch 70/100 | Loss 0.210556
InnerLR 0.471444
FineTuningLR 0.531866
Epoch 25 | Batch 80/100 | Loss 0.203858
InnerLR 0.471999
FineTuningLR 0.531925
Epoch 25 | Batch 90/100 | Loss 0.212410
InnerLR 0.472297
FineTuningLR 0.532161
100 Accuracy = 85.64% +- 1.98%
Epoch 25: 85.64
Epoch 26 | Batch 0/100 | Loss 0.171617
InnerLR 0.471890
FineTuningLR 0.532242
Epoch 26 | Batch 10/100 | Loss 0.147518
InnerLR 0.471277
FineTuningLR 0.532626
Epoch 26 | Batch 20/100 | Loss 0.156733
InnerLR 0.471049
FineTuningLR 0.532793
Epoch 26 | Batch 30/100 | Loss 0.185787
InnerLR 0.470938
FineTuningLR 0.532961
Epoch 26 | Batch 40/100 | Loss 0.177306
InnerLR 0.471423
FineTuningLR 0.533386
Epoch 26 | Batch 50/100 | Loss 0.185115
InnerLR 0.471282
FineTuningLR 0.533617
Epoch 26 | Batch 60/100 | Loss 0.204326
InnerLR 0.470295
FineTuningLR 0.533896
Epoch 26 | Batch 70/100 | Loss 0.198431
InnerLR 0.469373
FineTuningLR 0.534052
Epoch 26 | Batch 80/100 | Loss 0.199745
InnerLR 0.467922
FineTuningLR 0.534038
Epoch 26 | Batch 90/100 | Loss 0.200166
InnerLR 0.466652
FineTuningLR 0.534208
100 Accuracy = 84.75% +- 1.82%
Epoch 26: 84.75
Epoch 27 | Batch 0/100 | Loss 0.190094
InnerLR 0.464909
FineTuningLR 0.534866
Epoch 27 | Batch 10/100 | Loss 0.149274
InnerLR 0.464072
FineTuningLR 0.535649
Epoch 27 | Batch 20/100 | Loss 0.166926
InnerLR 0.462841
FineTuningLR 0.537002
Epoch 27 | Batch 30/100 | Loss 0.183689
InnerLR 0.461954
FineTuningLR 0.537901
Epoch 27 | Batch 40/100 | Loss 0.202614
InnerLR 0.460990
FineTuningLR 0.538892
Epoch 27 | Batch 50/100 | Loss 0.201569
InnerLR 0.460617
FineTuningLR 0.539458
Epoch 27 | Batch 60/100 | Loss 0.191452
InnerLR 0.460242
FineTuningLR 0.540503
Epoch 27 | Batch 70/100 | Loss 0.197060
InnerLR 0.459791
FineTuningLR 0.541115
Epoch 27 | Batch 80/100 | Loss 0.197881
InnerLR 0.458553
FineTuningLR 0.541998
Epoch 27 | Batch 90/100 | Loss 0.191023
InnerLR 0.457680
FineTuningLR 0.542769
100 Accuracy = 83.40% +- 1.90%
Epoch 27: 83.40
Epoch 28 | Batch 0/100 | Loss 0.068935
InnerLR 0.456666
FineTuningLR 0.543746
Epoch 28 | Batch 10/100 | Loss 0.120334
InnerLR 0.456203
FineTuningLR 0.544225
Epoch 28 | Batch 20/100 | Loss 0.158187
InnerLR 0.456097
FineTuningLR 0.545043
Epoch 28 | Batch 30/100 | Loss 0.167546
InnerLR 0.455893
FineTuningLR 0.545682
Epoch 28 | Batch 40/100 | Loss 0.160578
InnerLR 0.455739
FineTuningLR 0.547059
Epoch 28 | Batch 50/100 | Loss 0.160933
InnerLR 0.455775
FineTuningLR 0.548129
Epoch 28 | Batch 60/100 | Loss 0.167391
InnerLR 0.455915
FineTuningLR 0.548888
Epoch 28 | Batch 70/100 | Loss 0.163029
InnerLR 0.456207
FineTuningLR 0.549619
Epoch 28 | Batch 80/100 | Loss 0.158873
InnerLR 0.455989
FineTuningLR 0.551097
Epoch 28 | Batch 90/100 | Loss 0.169248
InnerLR 0.455702
FineTuningLR 0.552062
100 Accuracy = 84.68% +- 2.10%
Epoch 28: 84.68
Epoch 29 | Batch 0/100 | Loss 0.116377
InnerLR 0.455687
FineTuningLR 0.553417
Epoch 29 | Batch 10/100 | Loss 0.152749
InnerLR 0.455538
FineTuningLR 0.554177
Epoch 29 | Batch 20/100 | Loss 0.152970
InnerLR 0.455356
FineTuningLR 0.555422
Epoch 29 | Batch 30/100 | Loss 0.151147
InnerLR 0.454811
FineTuningLR 0.556343
Epoch 29 | Batch 40/100 | Loss 0.164652
InnerLR 0.454030
FineTuningLR 0.557598
Epoch 29 | Batch 50/100 | Loss 0.166608
InnerLR 0.453273
FineTuningLR 0.558368
Epoch 29 | Batch 60/100 | Loss 0.170134
InnerLR 0.452410
FineTuningLR 0.559109
Epoch 29 | Batch 70/100 | Loss 0.188173
InnerLR 0.451743
FineTuningLR 0.559288
Epoch 29 | Batch 80/100 | Loss 0.189051
InnerLR 0.450609
FineTuningLR 0.559844
Epoch 29 | Batch 90/100 | Loss 0.187674
InnerLR 0.449700
FineTuningLR 0.560447
100 Accuracy = 84.93% +- 2.03%
Epoch 29: 84.93
Epoch 30 | Batch 0/100 | Loss 0.167757
InnerLR 0.448914
FineTuningLR 0.561280
Epoch 30 | Batch 10/100 | Loss 0.186790
InnerLR 0.448647
FineTuningLR 0.561771
Epoch 30 | Batch 20/100 | Loss 0.169436
InnerLR 0.447895
FineTuningLR 0.563065
Epoch 30 | Batch 30/100 | Loss 0.170526
InnerLR 0.447446
FineTuningLR 0.563824
Epoch 30 | Batch 40/100 | Loss 0.192325
InnerLR 0.446403
FineTuningLR 0.564672
Epoch 30 | Batch 50/100 | Loss 0.184136
InnerLR 0.446183
FineTuningLR 0.565321
Epoch 30 | Batch 60/100 | Loss 0.175587
InnerLR 0.446171
FineTuningLR 0.566852
Epoch 30 | Batch 70/100 | Loss 0.171240
InnerLR 0.446294
FineTuningLR 0.568082
Epoch 30 | Batch 80/100 | Loss 0.170535
InnerLR 0.446930
FineTuningLR 0.569700
Epoch 30 | Batch 90/100 | Loss 0.170694
InnerLR 0.447485
FineTuningLR 0.570591
100 Accuracy = 86.20% +- 1.81%
Epoch 30: 86.20
Epoch 31 | Batch 0/100 | Loss 0.408031
InnerLR 0.448077
FineTuningLR 0.572086
Epoch 31 | Batch 10/100 | Loss 0.171087
InnerLR 0.448120
FineTuningLR 0.572766
Epoch 31 | Batch 20/100 | Loss 0.171734
InnerLR 0.447846
FineTuningLR 0.573578
Epoch 31 | Batch 30/100 | Loss 0.155365
InnerLR 0.447759
FineTuningLR 0.574129
Epoch 31 | Batch 40/100 | Loss 0.186167
InnerLR 0.447798
FineTuningLR 0.574353
Epoch 31 | Batch 50/100 | Loss 0.181770
InnerLR 0.447544
FineTuningLR 0.574192
Epoch 31 | Batch 60/100 | Loss 0.181660
InnerLR 0.446798
FineTuningLR 0.574419
Epoch 31 | Batch 70/100 | Loss 0.182883
InnerLR 0.445998
FineTuningLR 0.574604
Epoch 31 | Batch 80/100 | Loss 0.181322
InnerLR 0.444310
FineTuningLR 0.574856
Epoch 31 | Batch 90/100 | Loss 0.179616
InnerLR 0.442921
FineTuningLR 0.574960
100 Accuracy = 84.95% +- 2.14%
Epoch 31: 84.95
Epoch 32 | Batch 0/100 | Loss 0.170365
InnerLR 0.440969
FineTuningLR 0.575365
Epoch 32 | Batch 10/100 | Loss 0.151911
InnerLR 0.439751
FineTuningLR 0.575967
Epoch 32 | Batch 20/100 | Loss 0.142743
InnerLR 0.437857
FineTuningLR 0.576760
Epoch 32 | Batch 30/100 | Loss 0.170701
InnerLR 0.436588
FineTuningLR 0.577437
Epoch 32 | Batch 40/100 | Loss 0.165548
InnerLR 0.434524
FineTuningLR 0.578717
Epoch 32 | Batch 50/100 | Loss 0.164511
InnerLR 0.432928
FineTuningLR 0.579345
Epoch 32 | Batch 60/100 | Loss 0.164021
InnerLR 0.430960
FineTuningLR 0.580286
Epoch 32 | Batch 70/100 | Loss 0.162660
InnerLR 0.430474
FineTuningLR 0.580631
Epoch 32 | Batch 80/100 | Loss 0.160256
InnerLR 0.429413
FineTuningLR 0.581548
Epoch 32 | Batch 90/100 | Loss 0.162942
InnerLR 0.429029
FineTuningLR 0.582024
100 Accuracy = 85.05% +- 2.17%
Epoch 32: 85.05
Epoch 33 | Batch 0/100 | Loss 0.254399
InnerLR 0.428139
FineTuningLR 0.582980
Epoch 33 | Batch 10/100 | Loss 0.346299
InnerLR 0.427384
FineTuningLR 0.583143
Epoch 33 | Batch 20/100 | Loss 0.245012
InnerLR 0.426529
FineTuningLR 0.583552
Epoch 33 | Batch 30/100 | Loss 0.210629
InnerLR 0.425775
FineTuningLR 0.583967
Epoch 33 | Batch 40/100 | Loss 0.199741
InnerLR 0.425120
FineTuningLR 0.585159
Epoch 33 | Batch 50/100 | Loss 0.184855
InnerLR 0.424564
FineTuningLR 0.586318
Epoch 33 | Batch 60/100 | Loss 0.187865
InnerLR 0.423729
FineTuningLR 0.587759
Epoch 33 | Batch 70/100 | Loss 0.180751
InnerLR 0.422781
FineTuningLR 0.588903
Epoch 33 | Batch 80/100 | Loss 0.175895
InnerLR 0.421515
FineTuningLR 0.590954
Epoch 33 | Batch 90/100 | Loss 0.183944
InnerLR 0.420629
FineTuningLR 0.592382
100 Accuracy = 86.04% +- 1.91%
Epoch 33: 86.04
Epoch 34 | Batch 0/100 | Loss 0.203021
InnerLR 0.419360
FineTuningLR 0.593940
Epoch 34 | Batch 10/100 | Loss 0.162857
InnerLR 0.418204
FineTuningLR 0.595115
Epoch 34 | Batch 20/100 | Loss 0.177423
InnerLR 0.416207
FineTuningLR 0.596745
Epoch 34 | Batch 30/100 | Loss 0.205125
InnerLR 0.414913
FineTuningLR 0.597710
Epoch 34 | Batch 40/100 | Loss 0.196534
InnerLR 0.412934
FineTuningLR 0.598873
Epoch 34 | Batch 50/100 | Loss 0.195191
InnerLR 0.412006
FineTuningLR 0.599639
Epoch 34 | Batch 60/100 | Loss 0.186689
InnerLR 0.411437
FineTuningLR 0.599975
Epoch 34 | Batch 70/100 | Loss 0.181972
InnerLR 0.411344
FineTuningLR 0.599823
Epoch 34 | Batch 80/100 | Loss 0.193671
InnerLR 0.410867
FineTuningLR 0.599832
Epoch 34 | Batch 90/100 | Loss 0.187819
InnerLR 0.410560
FineTuningLR 0.600139
100 Accuracy = 84.71% +- 1.95%
Epoch 34: 84.71
Epoch 35 | Batch 0/100 | Loss 0.375821
InnerLR 0.409548
FineTuningLR 0.600661
Epoch 35 | Batch 10/100 | Loss 0.209398
InnerLR 0.408510
FineTuningLR 0.600681
Epoch 35 | Batch 20/100 | Loss 0.178599
InnerLR 0.407009
FineTuningLR 0.601258
Epoch 35 | Batch 30/100 | Loss 0.156803
InnerLR 0.406613
FineTuningLR 0.601780
Epoch 35 | Batch 40/100 | Loss 0.166670
InnerLR 0.406037
FineTuningLR 0.602539
Epoch 35 | Batch 50/100 | Loss 0.161460
InnerLR 0.405314
FineTuningLR 0.603073
Epoch 35 | Batch 60/100 | Loss 0.157363
InnerLR 0.404216
FineTuningLR 0.604014
Epoch 35 | Batch 70/100 | Loss 0.163661
InnerLR 0.403582
FineTuningLR 0.604680
Epoch 35 | Batch 80/100 | Loss 0.168281
InnerLR 0.403433
FineTuningLR 0.605137
Epoch 35 | Batch 90/100 | Loss 0.163818
InnerLR 0.403821
FineTuningLR 0.605094
100 Accuracy = 85.00% +- 2.11%
Epoch 35: 85.00
Epoch 36 | Batch 0/100 | Loss 0.162270
InnerLR 0.404204
FineTuningLR 0.605475
Epoch 36 | Batch 10/100 | Loss 0.176184
InnerLR 0.404599
FineTuningLR 0.606093
Epoch 36 | Batch 20/100 | Loss 0.179633
InnerLR 0.404917
FineTuningLR 0.606952
Epoch 36 | Batch 30/100 | Loss 0.176610
InnerLR 0.405593
FineTuningLR 0.607226
Epoch 36 | Batch 40/100 | Loss 0.179821
InnerLR 0.405900
FineTuningLR 0.607709
Epoch 36 | Batch 50/100 | Loss 0.202381
InnerLR 0.406010
FineTuningLR 0.608023
Epoch 36 | Batch 60/100 | Loss 0.217809
InnerLR 0.406151
FineTuningLR 0.608296
Epoch 36 | Batch 70/100 | Loss 0.205410
InnerLR 0.405890
FineTuningLR 0.608219
Epoch 36 | Batch 80/100 | Loss 0.204357
InnerLR 0.405926
FineTuningLR 0.608122
Epoch 36 | Batch 90/100 | Loss 0.228526
InnerLR 0.405774
FineTuningLR 0.607744
100 Accuracy = 84.81% +- 1.85%
Epoch 36: 84.81
Epoch 37 | Batch 0/100 | Loss 0.274756
InnerLR 0.406206
FineTuningLR 0.606940
Epoch 37 | Batch 10/100 | Loss 0.204649
InnerLR 0.406708
FineTuningLR 0.606354
Epoch 37 | Batch 20/100 | Loss 0.158407
InnerLR 0.407696
FineTuningLR 0.605906
Epoch 37 | Batch 30/100 | Loss 0.162671
InnerLR 0.407821
FineTuningLR 0.606174
Epoch 37 | Batch 40/100 | Loss 0.167044
InnerLR 0.407462
FineTuningLR 0.606259
Epoch 37 | Batch 50/100 | Loss 0.171385
InnerLR 0.407286
FineTuningLR 0.606081
Epoch 37 | Batch 60/100 | Loss 0.175311
InnerLR 0.407446
FineTuningLR 0.605574
Epoch 37 | Batch 70/100 | Loss 0.171814
InnerLR 0.407392
FineTuningLR 0.605534
Epoch 37 | Batch 80/100 | Loss 0.166137
InnerLR 0.407648
FineTuningLR 0.605737
Epoch 37 | Batch 90/100 | Loss 0.167825
InnerLR 0.407512
FineTuningLR 0.605730
100 Accuracy = 85.87% +- 1.88%
Epoch 37: 85.87
Epoch 38 | Batch 0/100 | Loss 0.117132
InnerLR 0.406799
FineTuningLR 0.605582
Epoch 38 | Batch 10/100 | Loss 0.152984
InnerLR 0.406178
FineTuningLR 0.605974
Epoch 38 | Batch 20/100 | Loss 0.134250
InnerLR 0.405799
FineTuningLR 0.606570
Epoch 38 | Batch 30/100 | Loss 0.129257
InnerLR 0.405425
FineTuningLR 0.607352
Epoch 38 | Batch 40/100 | Loss 0.140672
InnerLR 0.404164
FineTuningLR 0.608606
Epoch 38 | Batch 50/100 | Loss 0.147227
InnerLR 0.403021
FineTuningLR 0.609443
Epoch 38 | Batch 60/100 | Loss 0.162127
InnerLR 0.401157
FineTuningLR 0.610698
Epoch 38 | Batch 70/100 | Loss 0.161914
InnerLR 0.399953
FineTuningLR 0.611314
Epoch 38 | Batch 80/100 | Loss 0.166726
InnerLR 0.399043
FineTuningLR 0.611978
Epoch 38 | Batch 90/100 | Loss 0.167308
InnerLR 0.398452
FineTuningLR 0.612174
100 Accuracy = 85.04% +- 2.01%
Epoch 38: 85.04
Epoch 39 | Batch 0/100 | Loss 0.097294
InnerLR 0.397373
FineTuningLR 0.612924
Epoch 39 | Batch 10/100 | Loss 0.123043
InnerLR 0.396831
FineTuningLR 0.613349
Epoch 39 | Batch 20/100 | Loss 0.132090
InnerLR 0.396364
FineTuningLR 0.614143
Epoch 39 | Batch 30/100 | Loss 0.178375
InnerLR 0.396423
FineTuningLR 0.614415
Epoch 39 | Batch 40/100 | Loss 0.170248
InnerLR 0.396174
FineTuningLR 0.614796
Epoch 39 | Batch 50/100 | Loss 0.165928
InnerLR 0.395911
FineTuningLR 0.615156
Epoch 39 | Batch 60/100 | Loss 0.158783
InnerLR 0.395729
FineTuningLR 0.615976
Epoch 39 | Batch 70/100 | Loss 0.160396
InnerLR 0.395340
FineTuningLR 0.616289
Epoch 39 | Batch 80/100 | Loss 0.159078
InnerLR 0.395019
FineTuningLR 0.616041
Epoch 39 | Batch 90/100 | Loss 0.171554
InnerLR 0.394951
FineTuningLR 0.615479
100 Accuracy = 84.13% +- 2.07%
Epoch 39: 84.13
Epoch 40 | Batch 0/100 | Loss 0.122041
InnerLR 0.395258
FineTuningLR 0.614253
Epoch 40 | Batch 10/100 | Loss 0.159851
InnerLR 0.395155
FineTuningLR 0.613715
Epoch 40 | Batch 20/100 | Loss 0.196184
InnerLR 0.394360
FineTuningLR 0.613093
Epoch 40 | Batch 30/100 | Loss 0.202673
InnerLR 0.393914
FineTuningLR 0.612977
Epoch 40 | Batch 40/100 | Loss 0.207983
InnerLR 0.393588
FineTuningLR 0.612967
Epoch 40 | Batch 50/100 | Loss 0.195811
InnerLR 0.393506
FineTuningLR 0.612648
Epoch 40 | Batch 60/100 | Loss 0.181628
InnerLR 0.393529
FineTuningLR 0.612706
Epoch 40 | Batch 70/100 | Loss 0.187473
InnerLR 0.393434
FineTuningLR 0.613132
Epoch 40 | Batch 80/100 | Loss 0.180774
InnerLR 0.392784
FineTuningLR 0.613763
Epoch 40 | Batch 90/100 | Loss 0.173695
InnerLR 0.392723
FineTuningLR 0.614582
100 Accuracy = 85.96% +- 1.91%
Epoch 40: 85.96
Epoch 41 | Batch 0/100 | Loss 0.082462
InnerLR 0.393286
FineTuningLR 0.615932
Epoch 41 | Batch 10/100 | Loss 0.171181
InnerLR 0.393421
FineTuningLR 0.616809
Epoch 41 | Batch 20/100 | Loss 0.171759
InnerLR 0.393834
FineTuningLR 0.617773
Epoch 41 | Batch 30/100 | Loss 0.156443
InnerLR 0.394284
FineTuningLR 0.618131
Epoch 41 | Batch 40/100 | Loss 0.161265
InnerLR 0.394665
FineTuningLR 0.618443
Epoch 41 | Batch 50/100 | Loss 0.178763
InnerLR 0.394876
FineTuningLR 0.618914
Epoch 41 | Batch 60/100 | Loss 0.176464
InnerLR 0.395859
FineTuningLR 0.619175
Epoch 41 | Batch 70/100 | Loss 0.170215
InnerLR 0.396319
FineTuningLR 0.619444
Epoch 41 | Batch 80/100 | Loss 0.172905
InnerLR 0.397290
FineTuningLR 0.619469
Epoch 41 | Batch 90/100 | Loss 0.168403
InnerLR 0.397767
FineTuningLR 0.619944
100 Accuracy = 86.44% +- 1.64%
Epoch 41: 86.44
Epoch 42 | Batch 0/100 | Loss 0.177534
InnerLR 0.397816
FineTuningLR 0.620469
Epoch 42 | Batch 10/100 | Loss 0.125276
InnerLR 0.398244
FineTuningLR 0.620932
Epoch 42 | Batch 20/100 | Loss 0.148419
InnerLR 0.398592
FineTuningLR 0.621824
Epoch 42 | Batch 30/100 | Loss 0.163221
InnerLR 0.398254
FineTuningLR 0.622718
Epoch 42 | Batch 40/100 | Loss 0.165218
InnerLR 0.397398
FineTuningLR 0.623966
Epoch 42 | Batch 50/100 | Loss 0.166702
InnerLR 0.396888
FineTuningLR 0.624601
Epoch 42 | Batch 60/100 | Loss 0.166824
InnerLR 0.397061
FineTuningLR 0.624929
Epoch 42 | Batch 70/100 | Loss 0.163891
InnerLR 0.397201
FineTuningLR 0.625230
Epoch 42 | Batch 80/100 | Loss 0.167499
InnerLR 0.397396
FineTuningLR 0.626228
Epoch 42 | Batch 90/100 | Loss 0.168051
InnerLR 0.397193
FineTuningLR 0.626979
100 Accuracy = 84.16% +- 1.88%
Epoch 42: 84.16
Epoch 43 | Batch 0/100 | Loss 0.127229
InnerLR 0.396439
FineTuningLR 0.627265
Epoch 43 | Batch 10/100 | Loss 0.196688
InnerLR 0.395710
FineTuningLR 0.627406
Epoch 43 | Batch 20/100 | Loss 0.228446
InnerLR 0.395370
FineTuningLR 0.627348
Epoch 43 | Batch 30/100 | Loss 0.235280
InnerLR 0.395413
FineTuningLR 0.627009
Epoch 43 | Batch 40/100 | Loss 0.213913
InnerLR 0.394998
FineTuningLR 0.626792
Epoch 43 | Batch 50/100 | Loss 0.195246
InnerLR 0.394966
FineTuningLR 0.626458
Epoch 43 | Batch 60/100 | Loss 0.195516
InnerLR 0.395015
FineTuningLR 0.626315
Epoch 43 | Batch 70/100 | Loss 0.190923
InnerLR 0.395214
FineTuningLR 0.626044
Epoch 43 | Batch 80/100 | Loss 0.181269
InnerLR 0.395343
FineTuningLR 0.625921
Epoch 43 | Batch 90/100 | Loss 0.176286
InnerLR 0.395713
FineTuningLR 0.626209
100 Accuracy = 86.17% +- 2.01%
Epoch 43: 86.17
Epoch 44 | Batch 0/100 | Loss 0.523533
InnerLR 0.395737
FineTuningLR 0.626984
Epoch 44 | Batch 10/100 | Loss 0.230580
InnerLR 0.395961
FineTuningLR 0.627315
Epoch 44 | Batch 20/100 | Loss 0.205995
InnerLR 0.396149
FineTuningLR 0.627874
Epoch 44 | Batch 30/100 | Loss 0.188436
InnerLR 0.396453
FineTuningLR 0.628030
Epoch 44 | Batch 40/100 | Loss 0.172992
InnerLR 0.396163
FineTuningLR 0.628915
Epoch 44 | Batch 50/100 | Loss 0.168286
InnerLR 0.396028
FineTuningLR 0.629495
Epoch 44 | Batch 60/100 | Loss 0.184666
InnerLR 0.395751
FineTuningLR 0.629758
Epoch 44 | Batch 70/100 | Loss 0.173327
InnerLR 0.395585
FineTuningLR 0.630032
Epoch 44 | Batch 80/100 | Loss 0.176707
InnerLR 0.394789
FineTuningLR 0.630869
Epoch 44 | Batch 90/100 | Loss 0.179547
InnerLR 0.394508
FineTuningLR 0.630965
100 Accuracy = 84.72% +- 1.92%
Epoch 44: 84.72
Epoch 45 | Batch 0/100 | Loss 0.317650
InnerLR 0.393993
FineTuningLR 0.630895
Epoch 45 | Batch 10/100 | Loss 0.206980
InnerLR 0.393500
FineTuningLR 0.630953
Epoch 45 | Batch 20/100 | Loss 0.179710
InnerLR 0.392844
FineTuningLR 0.631142
Epoch 45 | Batch 30/100 | Loss 0.173932
InnerLR 0.391972
FineTuningLR 0.631595
Epoch 45 | Batch 40/100 | Loss 0.173552
InnerLR 0.391413
FineTuningLR 0.632244
Epoch 45 | Batch 50/100 | Loss 0.174786
InnerLR 0.391419
FineTuningLR 0.632591
Epoch 45 | Batch 60/100 | Loss 0.166317
InnerLR 0.391150
FineTuningLR 0.633533
Epoch 45 | Batch 70/100 | Loss 0.163192
InnerLR 0.391263
FineTuningLR 0.634139
Epoch 45 | Batch 80/100 | Loss 0.165489
InnerLR 0.390947
FineTuningLR 0.635362
Epoch 45 | Batch 90/100 | Loss 0.162720
InnerLR 0.390624
FineTuningLR 0.636050
100 Accuracy = 85.15% +- 1.76%
Epoch 45: 85.15
Epoch 46 | Batch 0/100 | Loss 0.088289
InnerLR 0.389461
FineTuningLR 0.636820
Epoch 46 | Batch 10/100 | Loss 0.163945
InnerLR 0.388767
FineTuningLR 0.637291
Epoch 46 | Batch 20/100 | Loss 0.200896
InnerLR 0.387861
FineTuningLR 0.637951
Epoch 46 | Batch 30/100 | Loss 0.192665
InnerLR 0.387406
FineTuningLR 0.638460
Epoch 46 | Batch 40/100 | Loss 0.183606
InnerLR 0.386343
FineTuningLR 0.639508
Epoch 46 | Batch 50/100 | Loss 0.183246
InnerLR 0.385770
FineTuningLR 0.640069
Epoch 46 | Batch 60/100 | Loss 0.187235
InnerLR 0.385506
FineTuningLR 0.640190
Epoch 46 | Batch 70/100 | Loss 0.184565
InnerLR 0.385359
FineTuningLR 0.640207
Epoch 46 | Batch 80/100 | Loss 0.191828
InnerLR 0.385445
FineTuningLR 0.640007
Epoch 46 | Batch 90/100 | Loss 0.197094
InnerLR 0.385181
FineTuningLR 0.639963
100 Accuracy = 85.99% +- 2.09%
Epoch 46: 85.99
Epoch 47 | Batch 0/100 | Loss 0.091503
InnerLR 0.384775
FineTuningLR 0.639585
Epoch 47 | Batch 10/100 | Loss 0.175169
InnerLR 0.384640
FineTuningLR 0.639453
Epoch 47 | Batch 20/100 | Loss 0.180548
InnerLR 0.384643
FineTuningLR 0.639521
Epoch 47 | Batch 30/100 | Loss 0.177928
InnerLR 0.385014
FineTuningLR 0.639718
Epoch 47 | Batch 40/100 | Loss 0.190396
InnerLR 0.385307
FineTuningLR 0.640103
Epoch 47 | Batch 50/100 | Loss 0.197627
InnerLR 0.385147
FineTuningLR 0.640813
Epoch 47 | Batch 60/100 | Loss 0.190818
InnerLR 0.384800
FineTuningLR 0.641772
Epoch 47 | Batch 70/100 | Loss 0.184125
InnerLR 0.384396
FineTuningLR 0.642443
Epoch 47 | Batch 80/100 | Loss 0.179623
InnerLR 0.384288
FineTuningLR 0.643412
Epoch 47 | Batch 90/100 | Loss 0.182149
InnerLR 0.383915
FineTuningLR 0.644021
100 Accuracy = 84.88% +- 2.07%
Epoch 47: 84.88
Epoch 48 | Batch 0/100 | Loss 0.099090
InnerLR 0.383042
FineTuningLR 0.644716
Epoch 48 | Batch 10/100 | Loss 0.126140
InnerLR 0.382779
FineTuningLR 0.644960
Epoch 48 | Batch 20/100 | Loss 0.149429
InnerLR 0.382896
FineTuningLR 0.645400
Epoch 48 | Batch 30/100 | Loss 0.159177
InnerLR 0.382796
FineTuningLR 0.645550
Epoch 48 | Batch 40/100 | Loss 0.171487
InnerLR 0.382313
FineTuningLR 0.645787
Epoch 48 | Batch 50/100 | Loss 0.174827
InnerLR 0.381776
FineTuningLR 0.645611
Epoch 48 | Batch 60/100 | Loss 0.175198
InnerLR 0.380681
FineTuningLR 0.645305
Epoch 48 | Batch 70/100 | Loss 0.182858
InnerLR 0.379588
FineTuningLR 0.645566
Epoch 48 | Batch 80/100 | Loss 0.176404
InnerLR 0.378344
FineTuningLR 0.646305
Epoch 48 | Batch 90/100 | Loss 0.174004
InnerLR 0.377778
FineTuningLR 0.646785
100 Accuracy = 86.01% +- 1.85%
Epoch 48: 86.01
Epoch 49 | Batch 0/100 | Loss 0.530747
InnerLR 0.376371
FineTuningLR 0.647444
Epoch 49 | Batch 10/100 | Loss 0.167535
InnerLR 0.375400
FineTuningLR 0.647449
Epoch 49 | Batch 20/100 | Loss 0.169000
InnerLR 0.374668
FineTuningLR 0.647127
Epoch 49 | Batch 30/100 | Loss 0.184214
InnerLR 0.374666
FineTuningLR 0.646693
Epoch 49 | Batch 40/100 | Loss 0.197466
InnerLR 0.374953
FineTuningLR 0.646225
Epoch 49 | Batch 50/100 | Loss 0.186958
InnerLR 0.375254
FineTuningLR 0.645972
Epoch 49 | Batch 60/100 | Loss 0.177870
InnerLR 0.375111
FineTuningLR 0.646249
Epoch 49 | Batch 70/100 | Loss 0.175162
InnerLR 0.375286
FineTuningLR 0.646390
Epoch 49 | Batch 80/100 | Loss 0.175105
InnerLR 0.375315
FineTuningLR 0.646622
Epoch 49 | Batch 90/100 | Loss 0.171798
InnerLR 0.375538
FineTuningLR 0.646196
100 Accuracy = 86.67% +- 1.73%
Epoch 49: 86.67
Epoch 50 | Batch 0/100 | Loss 0.115436
InnerLR 0.375348
FineTuningLR 0.645617
Epoch 50 | Batch 10/100 | Loss 0.140078
InnerLR 0.375016
FineTuningLR 0.645625
Epoch 50 | Batch 20/100 | Loss 0.127546
InnerLR 0.374786
FineTuningLR 0.645571
Epoch 50 | Batch 30/100 | Loss 0.134164
InnerLR 0.374431
FineTuningLR 0.645400
Epoch 50 | Batch 40/100 | Loss 0.155053
InnerLR 0.373767
FineTuningLR 0.645063
Epoch 50 | Batch 50/100 | Loss 0.149599
InnerLR 0.373255
FineTuningLR 0.644675
Epoch 50 | Batch 60/100 | Loss 0.152896
InnerLR 0.372255
FineTuningLR 0.644757
Epoch 50 | Batch 70/100 | Loss 0.163340
InnerLR 0.372076
FineTuningLR 0.644857
Epoch 50 | Batch 80/100 | Loss 0.169976
InnerLR 0.372187
FineTuningLR 0.644340
Epoch 50 | Batch 90/100 | Loss 0.175114
InnerLR 0.372456
FineTuningLR 0.643568
100 Accuracy = 84.28% +- 1.91%
Epoch 50: 84.28
Epoch 51 | Batch 0/100 | Loss 0.120966
InnerLR 0.372802
FineTuningLR 0.641986
Epoch 51 | Batch 10/100 | Loss 0.216780
InnerLR 0.372663
FineTuningLR 0.640734
Epoch 51 | Batch 20/100 | Loss 0.257084
InnerLR 0.372166
FineTuningLR 0.638636
Epoch 51 | Batch 30/100 | Loss 0.245994
InnerLR 0.371903
FineTuningLR 0.637284
Epoch 51 | Batch 40/100 | Loss 0.213829
InnerLR 0.371656
FineTuningLR 0.635861
Epoch 51 | Batch 50/100 | Loss 0.207928
InnerLR 0.371896
FineTuningLR 0.635012
Epoch 51 | Batch 60/100 | Loss 0.227741
InnerLR 0.372091
FineTuningLR 0.634063
Epoch 51 | Batch 70/100 | Loss 0.221906
InnerLR 0.372220
FineTuningLR 0.633552
Epoch 51 | Batch 80/100 | Loss 0.212831
InnerLR 0.371987
FineTuningLR 0.632918
Epoch 51 | Batch 90/100 | Loss 0.202773
InnerLR 0.372304
FineTuningLR 0.632360
100 Accuracy = 83.97% +- 2.16%
Epoch 51: 83.97
Epoch 52 | Batch 0/100 | Loss 0.103179
InnerLR 0.372344
FineTuningLR 0.631852
Epoch 52 | Batch 10/100 | Loss 0.177674
InnerLR 0.372713
FineTuningLR 0.631382
Epoch 52 | Batch 20/100 | Loss 0.164742
InnerLR 0.372969
FineTuningLR 0.631092
Epoch 52 | Batch 30/100 | Loss 0.168961
InnerLR 0.373103
FineTuningLR 0.630801
Epoch 52 | Batch 40/100 | Loss 0.151448
InnerLR 0.373430
FineTuningLR 0.630522
Epoch 52 | Batch 50/100 | Loss 0.158150
InnerLR 0.373720
FineTuningLR 0.630272
Epoch 52 | Batch 60/100 | Loss 0.167369
InnerLR 0.374803
FineTuningLR 0.629844
Epoch 52 | Batch 70/100 | Loss 0.166431
InnerLR 0.375275
FineTuningLR 0.629474
Epoch 52 | Batch 80/100 | Loss 0.168543
InnerLR 0.375474
FineTuningLR 0.628424
Epoch 52 | Batch 90/100 | Loss 0.173400
InnerLR 0.375612
FineTuningLR 0.627927
100 Accuracy = 84.65% +- 1.95%
Epoch 52: 84.65
Epoch 53 | Batch 0/100 | Loss 0.148932
InnerLR 0.375319
FineTuningLR 0.626900
Epoch 53 | Batch 10/100 | Loss 0.177657
InnerLR 0.375046
FineTuningLR 0.626605
Epoch 53 | Batch 20/100 | Loss 0.186183
InnerLR 0.374674
FineTuningLR 0.626313
Epoch 53 | Batch 30/100 | Loss 0.173463
InnerLR 0.374651
FineTuningLR 0.626176
Epoch 53 | Batch 40/100 | Loss 0.178431
InnerLR 0.374667
FineTuningLR 0.625641
Epoch 53 | Batch 50/100 | Loss 0.170624
InnerLR 0.374763
FineTuningLR 0.625280
Epoch 53 | Batch 60/100 | Loss 0.165600
InnerLR 0.375034
FineTuningLR 0.624399
Epoch 53 | Batch 70/100 | Loss 0.169080
InnerLR 0.375266
FineTuningLR 0.624093
Epoch 53 | Batch 80/100 | Loss 0.181377
InnerLR 0.375474
FineTuningLR 0.623788
Epoch 53 | Batch 90/100 | Loss 0.193068
InnerLR 0.375197
FineTuningLR 0.623416
100 Accuracy = 85.99% +- 1.87%
Epoch 53: 85.99
Epoch 54 | Batch 0/100 | Loss 0.403570
InnerLR 0.374348
FineTuningLR 0.622692
Epoch 54 | Batch 10/100 | Loss 0.182857
InnerLR 0.373884
FineTuningLR 0.621986
Epoch 54 | Batch 20/100 | Loss 0.169266
InnerLR 0.373400
FineTuningLR 0.620800
Epoch 54 | Batch 30/100 | Loss 0.162603
InnerLR 0.372843
FineTuningLR 0.620368
Epoch 54 | Batch 40/100 | Loss 0.153327
InnerLR 0.372047
FineTuningLR 0.620295
Epoch 54 | Batch 50/100 | Loss 0.155774
InnerLR 0.371916
FineTuningLR 0.620071
Epoch 54 | Batch 60/100 | Loss 0.165431
InnerLR 0.371120
FineTuningLR 0.619624
Epoch 54 | Batch 70/100 | Loss 0.173820
InnerLR 0.370428
FineTuningLR 0.619316
Epoch 54 | Batch 80/100 | Loss 0.165526
InnerLR 0.370056
FineTuningLR 0.618842
Epoch 54 | Batch 90/100 | Loss 0.170534
InnerLR 0.369833
FineTuningLR 0.618876
100 Accuracy = 85.45% +- 1.89%
Epoch 54: 85.45
Epoch 55 | Batch 0/100 | Loss 1.560244
InnerLR 0.368931
FineTuningLR 0.619063
Epoch 55 | Batch 10/100 | Loss 0.287246
InnerLR 0.368858
FineTuningLR 0.619045
Epoch 55 | Batch 20/100 | Loss 0.216128
InnerLR 0.369064
FineTuningLR 0.619514
Epoch 55 | Batch 30/100 | Loss 0.200213
InnerLR 0.369335
FineTuningLR 0.620054
Epoch 55 | Batch 40/100 | Loss 0.175258
InnerLR 0.370150
FineTuningLR 0.620593
Epoch 55 | Batch 50/100 | Loss 0.170254
InnerLR 0.370722
FineTuningLR 0.620729
Epoch 55 | Batch 60/100 | Loss 0.183163
InnerLR 0.371219
FineTuningLR 0.620888
Epoch 55 | Batch 70/100 | Loss 0.172187
InnerLR 0.371502
FineTuningLR 0.620944
Epoch 55 | Batch 80/100 | Loss 0.173199
InnerLR 0.371617
FineTuningLR 0.620803
Epoch 55 | Batch 90/100 | Loss 0.179856
InnerLR 0.371783
FineTuningLR 0.620540
100 Accuracy = 86.29% +- 2.22%
Epoch 55: 86.29
Epoch 56 | Batch 0/100 | Loss 0.130073
InnerLR 0.371615
FineTuningLR 0.620776
Epoch 56 | Batch 10/100 | Loss 0.174768
InnerLR 0.371259
FineTuningLR 0.621123
Epoch 56 | Batch 20/100 | Loss 0.153904
InnerLR 0.370668
FineTuningLR 0.621680
Epoch 56 | Batch 30/100 | Loss 0.148159
InnerLR 0.370100
FineTuningLR 0.621997
Epoch 56 | Batch 40/100 | Loss 0.137918
InnerLR 0.369423
FineTuningLR 0.622532
Epoch 56 | Batch 50/100 | Loss 0.196849
InnerLR 0.368740
FineTuningLR 0.622733
Epoch 56 | Batch 60/100 | Loss 0.188543
InnerLR 0.367421
FineTuningLR 0.622672
Epoch 56 | Batch 70/100 | Loss 0.208334
InnerLR 0.366760
FineTuningLR 0.622430
Epoch 56 | Batch 80/100 | Loss 0.204511
InnerLR 0.366619
FineTuningLR 0.621870
Epoch 56 | Batch 90/100 | Loss 0.200540
InnerLR 0.366217
FineTuningLR 0.621951
100 Accuracy = 84.25% +- 2.06%
Epoch 56: 84.25
Epoch 57 | Batch 0/100 | Loss 0.134262
InnerLR 0.364999
FineTuningLR 0.622176
Epoch 57 | Batch 10/100 | Loss 0.155778
InnerLR 0.364522
FineTuningLR 0.622283
Epoch 57 | Batch 20/100 | Loss 0.197747
InnerLR 0.364714
FineTuningLR 0.621750
Epoch 57 | Batch 30/100 | Loss 0.173765
InnerLR 0.365064
FineTuningLR 0.621197
Epoch 57 | Batch 40/100 | Loss 0.161309
InnerLR 0.364886
FineTuningLR 0.621289
Epoch 57 | Batch 50/100 | Loss 0.160181
InnerLR 0.364558
FineTuningLR 0.621859
Epoch 57 | Batch 60/100 | Loss 0.157946
InnerLR 0.363651
FineTuningLR 0.622621
Epoch 57 | Batch 70/100 | Loss 0.159376
InnerLR 0.363158
FineTuningLR 0.622929
Epoch 57 | Batch 80/100 | Loss 0.162415
InnerLR 0.362533
FineTuningLR 0.623334
Epoch 57 | Batch 90/100 | Loss 0.157294
InnerLR 0.362466
FineTuningLR 0.623723
100 Accuracy = 84.87% +- 1.92%
Epoch 57: 84.87
Epoch 58 | Batch 0/100 | Loss 0.119025
InnerLR 0.362246
FineTuningLR 0.624335
Epoch 58 | Batch 10/100 | Loss 0.177542
InnerLR 0.361969
FineTuningLR 0.624566
Epoch 58 | Batch 20/100 | Loss 0.211473
InnerLR 0.362176
FineTuningLR 0.624882
Epoch 58 | Batch 30/100 | Loss 0.182685
InnerLR 0.361841
FineTuningLR 0.625097
Epoch 58 | Batch 40/100 | Loss 0.179849
InnerLR 0.361235
FineTuningLR 0.625689
Epoch 58 | Batch 50/100 | Loss 0.168606
InnerLR 0.360427
FineTuningLR 0.626330
Epoch 58 | Batch 60/100 | Loss 0.168362
InnerLR 0.358770
FineTuningLR 0.627744
Epoch 58 | Batch 70/100 | Loss 0.170368
InnerLR 0.357663
FineTuningLR 0.628742
Epoch 58 | Batch 80/100 | Loss 0.169238
InnerLR 0.356596
FineTuningLR 0.629444
Epoch 58 | Batch 90/100 | Loss 0.166213
InnerLR 0.355725
FineTuningLR 0.629982
100 Accuracy = 85.37% +- 1.72%
Epoch 58: 85.37
Epoch 59 | Batch 0/100 | Loss 0.167741
InnerLR 0.355007
FineTuningLR 0.630434
Epoch 59 | Batch 10/100 | Loss 0.144638
InnerLR 0.354731
FineTuningLR 0.630444
Epoch 59 | Batch 20/100 | Loss 0.176977
InnerLR 0.354298
FineTuningLR 0.630875
Epoch 59 | Batch 30/100 | Loss 0.162456
InnerLR 0.353712
FineTuningLR 0.631056
Epoch 59 | Batch 40/100 | Loss 0.152129
InnerLR 0.352572
FineTuningLR 0.631762
Epoch 59 | Batch 50/100 | Loss 0.180259
InnerLR 0.352009
FineTuningLR 0.632189
Epoch 59 | Batch 60/100 | Loss 0.175604
InnerLR 0.350894
FineTuningLR 0.633095
Epoch 59 | Batch 70/100 | Loss 0.188225
InnerLR 0.350446
FineTuningLR 0.633450
Epoch 59 | Batch 80/100 | Loss 0.178095
InnerLR 0.350196
FineTuningLR 0.634162
Epoch 59 | Batch 90/100 | Loss 0.182028
InnerLR 0.349628
FineTuningLR 0.635006
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 84.65% +- 1.84%
Epoch 59: 84.65
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_16_lr_0.001/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_16_lr_0.001/tabula_muris/leo_FCNet/20231211_174753
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 98.16% +- 0.20%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_16_lr_0.001/tabula_muris/leo_FCNet/20231211_174753
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 84.79% +- 0.84%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_16_lr_0.001/tabula_muris/leo_FCNet/20231211_174753
600 Accuracy = 84.81% +- 0.70%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_16_lr_0.001/results.txt
+-------+-------------------+--------------------+
| split |      acc_mean     |      acc_std       |
+-------+-------------------+--------------------+
| train | 98.15777777777777 | 2.4894433906119917 |
|  val  | 84.78888888888888 | 10.516295409306572 |
|  test | 84.80888888888889 | 8.806928809847868  |
+-------+-------------------+--------------------+
