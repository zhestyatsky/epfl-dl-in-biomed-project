/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 5
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 5
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 5
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 0.5
    finetuning_lr_init: 0.05
    num_adaptation_steps: 5
    kl_coef: 0.01
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 0.1
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 8
    enable_finetuning_loop: true
  n_task: 4
  latent_space_dim: 8
  leo_inner_lr_init: 0.5
  leo_finetuning_lr_init: 0.05
  num_adaptation_steps: 5
  kl_coef: 0.01
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 0.1
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-06
  optimize_backbone: false
  pretrained_backbone_weights_path: pretrained_weights/tabula_muris_baseline_model.tar
  enable_finetuning_loop: true
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0003
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.0003
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.0003
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0003/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Using pretrained backbone from pretrained_weights/tabula_muris_baseline_model.tar.
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=8, bias=False)
    (relation_net): Sequential(
      (0): Linear(in_features=16, out_features=16, bias=False)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=16, bias=False)
      (3): ReLU()
      (4): Linear(in_features=16, out_features=16, bias=False)
    )
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=8, out_features=130, bias=False)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 1e-06

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 0
)
Epoch 0 | Batch 0/100 | Loss 2.793048
InnerLR 0.500000
FineTuningLR 0.050000
Epoch 0 | Batch 10/100 | Loss 5.396592
InnerLR 0.500600
FineTuningLR 0.050600
Epoch 0 | Batch 20/100 | Loss 5.754649
InnerLR 0.501415
FineTuningLR 0.051499
Epoch 0 | Batch 30/100 | Loss 5.719268
InnerLR 0.501970
FineTuningLR 0.052094
Epoch 0 | Batch 40/100 | Loss 5.489640
InnerLR 0.502836
FineTuningLR 0.052982
Epoch 0 | Batch 50/100 | Loss 5.643929
InnerLR 0.503425
FineTuningLR 0.053573
Epoch 0 | Batch 60/100 | Loss 5.524428
InnerLR 0.504318
FineTuningLR 0.054459
Epoch 0 | Batch 70/100 | Loss 5.567571
InnerLR 0.504918
FineTuningLR 0.055049
Epoch 0 | Batch 80/100 | Loss 5.560124
InnerLR 0.505821
FineTuningLR 0.055935
Epoch 0 | Batch 90/100 | Loss 5.475638
InnerLR 0.506425
FineTuningLR 0.056526
100 Accuracy = 49.53% +- 2.29%
Epoch 0: 49.53
best model! save...
Epoch 1 | Batch 0/100 | Loss 5.649533
InnerLR 0.507332
FineTuningLR 0.057413
Epoch 1 | Batch 10/100 | Loss 6.019801
InnerLR 0.507938
FineTuningLR 0.058005
Epoch 1 | Batch 20/100 | Loss 5.628174
InnerLR 0.508847
FineTuningLR 0.058893
Epoch 1 | Batch 30/100 | Loss 5.235878
InnerLR 0.509453
FineTuningLR 0.059485
Epoch 1 | Batch 40/100 | Loss 5.350309
InnerLR 0.510363
FineTuningLR 0.060374
Epoch 1 | Batch 50/100 | Loss 5.282862
InnerLR 0.510969
FineTuningLR 0.060967
Epoch 1 | Batch 60/100 | Loss 5.329195
InnerLR 0.511879
FineTuningLR 0.061856
Epoch 1 | Batch 70/100 | Loss 5.442903
InnerLR 0.512485
FineTuningLR 0.062450
Epoch 1 | Batch 80/100 | Loss 5.508441
InnerLR 0.513393
FineTuningLR 0.063341
Epoch 1 | Batch 90/100 | Loss 5.374762
InnerLR 0.513938
FineTuningLR 0.063935
100 Accuracy = 50.41% +- 2.11%
Epoch 1: 50.41
best model! save...
Epoch 2 | Batch 0/100 | Loss 6.783336
InnerLR 0.514698
FineTuningLR 0.064826
Epoch 2 | Batch 10/100 | Loss 5.331964
InnerLR 0.515227
FineTuningLR 0.065421
Epoch 2 | Batch 20/100 | Loss 5.440309
InnerLR 0.516048
FineTuningLR 0.066313
Epoch 2 | Batch 30/100 | Loss 5.019883
InnerLR 0.516493
FineTuningLR 0.066908
Epoch 2 | Batch 40/100 | Loss 4.907000
InnerLR 0.517215
FineTuningLR 0.067801
Epoch 2 | Batch 50/100 | Loss 4.877472
InnerLR 0.517726
FineTuningLR 0.068396
Epoch 2 | Batch 60/100 | Loss 4.886209
InnerLR 0.518524
FineTuningLR 0.069289
Epoch 2 | Batch 70/100 | Loss 4.730129
InnerLR 0.519072
FineTuningLR 0.069885
Epoch 2 | Batch 80/100 | Loss 4.689299
InnerLR 0.519914
FineTuningLR 0.070779
Epoch 2 | Batch 90/100 | Loss 4.627128
InnerLR 0.520486
FineTuningLR 0.071375
100 Accuracy = 54.32% +- 2.51%
Epoch 2: 54.32
best model! save...
Epoch 3 | Batch 0/100 | Loss 2.851640
InnerLR 0.521354
FineTuningLR 0.072269
Epoch 3 | Batch 10/100 | Loss 4.697255
InnerLR 0.521938
FineTuningLR 0.072865
Epoch 3 | Batch 20/100 | Loss 4.173235
InnerLR 0.522821
FineTuningLR 0.073760
Epoch 3 | Batch 30/100 | Loss 4.100296
InnerLR 0.523413
FineTuningLR 0.074356
Epoch 3 | Batch 40/100 | Loss 4.177443
InnerLR 0.524245
FineTuningLR 0.075251
Epoch 3 | Batch 50/100 | Loss 4.140227
InnerLR 0.524738
FineTuningLR 0.075848
Epoch 3 | Batch 60/100 | Loss 4.158835
InnerLR 0.525516
FineTuningLR 0.076743
Epoch 3 | Batch 70/100 | Loss 4.069366
InnerLR 0.526055
FineTuningLR 0.077340
Epoch 3 | Batch 80/100 | Loss 4.167646
InnerLR 0.526770
FineTuningLR 0.078236
Epoch 3 | Batch 90/100 | Loss 4.178130
InnerLR 0.527241
FineTuningLR 0.078833
100 Accuracy = 56.73% +- 2.09%
Epoch 3: 56.73
best model! save...
Epoch 4 | Batch 0/100 | Loss 5.684351
InnerLR 0.527934
FineTuningLR 0.079728
Epoch 4 | Batch 10/100 | Loss 4.121667
InnerLR 0.528296
FineTuningLR 0.080326
Epoch 4 | Batch 20/100 | Loss 4.030461
InnerLR 0.528785
FineTuningLR 0.081221
Epoch 4 | Batch 30/100 | Loss 4.057330
InnerLR 0.528988
FineTuningLR 0.081819
Epoch 4 | Batch 40/100 | Loss 4.102516
InnerLR 0.529431
FineTuningLR 0.082715
Epoch 4 | Batch 50/100 | Loss 4.021517
InnerLR 0.529797
FineTuningLR 0.083312
Epoch 4 | Batch 60/100 | Loss 3.927629
InnerLR 0.530429
FineTuningLR 0.084209
Epoch 4 | Batch 70/100 | Loss 3.843511
InnerLR 0.530892
FineTuningLR 0.084806
Epoch 4 | Batch 80/100 | Loss 3.858843
InnerLR 0.531635
FineTuningLR 0.085703
Epoch 4 | Batch 90/100 | Loss 3.853875
InnerLR 0.532155
FineTuningLR 0.086300
100 Accuracy = 56.79% +- 2.60%
Epoch 4: 56.79
best model! save...
Epoch 5 | Batch 0/100 | Loss 3.870146
InnerLR 0.532964
FineTuningLR 0.087197
Epoch 5 | Batch 10/100 | Loss 3.781442
InnerLR 0.533457
FineTuningLR 0.087795
Epoch 5 | Batch 20/100 | Loss 4.073468
InnerLR 0.534142
FineTuningLR 0.088701
Epoch 5 | Batch 30/100 | Loss 3.916780
InnerLR 0.534500
FineTuningLR 0.089314
Epoch 5 | Batch 40/100 | Loss 4.035236
InnerLR 0.535121
FineTuningLR 0.090228
Epoch 5 | Batch 50/100 | Loss 4.095461
InnerLR 0.535518
FineTuningLR 0.090834
Epoch 5 | Batch 60/100 | Loss 3.956184
InnerLR 0.535945
FineTuningLR 0.091740
Epoch 5 | Batch 70/100 | Loss 4.023812
InnerLR 0.536304
FineTuningLR 0.092342
Epoch 5 | Batch 80/100 | Loss 3.924018
InnerLR 0.536927
FineTuningLR 0.093244
Epoch 5 | Batch 90/100 | Loss 3.884349
InnerLR 0.537386
FineTuningLR 0.093844
100 Accuracy = 58.41% +- 2.15%
Epoch 5: 58.41
best model! save...
Epoch 6 | Batch 0/100 | Loss 3.085426
InnerLR 0.537961
FineTuningLR 0.094743
Epoch 6 | Batch 10/100 | Loss 3.140421
InnerLR 0.538335
FineTuningLR 0.095341
Epoch 6 | Batch 20/100 | Loss 3.396769
InnerLR 0.538619
FineTuningLR 0.096239
Epoch 6 | Batch 30/100 | Loss 3.173854
InnerLR 0.538811
FineTuningLR 0.096837
Epoch 6 | Batch 40/100 | Loss 3.360090
InnerLR 0.539163
FineTuningLR 0.097733
Epoch 6 | Batch 50/100 | Loss 3.362751
InnerLR 0.539369
FineTuningLR 0.098331
Epoch 6 | Batch 60/100 | Loss 3.382701
InnerLR 0.539651
FineTuningLR 0.099227
Epoch 6 | Batch 70/100 | Loss 3.346242
InnerLR 0.539876
FineTuningLR 0.099824
Epoch 6 | Batch 80/100 | Loss 3.298535
InnerLR 0.539988
FineTuningLR 0.100720
Epoch 6 | Batch 90/100 | Loss 3.280855
InnerLR 0.540152
FineTuningLR 0.101317
100 Accuracy = 61.85% +- 2.03%
Epoch 6: 61.85
best model! save...
Epoch 7 | Batch 0/100 | Loss 4.778327
InnerLR 0.540436
FineTuningLR 0.102234
Epoch 7 | Batch 10/100 | Loss 3.329406
InnerLR 0.540634
FineTuningLR 0.102849
Epoch 7 | Batch 20/100 | Loss 3.068503
InnerLR 0.540733
FineTuningLR 0.103764
Epoch 7 | Batch 30/100 | Loss 3.203760
InnerLR 0.540817
FineTuningLR 0.104370
Epoch 7 | Batch 40/100 | Loss 3.125111
InnerLR 0.541008
FineTuningLR 0.105277
Epoch 7 | Batch 50/100 | Loss 3.157177
InnerLR 0.541212
FineTuningLR 0.105879
Epoch 7 | Batch 60/100 | Loss 3.144448
InnerLR 0.541657
FineTuningLR 0.106780
Epoch 7 | Batch 70/100 | Loss 3.150539
InnerLR 0.541850
FineTuningLR 0.107379
Epoch 7 | Batch 80/100 | Loss 3.142563
InnerLR 0.541935
FineTuningLR 0.108286
Epoch 7 | Batch 90/100 | Loss 3.134492
InnerLR 0.541909
FineTuningLR 0.108888
100 Accuracy = 62.05% +- 2.53%
Epoch 7: 62.05
best model! save...
Epoch 8 | Batch 0/100 | Loss 3.941984
InnerLR 0.541847
FineTuningLR 0.109789
Epoch 8 | Batch 10/100 | Loss 2.933582
InnerLR 0.541904
FineTuningLR 0.110394
Epoch 8 | Batch 20/100 | Loss 2.870977
InnerLR 0.542051
FineTuningLR 0.111307
Epoch 8 | Batch 30/100 | Loss 2.706925
InnerLR 0.542080
FineTuningLR 0.111912
Epoch 8 | Batch 40/100 | Loss 2.736771
InnerLR 0.542098
FineTuningLR 0.112816
Epoch 8 | Batch 50/100 | Loss 2.816275
InnerLR 0.542060
FineTuningLR 0.113417
Epoch 8 | Batch 60/100 | Loss 2.777958
InnerLR 0.542050
FineTuningLR 0.114317
Epoch 8 | Batch 70/100 | Loss 2.721627
InnerLR 0.541964
FineTuningLR 0.114916
Epoch 8 | Batch 80/100 | Loss 2.720505
InnerLR 0.541758
FineTuningLR 0.115828
Epoch 8 | Batch 90/100 | Loss 2.653937
InnerLR 0.541693
FineTuningLR 0.116438
100 Accuracy = 65.21% +- 1.93%
Epoch 8: 65.21
best model! save...
Epoch 9 | Batch 0/100 | Loss 1.690601
InnerLR 0.541549
FineTuningLR 0.117347
Epoch 9 | Batch 10/100 | Loss 2.317687
InnerLR 0.541406
FineTuningLR 0.117950
Epoch 9 | Batch 20/100 | Loss 2.463609
InnerLR 0.541312
FineTuningLR 0.118852
Epoch 9 | Batch 30/100 | Loss 2.434573
InnerLR 0.541157
FineTuningLR 0.119452
Epoch 9 | Batch 40/100 | Loss 2.324196
InnerLR 0.540783
FineTuningLR 0.120359
Epoch 9 | Batch 50/100 | Loss 2.480832
InnerLR 0.540584
FineTuningLR 0.120972
Epoch 9 | Batch 60/100 | Loss 2.450649
InnerLR 0.540144
FineTuningLR 0.121885
Epoch 9 | Batch 70/100 | Loss 2.418791
InnerLR 0.539778
FineTuningLR 0.122490
Epoch 9 | Batch 80/100 | Loss 2.431392
InnerLR 0.539292
FineTuningLR 0.123413
Epoch 9 | Batch 90/100 | Loss 2.412076
InnerLR 0.538967
FineTuningLR 0.124041
100 Accuracy = 63.33% +- 1.85%
Epoch 9: 63.33
Epoch 10 | Batch 0/100 | Loss 1.236681
InnerLR 0.538389
FineTuningLR 0.124975
Epoch 10 | Batch 10/100 | Loss 2.398358
InnerLR 0.538067
FineTuningLR 0.125591
Epoch 10 | Batch 20/100 | Loss 2.333810
InnerLR 0.537486
FineTuningLR 0.126507
Epoch 10 | Batch 30/100 | Loss 2.291416
InnerLR 0.537223
FineTuningLR 0.127113
Epoch 10 | Batch 40/100 | Loss 2.211521
InnerLR 0.536904
FineTuningLR 0.128018
Epoch 10 | Batch 50/100 | Loss 2.105258
InnerLR 0.536633
FineTuningLR 0.128619
Epoch 10 | Batch 60/100 | Loss 2.201614
InnerLR 0.536111
FineTuningLR 0.129517
Epoch 10 | Batch 70/100 | Loss 2.164395
InnerLR 0.535879
FineTuningLR 0.130115
Epoch 10 | Batch 80/100 | Loss 2.205874
InnerLR 0.535644
FineTuningLR 0.131010
Epoch 10 | Batch 90/100 | Loss 2.161104
InnerLR 0.535498
FineTuningLR 0.131606
100 Accuracy = 65.64% +- 2.19%
Epoch 10: 65.64
best model! save...
Epoch 11 | Batch 0/100 | Loss 1.011372
InnerLR 0.535284
FineTuningLR 0.132498
Epoch 11 | Batch 10/100 | Loss 1.847291
InnerLR 0.535033
FineTuningLR 0.133093
Epoch 11 | Batch 20/100 | Loss 1.802206
InnerLR 0.534594
FineTuningLR 0.133985
Epoch 11 | Batch 30/100 | Loss 1.729991
InnerLR 0.534301
FineTuningLR 0.134579
Epoch 11 | Batch 40/100 | Loss 1.861159
InnerLR 0.533753
FineTuningLR 0.135470
Epoch 11 | Batch 50/100 | Loss 1.915709
InnerLR 0.533447
FineTuningLR 0.136064
Epoch 11 | Batch 60/100 | Loss 1.947922
InnerLR 0.532884
FineTuningLR 0.136954
Epoch 11 | Batch 70/100 | Loss 1.947027
InnerLR 0.532570
FineTuningLR 0.137548
Epoch 11 | Batch 80/100 | Loss 1.956604
InnerLR 0.532163
FineTuningLR 0.138439
Epoch 11 | Batch 90/100 | Loss 1.926054
InnerLR 0.531928
FineTuningLR 0.139032
100 Accuracy = 66.84% +- 2.11%
Epoch 11: 66.84
best model! save...
Epoch 12 | Batch 0/100 | Loss 1.173242
InnerLR 0.531673
FineTuningLR 0.139923
Epoch 12 | Batch 10/100 | Loss 1.796933
InnerLR 0.531474
FineTuningLR 0.140517
Epoch 12 | Batch 20/100 | Loss 1.967557
InnerLR 0.531151
FineTuningLR 0.141408
Epoch 12 | Batch 30/100 | Loss 1.894255
InnerLR 0.530878
FineTuningLR 0.142001
Epoch 12 | Batch 40/100 | Loss 1.788832
InnerLR 0.530354
FineTuningLR 0.142892
Epoch 12 | Batch 50/100 | Loss 1.732976
InnerLR 0.530006
FineTuningLR 0.143486
Epoch 12 | Batch 60/100 | Loss 1.757159
InnerLR 0.529532
FineTuningLR 0.144377
Epoch 12 | Batch 70/100 | Loss 1.761255
InnerLR 0.529222
FineTuningLR 0.144971
Epoch 12 | Batch 80/100 | Loss 1.718252
InnerLR 0.528654
FineTuningLR 0.145862
Epoch 12 | Batch 90/100 | Loss 1.742990
InnerLR 0.528223
FineTuningLR 0.146456
100 Accuracy = 68.15% +- 2.27%
Epoch 12: 68.15
best model! save...
Epoch 13 | Batch 0/100 | Loss 2.544772
InnerLR 0.527576
FineTuningLR 0.147348
Epoch 13 | Batch 10/100 | Loss 1.477384
InnerLR 0.527176
FineTuningLR 0.147942
Epoch 13 | Batch 20/100 | Loss 1.485727
InnerLR 0.526621
FineTuningLR 0.148833
Epoch 13 | Batch 30/100 | Loss 1.619764
InnerLR 0.526231
FineTuningLR 0.149428
Epoch 13 | Batch 40/100 | Loss 1.775517
InnerLR 0.525571
FineTuningLR 0.150319
Epoch 13 | Batch 50/100 | Loss 1.747971
InnerLR 0.525092
FineTuningLR 0.150914
Epoch 13 | Batch 60/100 | Loss 1.717734
InnerLR 0.524330
FineTuningLR 0.151805
Epoch 13 | Batch 70/100 | Loss 1.691932
InnerLR 0.523800
FineTuningLR 0.152400
Epoch 13 | Batch 80/100 | Loss 1.663475
InnerLR 0.523039
FineTuningLR 0.153292
Epoch 13 | Batch 90/100 | Loss 1.654561
InnerLR 0.522581
FineTuningLR 0.153886
100 Accuracy = 70.28% +- 2.30%
Epoch 13: 70.28
best model! save...
Epoch 14 | Batch 0/100 | Loss 0.990717
InnerLR 0.521843
FineTuningLR 0.154778
Epoch 14 | Batch 10/100 | Loss 1.541141
InnerLR 0.521325
FineTuningLR 0.155373
Epoch 14 | Batch 20/100 | Loss 1.426314
InnerLR 0.520578
FineTuningLR 0.156265
Epoch 14 | Batch 30/100 | Loss 1.466437
InnerLR 0.520128
FineTuningLR 0.156860
Epoch 14 | Batch 40/100 | Loss 1.461120
InnerLR 0.519403
FineTuningLR 0.157755
Epoch 14 | Batch 50/100 | Loss 1.463806
InnerLR 0.518897
FineTuningLR 0.158356
Epoch 14 | Batch 60/100 | Loss 1.466618
InnerLR 0.518103
FineTuningLR 0.159256
Epoch 14 | Batch 70/100 | Loss 1.425989
InnerLR 0.517556
FineTuningLR 0.159854
Epoch 14 | Batch 80/100 | Loss 1.405703
InnerLR 0.516879
FineTuningLR 0.160750
Epoch 14 | Batch 90/100 | Loss 1.383883
InnerLR 0.516392
FineTuningLR 0.161347
100 Accuracy = 70.69% +- 2.02%
Epoch 14: 70.69
best model! save...
Epoch 15 | Batch 0/100 | Loss 0.617197
InnerLR 0.515621
FineTuningLR 0.162242
Epoch 15 | Batch 10/100 | Loss 1.440261
InnerLR 0.515200
FineTuningLR 0.162838
Epoch 15 | Batch 20/100 | Loss 1.373206
InnerLR 0.514506
FineTuningLR 0.163732
Epoch 15 | Batch 30/100 | Loss 1.294968
InnerLR 0.514010
FineTuningLR 0.164328
Epoch 15 | Batch 40/100 | Loss 1.297288
InnerLR 0.513228
FineTuningLR 0.165221
Epoch 15 | Batch 50/100 | Loss 1.282762
InnerLR 0.512692
FineTuningLR 0.165820
Epoch 15 | Batch 60/100 | Loss 1.271137
InnerLR 0.511869
FineTuningLR 0.166722
Epoch 15 | Batch 70/100 | Loss 1.237794
InnerLR 0.511307
FineTuningLR 0.167321
Epoch 15 | Batch 80/100 | Loss 1.224039
InnerLR 0.510449
FineTuningLR 0.168219
Epoch 15 | Batch 90/100 | Loss 1.221857
InnerLR 0.509869
FineTuningLR 0.168817
100 Accuracy = 70.64% +- 2.13%
Epoch 15: 70.64
Epoch 16 | Batch 0/100 | Loss 1.392706
InnerLR 0.508991
FineTuningLR 0.169713
Epoch 16 | Batch 10/100 | Loss 1.353655
InnerLR 0.508401
FineTuningLR 0.170310
Epoch 16 | Batch 20/100 | Loss 1.270009
InnerLR 0.507511
FineTuningLR 0.171204
Epoch 16 | Batch 30/100 | Loss 1.134136
InnerLR 0.506915
FineTuningLR 0.171800
Epoch 16 | Batch 40/100 | Loss 1.101013
InnerLR 0.506018
FineTuningLR 0.172694
Epoch 16 | Batch 50/100 | Loss 1.025296
InnerLR 0.505479
FineTuningLR 0.173290
Epoch 16 | Batch 60/100 | Loss 1.017664
InnerLR 0.504725
FineTuningLR 0.174183
Epoch 16 | Batch 70/100 | Loss 0.977373
InnerLR 0.504199
FineTuningLR 0.174779
Epoch 16 | Batch 80/100 | Loss 0.964494
InnerLR 0.503382
FineTuningLR 0.175672
Epoch 16 | Batch 90/100 | Loss 0.970498
InnerLR 0.502824
FineTuningLR 0.176268
100 Accuracy = 74.53% +- 2.06%
Epoch 16: 74.53
best model! save...
Epoch 17 | Batch 0/100 | Loss 1.030334
InnerLR 0.501970
FineTuningLR 0.177161
Epoch 17 | Batch 10/100 | Loss 0.839963
InnerLR 0.501393
FineTuningLR 0.177756
Epoch 17 | Batch 20/100 | Loss 0.930672
InnerLR 0.500517
FineTuningLR 0.178650
Epoch 17 | Batch 30/100 | Loss 0.933801
InnerLR 0.499929
FineTuningLR 0.179245
Epoch 17 | Batch 40/100 | Loss 0.898378
InnerLR 0.499040
FineTuningLR 0.180138
Epoch 17 | Batch 50/100 | Loss 0.879099
InnerLR 0.498445
FineTuningLR 0.180734
Epoch 17 | Batch 60/100 | Loss 0.878609
InnerLR 0.497549
FineTuningLR 0.181627
Epoch 17 | Batch 70/100 | Loss 0.866443
InnerLR 0.496976
FineTuningLR 0.182240
Epoch 17 | Batch 80/100 | Loss 0.863091
InnerLR 0.496106
FineTuningLR 0.183152
Epoch 17 | Batch 90/100 | Loss 0.862345
InnerLR 0.495519
FineTuningLR 0.183757
100 Accuracy = 74.16% +- 2.11%
Epoch 17: 74.16
Epoch 18 | Batch 0/100 | Loss 0.618491
InnerLR 0.494634
FineTuningLR 0.184662
Epoch 18 | Batch 10/100 | Loss 0.755589
InnerLR 0.494040
FineTuningLR 0.185263
Epoch 18 | Batch 20/100 | Loss 0.771287
InnerLR 0.493145
FineTuningLR 0.186163
Epoch 18 | Batch 30/100 | Loss 0.741355
InnerLR 0.492547
FineTuningLR 0.186762
Epoch 18 | Batch 40/100 | Loss 0.719509
InnerLR 0.491647
FineTuningLR 0.187658
Epoch 18 | Batch 50/100 | Loss 0.695324
InnerLR 0.491046
FineTuningLR 0.188256
Epoch 18 | Batch 60/100 | Loss 0.679347
InnerLR 0.490144
FineTuningLR 0.189151
Epoch 18 | Batch 70/100 | Loss 0.667288
InnerLR 0.489541
FineTuningLR 0.189748
Epoch 18 | Batch 80/100 | Loss 0.664532
InnerLR 0.488636
FineTuningLR 0.190642
Epoch 18 | Batch 90/100 | Loss 0.666865
InnerLR 0.488033
FineTuningLR 0.191238
100 Accuracy = 73.00% +- 2.12%
Epoch 18: 73.00
Epoch 19 | Batch 0/100 | Loss 0.512105
InnerLR 0.487128
FineTuningLR 0.192132
Epoch 19 | Batch 10/100 | Loss 0.557540
InnerLR 0.486524
FineTuningLR 0.192728
Epoch 19 | Batch 20/100 | Loss 0.665800
InnerLR 0.485618
FineTuningLR 0.193622
Epoch 19 | Batch 30/100 | Loss 0.659674
InnerLR 0.485014
FineTuningLR 0.194217
Epoch 19 | Batch 40/100 | Loss 0.665080
InnerLR 0.484107
FineTuningLR 0.195111
Epoch 19 | Batch 50/100 | Loss 0.645761
InnerLR 0.483503
FineTuningLR 0.195707
Epoch 19 | Batch 60/100 | Loss 0.614235
InnerLR 0.482596
FineTuningLR 0.196600
Epoch 19 | Batch 70/100 | Loss 0.616972
InnerLR 0.481992
FineTuningLR 0.197196
Epoch 19 | Batch 80/100 | Loss 0.623472
InnerLR 0.481086
FineTuningLR 0.198089
Epoch 19 | Batch 90/100 | Loss 0.623586
InnerLR 0.480481
FineTuningLR 0.198685
100 Accuracy = 77.51% +- 2.04%
Epoch 19: 77.51
best model! save...
Epoch 20 | Batch 0/100 | Loss 0.579515
InnerLR 0.479575
FineTuningLR 0.199579
Epoch 20 | Batch 10/100 | Loss 0.530206
InnerLR 0.478970
FineTuningLR 0.200174
Epoch 20 | Batch 20/100 | Loss 0.521130
InnerLR 0.478064
FineTuningLR 0.201068
Epoch 20 | Batch 30/100 | Loss 0.496077
InnerLR 0.477460
FineTuningLR 0.201664
Epoch 20 | Batch 40/100 | Loss 0.528846
InnerLR 0.476553
FineTuningLR 0.202558
Epoch 20 | Batch 50/100 | Loss 0.526567
InnerLR 0.475949
FineTuningLR 0.203153
Epoch 20 | Batch 60/100 | Loss 0.523626
InnerLR 0.475043
FineTuningLR 0.204047
Epoch 20 | Batch 70/100 | Loss 0.509184
InnerLR 0.474438
FineTuningLR 0.204643
Epoch 20 | Batch 80/100 | Loss 0.514234
InnerLR 0.473532
FineTuningLR 0.205537
Epoch 20 | Batch 90/100 | Loss 0.518216
InnerLR 0.472928
FineTuningLR 0.206133
100 Accuracy = 79.65% +- 1.98%
Epoch 20: 79.65
best model! save...
Epoch 21 | Batch 0/100 | Loss 0.510619
InnerLR 0.472022
FineTuningLR 0.207027
Epoch 21 | Batch 10/100 | Loss 0.480447
InnerLR 0.471418
FineTuningLR 0.207623
Epoch 21 | Batch 20/100 | Loss 0.463359
InnerLR 0.470511
FineTuningLR 0.208517
Epoch 21 | Batch 30/100 | Loss 0.462297
InnerLR 0.469907
FineTuningLR 0.209113
Epoch 21 | Batch 40/100 | Loss 0.456949
InnerLR 0.469001
FineTuningLR 0.210007
Epoch 21 | Batch 50/100 | Loss 0.466586
InnerLR 0.468397
FineTuningLR 0.210603
Epoch 21 | Batch 60/100 | Loss 0.470222
InnerLR 0.467491
FineTuningLR 0.211497
Epoch 21 | Batch 70/100 | Loss 0.470071
InnerLR 0.466887
FineTuningLR 0.212093
Epoch 21 | Batch 80/100 | Loss 0.470859
InnerLR 0.465981
FineTuningLR 0.212987
Epoch 21 | Batch 90/100 | Loss 0.471101
InnerLR 0.465378
FineTuningLR 0.213583
100 Accuracy = 78.31% +- 1.86%
Epoch 21: 78.31
Epoch 22 | Batch 0/100 | Loss 0.348502
InnerLR 0.464472
FineTuningLR 0.214478
Epoch 22 | Batch 10/100 | Loss 0.385665
InnerLR 0.463868
FineTuningLR 0.215074
Epoch 22 | Batch 20/100 | Loss 0.449122
InnerLR 0.462962
FineTuningLR 0.215968
Epoch 22 | Batch 30/100 | Loss 0.471963
InnerLR 0.462358
FineTuningLR 0.216564
Epoch 22 | Batch 40/100 | Loss 0.468909
InnerLR 0.461453
FineTuningLR 0.217459
Epoch 22 | Batch 50/100 | Loss 0.475476
InnerLR 0.460849
FineTuningLR 0.218055
Epoch 22 | Batch 60/100 | Loss 0.468542
InnerLR 0.459943
FineTuningLR 0.218950
Epoch 22 | Batch 70/100 | Loss 0.465265
InnerLR 0.459339
FineTuningLR 0.219546
Epoch 22 | Batch 80/100 | Loss 0.459279
InnerLR 0.458435
FineTuningLR 0.220442
Epoch 22 | Batch 90/100 | Loss 0.460411
InnerLR 0.457833
FineTuningLR 0.221039
100 Accuracy = 77.75% +- 2.33%
Epoch 22: 77.75
Epoch 23 | Batch 0/100 | Loss 0.432067
InnerLR 0.456928
FineTuningLR 0.221935
Epoch 23 | Batch 10/100 | Loss 0.487814
InnerLR 0.456325
FineTuningLR 0.222532
Epoch 23 | Batch 20/100 | Loss 0.447508
InnerLR 0.455421
FineTuningLR 0.223427
Epoch 23 | Batch 30/100 | Loss 0.439085
InnerLR 0.454817
FineTuningLR 0.224024
Epoch 23 | Batch 40/100 | Loss 0.425192
InnerLR 0.453912
FineTuningLR 0.224919
Epoch 23 | Batch 50/100 | Loss 0.416905
InnerLR 0.453309
FineTuningLR 0.225516
Epoch 23 | Batch 60/100 | Loss 0.413288
InnerLR 0.452404
FineTuningLR 0.226411
Epoch 23 | Batch 70/100 | Loss 0.410181
InnerLR 0.451800
FineTuningLR 0.227008
Epoch 23 | Batch 80/100 | Loss 0.407467
InnerLR 0.450895
FineTuningLR 0.227902
Epoch 23 | Batch 90/100 | Loss 0.402056
InnerLR 0.450292
FineTuningLR 0.228499
100 Accuracy = 78.77% +- 1.99%
Epoch 23: 78.77
Epoch 24 | Batch 0/100 | Loss 0.423528
InnerLR 0.449443
FineTuningLR 0.229417
Epoch 24 | Batch 10/100 | Loss 0.373507
InnerLR 0.448885
FineTuningLR 0.230032
Epoch 24 | Batch 20/100 | Loss 0.367309
InnerLR 0.448032
FineTuningLR 0.230948
Epoch 24 | Batch 30/100 | Loss 0.372483
InnerLR 0.447455
FineTuningLR 0.231555
Epoch 24 | Batch 40/100 | Loss 0.388212
InnerLR 0.446580
FineTuningLR 0.232462
Epoch 24 | Batch 50/100 | Loss 0.389282
InnerLR 0.445992
FineTuningLR 0.233065
Epoch 24 | Batch 60/100 | Loss 0.381938
InnerLR 0.445105
FineTuningLR 0.233966
Epoch 24 | Batch 70/100 | Loss 0.378450
InnerLR 0.444510
FineTuningLR 0.234566
Epoch 24 | Batch 80/100 | Loss 0.368313
InnerLR 0.443615
FineTuningLR 0.235465
Epoch 24 | Batch 90/100 | Loss 0.372831
InnerLR 0.443023
FineTuningLR 0.236068
100 Accuracy = 79.29% +- 1.98%
Epoch 24: 79.29
Epoch 25 | Batch 0/100 | Loss 0.325337
InnerLR 0.442137
FineTuningLR 0.236976
Epoch 25 | Batch 10/100 | Loss 0.384232
InnerLR 0.441544
FineTuningLR 0.237580
Epoch 25 | Batch 20/100 | Loss 0.428190
InnerLR 0.440764
FineTuningLR 0.238369
Epoch 25 | Batch 30/100 | Loss 0.407613
InnerLR 0.440260
FineTuningLR 0.238877
Epoch 25 | Batch 40/100 | Loss 0.391768
InnerLR 0.439468
FineTuningLR 0.239670
Epoch 25 | Batch 50/100 | Loss 0.386981
InnerLR 0.438923
FineTuningLR 0.240215
Epoch 25 | Batch 60/100 | Loss 0.374775
InnerLR 0.438084
FineTuningLR 0.241049
Epoch 25 | Batch 70/100 | Loss 0.376623
InnerLR 0.437515
FineTuningLR 0.241615
Epoch 25 | Batch 80/100 | Loss 0.378057
InnerLR 0.436649
FineTuningLR 0.242474
Epoch 25 | Batch 90/100 | Loss 0.371703
InnerLR 0.436079
FineTuningLR 0.243062
100 Accuracy = 78.87% +- 2.06%
Epoch 25: 78.87
Epoch 26 | Batch 0/100 | Loss 0.219802
InnerLR 0.435211
FineTuningLR 0.243948
Epoch 26 | Batch 10/100 | Loss 0.343559
InnerLR 0.434627
FineTuningLR 0.244539
Epoch 26 | Batch 20/100 | Loss 0.349367
InnerLR 0.433744
FineTuningLR 0.245428
Epoch 26 | Batch 30/100 | Loss 0.351009
InnerLR 0.433152
FineTuningLR 0.246022
Epoch 26 | Batch 40/100 | Loss 0.330183
InnerLR 0.432259
FineTuningLR 0.246913
Epoch 26 | Batch 50/100 | Loss 0.354548
InnerLR 0.431662
FineTuningLR 0.247507
Epoch 26 | Batch 60/100 | Loss 0.355036
InnerLR 0.430764
FineTuningLR 0.248399
Epoch 26 | Batch 70/100 | Loss 0.348769
InnerLR 0.430164
FineTuningLR 0.248994
Epoch 26 | Batch 80/100 | Loss 0.343179
InnerLR 0.429307
FineTuningLR 0.249897
Epoch 26 | Batch 90/100 | Loss 0.338376
InnerLR 0.428785
FineTuningLR 0.250513
100 Accuracy = 79.53% +- 2.00%
Epoch 26: 79.53
Epoch 27 | Batch 0/100 | Loss 0.209765
InnerLR 0.427981
FineTuningLR 0.251437
Epoch 27 | Batch 10/100 | Loss 0.365316
InnerLR 0.427439
FineTuningLR 0.252055
Epoch 27 | Batch 20/100 | Loss 0.369839
InnerLR 0.426660
FineTuningLR 0.252910
Epoch 27 | Batch 30/100 | Loss 0.361189
InnerLR 0.426186
FineTuningLR 0.253410
Epoch 27 | Batch 40/100 | Loss 0.365694
InnerLR 0.425430
FineTuningLR 0.254192
Epoch 27 | Batch 50/100 | Loss 0.356004
InnerLR 0.424903
FineTuningLR 0.254730
Epoch 27 | Batch 60/100 | Loss 0.359894
InnerLR 0.424086
FineTuningLR 0.255558
Epoch 27 | Batch 70/100 | Loss 0.352605
InnerLR 0.423526
FineTuningLR 0.256120
Epoch 27 | Batch 80/100 | Loss 0.352632
InnerLR 0.422672
FineTuningLR 0.256974
Epoch 27 | Batch 90/100 | Loss 0.349001
InnerLR 0.422121
FineTuningLR 0.257561
100 Accuracy = 80.44% +- 1.95%
Epoch 27: 80.44
best model! save...
Epoch 28 | Batch 0/100 | Loss 0.211933
InnerLR 0.421310
FineTuningLR 0.258460
Epoch 28 | Batch 10/100 | Loss 0.290007
InnerLR 0.420754
FineTuningLR 0.259059
Epoch 28 | Batch 20/100 | Loss 0.308167
InnerLR 0.419903
FineTuningLR 0.259955
Epoch 28 | Batch 30/100 | Loss 0.306021
InnerLR 0.419327
FineTuningLR 0.260552
Epoch 28 | Batch 40/100 | Loss 0.322228
InnerLR 0.418453
FineTuningLR 0.261447
Epoch 28 | Batch 50/100 | Loss 0.328401
InnerLR 0.417865
FineTuningLR 0.262043
Epoch 28 | Batch 60/100 | Loss 0.336312
InnerLR 0.416977
FineTuningLR 0.262936
Epoch 28 | Batch 70/100 | Loss 0.337684
InnerLR 0.416382
FineTuningLR 0.263532
Epoch 28 | Batch 80/100 | Loss 0.336888
InnerLR 0.415486
FineTuningLR 0.264425
Epoch 28 | Batch 90/100 | Loss 0.331240
InnerLR 0.414887
FineTuningLR 0.265020
100 Accuracy = 83.63% +- 1.65%
Epoch 28: 83.63
best model! save...
Epoch 29 | Batch 0/100 | Loss 0.489753
InnerLR 0.413986
FineTuningLR 0.265913
Epoch 29 | Batch 10/100 | Loss 0.342267
InnerLR 0.413385
FineTuningLR 0.266509
Epoch 29 | Batch 20/100 | Loss 0.320431
InnerLR 0.412481
FineTuningLR 0.267401
Epoch 29 | Batch 30/100 | Loss 0.307059
InnerLR 0.411878
FineTuningLR 0.267997
Epoch 29 | Batch 40/100 | Loss 0.314280
InnerLR 0.410973
FineTuningLR 0.268889
Epoch 29 | Batch 50/100 | Loss 0.324325
InnerLR 0.410369
FineTuningLR 0.269484
Epoch 29 | Batch 60/100 | Loss 0.332072
InnerLR 0.409463
FineTuningLR 0.270377
Epoch 29 | Batch 70/100 | Loss 0.333458
InnerLR 0.408859
FineTuningLR 0.270972
Epoch 29 | Batch 80/100 | Loss 0.322786
InnerLR 0.407952
FineTuningLR 0.271865
Epoch 29 | Batch 90/100 | Loss 0.320818
InnerLR 0.407347
FineTuningLR 0.272460
100 Accuracy = 80.31% +- 1.95%
Epoch 29: 80.31
Epoch 30 | Batch 0/100 | Loss 0.116785
InnerLR 0.406441
FineTuningLR 0.273353
Epoch 30 | Batch 10/100 | Loss 0.261602
InnerLR 0.405836
FineTuningLR 0.273948
Epoch 30 | Batch 20/100 | Loss 0.310710
InnerLR 0.404929
FineTuningLR 0.274841
Epoch 30 | Batch 30/100 | Loss 0.343744
InnerLR 0.404324
FineTuningLR 0.275436
Epoch 30 | Batch 40/100 | Loss 0.327159
InnerLR 0.403417
FineTuningLR 0.276329
Epoch 30 | Batch 50/100 | Loss 0.321168
InnerLR 0.402812
FineTuningLR 0.276925
Epoch 30 | Batch 60/100 | Loss 0.316429
InnerLR 0.401905
FineTuningLR 0.277818
Epoch 30 | Batch 70/100 | Loss 0.310977
InnerLR 0.401300
FineTuningLR 0.278413
Epoch 30 | Batch 80/100 | Loss 0.311055
InnerLR 0.400393
FineTuningLR 0.279306
Epoch 30 | Batch 90/100 | Loss 0.312555
InnerLR 0.399789
FineTuningLR 0.279901
100 Accuracy = 81.13% +- 1.76%
Epoch 30: 81.13
Epoch 31 | Batch 0/100 | Loss 0.258041
InnerLR 0.398882
FineTuningLR 0.280794
Epoch 31 | Batch 10/100 | Loss 0.330836
InnerLR 0.398277
FineTuningLR 0.281390
Epoch 31 | Batch 20/100 | Loss 0.304702
InnerLR 0.397404
FineTuningLR 0.282295
Epoch 31 | Batch 30/100 | Loss 0.295921
InnerLR 0.396856
FineTuningLR 0.282911
Epoch 31 | Batch 40/100 | Loss 0.307956
InnerLR 0.396015
FineTuningLR 0.283827
Epoch 31 | Batch 50/100 | Loss 0.319099
InnerLR 0.395444
FineTuningLR 0.284434
Epoch 31 | Batch 60/100 | Loss 0.312183
InnerLR 0.394575
FineTuningLR 0.285341
Epoch 31 | Batch 70/100 | Loss 0.308070
InnerLR 0.393992
FineTuningLR 0.285945
Epoch 31 | Batch 80/100 | Loss 0.311845
InnerLR 0.393112
FineTuningLR 0.286850
Epoch 31 | Batch 90/100 | Loss 0.308486
InnerLR 0.392521
FineTuningLR 0.287451
100 Accuracy = 81.41% +- 1.90%
Epoch 31: 81.41
Epoch 32 | Batch 0/100 | Loss 0.260670
InnerLR 0.391630
FineTuningLR 0.288351
Epoch 32 | Batch 10/100 | Loss 0.259155
InnerLR 0.391033
FineTuningLR 0.288950
Epoch 32 | Batch 20/100 | Loss 0.285195
InnerLR 0.390148
FineTuningLR 0.289856
Epoch 32 | Batch 30/100 | Loss 0.312016
InnerLR 0.389570
FineTuningLR 0.290468
Epoch 32 | Batch 40/100 | Loss 0.308788
InnerLR 0.388694
FineTuningLR 0.291219
Epoch 32 | Batch 50/100 | Loss 0.314822
InnerLR 0.388105
FineTuningLR 0.291741
Epoch 32 | Batch 60/100 | Loss 0.309931
InnerLR 0.387216
FineTuningLR 0.292550
Epoch 32 | Batch 70/100 | Loss 0.302629
InnerLR 0.386620
FineTuningLR 0.293102
Epoch 32 | Batch 80/100 | Loss 0.298396
InnerLR 0.385723
FineTuningLR 0.293945
Epoch 32 | Batch 90/100 | Loss 0.295191
InnerLR 0.385123
FineTuningLR 0.294515
100 Accuracy = 80.68% +- 2.18%
Epoch 32: 80.68
Epoch 33 | Batch 0/100 | Loss 0.360820
InnerLR 0.384222
FineTuningLR 0.295378
Epoch 33 | Batch 10/100 | Loss 0.236737
InnerLR 0.383651
FineTuningLR 0.295971
Epoch 33 | Batch 20/100 | Loss 0.260795
InnerLR 0.382822
FineTuningLR 0.296875
Epoch 33 | Batch 30/100 | Loss 0.285239
InnerLR 0.382257
FineTuningLR 0.297476
Epoch 33 | Batch 40/100 | Loss 0.292367
InnerLR 0.381395
FineTuningLR 0.298375
Epoch 33 | Batch 50/100 | Loss 0.289905
InnerLR 0.380813
FineTuningLR 0.298974
Epoch 33 | Batch 60/100 | Loss 0.295113
InnerLR 0.379959
FineTuningLR 0.299887
Epoch 33 | Batch 70/100 | Loss 0.294548
InnerLR 0.379389
FineTuningLR 0.300498
Epoch 33 | Batch 80/100 | Loss 0.297836
InnerLR 0.378521
FineTuningLR 0.301348
Epoch 33 | Batch 90/100 | Loss 0.294449
InnerLR 0.377936
FineTuningLR 0.301851
100 Accuracy = 83.12% +- 1.98%
Epoch 33: 83.12
Epoch 34 | Batch 0/100 | Loss 0.299137
InnerLR 0.377051
FineTuningLR 0.302636
Epoch 34 | Batch 10/100 | Loss 0.281184
InnerLR 0.376458
FineTuningLR 0.303176
Epoch 34 | Batch 20/100 | Loss 0.285616
InnerLR 0.375564
FineTuningLR 0.304005
Epoch 34 | Batch 30/100 | Loss 0.282268
InnerLR 0.374965
FineTuningLR 0.304567
Epoch 34 | Batch 40/100 | Loss 0.295399
InnerLR 0.374065
FineTuningLR 0.305421
Epoch 34 | Batch 50/100 | Loss 0.287538
InnerLR 0.373464
FineTuningLR 0.305997
Epoch 34 | Batch 60/100 | Loss 0.285055
InnerLR 0.372560
FineTuningLR 0.306866
Epoch 34 | Batch 70/100 | Loss 0.284273
InnerLR 0.371957
FineTuningLR 0.307450
Epoch 34 | Batch 80/100 | Loss 0.286776
InnerLR 0.371051
FineTuningLR 0.308328
Epoch 34 | Batch 90/100 | Loss 0.281282
InnerLR 0.370447
FineTuningLR 0.308916
100 Accuracy = 81.09% +- 2.11%
Epoch 34: 81.09
Epoch 35 | Batch 0/100 | Loss 0.288523
InnerLR 0.369540
FineTuningLR 0.309687
Epoch 35 | Batch 10/100 | Loss 0.252792
InnerLR 0.368935
FineTuningLR 0.310187
Epoch 35 | Batch 20/100 | Loss 0.250237
InnerLR 0.368028
FineTuningLR 0.310968
Epoch 35 | Batch 30/100 | Loss 0.253341
InnerLR 0.367423
FineTuningLR 0.311506
Epoch 35 | Batch 40/100 | Loss 0.263645
InnerLR 0.366515
FineTuningLR 0.312333
Epoch 35 | Batch 50/100 | Loss 0.269666
InnerLR 0.365910
FineTuningLR 0.312894
Epoch 35 | Batch 60/100 | Loss 0.277621
InnerLR 0.365002
FineTuningLR 0.313748
Epoch 35 | Batch 70/100 | Loss 0.280732
InnerLR 0.364397
FineTuningLR 0.314323
Epoch 35 | Batch 80/100 | Loss 0.282762
InnerLR 0.363489
FineTuningLR 0.315192
Epoch 35 | Batch 90/100 | Loss 0.282110
InnerLR 0.362909
FineTuningLR 0.315787
100 Accuracy = 83.17% +- 2.03%
Epoch 35: 83.17
Epoch 36 | Batch 0/100 | Loss 0.158233
InnerLR 0.362077
FineTuningLR 0.316706
Epoch 36 | Batch 10/100 | Loss 0.218301
InnerLR 0.361510
FineTuningLR 0.317314
Epoch 36 | Batch 20/100 | Loss 0.251501
InnerLR 0.360646
FineTuningLR 0.318221
Epoch 36 | Batch 30/100 | Loss 0.258179
InnerLR 0.360063
FineTuningLR 0.318824
Epoch 36 | Batch 40/100 | Loss 0.265542
InnerLR 0.359181
FineTuningLR 0.319725
Epoch 36 | Batch 50/100 | Loss 0.264760
InnerLR 0.358588
FineTuningLR 0.320324
Epoch 36 | Batch 60/100 | Loss 0.264708
InnerLR 0.357695
FineTuningLR 0.321221
Epoch 36 | Batch 70/100 | Loss 0.263517
InnerLR 0.357098
FineTuningLR 0.321818
Epoch 36 | Batch 80/100 | Loss 0.269187
InnerLR 0.356198
FineTuningLR 0.322713
Epoch 36 | Batch 90/100 | Loss 0.265530
InnerLR 0.355597
FineTuningLR 0.323309
100 Accuracy = 81.13% +- 2.10%
Epoch 36: 81.13
Epoch 37 | Batch 0/100 | Loss 0.162153
InnerLR 0.354694
FineTuningLR 0.324202
Epoch 37 | Batch 10/100 | Loss 0.267527
InnerLR 0.354091
FineTuningLR 0.324798
Epoch 37 | Batch 20/100 | Loss 0.257586
InnerLR 0.353185
FineTuningLR 0.325690
Epoch 37 | Batch 30/100 | Loss 0.295471
InnerLR 0.352581
FineTuningLR 0.326285
Epoch 37 | Batch 40/100 | Loss 0.298434
InnerLR 0.351674
FineTuningLR 0.327178
Epoch 37 | Batch 50/100 | Loss 0.287700
InnerLR 0.351070
FineTuningLR 0.327772
Epoch 37 | Batch 60/100 | Loss 0.288774
InnerLR 0.350162
FineTuningLR 0.328665
Epoch 37 | Batch 70/100 | Loss 0.281101
InnerLR 0.349557
FineTuningLR 0.329259
Epoch 37 | Batch 80/100 | Loss 0.278678
InnerLR 0.348650
FineTuningLR 0.330151
Epoch 37 | Batch 90/100 | Loss 0.278367
InnerLR 0.348044
FineTuningLR 0.330746
100 Accuracy = 82.15% +- 1.78%
Epoch 37: 82.15
Epoch 38 | Batch 0/100 | Loss 0.271672
InnerLR 0.347136
FineTuningLR 0.331638
Epoch 38 | Batch 10/100 | Loss 0.290639
InnerLR 0.346531
FineTuningLR 0.332232
Epoch 38 | Batch 20/100 | Loss 0.289720
InnerLR 0.345623
FineTuningLR 0.333124
Epoch 38 | Batch 30/100 | Loss 0.281554
InnerLR 0.345017
FineTuningLR 0.333719
Epoch 38 | Batch 40/100 | Loss 0.271890
InnerLR 0.344109
FineTuningLR 0.334611
Epoch 38 | Batch 50/100 | Loss 0.270611
InnerLR 0.343504
FineTuningLR 0.335206
Epoch 38 | Batch 60/100 | Loss 0.270145
InnerLR 0.342596
FineTuningLR 0.336098
Epoch 38 | Batch 70/100 | Loss 0.267886
InnerLR 0.341990
FineTuningLR 0.336693
Epoch 38 | Batch 80/100 | Loss 0.262304
InnerLR 0.341082
FineTuningLR 0.337585
Epoch 38 | Batch 90/100 | Loss 0.266115
InnerLR 0.340477
FineTuningLR 0.338179
100 Accuracy = 81.41% +- 2.15%
Epoch 38: 81.41
Epoch 39 | Batch 0/100 | Loss 0.426143
InnerLR 0.339577
FineTuningLR 0.339078
Epoch 39 | Batch 10/100 | Loss 0.322560
InnerLR 0.339003
FineTuningLR 0.339549
Epoch 39 | Batch 20/100 | Loss 0.283635
InnerLR 0.338130
FineTuningLR 0.340136
Epoch 39 | Batch 30/100 | Loss 0.274642
InnerLR 0.337543
FineTuningLR 0.340574
Epoch 39 | Batch 40/100 | Loss 0.260976
InnerLR 0.336656
FineTuningLR 0.341286
Epoch 39 | Batch 50/100 | Loss 0.265975
InnerLR 0.336061
FineTuningLR 0.341789
Epoch 39 | Batch 60/100 | Loss 0.268316
InnerLR 0.335166
FineTuningLR 0.342574
Epoch 39 | Batch 70/100 | Loss 0.272115
InnerLR 0.334567
FineTuningLR 0.343114
Epoch 39 | Batch 80/100 | Loss 0.275564
InnerLR 0.333687
FineTuningLR 0.343883
Epoch 39 | Batch 90/100 | Loss 0.271238
InnerLR 0.333102
FineTuningLR 0.344396
100 Accuracy = 81.21% +- 2.21%
Epoch 39: 81.21
Epoch 40 | Batch 0/100 | Loss 0.188507
InnerLR 0.332218
FineTuningLR 0.345195
Epoch 40 | Batch 10/100 | Loss 0.255479
InnerLR 0.331625
FineTuningLR 0.345742
Epoch 40 | Batch 20/100 | Loss 0.245035
InnerLR 0.330730
FineTuningLR 0.346579
Epoch 40 | Batch 30/100 | Loss 0.257838
InnerLR 0.330132
FineTuningLR 0.347145
Epoch 40 | Batch 40/100 | Loss 0.271269
InnerLR 0.329232
FineTuningLR 0.347833
Epoch 40 | Batch 50/100 | Loss 0.263719
InnerLR 0.328630
FineTuningLR 0.348217
Epoch 40 | Batch 60/100 | Loss 0.270522
InnerLR 0.327778
FineTuningLR 0.348874
Epoch 40 | Batch 70/100 | Loss 0.270980
InnerLR 0.327262
FineTuningLR 0.349357
Epoch 40 | Batch 80/100 | Loss 0.266437
InnerLR 0.326467
FineTuningLR 0.350127
Epoch 40 | Batch 90/100 | Loss 0.260643
InnerLR 0.325932
FineTuningLR 0.350669
100 Accuracy = 83.51% +- 1.74%
Epoch 40: 83.51
Epoch 41 | Batch 0/100 | Loss 0.371348
InnerLR 0.325105
FineTuningLR 0.351499
Epoch 41 | Batch 10/100 | Loss 0.270671
InnerLR 0.324540
FineTuningLR 0.352063
Epoch 41 | Batch 20/100 | Loss 0.263429
InnerLR 0.323680
FineTuningLR 0.352918
Epoch 41 | Batch 30/100 | Loss 0.247554
InnerLR 0.323098
FineTuningLR 0.353494
Epoch 41 | Batch 40/100 | Loss 0.243737
InnerLR 0.322218
FineTuningLR 0.354365
Epoch 41 | Batch 50/100 | Loss 0.244140
InnerLR 0.321626
FineTuningLR 0.354949
Epoch 41 | Batch 60/100 | Loss 0.248866
InnerLR 0.320734
FineTuningLR 0.355828
Epoch 41 | Batch 70/100 | Loss 0.246415
InnerLR 0.320137
FineTuningLR 0.356417
Epoch 41 | Batch 80/100 | Loss 0.244694
InnerLR 0.319238
FineTuningLR 0.357302
Epoch 41 | Batch 90/100 | Loss 0.245705
InnerLR 0.318663
FineTuningLR 0.357910
100 Accuracy = 83.77% +- 1.87%
Epoch 41: 83.77
best model! save...
Epoch 42 | Batch 0/100 | Loss 0.339771
InnerLR 0.317791
FineTuningLR 0.358818
Epoch 42 | Batch 10/100 | Loss 0.328596
InnerLR 0.317264
FineTuningLR 0.359420
Epoch 42 | Batch 20/100 | Loss 0.270089
InnerLR 0.316525
FineTuningLR 0.360321
Epoch 42 | Batch 30/100 | Loss 0.251492
InnerLR 0.316100
FineTuningLR 0.360935
Epoch 42 | Batch 40/100 | Loss 0.245670
InnerLR 0.315401
FineTuningLR 0.361849
Epoch 42 | Batch 50/100 | Loss 0.235613
InnerLR 0.314902
FineTuningLR 0.362454
Epoch 42 | Batch 60/100 | Loss 0.248038
InnerLR 0.314116
FineTuningLR 0.363300
Epoch 42 | Batch 70/100 | Loss 0.261009
InnerLR 0.313574
FineTuningLR 0.363740
Epoch 42 | Batch 80/100 | Loss 0.264642
InnerLR 0.312737
FineTuningLR 0.364377
Epoch 42 | Batch 90/100 | Loss 0.263407
InnerLR 0.312168
FineTuningLR 0.364841
100 Accuracy = 81.64% +- 2.11%
Epoch 42: 81.64
Epoch 43 | Batch 0/100 | Loss 0.175550
InnerLR 0.311304
FineTuningLR 0.365584
Epoch 43 | Batch 10/100 | Loss 0.195859
InnerLR 0.310720
FineTuningLR 0.366102
Epoch 43 | Batch 20/100 | Loss 0.212251
InnerLR 0.309837
FineTuningLR 0.366906
Epoch 43 | Batch 30/100 | Loss 0.227024
InnerLR 0.309244
FineTuningLR 0.367456
Epoch 43 | Batch 40/100 | Loss 0.229987
InnerLR 0.308351
FineTuningLR 0.368295
Epoch 43 | Batch 50/100 | Loss 0.230853
InnerLR 0.307752
FineTuningLR 0.368864
Epoch 43 | Batch 60/100 | Loss 0.245744
InnerLR 0.306913
FineTuningLR 0.369665
Epoch 43 | Batch 70/100 | Loss 0.246385
InnerLR 0.306415
FineTuningLR 0.370143
Epoch 43 | Batch 80/100 | Loss 0.245039
InnerLR 0.305630
FineTuningLR 0.370898
Epoch 43 | Batch 90/100 | Loss 0.242444
InnerLR 0.305087
FineTuningLR 0.371423
100 Accuracy = 83.05% +- 1.79%
Epoch 43: 83.05
Epoch 44 | Batch 0/100 | Loss 0.472431
InnerLR 0.304252
FineTuningLR 0.372234
Epoch 44 | Batch 10/100 | Loss 0.289839
InnerLR 0.303687
FineTuningLR 0.372671
Epoch 44 | Batch 20/100 | Loss 0.259487
InnerLR 0.302826
FineTuningLR 0.373380
Epoch 44 | Batch 30/100 | Loss 0.252436
InnerLR 0.302249
FineTuningLR 0.373885
Epoch 44 | Batch 40/100 | Loss 0.283095
InnerLR 0.301603
FineTuningLR 0.374620
Epoch 44 | Batch 50/100 | Loss 0.279699
InnerLR 0.301204
FineTuningLR 0.375062
Epoch 44 | Batch 60/100 | Loss 0.281365
InnerLR 0.300534
FineTuningLR 0.375666
Epoch 44 | Batch 70/100 | Loss 0.270919
InnerLR 0.300050
FineTuningLR 0.376080
Epoch 44 | Batch 80/100 | Loss 0.270394
InnerLR 0.299283
FineTuningLR 0.376762
Epoch 44 | Batch 90/100 | Loss 0.269938
InnerLR 0.298749
FineTuningLR 0.377250
100 Accuracy = 83.77% +- 2.01%
Epoch 44: 83.77
Epoch 45 | Batch 0/100 | Loss 0.198152
InnerLR 0.297923
FineTuningLR 0.378019
Epoch 45 | Batch 10/100 | Loss 0.338894
InnerLR 0.297536
FineTuningLR 0.378378
Epoch 45 | Batch 20/100 | Loss 0.293312
InnerLR 0.297005
FineTuningLR 0.378949
Epoch 45 | Batch 30/100 | Loss 0.261617
InnerLR 0.296592
FineTuningLR 0.379380
Epoch 45 | Batch 40/100 | Loss 0.261982
InnerLR 0.295907
FineTuningLR 0.380083
Epoch 45 | Batch 50/100 | Loss 0.256299
InnerLR 0.295415
FineTuningLR 0.380581
Epoch 45 | Batch 60/100 | Loss 0.244799
InnerLR 0.294637
FineTuningLR 0.381361
Epoch 45 | Batch 70/100 | Loss 0.246912
InnerLR 0.294099
FineTuningLR 0.381899
Epoch 45 | Batch 80/100 | Loss 0.248027
InnerLR 0.293267
FineTuningLR 0.382725
Epoch 45 | Batch 90/100 | Loss 0.246496
InnerLR 0.292701
FineTuningLR 0.383285
100 Accuracy = 82.48% +- 1.84%
Epoch 45: 82.48
Epoch 46 | Batch 0/100 | Loss 0.222842
InnerLR 0.291838
FineTuningLR 0.384138
Epoch 46 | Batch 10/100 | Loss 0.250175
InnerLR 0.291255
FineTuningLR 0.384600
Epoch 46 | Batch 20/100 | Loss 0.247485
InnerLR 0.290373
FineTuningLR 0.385339
Epoch 46 | Batch 30/100 | Loss 0.270392
InnerLR 0.289781
FineTuningLR 0.385855
Epoch 46 | Batch 40/100 | Loss 0.257722
InnerLR 0.288888
FineTuningLR 0.386495
Epoch 46 | Batch 50/100 | Loss 0.258077
InnerLR 0.288344
FineTuningLR 0.386824
Epoch 46 | Batch 60/100 | Loss 0.249141
InnerLR 0.287507
FineTuningLR 0.387297
Epoch 46 | Batch 70/100 | Loss 0.246842
InnerLR 0.286946
FineTuningLR 0.387651
Epoch 46 | Batch 80/100 | Loss 0.245882
InnerLR 0.286090
FineTuningLR 0.388264
Epoch 46 | Batch 90/100 | Loss 0.241979
InnerLR 0.285510
FineTuningLR 0.388716
100 Accuracy = 82.31% +- 1.98%
Epoch 46: 82.31
Epoch 47 | Batch 0/100 | Loss 0.256269
InnerLR 0.284632
FineTuningLR 0.389444
Epoch 47 | Batch 10/100 | Loss 0.222127
InnerLR 0.284041
FineTuningLR 0.389954
Epoch 47 | Batch 20/100 | Loss 0.222384
InnerLR 0.283150
FineTuningLR 0.390749
Epoch 47 | Batch 30/100 | Loss 0.207554
InnerLR 0.282553
FineTuningLR 0.391294
Epoch 47 | Batch 40/100 | Loss 0.205522
InnerLR 0.281654
FineTuningLR 0.392128
Epoch 47 | Batch 50/100 | Loss 0.220022
InnerLR 0.281169
FineTuningLR 0.392580
Epoch 47 | Batch 60/100 | Loss 0.239136
InnerLR 0.280563
FineTuningLR 0.393146
Epoch 47 | Batch 70/100 | Loss 0.230683
InnerLR 0.280117
FineTuningLR 0.393579
Epoch 47 | Batch 80/100 | Loss 0.230550
InnerLR 0.279452
FineTuningLR 0.394318
Epoch 47 | Batch 90/100 | Loss 0.234738
InnerLR 0.278971
FineTuningLR 0.394835
100 Accuracy = 86.32% +- 1.77%
Epoch 47: 86.32
best model! save...
Epoch 48 | Batch 0/100 | Loss 0.256692
InnerLR 0.278206
FineTuningLR 0.395637
Epoch 48 | Batch 10/100 | Loss 0.215794
InnerLR 0.277673
FineTuningLR 0.396185
Epoch 48 | Batch 20/100 | Loss 0.204474
InnerLR 0.276825
FineTuningLR 0.396896
Epoch 48 | Batch 30/100 | Loss 0.206245
InnerLR 0.276250
FineTuningLR 0.397398
Epoch 48 | Batch 40/100 | Loss 0.216652
InnerLR 0.275377
FineTuningLR 0.398182
Epoch 48 | Batch 50/100 | Loss 0.230286
InnerLR 0.274850
FineTuningLR 0.398663
Epoch 48 | Batch 60/100 | Loss 0.234976
InnerLR 0.274148
FineTuningLR 0.399371
Epoch 48 | Batch 70/100 | Loss 0.232356
InnerLR 0.273647
FineTuningLR 0.399871
Epoch 48 | Batch 80/100 | Loss 0.230968
InnerLR 0.272860
FineTuningLR 0.400654
Epoch 48 | Batch 90/100 | Loss 0.233808
InnerLR 0.272316
FineTuningLR 0.401080
100 Accuracy = 81.56% +- 1.99%
Epoch 48: 81.56
Epoch 49 | Batch 0/100 | Loss 0.133484
InnerLR 0.271485
FineTuningLR 0.401610
Epoch 49 | Batch 10/100 | Loss 0.296035
InnerLR 0.270919
FineTuningLR 0.401906
Epoch 49 | Batch 20/100 | Loss 0.265669
InnerLR 0.270056
FineTuningLR 0.402394
Epoch 49 | Batch 30/100 | Loss 0.250083
InnerLR 0.269478
FineTuningLR 0.402715
Epoch 49 | Batch 40/100 | Loss 0.249974
InnerLR 0.268674
FineTuningLR 0.403245
Epoch 49 | Batch 50/100 | Loss 0.243093
InnerLR 0.268203
FineTuningLR 0.403593
Epoch 49 | Batch 60/100 | Loss 0.241229
InnerLR 0.267449
FineTuningLR 0.404200
Epoch 49 | Batch 70/100 | Loss 0.239151
InnerLR 0.266923
FineTuningLR 0.404649
Epoch 49 | Batch 80/100 | Loss 0.233876
InnerLR 0.266105
FineTuningLR 0.405372
Epoch 49 | Batch 90/100 | Loss 0.229185
InnerLR 0.265546
FineTuningLR 0.405881
100 Accuracy = 82.44% +- 1.99%
Epoch 49: 82.44
Epoch 50 | Batch 0/100 | Loss 0.383618
InnerLR 0.264691
FineTuningLR 0.406673
Epoch 50 | Batch 10/100 | Loss 0.246920
InnerLR 0.264112
FineTuningLR 0.407104
Epoch 50 | Batch 20/100 | Loss 0.223048
InnerLR 0.263235
FineTuningLR 0.407806
Epoch 50 | Batch 30/100 | Loss 0.229306
InnerLR 0.262643
FineTuningLR 0.408302
Epoch 50 | Batch 40/100 | Loss 0.221519
InnerLR 0.261787
FineTuningLR 0.409098
Epoch 50 | Batch 50/100 | Loss 0.227698
InnerLR 0.261219
FineTuningLR 0.409650
Epoch 50 | Batch 60/100 | Loss 0.228814
InnerLR 0.260356
FineTuningLR 0.410494
Epoch 50 | Batch 70/100 | Loss 0.228177
InnerLR 0.259773
FineTuningLR 0.411064
Epoch 50 | Batch 80/100 | Loss 0.223960
InnerLR 0.258892
FineTuningLR 0.411869
Epoch 50 | Batch 90/100 | Loss 0.223216
InnerLR 0.258300
FineTuningLR 0.412347
100 Accuracy = 82.89% +- 2.22%
Epoch 50: 82.89
Epoch 51 | Batch 0/100 | Loss 0.248025
InnerLR 0.257394
FineTuningLR 0.413077
Epoch 51 | Batch 10/100 | Loss 0.254699
InnerLR 0.256775
FineTuningLR 0.413443
Epoch 51 | Batch 20/100 | Loss 0.328313
InnerLR 0.255912
FineTuningLR 0.413851
Epoch 51 | Batch 30/100 | Loss 0.285925
InnerLR 0.255402
FineTuningLR 0.414126
Epoch 51 | Batch 40/100 | Loss 0.265162
InnerLR 0.254719
FineTuningLR 0.414649
Epoch 51 | Batch 50/100 | Loss 0.263000
InnerLR 0.254263
FineTuningLR 0.415056
Epoch 51 | Batch 60/100 | Loss 0.247597
InnerLR 0.253527
FineTuningLR 0.415730
Epoch 51 | Batch 70/100 | Loss 0.249251
InnerLR 0.253010
FineTuningLR 0.416154
Epoch 51 | Batch 80/100 | Loss 0.257654
InnerLR 0.252319
FineTuningLR 0.416660
Epoch 51 | Batch 90/100 | Loss 0.262021
InnerLR 0.252034
FineTuningLR 0.416963
100 Accuracy = 82.13% +- 1.73%
Epoch 51: 82.13
Epoch 52 | Batch 0/100 | Loss 0.145218
InnerLR 0.251550
FineTuningLR 0.417170
Epoch 52 | Batch 10/100 | Loss 0.277693
InnerLR 0.251155
FineTuningLR 0.417214
Epoch 52 | Batch 20/100 | Loss 0.320993
InnerLR 0.250714
FineTuningLR 0.417411
Epoch 52 | Batch 30/100 | Loss 0.280116
InnerLR 0.250420
FineTuningLR 0.417466
Epoch 52 | Batch 40/100 | Loss 0.266749
InnerLR 0.249929
FineTuningLR 0.417672
Epoch 52 | Batch 50/100 | Loss 0.268044
InnerLR 0.249609
FineTuningLR 0.417844
Epoch 52 | Batch 60/100 | Loss 0.267242
InnerLR 0.249030
FineTuningLR 0.418189
Epoch 52 | Batch 70/100 | Loss 0.261882
InnerLR 0.248593
FineTuningLR 0.418433
Epoch 52 | Batch 80/100 | Loss 0.255627
InnerLR 0.247887
FineTuningLR 0.418926
Epoch 52 | Batch 90/100 | Loss 0.249081
InnerLR 0.247388
FineTuningLR 0.419319
100 Accuracy = 82.25% +- 1.91%
Epoch 52: 82.25
Epoch 53 | Batch 0/100 | Loss 0.603640
InnerLR 0.246602
FineTuningLR 0.419978
Epoch 53 | Batch 10/100 | Loss 0.284909
InnerLR 0.246056
FineTuningLR 0.420284
Epoch 53 | Batch 20/100 | Loss 0.243205
InnerLR 0.245329
FineTuningLR 0.420770
Epoch 53 | Batch 30/100 | Loss 0.227702
InnerLR 0.244850
FineTuningLR 0.421157
Epoch 53 | Batch 40/100 | Loss 0.217330
InnerLR 0.244089
FineTuningLR 0.421810
Epoch 53 | Batch 50/100 | Loss 0.228329
InnerLR 0.243619
FineTuningLR 0.422223
Epoch 53 | Batch 60/100 | Loss 0.223480
InnerLR 0.243025
FineTuningLR 0.422862
Epoch 53 | Batch 70/100 | Loss 0.217580
InnerLR 0.242607
FineTuningLR 0.423340
Epoch 53 | Batch 80/100 | Loss 0.215603
InnerLR 0.242063
FineTuningLR 0.424112
Epoch 53 | Batch 90/100 | Loss 0.213212
InnerLR 0.241678
FineTuningLR 0.424645
100 Accuracy = 83.43% +- 1.76%
Epoch 53: 83.43
Epoch 54 | Batch 0/100 | Loss 0.261430
InnerLR 0.241025
FineTuningLR 0.425466
Epoch 54 | Batch 10/100 | Loss 0.204199
InnerLR 0.240550
FineTuningLR 0.426025
Epoch 54 | Batch 20/100 | Loss 0.239397
InnerLR 0.239792
FineTuningLR 0.426875
Epoch 54 | Batch 30/100 | Loss 0.220117
InnerLR 0.239263
FineTuningLR 0.427448
Epoch 54 | Batch 40/100 | Loss 0.203585
InnerLR 0.238443
FineTuningLR 0.428316
Epoch 54 | Batch 50/100 | Loss 0.207901
InnerLR 0.237998
FineTuningLR 0.428898
Epoch 54 | Batch 60/100 | Loss 0.212026
InnerLR 0.237275
FineTuningLR 0.429776
Epoch 54 | Batch 70/100 | Loss 0.206831
InnerLR 0.236764
FineTuningLR 0.430363
Epoch 54 | Batch 80/100 | Loss 0.205126
InnerLR 0.236080
FineTuningLR 0.431247
Epoch 54 | Batch 90/100 | Loss 0.215823
InnerLR 0.235799
FineTuningLR 0.431724
100 Accuracy = 82.44% +- 2.19%
Epoch 54: 82.44
Epoch 55 | Batch 0/100 | Loss 0.092523
InnerLR 0.235344
FineTuningLR 0.432481
Epoch 55 | Batch 10/100 | Loss 0.165581
InnerLR 0.234969
FineTuningLR 0.433007
Epoch 55 | Batch 20/100 | Loss 0.190690
InnerLR 0.234328
FineTuningLR 0.433819
Epoch 55 | Batch 30/100 | Loss 0.184364
InnerLR 0.233859
FineTuningLR 0.434373
Epoch 55 | Batch 40/100 | Loss 0.184579
InnerLR 0.233109
FineTuningLR 0.435218
Epoch 55 | Batch 50/100 | Loss 0.205322
InnerLR 0.232645
FineTuningLR 0.435676
Epoch 55 | Batch 60/100 | Loss 0.206407
InnerLR 0.232202
FineTuningLR 0.436410
Epoch 55 | Batch 70/100 | Loss 0.213415
InnerLR 0.232083
FineTuningLR 0.436864
Epoch 55 | Batch 80/100 | Loss 0.208859
InnerLR 0.231814
FineTuningLR 0.437518
Epoch 55 | Batch 90/100 | Loss 0.214624
InnerLR 0.231535
FineTuningLR 0.437878
100 Accuracy = 84.11% +- 1.95%
Epoch 55: 84.11
Epoch 56 | Batch 0/100 | Loss 0.264794
InnerLR 0.231128
FineTuningLR 0.438393
Epoch 56 | Batch 10/100 | Loss 0.210088
InnerLR 0.230825
FineTuningLR 0.438769
Epoch 56 | Batch 20/100 | Loss 0.223144
InnerLR 0.230265
FineTuningLR 0.439248
Epoch 56 | Batch 30/100 | Loss 0.219203
InnerLR 0.229838
FineTuningLR 0.439631
Epoch 56 | Batch 40/100 | Loss 0.237890
InnerLR 0.229250
FineTuningLR 0.440107
Epoch 56 | Batch 50/100 | Loss 0.244512
InnerLR 0.228843
FineTuningLR 0.440383
Epoch 56 | Batch 60/100 | Loss 0.234040
InnerLR 0.228164
FineTuningLR 0.440747
Epoch 56 | Batch 70/100 | Loss 0.253154
InnerLR 0.227853
FineTuningLR 0.440957
Epoch 56 | Batch 80/100 | Loss 0.246580
InnerLR 0.227365
FineTuningLR 0.441402
Epoch 56 | Batch 90/100 | Loss 0.241397
InnerLR 0.227024
FineTuningLR 0.441776
100 Accuracy = 84.60% +- 1.83%
Epoch 56: 84.60
Epoch 57 | Batch 0/100 | Loss 0.096628
InnerLR 0.226487
FineTuningLR 0.442422
Epoch 57 | Batch 10/100 | Loss 0.212996
InnerLR 0.226094
FineTuningLR 0.442907
Epoch 57 | Batch 20/100 | Loss 0.216834
InnerLR 0.225435
FineTuningLR 0.443515
Epoch 57 | Batch 30/100 | Loss 0.207426
InnerLR 0.224962
FineTuningLR 0.443968
Epoch 57 | Batch 40/100 | Loss 0.210185
InnerLR 0.224319
FineTuningLR 0.444700
Epoch 57 | Batch 50/100 | Loss 0.209299
InnerLR 0.223942
FineTuningLR 0.445155
Epoch 57 | Batch 60/100 | Loss 0.223987
InnerLR 0.223443
FineTuningLR 0.445754
Epoch 57 | Batch 70/100 | Loss 0.235668
InnerLR 0.223180
FineTuningLR 0.445956
Epoch 57 | Batch 80/100 | Loss 0.225584
InnerLR 0.222909
FineTuningLR 0.446317
Epoch 57 | Batch 90/100 | Loss 0.226785
InnerLR 0.222629
FineTuningLR 0.446640
100 Accuracy = 83.93% +- 1.93%
Epoch 57: 83.93
Epoch 58 | Batch 0/100 | Loss 0.139811
InnerLR 0.222261
FineTuningLR 0.447058
Epoch 58 | Batch 10/100 | Loss 0.204157
InnerLR 0.222047
FineTuningLR 0.447238
Epoch 58 | Batch 20/100 | Loss 0.186743
InnerLR 0.221591
FineTuningLR 0.447574
Epoch 58 | Batch 30/100 | Loss 0.200336
InnerLR 0.221216
FineTuningLR 0.447885
Epoch 58 | Batch 40/100 | Loss 0.201644
InnerLR 0.220574
FineTuningLR 0.448335
Epoch 58 | Batch 50/100 | Loss 0.204004
InnerLR 0.220105
FineTuningLR 0.448671
Epoch 58 | Batch 60/100 | Loss 0.204128
InnerLR 0.219410
FineTuningLR 0.449258
Epoch 58 | Batch 70/100 | Loss 0.202324
InnerLR 0.218996
FineTuningLR 0.449703
Epoch 58 | Batch 80/100 | Loss 0.201527
InnerLR 0.218388
FineTuningLR 0.450422
Epoch 58 | Batch 90/100 | Loss 0.199529
InnerLR 0.217935
FineTuningLR 0.450928
100 Accuracy = 82.87% +- 2.30%
Epoch 58: 82.87
Epoch 59 | Batch 0/100 | Loss 0.330698
InnerLR 0.217204
FineTuningLR 0.451718
Epoch 59 | Batch 10/100 | Loss 0.225674
InnerLR 0.216688
FineTuningLR 0.452261
Epoch 59 | Batch 20/100 | Loss 0.220500
InnerLR 0.215884
FineTuningLR 0.452932
Epoch 59 | Batch 30/100 | Loss 0.206933
InnerLR 0.215332
FineTuningLR 0.453413
Epoch 59 | Batch 40/100 | Loss 0.200653
InnerLR 0.214485
FineTuningLR 0.454013
Epoch 59 | Batch 50/100 | Loss 0.237534
InnerLR 0.213911
FineTuningLR 0.454286
Epoch 59 | Batch 60/100 | Loss 0.236214
InnerLR 0.213154
FineTuningLR 0.454617
Epoch 59 | Batch 70/100 | Loss 0.230392
InnerLR 0.212709
FineTuningLR 0.454899
Epoch 59 | Batch 80/100 | Loss 0.229503
InnerLR 0.212039
FineTuningLR 0.455342
Epoch 59 | Batch 90/100 | Loss 0.233050
InnerLR 0.211551
FineTuningLR 0.455679
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 84.67% +- 1.82%
Epoch 59: 84.67
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0003/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0003/tabula_muris/leo_FCNet/20231211_172803
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 97.79% +- 0.23%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0003/tabula_muris/leo_FCNet/20231211_172803
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 83.75% +- 0.77%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0003/tabula_muris/leo_FCNet/20231211_172803
600 Accuracy = 80.00% +- 0.77%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0003/results.txt
+-------+-------------------+-------------------+
| split |      acc_mean     |      acc_std      |
+-------+-------------------+-------------------+
| train | 97.78666666666666 | 2.913386727199502 |
|  val  | 83.74666666666667 | 9.586462677477375 |
|  test |        80.0       |  9.61880873505038 |
+-------+-------------------+-------------------+
