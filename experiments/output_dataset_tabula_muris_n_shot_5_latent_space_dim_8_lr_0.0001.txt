/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 5
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 5
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 5
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 0.5
    finetuning_lr_init: 0.05
    num_adaptation_steps: 5
    kl_coef: 0.01
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 0.1
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 8
    enable_finetuning_loop: true
  n_task: 4
  latent_space_dim: 8
  leo_inner_lr_init: 0.5
  leo_finetuning_lr_init: 0.05
  num_adaptation_steps: 5
  kl_coef: 0.01
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 0.1
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-06
  optimize_backbone: false
  pretrained_backbone_weights_path: pretrained_weights/tabula_muris_baseline_model.tar
  enable_finetuning_loop: true
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0001
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.0001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.0001
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0001/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Using pretrained backbone from pretrained_weights/tabula_muris_baseline_model.tar.
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=8, bias=False)
    (relation_net): Sequential(
      (0): Linear(in_features=16, out_features=16, bias=False)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=16, bias=False)
      (3): ReLU()
      (4): Linear(in_features=16, out_features=16, bias=False)
    )
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=8, out_features=130, bias=False)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 1e-06

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
)
Epoch 0 | Batch 0/100 | Loss 2.793048
InnerLR 0.500000
FineTuningLR 0.050000
Epoch 0 | Batch 10/100 | Loss 5.408372
InnerLR 0.500200
FineTuningLR 0.050200
Epoch 0 | Batch 20/100 | Loss 5.785842
InnerLR 0.500398
FineTuningLR 0.050500
Epoch 0 | Batch 30/100 | Loss 5.766767
InnerLR 0.500535
FineTuningLR 0.050700
Epoch 0 | Batch 40/100 | Loss 5.549414
InnerLR 0.500777
FineTuningLR 0.051000
Epoch 0 | Batch 50/100 | Loss 5.718578
InnerLR 0.500951
FineTuningLR 0.051200
Epoch 0 | Batch 60/100 | Loss 5.613343
InnerLR 0.501223
FineTuningLR 0.051500
Epoch 0 | Batch 70/100 | Loss 5.667354
InnerLR 0.501410
FineTuningLR 0.051700
Epoch 0 | Batch 80/100 | Loss 5.680753
InnerLR 0.501696
FineTuningLR 0.052000
Epoch 0 | Batch 90/100 | Loss 5.608145
InnerLR 0.501889
FineTuningLR 0.052200
100 Accuracy = 48.17% +- 2.33%
Epoch 0: 48.17
best model! save...
Epoch 1 | Batch 0/100 | Loss 5.851151
InnerLR 0.502181
FineTuningLR 0.052500
Epoch 1 | Batch 10/100 | Loss 6.328857
InnerLR 0.502377
FineTuningLR 0.052700
Epoch 1 | Batch 20/100 | Loss 5.959354
InnerLR 0.502672
FineTuningLR 0.053000
Epoch 1 | Batch 30/100 | Loss 5.556738
InnerLR 0.502870
FineTuningLR 0.053200
Epoch 1 | Batch 40/100 | Loss 5.692636
InnerLR 0.503167
FineTuningLR 0.053500
Epoch 1 | Batch 50/100 | Loss 5.630134
InnerLR 0.503366
FineTuningLR 0.053700
Epoch 1 | Batch 60/100 | Loss 5.704409
InnerLR 0.503664
FineTuningLR 0.054000
Epoch 1 | Batch 70/100 | Loss 5.834491
InnerLR 0.503864
FineTuningLR 0.054200
Epoch 1 | Batch 80/100 | Loss 5.925571
InnerLR 0.504163
FineTuningLR 0.054500
Epoch 1 | Batch 90/100 | Loss 5.796517
InnerLR 0.504362
FineTuningLR 0.054700
100 Accuracy = 47.83% +- 2.17%
Epoch 1: 47.83
Epoch 2 | Batch 0/100 | Loss 7.357573
InnerLR 0.504662
FineTuningLR 0.055000
Epoch 2 | Batch 10/100 | Loss 5.908971
InnerLR 0.504862
FineTuningLR 0.055200
Epoch 2 | Batch 20/100 | Loss 6.065518
InnerLR 0.505161
FineTuningLR 0.055500
Epoch 2 | Batch 30/100 | Loss 5.620937
InnerLR 0.505323
FineTuningLR 0.055700
Epoch 2 | Batch 40/100 | Loss 5.515845
InnerLR 0.505579
FineTuningLR 0.056000
Epoch 2 | Batch 50/100 | Loss 5.486917
InnerLR 0.505756
FineTuningLR 0.056200
Epoch 2 | Batch 60/100 | Loss 5.516354
InnerLR 0.506030
FineTuningLR 0.056500
Epoch 2 | Batch 70/100 | Loss 5.380313
InnerLR 0.506217
FineTuningLR 0.056700
Epoch 2 | Batch 80/100 | Loss 5.355161
InnerLR 0.506501
FineTuningLR 0.057000
Epoch 2 | Batch 90/100 | Loss 5.304106
InnerLR 0.506694
FineTuningLR 0.057200
100 Accuracy = 50.08% +- 2.53%
Epoch 2: 50.08
best model! save...
Epoch 3 | Batch 0/100 | Loss 3.524301
InnerLR 0.506985
FineTuningLR 0.057500
Epoch 3 | Batch 10/100 | Loss 5.548596
InnerLR 0.507180
FineTuningLR 0.057700
Epoch 3 | Batch 20/100 | Loss 4.990626
InnerLR 0.507475
FineTuningLR 0.058000
Epoch 3 | Batch 30/100 | Loss 4.936624
InnerLR 0.507672
FineTuningLR 0.058200
Epoch 3 | Batch 40/100 | Loss 5.001851
InnerLR 0.507950
FineTuningLR 0.058501
Epoch 3 | Batch 50/100 | Loss 4.970325
InnerLR 0.508117
FineTuningLR 0.058703
Epoch 3 | Batch 60/100 | Loss 4.996876
InnerLR 0.508379
FineTuningLR 0.059005
Epoch 3 | Batch 70/100 | Loss 4.917846
InnerLR 0.508560
FineTuningLR 0.059206
Epoch 3 | Batch 80/100 | Loss 5.011097
InnerLR 0.508745
FineTuningLR 0.059507
Epoch 3 | Batch 90/100 | Loss 5.029152
InnerLR 0.508837
FineTuningLR 0.059708
100 Accuracy = 51.60% +- 2.18%
Epoch 3: 51.60
best model! save...
Epoch 4 | Batch 0/100 | Loss 6.666286
InnerLR 0.508958
FineTuningLR 0.060008
Epoch 4 | Batch 10/100 | Loss 5.255342
InnerLR 0.509067
FineTuningLR 0.060208
Epoch 4 | Batch 20/100 | Loss 5.062109
InnerLR 0.509241
FineTuningLR 0.060508
Epoch 4 | Batch 30/100 | Loss 5.086690
InnerLR 0.509353
FineTuningLR 0.060708
Epoch 4 | Batch 40/100 | Loss 5.119465
InnerLR 0.509552
FineTuningLR 0.061008
Epoch 4 | Batch 50/100 | Loss 5.035851
InnerLR 0.509700
FineTuningLR 0.061208
Epoch 4 | Batch 60/100 | Loss 4.947526
InnerLR 0.509940
FineTuningLR 0.061508
Epoch 4 | Batch 70/100 | Loss 4.843989
InnerLR 0.510109
FineTuningLR 0.061708
Epoch 4 | Batch 80/100 | Loss 4.889118
InnerLR 0.510374
FineTuningLR 0.062008
Epoch 4 | Batch 90/100 | Loss 4.911371
InnerLR 0.510556
FineTuningLR 0.062207
100 Accuracy = 50.00% +- 2.66%
Epoch 4: 50.00
Epoch 5 | Batch 0/100 | Loss 5.006794
InnerLR 0.510835
FineTuningLR 0.062507
Epoch 5 | Batch 10/100 | Loss 4.964636
InnerLR 0.511005
FineTuningLR 0.062707
Epoch 5 | Batch 20/100 | Loss 5.244131
InnerLR 0.511224
FineTuningLR 0.063007
Epoch 5 | Batch 30/100 | Loss 5.125066
InnerLR 0.511334
FineTuningLR 0.063213
Epoch 5 | Batch 40/100 | Loss 5.322522
InnerLR 0.511475
FineTuningLR 0.063520
Epoch 5 | Batch 50/100 | Loss 5.436910
InnerLR 0.511594
FineTuningLR 0.063723
Epoch 5 | Batch 60/100 | Loss 5.317906
InnerLR 0.511801
FineTuningLR 0.064027
Epoch 5 | Batch 70/100 | Loss 5.397335
InnerLR 0.511954
FineTuningLR 0.064228
Epoch 5 | Batch 80/100 | Loss 5.268795
InnerLR 0.512200
FineTuningLR 0.064530
Epoch 5 | Batch 90/100 | Loss 5.226908
InnerLR 0.512372
FineTuningLR 0.064730
100 Accuracy = 50.83% +- 2.37%
Epoch 5: 50.83
Epoch 6 | Batch 0/100 | Loss 4.784726
InnerLR 0.512640
FineTuningLR 0.065031
Epoch 6 | Batch 10/100 | Loss 4.312272
InnerLR 0.512824
FineTuningLR 0.065231
Epoch 6 | Batch 20/100 | Loss 4.725548
InnerLR 0.513106
FineTuningLR 0.065531
Epoch 6 | Batch 30/100 | Loss 4.474351
InnerLR 0.513297
FineTuningLR 0.065731
Epoch 6 | Batch 40/100 | Loss 4.766583
InnerLR 0.513587
FineTuningLR 0.066030
Epoch 6 | Batch 50/100 | Loss 4.795198
InnerLR 0.513781
FineTuningLR 0.066230
Epoch 6 | Batch 60/100 | Loss 4.879328
InnerLR 0.514076
FineTuningLR 0.066529
Epoch 6 | Batch 70/100 | Loss 4.842393
InnerLR 0.514273
FineTuningLR 0.066728
Epoch 6 | Batch 80/100 | Loss 4.795764
InnerLR 0.514570
FineTuningLR 0.067027
Epoch 6 | Batch 90/100 | Loss 4.817552
InnerLR 0.514769
FineTuningLR 0.067227
100 Accuracy = 53.27% +- 2.19%
Epoch 6: 53.27
best model! save...
Epoch 7 | Batch 0/100 | Loss 6.932542
InnerLR 0.515029
FineTuningLR 0.067526
Epoch 7 | Batch 10/100 | Loss 4.998176
InnerLR 0.515198
FineTuningLR 0.067725
Epoch 7 | Batch 20/100 | Loss 4.640872
InnerLR 0.515462
FineTuningLR 0.068024
Epoch 7 | Batch 30/100 | Loss 4.711575
InnerLR 0.515644
FineTuningLR 0.068224
Epoch 7 | Batch 40/100 | Loss 4.697282
InnerLR 0.515923
FineTuningLR 0.068523
Epoch 7 | Batch 50/100 | Loss 4.787790
InnerLR 0.516112
FineTuningLR 0.068722
Epoch 7 | Batch 60/100 | Loss 4.821160
InnerLR 0.516400
FineTuningLR 0.069021
Epoch 7 | Batch 70/100 | Loss 4.825924
InnerLR 0.516594
FineTuningLR 0.069221
Epoch 7 | Batch 80/100 | Loss 4.823348
InnerLR 0.516887
FineTuningLR 0.069520
Epoch 7 | Batch 90/100 | Loss 4.824503
InnerLR 0.517049
FineTuningLR 0.069722
100 Accuracy = 52.83% +- 2.67%
Epoch 7: 52.83
Epoch 8 | Batch 0/100 | Loss 5.829178
InnerLR 0.517306
FineTuningLR 0.070024
Epoch 8 | Batch 10/100 | Loss 4.966208
InnerLR 0.517483
FineTuningLR 0.070225
Epoch 8 | Batch 20/100 | Loss 4.799843
InnerLR 0.517758
FineTuningLR 0.070525
Epoch 8 | Batch 30/100 | Loss 4.637253
InnerLR 0.517945
FineTuningLR 0.070726
Epoch 8 | Batch 40/100 | Loss 4.605073
InnerLR 0.518176
FineTuningLR 0.071026
Epoch 8 | Batch 50/100 | Loss 4.675077
InnerLR 0.518303
FineTuningLR 0.071225
Epoch 8 | Batch 60/100 | Loss 4.623209
InnerLR 0.518519
FineTuningLR 0.071525
Epoch 8 | Batch 70/100 | Loss 4.587950
InnerLR 0.518676
FineTuningLR 0.071725
Epoch 8 | Batch 80/100 | Loss 4.558433
InnerLR 0.518926
FineTuningLR 0.072024
Epoch 8 | Batch 90/100 | Loss 4.445160
InnerLR 0.519101
FineTuningLR 0.072223
100 Accuracy = 55.11% +- 2.20%
Epoch 8: 55.11
best model! save...
Epoch 9 | Batch 0/100 | Loss 3.723036
InnerLR 0.519372
FineTuningLR 0.072523
Epoch 9 | Batch 10/100 | Loss 4.470786
InnerLR 0.519558
FineTuningLR 0.072722
Epoch 9 | Batch 20/100 | Loss 4.418113
InnerLR 0.519841
FineTuningLR 0.073021
Epoch 9 | Batch 30/100 | Loss 4.361501
InnerLR 0.520033
FineTuningLR 0.073221
Epoch 9 | Batch 40/100 | Loss 4.157627
InnerLR 0.520324
FineTuningLR 0.073520
Epoch 9 | Batch 50/100 | Loss 4.471427
InnerLR 0.520499
FineTuningLR 0.073719
Epoch 9 | Batch 60/100 | Loss 4.418142
InnerLR 0.520745
FineTuningLR 0.074018
Epoch 9 | Batch 70/100 | Loss 4.389578
InnerLR 0.520917
FineTuningLR 0.074218
Epoch 9 | Batch 80/100 | Loss 4.380829
InnerLR 0.521186
FineTuningLR 0.074517
Epoch 9 | Batch 90/100 | Loss 4.362030
InnerLR 0.521370
FineTuningLR 0.074716
100 Accuracy = 51.96% +- 2.08%
Epoch 9: 51.96
Epoch 10 | Batch 0/100 | Loss 2.901926
InnerLR 0.521651
FineTuningLR 0.075015
Epoch 10 | Batch 10/100 | Loss 4.541158
InnerLR 0.521842
FineTuningLR 0.075215
Epoch 10 | Batch 20/100 | Loss 4.447629
InnerLR 0.522057
FineTuningLR 0.075514
Epoch 10 | Batch 30/100 | Loss 4.302491
InnerLR 0.522152
FineTuningLR 0.075713
Epoch 10 | Batch 40/100 | Loss 4.185736
InnerLR 0.522330
FineTuningLR 0.076013
Epoch 10 | Batch 50/100 | Loss 4.052809
InnerLR 0.522468
FineTuningLR 0.076212
Epoch 10 | Batch 60/100 | Loss 4.150222
InnerLR 0.522697
FineTuningLR 0.076511
Epoch 10 | Batch 70/100 | Loss 4.160886
InnerLR 0.522860
FineTuningLR 0.076711
Epoch 10 | Batch 80/100 | Loss 4.247502
InnerLR 0.523118
FineTuningLR 0.077010
Epoch 10 | Batch 90/100 | Loss 4.192598
InnerLR 0.523297
FineTuningLR 0.077209
100 Accuracy = 54.12% +- 2.30%
Epoch 10: 54.12
Epoch 11 | Batch 0/100 | Loss 2.130757
InnerLR 0.523573
FineTuningLR 0.077509
Epoch 11 | Batch 10/100 | Loss 4.193561
InnerLR 0.523760
FineTuningLR 0.077708
Epoch 11 | Batch 20/100 | Loss 3.987008
InnerLR 0.523992
FineTuningLR 0.078007
Epoch 11 | Batch 30/100 | Loss 3.939799
InnerLR 0.524157
FineTuningLR 0.078207
Epoch 11 | Batch 40/100 | Loss 4.104757
InnerLR 0.524417
FineTuningLR 0.078506
Epoch 11 | Batch 50/100 | Loss 4.101834
InnerLR 0.524597
FineTuningLR 0.078705
Epoch 11 | Batch 60/100 | Loss 4.138348
InnerLR 0.524873
FineTuningLR 0.079005
Epoch 11 | Batch 70/100 | Loss 4.130091
InnerLR 0.525041
FineTuningLR 0.079204
Epoch 11 | Batch 80/100 | Loss 4.101339
InnerLR 0.525279
FineTuningLR 0.079503
Epoch 11 | Batch 90/100 | Loss 4.058048
InnerLR 0.525447
FineTuningLR 0.079703
100 Accuracy = 54.65% +- 2.32%
Epoch 11: 54.65
Epoch 12 | Batch 0/100 | Loss 2.906740
InnerLR 0.525711
FineTuningLR 0.080002
Epoch 12 | Batch 10/100 | Loss 3.873452
InnerLR 0.525892
FineTuningLR 0.080202
Epoch 12 | Batch 20/100 | Loss 4.108515
InnerLR 0.526171
FineTuningLR 0.080501
Epoch 12 | Batch 30/100 | Loss 4.128979
InnerLR 0.526360
FineTuningLR 0.080701
Epoch 12 | Batch 40/100 | Loss 4.070729
InnerLR 0.526648
FineTuningLR 0.081000
Epoch 12 | Batch 50/100 | Loss 4.018191
InnerLR 0.526803
FineTuningLR 0.081199
Epoch 12 | Batch 60/100 | Loss 4.110011
InnerLR 0.527052
FineTuningLR 0.081499
Epoch 12 | Batch 70/100 | Loss 4.067040
InnerLR 0.527226
FineTuningLR 0.081698
Epoch 12 | Batch 80/100 | Loss 3.986007
InnerLR 0.527497
FineTuningLR 0.081998
Epoch 12 | Batch 90/100 | Loss 4.015150
InnerLR 0.527681
FineTuningLR 0.082197
100 Accuracy = 55.96% +- 2.31%
Epoch 12: 55.96
best model! save...
Epoch 13 | Batch 0/100 | Loss 5.573595
InnerLR 0.527964
FineTuningLR 0.082497
Epoch 13 | Batch 10/100 | Loss 3.760126
InnerLR 0.528155
FineTuningLR 0.082696
Epoch 13 | Batch 20/100 | Loss 3.814754
InnerLR 0.528445
FineTuningLR 0.082995
Epoch 13 | Batch 30/100 | Loss 4.124306
InnerLR 0.528582
FineTuningLR 0.083195
Epoch 13 | Batch 40/100 | Loss 4.356550
InnerLR 0.528764
FineTuningLR 0.083494
Epoch 13 | Batch 50/100 | Loss 4.287122
InnerLR 0.528879
FineTuningLR 0.083694
Epoch 13 | Batch 60/100 | Loss 4.278214
InnerLR 0.529082
FineTuningLR 0.083993
Epoch 13 | Batch 70/100 | Loss 4.229526
InnerLR 0.529214
FineTuningLR 0.084194
Epoch 13 | Batch 80/100 | Loss 4.183265
InnerLR 0.529374
FineTuningLR 0.084498
Epoch 13 | Batch 90/100 | Loss 4.156317
InnerLR 0.529453
FineTuningLR 0.084699
100 Accuracy = 56.67% +- 2.45%
Epoch 13: 56.67
best model! save...
Epoch 14 | Batch 0/100 | Loss 2.057451
InnerLR 0.529614
FineTuningLR 0.085001
Epoch 14 | Batch 10/100 | Loss 3.881214
InnerLR 0.529705
FineTuningLR 0.085201
Epoch 14 | Batch 20/100 | Loss 3.820373
InnerLR 0.529879
FineTuningLR 0.085502
Epoch 14 | Batch 30/100 | Loss 3.830087
InnerLR 0.530015
FineTuningLR 0.085702
Epoch 14 | Batch 40/100 | Loss 3.781687
InnerLR 0.530241
FineTuningLR 0.086002
Epoch 14 | Batch 50/100 | Loss 3.925511
InnerLR 0.530403
FineTuningLR 0.086202
Epoch 14 | Batch 60/100 | Loss 3.912848
InnerLR 0.530622
FineTuningLR 0.086502
Epoch 14 | Batch 70/100 | Loss 3.869202
InnerLR 0.530769
FineTuningLR 0.086701
Epoch 14 | Batch 80/100 | Loss 3.827970
InnerLR 0.530970
FineTuningLR 0.087001
Epoch 14 | Batch 90/100 | Loss 3.798922
InnerLR 0.531108
FineTuningLR 0.087201
100 Accuracy = 57.35% +- 2.20%
Epoch 14: 57.35
best model! save...
Epoch 15 | Batch 0/100 | Loss 2.562765
InnerLR 0.531278
FineTuningLR 0.087500
Epoch 15 | Batch 10/100 | Loss 4.010547
InnerLR 0.531377
FineTuningLR 0.087700
Epoch 15 | Batch 20/100 | Loss 3.956598
InnerLR 0.531547
FineTuningLR 0.088006
Epoch 15 | Batch 30/100 | Loss 3.778032
InnerLR 0.531677
FineTuningLR 0.088211
Epoch 15 | Batch 40/100 | Loss 3.796587
InnerLR 0.531876
FineTuningLR 0.088517
Epoch 15 | Batch 50/100 | Loss 3.710151
InnerLR 0.532001
FineTuningLR 0.088719
Epoch 15 | Batch 60/100 | Loss 3.820736
InnerLR 0.532139
FineTuningLR 0.089022
Epoch 15 | Batch 70/100 | Loss 3.734520
InnerLR 0.532213
FineTuningLR 0.089224
Epoch 15 | Batch 80/100 | Loss 3.679781
InnerLR 0.532341
FineTuningLR 0.089525
Epoch 15 | Batch 90/100 | Loss 3.645564
InnerLR 0.532434
FineTuningLR 0.089725
100 Accuracy = 56.40% +- 2.32%
Epoch 15: 56.40
Epoch 16 | Batch 0/100 | Loss 4.714189
InnerLR 0.532546
FineTuningLR 0.090026
Epoch 16 | Batch 10/100 | Loss 4.438913
InnerLR 0.532602
FineTuningLR 0.090227
Epoch 16 | Batch 20/100 | Loss 4.205210
InnerLR 0.532699
FineTuningLR 0.090529
Epoch 16 | Batch 30/100 | Loss 3.825118
InnerLR 0.532782
FineTuningLR 0.090731
Epoch 16 | Batch 40/100 | Loss 3.745500
InnerLR 0.532945
FineTuningLR 0.091034
Epoch 16 | Batch 50/100 | Loss 3.590595
InnerLR 0.533037
FineTuningLR 0.091236
Epoch 16 | Batch 60/100 | Loss 3.602044
InnerLR 0.533213
FineTuningLR 0.091538
Epoch 16 | Batch 70/100 | Loss 3.462507
InnerLR 0.533350
FineTuningLR 0.091738
Epoch 16 | Batch 80/100 | Loss 3.429867
InnerLR 0.533539
FineTuningLR 0.092039
Epoch 16 | Batch 90/100 | Loss 3.475246
InnerLR 0.533671
FineTuningLR 0.092239
100 Accuracy = 60.07% +- 2.47%
Epoch 16: 60.07
best model! save...
Epoch 17 | Batch 0/100 | Loss 4.217285
InnerLR 0.533872
FineTuningLR 0.092539
Epoch 17 | Batch 10/100 | Loss 3.329425
InnerLR 0.533960
FineTuningLR 0.092739
Epoch 17 | Batch 20/100 | Loss 3.573040
InnerLR 0.534089
FineTuningLR 0.093052
Epoch 17 | Batch 30/100 | Loss 3.830514
InnerLR 0.534190
FineTuningLR 0.093264
Epoch 17 | Batch 40/100 | Loss 3.730187
InnerLR 0.534356
FineTuningLR 0.093577
Epoch 17 | Batch 50/100 | Loss 3.644325
InnerLR 0.534425
FineTuningLR 0.093783
Epoch 17 | Batch 60/100 | Loss 3.579499
InnerLR 0.534572
FineTuningLR 0.094092
Epoch 17 | Batch 70/100 | Loss 3.524795
InnerLR 0.534694
FineTuningLR 0.094297
Epoch 17 | Batch 80/100 | Loss 3.541553
InnerLR 0.534811
FineTuningLR 0.094602
Epoch 17 | Batch 90/100 | Loss 3.529657
InnerLR 0.534868
FineTuningLR 0.094805
100 Accuracy = 59.72% +- 2.20%
Epoch 17: 59.72
Epoch 18 | Batch 0/100 | Loss 3.770732
InnerLR 0.535003
FineTuningLR 0.095107
Epoch 18 | Batch 10/100 | Loss 3.329688
InnerLR 0.535099
FineTuningLR 0.095308
Epoch 18 | Batch 20/100 | Loss 3.349092
InnerLR 0.535179
FineTuningLR 0.095608
Epoch 18 | Batch 30/100 | Loss 3.306207
InnerLR 0.535243
FineTuningLR 0.095808
Epoch 18 | Batch 40/100 | Loss 3.176064
InnerLR 0.535331
FineTuningLR 0.096108
Epoch 18 | Batch 50/100 | Loss 3.206802
InnerLR 0.535403
FineTuningLR 0.096307
Epoch 18 | Batch 60/100 | Loss 3.152899
InnerLR 0.535475
FineTuningLR 0.096606
Epoch 18 | Batch 70/100 | Loss 3.055819
InnerLR 0.535559
FineTuningLR 0.096805
Epoch 18 | Batch 80/100 | Loss 3.117129
InnerLR 0.535632
FineTuningLR 0.097104
Epoch 18 | Batch 90/100 | Loss 3.173746
InnerLR 0.535685
FineTuningLR 0.097303
100 Accuracy = 57.75% +- 2.33%
Epoch 18: 57.75
Epoch 19 | Batch 0/100 | Loss 3.414270
InnerLR 0.535732
FineTuningLR 0.097602
Epoch 19 | Batch 10/100 | Loss 2.919529
InnerLR 0.535728
FineTuningLR 0.097800
Epoch 19 | Batch 20/100 | Loss 3.164885
InnerLR 0.535756
FineTuningLR 0.098099
Epoch 19 | Batch 30/100 | Loss 3.209292
InnerLR 0.535805
FineTuningLR 0.098298
Epoch 19 | Batch 40/100 | Loss 3.314219
InnerLR 0.535894
FineTuningLR 0.098596
Epoch 19 | Batch 50/100 | Loss 3.327210
InnerLR 0.535975
FineTuningLR 0.098795
Epoch 19 | Batch 60/100 | Loss 3.222960
InnerLR 0.536137
FineTuningLR 0.099093
Epoch 19 | Batch 70/100 | Loss 3.175930
InnerLR 0.536267
FineTuningLR 0.099292
Epoch 19 | Batch 80/100 | Loss 3.235297
InnerLR 0.536432
FineTuningLR 0.099590
Epoch 19 | Batch 90/100 | Loss 3.230930
InnerLR 0.536505
FineTuningLR 0.099789
100 Accuracy = 58.97% +- 2.32%
Epoch 19: 58.97
Epoch 20 | Batch 0/100 | Loss 3.721611
InnerLR 0.536633
FineTuningLR 0.100087
Epoch 20 | Batch 10/100 | Loss 3.080675
InnerLR 0.536745
FineTuningLR 0.100286
Epoch 20 | Batch 20/100 | Loss 3.201774
InnerLR 0.536944
FineTuningLR 0.100585
Epoch 20 | Batch 30/100 | Loss 3.166950
InnerLR 0.537088
FineTuningLR 0.100787
Epoch 20 | Batch 40/100 | Loss 3.124603
InnerLR 0.537311
FineTuningLR 0.101096
Epoch 20 | Batch 50/100 | Loss 3.178570
InnerLR 0.537464
FineTuningLR 0.101305
Epoch 20 | Batch 60/100 | Loss 3.104361
InnerLR 0.537652
FineTuningLR 0.101614
Epoch 20 | Batch 70/100 | Loss 3.074502
InnerLR 0.537701
FineTuningLR 0.101819
Epoch 20 | Batch 80/100 | Loss 3.168419
InnerLR 0.537802
FineTuningLR 0.102123
Epoch 20 | Batch 90/100 | Loss 3.205262
InnerLR 0.537900
FineTuningLR 0.102325
100 Accuracy = 61.73% +- 2.09%
Epoch 20: 61.73
best model! save...
Epoch 21 | Batch 0/100 | Loss 1.945773
InnerLR 0.538045
FineTuningLR 0.102627
Epoch 21 | Batch 10/100 | Loss 3.273407
InnerLR 0.538155
FineTuningLR 0.102828
Epoch 21 | Batch 20/100 | Loss 2.998671
InnerLR 0.538312
FineTuningLR 0.103128
Epoch 21 | Batch 30/100 | Loss 3.022868
InnerLR 0.538428
FineTuningLR 0.103328
Epoch 21 | Batch 40/100 | Loss 2.929812
InnerLR 0.538557
FineTuningLR 0.103627
Epoch 21 | Batch 50/100 | Loss 2.977656
InnerLR 0.538588
FineTuningLR 0.103827
Epoch 21 | Batch 60/100 | Loss 3.071415
InnerLR 0.538666
FineTuningLR 0.104125
Epoch 21 | Batch 70/100 | Loss 3.060665
InnerLR 0.538754
FineTuningLR 0.104324
Epoch 21 | Batch 80/100 | Loss 3.065601
InnerLR 0.538831
FineTuningLR 0.104623
Epoch 21 | Batch 90/100 | Loss 3.069339
InnerLR 0.538906
FineTuningLR 0.104822
100 Accuracy = 60.57% +- 2.28%
Epoch 21: 60.57
Epoch 22 | Batch 0/100 | Loss 4.389167
InnerLR 0.539024
FineTuningLR 0.105120
Epoch 22 | Batch 10/100 | Loss 2.988813
InnerLR 0.539081
FineTuningLR 0.105319
Epoch 22 | Batch 20/100 | Loss 3.129961
InnerLR 0.539179
FineTuningLR 0.105617
Epoch 22 | Batch 30/100 | Loss 3.220698
InnerLR 0.539244
FineTuningLR 0.105815
Epoch 22 | Batch 40/100 | Loss 3.320046
InnerLR 0.539305
FineTuningLR 0.106113
Epoch 22 | Batch 50/100 | Loss 3.227953
InnerLR 0.539309
FineTuningLR 0.106312
Epoch 22 | Batch 60/100 | Loss 3.310272
InnerLR 0.539325
FineTuningLR 0.106610
Epoch 22 | Batch 70/100 | Loss 3.265055
InnerLR 0.539306
FineTuningLR 0.106809
Epoch 22 | Batch 80/100 | Loss 3.163712
InnerLR 0.539295
FineTuningLR 0.107107
Epoch 22 | Batch 90/100 | Loss 3.175582
InnerLR 0.539243
FineTuningLR 0.107306
100 Accuracy = 61.79% +- 2.40%
Epoch 22: 61.79
best model! save...
Epoch 23 | Batch 0/100 | Loss 2.283489
InnerLR 0.539167
FineTuningLR 0.107604
Epoch 23 | Batch 10/100 | Loss 3.530158
InnerLR 0.539082
FineTuningLR 0.107802
Epoch 23 | Batch 20/100 | Loss 3.217670
InnerLR 0.538986
FineTuningLR 0.108102
Epoch 23 | Batch 30/100 | Loss 3.184691
InnerLR 0.538951
FineTuningLR 0.108304
Epoch 23 | Batch 40/100 | Loss 3.079139
InnerLR 0.538878
FineTuningLR 0.108605
Epoch 23 | Batch 50/100 | Loss 2.968817
InnerLR 0.538864
FineTuningLR 0.108805
Epoch 23 | Batch 60/100 | Loss 2.980204
InnerLR 0.538862
FineTuningLR 0.109105
Epoch 23 | Batch 70/100 | Loss 2.970153
InnerLR 0.538888
FineTuningLR 0.109304
Epoch 23 | Batch 80/100 | Loss 2.912273
InnerLR 0.538887
FineTuningLR 0.109604
Epoch 23 | Batch 90/100 | Loss 2.905893
InnerLR 0.538851
FineTuningLR 0.109803
100 Accuracy = 61.15% +- 2.39%
Epoch 23: 61.15
Epoch 24 | Batch 0/100 | Loss 3.084933
InnerLR 0.538853
FineTuningLR 0.110101
Epoch 24 | Batch 10/100 | Loss 2.714649
InnerLR 0.538901
FineTuningLR 0.110301
Epoch 24 | Batch 20/100 | Loss 2.660052
InnerLR 0.538971
FineTuningLR 0.110599
Epoch 24 | Batch 30/100 | Loss 2.691289
InnerLR 0.539044
FineTuningLR 0.110802
Epoch 24 | Batch 40/100 | Loss 2.808468
InnerLR 0.539128
FineTuningLR 0.111110
Epoch 24 | Batch 50/100 | Loss 2.903288
InnerLR 0.539160
FineTuningLR 0.111314
Epoch 24 | Batch 60/100 | Loss 2.824759
InnerLR 0.539241
FineTuningLR 0.111617
Epoch 24 | Batch 70/100 | Loss 2.828430
InnerLR 0.539290
FineTuningLR 0.111819
Epoch 24 | Batch 80/100 | Loss 2.771786
InnerLR 0.539417
FineTuningLR 0.112120
Epoch 24 | Batch 90/100 | Loss 2.837597
InnerLR 0.539491
FineTuningLR 0.112321
100 Accuracy = 62.76% +- 2.05%
Epoch 24: 62.76
best model! save...
Epoch 25 | Batch 0/100 | Loss 2.173315
InnerLR 0.539607
FineTuningLR 0.112621
Epoch 25 | Batch 10/100 | Loss 2.417582
InnerLR 0.539659
FineTuningLR 0.112828
Epoch 25 | Batch 20/100 | Loss 2.884934
InnerLR 0.539683
FineTuningLR 0.113146
Epoch 25 | Batch 30/100 | Loss 2.763099
InnerLR 0.539648
FineTuningLR 0.113354
Epoch 25 | Batch 40/100 | Loss 2.731892
InnerLR 0.539558
FineTuningLR 0.113664
Epoch 25 | Batch 50/100 | Loss 2.757276
InnerLR 0.539490
FineTuningLR 0.113868
Epoch 25 | Batch 60/100 | Loss 2.720269
InnerLR 0.539340
FineTuningLR 0.114173
Epoch 25 | Batch 70/100 | Loss 2.764545
InnerLR 0.539276
FineTuningLR 0.114375
Epoch 25 | Batch 80/100 | Loss 2.747283
InnerLR 0.539196
FineTuningLR 0.114676
Epoch 25 | Batch 90/100 | Loss 2.711143
InnerLR 0.539157
FineTuningLR 0.114877
100 Accuracy = 61.77% +- 2.29%
Epoch 25: 61.77
Epoch 26 | Batch 0/100 | Loss 1.939072
InnerLR 0.539137
FineTuningLR 0.115177
Epoch 26 | Batch 10/100 | Loss 2.743012
InnerLR 0.539129
FineTuningLR 0.115376
Epoch 26 | Batch 20/100 | Loss 2.746189
InnerLR 0.539105
FineTuningLR 0.115675
Epoch 26 | Batch 30/100 | Loss 2.694333
InnerLR 0.539066
FineTuningLR 0.115874
Epoch 26 | Batch 40/100 | Loss 2.670423
InnerLR 0.539037
FineTuningLR 0.116176
Epoch 26 | Batch 50/100 | Loss 2.775175
InnerLR 0.538976
FineTuningLR 0.116378
Epoch 26 | Batch 60/100 | Loss 2.829338
InnerLR 0.538930
FineTuningLR 0.116679
Epoch 26 | Batch 70/100 | Loss 2.734113
InnerLR 0.538891
FineTuningLR 0.116880
Epoch 26 | Batch 80/100 | Loss 2.700547
InnerLR 0.538822
FineTuningLR 0.117180
Epoch 26 | Batch 90/100 | Loss 2.647835
InnerLR 0.538764
FineTuningLR 0.117379
100 Accuracy = 62.93% +- 2.38%
Epoch 26: 62.93
best model! save...
Epoch 27 | Batch 0/100 | Loss 2.280391
InnerLR 0.538666
FineTuningLR 0.117678
Epoch 27 | Batch 10/100 | Loss 2.810295
InnerLR 0.538619
FineTuningLR 0.117877
Epoch 27 | Batch 20/100 | Loss 2.622925
InnerLR 0.538569
FineTuningLR 0.118175
Epoch 27 | Batch 30/100 | Loss 2.703153
InnerLR 0.538579
FineTuningLR 0.118374
Epoch 27 | Batch 40/100 | Loss 2.716865
InnerLR 0.538548
FineTuningLR 0.118672
Epoch 27 | Batch 50/100 | Loss 2.640784
InnerLR 0.538504
FineTuningLR 0.118870
Epoch 27 | Batch 60/100 | Loss 2.630252
InnerLR 0.538431
FineTuningLR 0.119168
Epoch 27 | Batch 70/100 | Loss 2.590806
InnerLR 0.538409
FineTuningLR 0.119367
Epoch 27 | Batch 80/100 | Loss 2.559560
InnerLR 0.538352
FineTuningLR 0.119664
Epoch 27 | Batch 90/100 | Loss 2.573903
InnerLR 0.538308
FineTuningLR 0.119863
100 Accuracy = 61.92% +- 2.18%
Epoch 27: 61.92
Epoch 28 | Batch 0/100 | Loss 2.080741
InnerLR 0.538326
FineTuningLR 0.120160
Epoch 28 | Batch 10/100 | Loss 1.997341
InnerLR 0.538344
FineTuningLR 0.120359
Epoch 28 | Batch 20/100 | Loss 2.234850
InnerLR 0.538376
FineTuningLR 0.120656
Epoch 28 | Batch 30/100 | Loss 2.292006
InnerLR 0.538366
FineTuningLR 0.120855
Epoch 28 | Batch 40/100 | Loss 2.416025
InnerLR 0.538310
FineTuningLR 0.121152
Epoch 28 | Batch 50/100 | Loss 2.391079
InnerLR 0.538273
FineTuningLR 0.121351
Epoch 28 | Batch 60/100 | Loss 2.376962
InnerLR 0.538232
FineTuningLR 0.121650
Epoch 28 | Batch 70/100 | Loss 2.349338
InnerLR 0.538205
FineTuningLR 0.121852
Epoch 28 | Batch 80/100 | Loss 2.363213
InnerLR 0.538189
FineTuningLR 0.122154
Epoch 28 | Batch 90/100 | Loss 2.364380
InnerLR 0.538170
FineTuningLR 0.122354
100 Accuracy = 65.84% +- 2.36%
Epoch 28: 65.84
best model! save...
Epoch 29 | Batch 0/100 | Loss 3.577983
InnerLR 0.538153
FineTuningLR 0.122654
Epoch 29 | Batch 10/100 | Loss 2.444405
InnerLR 0.538179
FineTuningLR 0.122854
Epoch 29 | Batch 20/100 | Loss 2.323754
InnerLR 0.538205
FineTuningLR 0.123153
Epoch 29 | Batch 30/100 | Loss 2.458722
InnerLR 0.538182
FineTuningLR 0.123352
Epoch 29 | Batch 40/100 | Loss 2.346015
InnerLR 0.538162
FineTuningLR 0.123650
Epoch 29 | Batch 50/100 | Loss 2.423593
InnerLR 0.538187
FineTuningLR 0.123849
Epoch 29 | Batch 60/100 | Loss 2.411055
InnerLR 0.538210
FineTuningLR 0.124147
Epoch 29 | Batch 70/100 | Loss 2.391707
InnerLR 0.538187
FineTuningLR 0.124345
Epoch 29 | Batch 80/100 | Loss 2.369626
InnerLR 0.538145
FineTuningLR 0.124643
Epoch 29 | Batch 90/100 | Loss 2.359069
InnerLR 0.538114
FineTuningLR 0.124842
100 Accuracy = 62.53% +- 2.32%
Epoch 29: 62.53
Epoch 30 | Batch 0/100 | Loss 2.111227
InnerLR 0.538010
FineTuningLR 0.125140
Epoch 30 | Batch 10/100 | Loss 2.061187
InnerLR 0.537910
FineTuningLR 0.125338
Epoch 30 | Batch 20/100 | Loss 2.553875
InnerLR 0.537763
FineTuningLR 0.125637
Epoch 30 | Batch 30/100 | Loss 2.493320
InnerLR 0.537653
FineTuningLR 0.125836
Epoch 30 | Batch 40/100 | Loss 2.333650
InnerLR 0.537456
FineTuningLR 0.126134
Epoch 30 | Batch 50/100 | Loss 2.411385
InnerLR 0.537309
FineTuningLR 0.126333
Epoch 30 | Batch 60/100 | Loss 2.381123
InnerLR 0.537143
FineTuningLR 0.126631
Epoch 30 | Batch 70/100 | Loss 2.302348
InnerLR 0.537036
FineTuningLR 0.126829
Epoch 30 | Batch 80/100 | Loss 2.290943
InnerLR 0.536854
FineTuningLR 0.127135
Epoch 30 | Batch 90/100 | Loss 2.324877
InnerLR 0.536734
FineTuningLR 0.127337
100 Accuracy = 66.69% +- 2.14%
Epoch 30: 66.69
best model! save...
Epoch 31 | Batch 0/100 | Loss 1.651673
InnerLR 0.536590
FineTuningLR 0.127640
Epoch 31 | Batch 10/100 | Loss 2.034773
InnerLR 0.536519
FineTuningLR 0.127840
Epoch 31 | Batch 20/100 | Loss 1.982933
InnerLR 0.536367
FineTuningLR 0.128141
Epoch 31 | Batch 30/100 | Loss 1.873999
InnerLR 0.536260
FineTuningLR 0.128348
Epoch 31 | Batch 40/100 | Loss 1.891525
InnerLR 0.536065
FineTuningLR 0.128656
Epoch 31 | Batch 50/100 | Loss 1.951013
InnerLR 0.535957
FineTuningLR 0.128859
Epoch 31 | Batch 60/100 | Loss 2.015404
InnerLR 0.535763
FineTuningLR 0.129163
Epoch 31 | Batch 70/100 | Loss 2.033554
InnerLR 0.535637
FineTuningLR 0.129364
Epoch 31 | Batch 80/100 | Loss 2.023038
InnerLR 0.535447
FineTuningLR 0.129665
Epoch 31 | Batch 90/100 | Loss 2.072627
InnerLR 0.535303
FineTuningLR 0.129865
100 Accuracy = 66.25% +- 2.22%
Epoch 31: 66.25
Epoch 32 | Batch 0/100 | Loss 2.158478
InnerLR 0.535106
FineTuningLR 0.130165
Epoch 32 | Batch 10/100 | Loss 1.760898
InnerLR 0.535008
FineTuningLR 0.130364
Epoch 32 | Batch 20/100 | Loss 1.915264
InnerLR 0.534845
FineTuningLR 0.130663
Epoch 32 | Batch 30/100 | Loss 1.973914
InnerLR 0.534739
FineTuningLR 0.130862
Epoch 32 | Batch 40/100 | Loss 2.014023
InnerLR 0.534660
FineTuningLR 0.131160
Epoch 32 | Batch 50/100 | Loss 2.075484
InnerLR 0.534646
FineTuningLR 0.131358
Epoch 32 | Batch 60/100 | Loss 2.030448
InnerLR 0.534620
FineTuningLR 0.131656
Epoch 32 | Batch 70/100 | Loss 2.048300
InnerLR 0.534615
FineTuningLR 0.131855
Epoch 32 | Batch 80/100 | Loss 2.006230
InnerLR 0.534640
FineTuningLR 0.132152
Epoch 32 | Batch 90/100 | Loss 1.994411
InnerLR 0.534669
FineTuningLR 0.132351
100 Accuracy = 64.56% +- 2.40%
Epoch 32: 64.56
Epoch 33 | Batch 0/100 | Loss 2.828481
InnerLR 0.534633
FineTuningLR 0.132649
Epoch 33 | Batch 10/100 | Loss 1.561860
InnerLR 0.534587
FineTuningLR 0.132847
Epoch 33 | Batch 20/100 | Loss 1.708904
InnerLR 0.534491
FineTuningLR 0.133145
Epoch 33 | Batch 30/100 | Loss 1.895495
InnerLR 0.534433
FineTuningLR 0.133343
Epoch 33 | Batch 40/100 | Loss 1.916790
InnerLR 0.534296
FineTuningLR 0.133640
Epoch 33 | Batch 50/100 | Loss 1.928282
InnerLR 0.534179
FineTuningLR 0.133839
Epoch 33 | Batch 60/100 | Loss 1.980087
InnerLR 0.533975
FineTuningLR 0.134136
Epoch 33 | Batch 70/100 | Loss 1.947849
InnerLR 0.533823
FineTuningLR 0.134335
Epoch 33 | Batch 80/100 | Loss 1.999681
InnerLR 0.533579
FineTuningLR 0.134632
Epoch 33 | Batch 90/100 | Loss 1.976939
InnerLR 0.533407
FineTuningLR 0.134831
100 Accuracy = 66.87% +- 2.04%
Epoch 33: 66.87
best model! save...
Epoch 34 | Batch 0/100 | Loss 1.885170
InnerLR 0.533166
FineTuningLR 0.135135
Epoch 34 | Batch 10/100 | Loss 1.699548
InnerLR 0.533004
FineTuningLR 0.135338
Epoch 34 | Batch 20/100 | Loss 1.809963
InnerLR 0.532802
FineTuningLR 0.135642
Epoch 34 | Batch 30/100 | Loss 1.871245
InnerLR 0.532692
FineTuningLR 0.135851
Epoch 34 | Batch 40/100 | Loss 1.922434
InnerLR 0.532522
FineTuningLR 0.136160
Epoch 34 | Batch 50/100 | Loss 1.867727
InnerLR 0.532388
FineTuningLR 0.136365
Epoch 34 | Batch 60/100 | Loss 1.900970
InnerLR 0.532164
FineTuningLR 0.136669
Epoch 34 | Batch 70/100 | Loss 1.927871
InnerLR 0.532060
FineTuningLR 0.136871
Epoch 34 | Batch 80/100 | Loss 1.922968
InnerLR 0.531897
FineTuningLR 0.137173
Epoch 34 | Batch 90/100 | Loss 1.926804
InnerLR 0.531767
FineTuningLR 0.137373
100 Accuracy = 65.79% +- 2.30%
Epoch 34: 65.79
Epoch 35 | Batch 0/100 | Loss 2.173883
InnerLR 0.531547
FineTuningLR 0.137673
Epoch 35 | Batch 10/100 | Loss 1.993800
InnerLR 0.531425
FineTuningLR 0.137873
Epoch 35 | Batch 20/100 | Loss 1.737002
InnerLR 0.531254
FineTuningLR 0.138171
Epoch 35 | Batch 30/100 | Loss 1.858452
InnerLR 0.531131
FineTuningLR 0.138370
Epoch 35 | Batch 40/100 | Loss 1.803626
InnerLR 0.530919
FineTuningLR 0.138669
Epoch 35 | Batch 50/100 | Loss 1.772533
InnerLR 0.530778
FineTuningLR 0.138870
Epoch 35 | Batch 60/100 | Loss 1.788569
InnerLR 0.530620
FineTuningLR 0.139176
Epoch 35 | Batch 70/100 | Loss 1.812980
InnerLR 0.530492
FineTuningLR 0.139379
Epoch 35 | Batch 80/100 | Loss 1.794497
InnerLR 0.530276
FineTuningLR 0.139682
Epoch 35 | Batch 90/100 | Loss 1.812165
InnerLR 0.530120
FineTuningLR 0.139885
100 Accuracy = 68.93% +- 2.20%
Epoch 35: 68.93
best model! save...
Epoch 36 | Batch 0/100 | Loss 0.815575
InnerLR 0.529926
FineTuningLR 0.140187
Epoch 36 | Batch 10/100 | Loss 1.463877
InnerLR 0.529796
FineTuningLR 0.140396
Epoch 36 | Batch 20/100 | Loss 1.494321
InnerLR 0.529577
FineTuningLR 0.140705
Epoch 36 | Batch 30/100 | Loss 1.677534
InnerLR 0.529418
FineTuningLR 0.140909
Epoch 36 | Batch 40/100 | Loss 1.677838
InnerLR 0.529165
FineTuningLR 0.141213
Epoch 36 | Batch 50/100 | Loss 1.683259
InnerLR 0.528988
FineTuningLR 0.141415
Epoch 36 | Batch 60/100 | Loss 1.718451
InnerLR 0.528714
FineTuningLR 0.141716
Epoch 36 | Batch 70/100 | Loss 1.689933
InnerLR 0.528527
FineTuningLR 0.141916
Epoch 36 | Batch 80/100 | Loss 1.754807
InnerLR 0.528279
FineTuningLR 0.142216
Epoch 36 | Batch 90/100 | Loss 1.735761
InnerLR 0.528117
FineTuningLR 0.142415
100 Accuracy = 65.28% +- 2.41%
Epoch 36: 65.28
Epoch 37 | Batch 0/100 | Loss 1.031544
InnerLR 0.527860
FineTuningLR 0.142713
Epoch 37 | Batch 10/100 | Loss 1.503205
InnerLR 0.527720
FineTuningLR 0.142920
Epoch 37 | Batch 20/100 | Loss 1.521979
InnerLR 0.527514
FineTuningLR 0.143226
Epoch 37 | Batch 30/100 | Loss 1.746118
InnerLR 0.527362
FineTuningLR 0.143429
Epoch 37 | Batch 40/100 | Loss 1.730657
InnerLR 0.527209
FineTuningLR 0.143732
Epoch 37 | Batch 50/100 | Loss 1.650667
InnerLR 0.527095
FineTuningLR 0.143933
Epoch 37 | Batch 60/100 | Loss 1.653632
InnerLR 0.526894
FineTuningLR 0.144233
Epoch 37 | Batch 70/100 | Loss 1.595274
InnerLR 0.526747
FineTuningLR 0.144435
Epoch 37 | Batch 80/100 | Loss 1.644300
InnerLR 0.526508
FineTuningLR 0.144737
Epoch 37 | Batch 90/100 | Loss 1.680245
InnerLR 0.526339
FineTuningLR 0.144937
100 Accuracy = 67.41% +- 2.16%
Epoch 37: 67.41
Epoch 38 | Batch 0/100 | Loss 1.678123
InnerLR 0.526073
FineTuningLR 0.145237
Epoch 38 | Batch 10/100 | Loss 1.966841
InnerLR 0.525890
FineTuningLR 0.145436
Epoch 38 | Batch 20/100 | Loss 1.799644
InnerLR 0.525609
FineTuningLR 0.145735
Epoch 38 | Batch 30/100 | Loss 1.718737
InnerLR 0.525439
FineTuningLR 0.145934
Epoch 38 | Batch 40/100 | Loss 1.624987
InnerLR 0.525253
FineTuningLR 0.146232
Epoch 38 | Batch 50/100 | Loss 1.625469
InnerLR 0.525110
FineTuningLR 0.146430
Epoch 38 | Batch 60/100 | Loss 1.634697
InnerLR 0.524876
FineTuningLR 0.146728
Epoch 38 | Batch 70/100 | Loss 1.639130
InnerLR 0.524710
FineTuningLR 0.146926
Epoch 38 | Batch 80/100 | Loss 1.613623
InnerLR 0.524447
FineTuningLR 0.147223
Epoch 38 | Batch 90/100 | Loss 1.603630
InnerLR 0.524325
FineTuningLR 0.147421
100 Accuracy = 67.84% +- 2.15%
Epoch 38: 67.84
Epoch 39 | Batch 0/100 | Loss 2.214993
InnerLR 0.524173
FineTuningLR 0.147722
Epoch 39 | Batch 10/100 | Loss 1.636179
InnerLR 0.524058
FineTuningLR 0.147923
Epoch 39 | Batch 20/100 | Loss 1.583167
InnerLR 0.523910
FineTuningLR 0.148224
Epoch 39 | Batch 30/100 | Loss 1.629595
InnerLR 0.523788
FineTuningLR 0.148424
Epoch 39 | Batch 40/100 | Loss 1.609026
InnerLR 0.523596
FineTuningLR 0.148733
Epoch 39 | Batch 50/100 | Loss 1.650199
InnerLR 0.523451
FineTuningLR 0.148937
Epoch 39 | Batch 60/100 | Loss 1.657797
InnerLR 0.523252
FineTuningLR 0.149241
Epoch 39 | Batch 70/100 | Loss 1.679156
InnerLR 0.523115
FineTuningLR 0.149443
Epoch 39 | Batch 80/100 | Loss 1.685605
InnerLR 0.522907
FineTuningLR 0.149744
Epoch 39 | Batch 90/100 | Loss 1.642971
InnerLR 0.522778
FineTuningLR 0.149944
100 Accuracy = 65.97% +- 2.30%
Epoch 39: 65.97
Epoch 40 | Batch 0/100 | Loss 0.923444
InnerLR 0.522633
FineTuningLR 0.150243
Epoch 40 | Batch 10/100 | Loss 1.281037
InnerLR 0.522537
FineTuningLR 0.150443
Epoch 40 | Batch 20/100 | Loss 1.362222
InnerLR 0.522383
FineTuningLR 0.150747
Epoch 40 | Batch 30/100 | Loss 1.531896
InnerLR 0.522266
FineTuningLR 0.150951
Epoch 40 | Batch 40/100 | Loss 1.577511
InnerLR 0.522097
FineTuningLR 0.151256
Epoch 40 | Batch 50/100 | Loss 1.634321
InnerLR 0.521975
FineTuningLR 0.151459
Epoch 40 | Batch 60/100 | Loss 1.654751
InnerLR 0.521763
FineTuningLR 0.151761
Epoch 40 | Batch 70/100 | Loss 1.659518
InnerLR 0.521608
FineTuningLR 0.151961
Epoch 40 | Batch 80/100 | Loss 1.622588
InnerLR 0.521366
FineTuningLR 0.152266
Epoch 40 | Batch 90/100 | Loss 1.584485
InnerLR 0.521233
FineTuningLR 0.152469
100 Accuracy = 70.12% +- 2.20%
Epoch 40: 70.12
best model! save...
Epoch 41 | Batch 0/100 | Loss 2.044564
InnerLR 0.521010
FineTuningLR 0.152770
Epoch 41 | Batch 10/100 | Loss 1.598378
InnerLR 0.520869
FineTuningLR 0.152970
Epoch 41 | Batch 20/100 | Loss 1.513501
InnerLR 0.520662
FineTuningLR 0.153270
Epoch 41 | Batch 30/100 | Loss 1.413989
InnerLR 0.520509
FineTuningLR 0.153469
Epoch 41 | Batch 40/100 | Loss 1.446015
InnerLR 0.520263
FineTuningLR 0.153768
Epoch 41 | Batch 50/100 | Loss 1.441616
InnerLR 0.520090
FineTuningLR 0.153966
Epoch 41 | Batch 60/100 | Loss 1.452156
InnerLR 0.519836
FineTuningLR 0.154271
Epoch 41 | Batch 70/100 | Loss 1.431343
InnerLR 0.519664
FineTuningLR 0.154476
Epoch 41 | Batch 80/100 | Loss 1.440500
InnerLR 0.519395
FineTuningLR 0.154780
Epoch 41 | Batch 90/100 | Loss 1.438564
InnerLR 0.519211
FineTuningLR 0.154981
100 Accuracy = 68.73% +- 2.22%
Epoch 41: 68.73
Epoch 42 | Batch 0/100 | Loss 3.951924
InnerLR 0.518966
FineTuningLR 0.155282
Epoch 42 | Batch 10/100 | Loss 1.842723
InnerLR 0.518806
FineTuningLR 0.155482
Epoch 42 | Batch 20/100 | Loss 1.582494
InnerLR 0.518556
FineTuningLR 0.155785
Epoch 42 | Batch 30/100 | Loss 1.485263
InnerLR 0.518389
FineTuningLR 0.155990
Epoch 42 | Batch 40/100 | Loss 1.417471
InnerLR 0.518126
FineTuningLR 0.156295
Epoch 42 | Batch 50/100 | Loss 1.382920
InnerLR 0.517945
FineTuningLR 0.156497
Epoch 42 | Batch 60/100 | Loss 1.362376
InnerLR 0.517755
FineTuningLR 0.156801
Epoch 42 | Batch 70/100 | Loss 1.382300
InnerLR 0.517623
FineTuningLR 0.157003
Epoch 42 | Batch 80/100 | Loss 1.403393
InnerLR 0.517420
FineTuningLR 0.157304
Epoch 42 | Batch 90/100 | Loss 1.387559
InnerLR 0.517293
FineTuningLR 0.157504
100 Accuracy = 70.20% +- 2.21%
Epoch 42: 70.20
best model! save...
Epoch 43 | Batch 0/100 | Loss 1.232829
InnerLR 0.517077
FineTuningLR 0.157803
Epoch 43 | Batch 10/100 | Loss 1.127247
InnerLR 0.516920
FineTuningLR 0.158002
Epoch 43 | Batch 20/100 | Loss 1.319092
InnerLR 0.516668
FineTuningLR 0.158300
Epoch 43 | Batch 30/100 | Loss 1.251557
InnerLR 0.516530
FineTuningLR 0.158498
Epoch 43 | Batch 40/100 | Loss 1.236639
InnerLR 0.516302
FineTuningLR 0.158795
Epoch 43 | Batch 50/100 | Loss 1.229549
InnerLR 0.516137
FineTuningLR 0.158993
Epoch 43 | Batch 60/100 | Loss 1.246989
InnerLR 0.515878
FineTuningLR 0.159290
Epoch 43 | Batch 70/100 | Loss 1.253053
InnerLR 0.515700
FineTuningLR 0.159490
Epoch 43 | Batch 80/100 | Loss 1.262904
InnerLR 0.515478
FineTuningLR 0.159788
Epoch 43 | Batch 90/100 | Loss 1.247710
InnerLR 0.515318
FineTuningLR 0.159986
100 Accuracy = 68.29% +- 2.56%
Epoch 43: 68.29
Epoch 44 | Batch 0/100 | Loss 1.089053
InnerLR 0.515063
FineTuningLR 0.160284
Epoch 44 | Batch 10/100 | Loss 1.670479
InnerLR 0.514886
FineTuningLR 0.160482
Epoch 44 | Batch 20/100 | Loss 1.385547
InnerLR 0.514611
FineTuningLR 0.160779
Epoch 44 | Batch 30/100 | Loss 1.336665
InnerLR 0.514423
FineTuningLR 0.160977
Epoch 44 | Batch 40/100 | Loss 1.323037
InnerLR 0.514136
FineTuningLR 0.161274
Epoch 44 | Batch 50/100 | Loss 1.346220
InnerLR 0.513943
FineTuningLR 0.161472
Epoch 44 | Batch 60/100 | Loss 1.317581
InnerLR 0.513649
FineTuningLR 0.161768
Epoch 44 | Batch 70/100 | Loss 1.289351
InnerLR 0.513490
FineTuningLR 0.161966
Epoch 44 | Batch 80/100 | Loss 1.251756
InnerLR 0.513237
FineTuningLR 0.162263
Epoch 44 | Batch 90/100 | Loss 1.275802
InnerLR 0.513061
FineTuningLR 0.162461
100 Accuracy = 70.99% +- 2.10%
Epoch 44: 70.99
best model! save...
Epoch 45 | Batch 0/100 | Loss 0.906300
InnerLR 0.512787
FineTuningLR 0.162757
Epoch 45 | Batch 10/100 | Loss 1.255523
InnerLR 0.512600
FineTuningLR 0.162955
Epoch 45 | Batch 20/100 | Loss 1.299122
InnerLR 0.512314
FineTuningLR 0.163252
Epoch 45 | Batch 30/100 | Loss 1.207840
InnerLR 0.512120
FineTuningLR 0.163450
Epoch 45 | Batch 40/100 | Loss 1.217570
InnerLR 0.511873
FineTuningLR 0.163753
Epoch 45 | Batch 50/100 | Loss 1.228837
InnerLR 0.511699
FineTuningLR 0.163954
Epoch 45 | Batch 60/100 | Loss 1.181398
InnerLR 0.511428
FineTuningLR 0.164255
Epoch 45 | Batch 70/100 | Loss 1.197449
InnerLR 0.511243
FineTuningLR 0.164454
Epoch 45 | Batch 80/100 | Loss 1.186586
InnerLR 0.510958
FineTuningLR 0.164753
Epoch 45 | Batch 90/100 | Loss 1.190267
InnerLR 0.510766
FineTuningLR 0.164952
100 Accuracy = 71.00% +- 2.20%
Epoch 45: 71.00
best model! save...
Epoch 46 | Batch 0/100 | Loss 1.179546
InnerLR 0.510474
FineTuningLR 0.165250
Epoch 46 | Batch 10/100 | Loss 1.192639
InnerLR 0.510277
FineTuningLR 0.165449
Epoch 46 | Batch 20/100 | Loss 1.183411
InnerLR 0.509981
FineTuningLR 0.165746
Epoch 46 | Batch 30/100 | Loss 1.187381
InnerLR 0.509782
FineTuningLR 0.165944
Epoch 46 | Batch 40/100 | Loss 1.194024
InnerLR 0.509482
FineTuningLR 0.166241
Epoch 46 | Batch 50/100 | Loss 1.212090
InnerLR 0.509282
FineTuningLR 0.166439
Epoch 46 | Batch 60/100 | Loss 1.163168
InnerLR 0.508981
FineTuningLR 0.166736
Epoch 46 | Batch 70/100 | Loss 1.173244
InnerLR 0.508783
FineTuningLR 0.166936
Epoch 46 | Batch 80/100 | Loss 1.160153
InnerLR 0.508487
FineTuningLR 0.167238
Epoch 46 | Batch 90/100 | Loss 1.140163
InnerLR 0.508289
FineTuningLR 0.167438
100 Accuracy = 71.29% +- 2.10%
Epoch 46: 71.29
best model! save...
Epoch 47 | Batch 0/100 | Loss 1.215729
InnerLR 0.507990
FineTuningLR 0.167738
Epoch 47 | Batch 10/100 | Loss 1.065264
InnerLR 0.507790
FineTuningLR 0.167937
Epoch 47 | Batch 20/100 | Loss 1.073024
InnerLR 0.507490
FineTuningLR 0.168236
Epoch 47 | Batch 30/100 | Loss 0.985682
InnerLR 0.507289
FineTuningLR 0.168435
Epoch 47 | Batch 40/100 | Loss 1.008688
InnerLR 0.507025
FineTuningLR 0.168732
Epoch 47 | Batch 50/100 | Loss 1.048274
InnerLR 0.506855
FineTuningLR 0.168931
Epoch 47 | Batch 60/100 | Loss 1.073267
InnerLR 0.506589
FineTuningLR 0.169228
Epoch 47 | Batch 70/100 | Loss 1.045926
InnerLR 0.506405
FineTuningLR 0.169426
Epoch 47 | Batch 80/100 | Loss 1.030653
InnerLR 0.506124
FineTuningLR 0.169723
Epoch 47 | Batch 90/100 | Loss 1.065103
InnerLR 0.505932
FineTuningLR 0.169921
100 Accuracy = 74.79% +- 1.95%
Epoch 47: 74.79
best model! save...
Epoch 48 | Batch 0/100 | Loss 1.307128
InnerLR 0.505642
FineTuningLR 0.170218
Epoch 48 | Batch 10/100 | Loss 0.969152
InnerLR 0.505446
FineTuningLR 0.170416
Epoch 48 | Batch 20/100 | Loss 0.989875
InnerLR 0.505151
FineTuningLR 0.170713
Epoch 48 | Batch 30/100 | Loss 1.006970
InnerLR 0.504952
FineTuningLR 0.170911
Epoch 48 | Batch 40/100 | Loss 1.031186
InnerLR 0.504653
FineTuningLR 0.171208
Epoch 48 | Batch 50/100 | Loss 1.029847
InnerLR 0.504453
FineTuningLR 0.171406
Epoch 48 | Batch 60/100 | Loss 1.023362
InnerLR 0.504171
FineTuningLR 0.171704
Epoch 48 | Batch 70/100 | Loss 1.031267
InnerLR 0.504001
FineTuningLR 0.171905
Epoch 48 | Batch 80/100 | Loss 1.021548
InnerLR 0.503735
FineTuningLR 0.172205
Epoch 48 | Batch 90/100 | Loss 1.027100
InnerLR 0.503552
FineTuningLR 0.172405
100 Accuracy = 70.92% +- 2.20%
Epoch 48: 70.92
Epoch 49 | Batch 0/100 | Loss 0.608167
InnerLR 0.503271
FineTuningLR 0.172703
Epoch 49 | Batch 10/100 | Loss 1.010076
InnerLR 0.503080
FineTuningLR 0.172902
Epoch 49 | Batch 20/100 | Loss 0.959397
InnerLR 0.502844
FineTuningLR 0.173200
Epoch 49 | Batch 30/100 | Loss 0.924074
InnerLR 0.502677
FineTuningLR 0.173399
Epoch 49 | Batch 40/100 | Loss 0.919155
InnerLR 0.502413
FineTuningLR 0.173696
Epoch 49 | Batch 50/100 | Loss 0.919318
InnerLR 0.502232
FineTuningLR 0.173894
Epoch 49 | Batch 60/100 | Loss 0.915070
InnerLR 0.501952
FineTuningLR 0.174192
Epoch 49 | Batch 70/100 | Loss 0.913648
InnerLR 0.501762
FineTuningLR 0.174390
Epoch 49 | Batch 80/100 | Loss 0.908505
InnerLR 0.501473
FineTuningLR 0.174687
Epoch 49 | Batch 90/100 | Loss 0.910457
InnerLR 0.501278
FineTuningLR 0.174885
100 Accuracy = 72.08% +- 2.15%
Epoch 49: 72.08
Epoch 50 | Batch 0/100 | Loss 0.943755
InnerLR 0.500983
FineTuningLR 0.175182
Epoch 50 | Batch 10/100 | Loss 0.920773
InnerLR 0.500785
FineTuningLR 0.175380
Epoch 50 | Batch 20/100 | Loss 0.910947
InnerLR 0.500486
FineTuningLR 0.175677
Epoch 50 | Batch 30/100 | Loss 0.907987
InnerLR 0.500287
FineTuningLR 0.175875
Epoch 50 | Batch 40/100 | Loss 0.909494
InnerLR 0.499986
FineTuningLR 0.176172
Epoch 50 | Batch 50/100 | Loss 0.882132
InnerLR 0.499786
FineTuningLR 0.176370
Epoch 50 | Batch 60/100 | Loss 0.868838
InnerLR 0.499484
FineTuningLR 0.176667
Epoch 50 | Batch 70/100 | Loss 0.851497
InnerLR 0.499283
FineTuningLR 0.176865
Epoch 50 | Batch 80/100 | Loss 0.842483
InnerLR 0.498981
FineTuningLR 0.177162
Epoch 50 | Batch 90/100 | Loss 0.842078
InnerLR 0.498779
FineTuningLR 0.177360
100 Accuracy = 72.72% +- 2.37%
Epoch 50: 72.72
Epoch 51 | Batch 0/100 | Loss 0.928977
InnerLR 0.498477
FineTuningLR 0.177656
Epoch 51 | Batch 10/100 | Loss 0.754268
InnerLR 0.498275
FineTuningLR 0.177854
Epoch 51 | Batch 20/100 | Loss 0.805060
InnerLR 0.497972
FineTuningLR 0.178152
Epoch 51 | Batch 30/100 | Loss 0.805576
InnerLR 0.497770
FineTuningLR 0.178350
Epoch 51 | Batch 40/100 | Loss 0.828165
InnerLR 0.497468
FineTuningLR 0.178647
Epoch 51 | Batch 50/100 | Loss 0.858970
InnerLR 0.497266
FineTuningLR 0.178845
Epoch 51 | Batch 60/100 | Loss 0.823979
InnerLR 0.496963
FineTuningLR 0.179142
Epoch 51 | Batch 70/100 | Loss 0.829021
InnerLR 0.496799
FineTuningLR 0.179340
Epoch 51 | Batch 80/100 | Loss 0.818828
InnerLR 0.496541
FineTuningLR 0.179637
Epoch 51 | Batch 90/100 | Loss 0.820748
InnerLR 0.496361
FineTuningLR 0.179835
100 Accuracy = 71.71% +- 1.87%
Epoch 51: 71.71
Epoch 52 | Batch 0/100 | Loss 0.643847
InnerLR 0.496084
FineTuningLR 0.180132
Epoch 52 | Batch 10/100 | Loss 0.985212
InnerLR 0.495896
FineTuningLR 0.180330
Epoch 52 | Batch 20/100 | Loss 1.018615
InnerLR 0.495608
FineTuningLR 0.180627
Epoch 52 | Batch 30/100 | Loss 0.926611
InnerLR 0.495414
FineTuningLR 0.180825
Epoch 52 | Batch 40/100 | Loss 0.841776
InnerLR 0.495120
FineTuningLR 0.181122
Epoch 52 | Batch 50/100 | Loss 0.847651
InnerLR 0.494923
FineTuningLR 0.181320
Epoch 52 | Batch 60/100 | Loss 0.838693
InnerLR 0.494626
FineTuningLR 0.181617
Epoch 52 | Batch 70/100 | Loss 0.837861
InnerLR 0.494426
FineTuningLR 0.181815
Epoch 52 | Batch 80/100 | Loss 0.823900
InnerLR 0.494127
FineTuningLR 0.182113
Epoch 52 | Batch 90/100 | Loss 0.816053
InnerLR 0.493926
FineTuningLR 0.182311
100 Accuracy = 72.55% +- 2.00%
Epoch 52: 72.55
Epoch 53 | Batch 0/100 | Loss 0.913349
InnerLR 0.493625
FineTuningLR 0.182608
Epoch 53 | Batch 10/100 | Loss 0.810852
InnerLR 0.493424
FineTuningLR 0.182806
Epoch 53 | Batch 20/100 | Loss 0.719770
InnerLR 0.493123
FineTuningLR 0.183103
Epoch 53 | Batch 30/100 | Loss 0.735639
InnerLR 0.492921
FineTuningLR 0.183301
Epoch 53 | Batch 40/100 | Loss 0.709776
InnerLR 0.492619
FineTuningLR 0.183598
Epoch 53 | Batch 50/100 | Loss 0.721280
InnerLR 0.492417
FineTuningLR 0.183797
Epoch 53 | Batch 60/100 | Loss 0.712746
InnerLR 0.492115
FineTuningLR 0.184094
Epoch 53 | Batch 70/100 | Loss 0.703503
InnerLR 0.491913
FineTuningLR 0.184292
Epoch 53 | Batch 80/100 | Loss 0.710808
InnerLR 0.491611
FineTuningLR 0.184589
Epoch 53 | Batch 90/100 | Loss 0.713210
InnerLR 0.491409
FineTuningLR 0.184787
100 Accuracy = 72.83% +- 1.84%
Epoch 53: 72.83
Epoch 54 | Batch 0/100 | Loss 0.878768
InnerLR 0.491106
FineTuningLR 0.185085
Epoch 54 | Batch 10/100 | Loss 0.714402
InnerLR 0.490904
FineTuningLR 0.185283
Epoch 54 | Batch 20/100 | Loss 0.708884
InnerLR 0.490602
FineTuningLR 0.185580
Epoch 54 | Batch 30/100 | Loss 0.698047
InnerLR 0.490400
FineTuningLR 0.185778
Epoch 54 | Batch 40/100 | Loss 0.664454
InnerLR 0.490097
FineTuningLR 0.186076
Epoch 54 | Batch 50/100 | Loss 0.682772
InnerLR 0.489895
FineTuningLR 0.186274
Epoch 54 | Batch 60/100 | Loss 0.688261
InnerLR 0.489593
FineTuningLR 0.186571
Epoch 54 | Batch 70/100 | Loss 0.669018
InnerLR 0.489391
FineTuningLR 0.186769
Epoch 54 | Batch 80/100 | Loss 0.665937
InnerLR 0.489088
FineTuningLR 0.187067
Epoch 54 | Batch 90/100 | Loss 0.671082
InnerLR 0.488886
FineTuningLR 0.187265
100 Accuracy = 73.56% +- 2.02%
Epoch 54: 73.56
Epoch 55 | Batch 0/100 | Loss 0.700056
InnerLR 0.488584
FineTuningLR 0.187562
Epoch 55 | Batch 10/100 | Loss 0.623955
InnerLR 0.488382
FineTuningLR 0.187761
Epoch 55 | Batch 20/100 | Loss 0.708705
InnerLR 0.488079
FineTuningLR 0.188058
Epoch 55 | Batch 30/100 | Loss 0.685391
InnerLR 0.487877
FineTuningLR 0.188256
Epoch 55 | Batch 40/100 | Loss 0.660189
InnerLR 0.487575
FineTuningLR 0.188554
Epoch 55 | Batch 50/100 | Loss 0.658217
InnerLR 0.487373
FineTuningLR 0.188752
Epoch 55 | Batch 60/100 | Loss 0.639713
InnerLR 0.487070
FineTuningLR 0.189049
Epoch 55 | Batch 70/100 | Loss 0.639024
InnerLR 0.486868
FineTuningLR 0.189248
Epoch 55 | Batch 80/100 | Loss 0.634042
InnerLR 0.486566
FineTuningLR 0.189545
Epoch 55 | Batch 90/100 | Loss 0.639142
InnerLR 0.486364
FineTuningLR 0.189743
100 Accuracy = 76.17% +- 2.11%
Epoch 55: 76.17
best model! save...
Epoch 56 | Batch 0/100 | Loss 1.288068
InnerLR 0.486061
FineTuningLR 0.190041
Epoch 56 | Batch 10/100 | Loss 0.708690
InnerLR 0.485860
FineTuningLR 0.190239
Epoch 56 | Batch 20/100 | Loss 0.653486
InnerLR 0.485557
FineTuningLR 0.190536
Epoch 56 | Batch 30/100 | Loss 0.689543
InnerLR 0.485355
FineTuningLR 0.190735
Epoch 56 | Batch 40/100 | Loss 0.661869
InnerLR 0.485053
FineTuningLR 0.191032
Epoch 56 | Batch 50/100 | Loss 0.649367
InnerLR 0.484851
FineTuningLR 0.191231
Epoch 56 | Batch 60/100 | Loss 0.644284
InnerLR 0.484548
FineTuningLR 0.191528
Epoch 56 | Batch 70/100 | Loss 0.639857
InnerLR 0.484347
FineTuningLR 0.191726
Epoch 56 | Batch 80/100 | Loss 0.629903
InnerLR 0.484044
FineTuningLR 0.192024
Epoch 56 | Batch 90/100 | Loss 0.623463
InnerLR 0.483843
FineTuningLR 0.192222
100 Accuracy = 75.28% +- 1.92%
Epoch 56: 75.28
Epoch 57 | Batch 0/100 | Loss 0.276831
InnerLR 0.483540
FineTuningLR 0.192520
Epoch 57 | Batch 10/100 | Loss 0.654775
InnerLR 0.483338
FineTuningLR 0.192718
Epoch 57 | Batch 20/100 | Loss 0.620446
InnerLR 0.483036
FineTuningLR 0.193016
Epoch 57 | Batch 30/100 | Loss 0.598439
InnerLR 0.482834
FineTuningLR 0.193214
Epoch 57 | Batch 40/100 | Loss 0.601958
InnerLR 0.482532
FineTuningLR 0.193512
Epoch 57 | Batch 50/100 | Loss 0.583861
InnerLR 0.482330
FineTuningLR 0.193710
Epoch 57 | Batch 60/100 | Loss 0.600300
InnerLR 0.482027
FineTuningLR 0.194007
Epoch 57 | Batch 70/100 | Loss 0.592705
InnerLR 0.481864
FineTuningLR 0.194206
Epoch 57 | Batch 80/100 | Loss 0.584079
InnerLR 0.481606
FineTuningLR 0.194503
Epoch 57 | Batch 90/100 | Loss 0.583669
InnerLR 0.481427
FineTuningLR 0.194702
100 Accuracy = 76.71% +- 2.08%
Epoch 57: 76.71
best model! save...
Epoch 58 | Batch 0/100 | Loss 0.379808
InnerLR 0.481151
FineTuningLR 0.194999
Epoch 58 | Batch 10/100 | Loss 0.456922
InnerLR 0.480962
FineTuningLR 0.195198
Epoch 58 | Batch 20/100 | Loss 0.446306
InnerLR 0.480675
FineTuningLR 0.195495
Epoch 58 | Batch 30/100 | Loss 0.490988
InnerLR 0.480482
FineTuningLR 0.195694
Epoch 58 | Batch 40/100 | Loss 0.500837
InnerLR 0.480188
FineTuningLR 0.195991
Epoch 58 | Batch 50/100 | Loss 0.525700
InnerLR 0.479991
FineTuningLR 0.196190
Epoch 58 | Batch 60/100 | Loss 0.525147
InnerLR 0.479694
FineTuningLR 0.196488
Epoch 58 | Batch 70/100 | Loss 0.519473
InnerLR 0.479495
FineTuningLR 0.196686
Epoch 58 | Batch 80/100 | Loss 0.521206
InnerLR 0.479196
FineTuningLR 0.196984
Epoch 58 | Batch 90/100 | Loss 0.521242
InnerLR 0.478996
FineTuningLR 0.197182
100 Accuracy = 76.75% +- 2.34%
Epoch 58: 76.75
best model! save...
Epoch 59 | Batch 0/100 | Loss 0.651662
InnerLR 0.478696
FineTuningLR 0.197480
Epoch 59 | Batch 10/100 | Loss 0.581370
InnerLR 0.478495
FineTuningLR 0.197678
Epoch 59 | Batch 20/100 | Loss 0.569262
InnerLR 0.478194
FineTuningLR 0.197976
Epoch 59 | Batch 30/100 | Loss 0.550980
InnerLR 0.477993
FineTuningLR 0.198174
Epoch 59 | Batch 40/100 | Loss 0.543219
InnerLR 0.477691
FineTuningLR 0.198472
Epoch 59 | Batch 50/100 | Loss 0.532942
InnerLR 0.477490
FineTuningLR 0.198671
Epoch 59 | Batch 60/100 | Loss 0.528367
InnerLR 0.477188
FineTuningLR 0.198968
Epoch 59 | Batch 70/100 | Loss 0.529313
InnerLR 0.476987
FineTuningLR 0.199167
Epoch 59 | Batch 80/100 | Loss 0.524798
InnerLR 0.476685
FineTuningLR 0.199464
Epoch 59 | Batch 90/100 | Loss 0.531313
InnerLR 0.476483
FineTuningLR 0.199663
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 77.87% +- 1.86%
Epoch 59: 77.87
best model! save...
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0001/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0001/tabula_muris/leo_FCNet/20231211_173759
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 94.22% +- 0.36%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0001/tabula_muris/leo_FCNet/20231211_173759
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 77.34% +- 0.82%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0001/tabula_muris/leo_FCNet/20231211_173759
600 Accuracy = 69.92% +- 0.86%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_5_latent_space_dim_8_lr_0.0001/results.txt
+-------+-------------------+--------------------+
| split |      acc_mean     |      acc_std       |
+-------+-------------------+--------------------+
| train | 94.22222222222223 | 4.469264031991659  |
|  val  | 77.34444444444443 | 10.214435440004733 |
|  test | 69.91777777777779 | 10.800235708447511 |
+-------+-------------------+--------------------+
