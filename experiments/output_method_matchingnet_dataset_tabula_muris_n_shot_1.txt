/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/said.gurbuz/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/said.gurbuz/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 1
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 1
n_query: 15
method:
  name: matchingnet
  train_batch: null
  val_batch: null
  fast_weight: false
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 1
    _target_: methods.matchingnet.MatchingNet
model: FCNet
mode: train
exp:
  name: method_matchingnet_dataset_tabula_muris_n_shot_1
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.001
checkpoint:
  dir: checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_1/tabula_muris/matchingnet_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Model Architecture:
MatchingNet(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (loss_fn): NLLLoss()
  (FCE): FullyContextualEmbedding(
    (lstmcell): LSTMCell(128, 64)
    (softmax): Softmax(dim=None)
  )
  (G_encoder): LSTM(64, 64, batch_first=True, bidirectional=True)
  (relu): ReLU()
  (softmax): Softmax(dim=None)
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
Epoch 0 | Batch 0/100 | Loss 6.403896
Epoch 0 | Batch 10/100 | Loss 4.650192
Epoch 0 | Batch 20/100 | Loss 3.857999
Epoch 0 | Batch 30/100 | Loss 3.429591
Epoch 0 | Batch 40/100 | Loss 3.161693
Epoch 0 | Batch 50/100 | Loss 2.885804
Epoch 0 | Batch 60/100 | Loss 2.741975
Epoch 0 | Batch 70/100 | Loss 2.647342
Epoch 0 | Batch 80/100 | Loss 2.513291
Epoch 0 | Batch 90/100 | Loss 2.392401
100 Test Acc = 79.97% +- 2.49%
Epoch 0: 79.97
best model! save...
Epoch 1 | Batch 0/100 | Loss 0.566424
Epoch 1 | Batch 10/100 | Loss 1.548793
Epoch 1 | Batch 20/100 | Loss 1.508359
Epoch 1 | Batch 30/100 | Loss 1.559721
Epoch 1 | Batch 40/100 | Loss 1.561747
Epoch 1 | Batch 50/100 | Loss 1.566771
Epoch 1 | Batch 60/100 | Loss 1.517518
Epoch 1 | Batch 70/100 | Loss 1.498732
Epoch 1 | Batch 80/100 | Loss 1.403494
Epoch 1 | Batch 90/100 | Loss 1.399454
100 Test Acc = 76.40% +- 2.31%
Epoch 1: 76.40
Epoch 2 | Batch 0/100 | Loss 0.010080
Epoch 2 | Batch 10/100 | Loss 1.213718
Epoch 2 | Batch 20/100 | Loss 1.214322
Epoch 2 | Batch 30/100 | Loss 1.314911
Epoch 2 | Batch 40/100 | Loss 1.201776
Epoch 2 | Batch 50/100 | Loss 1.133559
Epoch 2 | Batch 60/100 | Loss 1.169480
Epoch 2 | Batch 70/100 | Loss 1.201773
Epoch 2 | Batch 80/100 | Loss 1.196686
Epoch 2 | Batch 90/100 | Loss 1.176754
100 Test Acc = 78.77% +- 2.56%
Epoch 2: 78.77
Epoch 3 | Batch 0/100 | Loss 1.853895
Epoch 3 | Batch 10/100 | Loss 1.024070
Epoch 3 | Batch 20/100 | Loss 0.904285
Epoch 3 | Batch 30/100 | Loss 0.849730
Epoch 3 | Batch 40/100 | Loss 1.020012
Epoch 3 | Batch 50/100 | Loss 1.050950
Epoch 3 | Batch 60/100 | Loss 1.132688
Epoch 3 | Batch 70/100 | Loss 1.146496
Epoch 3 | Batch 80/100 | Loss 1.106148
Epoch 3 | Batch 90/100 | Loss 1.140565
100 Test Acc = 77.91% +- 2.57%
Epoch 3: 77.91
Epoch 4 | Batch 0/100 | Loss 0.875636
Epoch 4 | Batch 10/100 | Loss 0.691291
Epoch 4 | Batch 20/100 | Loss 0.556458
Epoch 4 | Batch 30/100 | Loss 0.768440
Epoch 4 | Batch 40/100 | Loss 0.780804
Epoch 4 | Batch 50/100 | Loss 0.751966
Epoch 4 | Batch 60/100 | Loss 0.765481
Epoch 4 | Batch 70/100 | Loss 0.800585
Epoch 4 | Batch 80/100 | Loss 0.794625
Epoch 4 | Batch 90/100 | Loss 0.774818
100 Test Acc = 77.32% +- 2.49%
Epoch 4: 77.32
Epoch 5 | Batch 0/100 | Loss 1.460332
Epoch 5 | Batch 10/100 | Loss 1.022584
Epoch 5 | Batch 20/100 | Loss 0.766244
Epoch 5 | Batch 30/100 | Loss 0.752795
Epoch 5 | Batch 40/100 | Loss 0.738748
Epoch 5 | Batch 50/100 | Loss 0.737090
Epoch 5 | Batch 60/100 | Loss 0.683933
Epoch 5 | Batch 70/100 | Loss 0.731013
Epoch 5 | Batch 80/100 | Loss 0.713502
Epoch 5 | Batch 90/100 | Loss 0.715009
100 Test Acc = 74.99% +- 2.31%
Epoch 5: 74.99
Epoch 6 | Batch 0/100 | Loss 0.598769
Epoch 6 | Batch 10/100 | Loss 0.823549
Epoch 6 | Batch 20/100 | Loss 0.690321
Epoch 6 | Batch 30/100 | Loss 0.707286
Epoch 6 | Batch 40/100 | Loss 0.704840
Epoch 6 | Batch 50/100 | Loss 0.674195
Epoch 6 | Batch 60/100 | Loss 0.690131
Epoch 6 | Batch 70/100 | Loss 0.675763
Epoch 6 | Batch 80/100 | Loss 0.672965
Epoch 6 | Batch 90/100 | Loss 0.668595
100 Test Acc = 75.40% +- 2.57%
Epoch 6: 75.40
Epoch 7 | Batch 0/100 | Loss 0.052651
Epoch 7 | Batch 10/100 | Loss 0.347991
Epoch 7 | Batch 20/100 | Loss 0.433437
Epoch 7 | Batch 30/100 | Loss 0.513252
Epoch 7 | Batch 40/100 | Loss 0.565231
Epoch 7 | Batch 50/100 | Loss 0.564153
Epoch 7 | Batch 60/100 | Loss 0.652817
Epoch 7 | Batch 70/100 | Loss 0.636406
Epoch 7 | Batch 80/100 | Loss 0.610745
Epoch 7 | Batch 90/100 | Loss 0.608935
100 Test Acc = 74.89% +- 2.67%
Epoch 7: 74.89
Epoch 8 | Batch 0/100 | Loss 0.344799
Epoch 8 | Batch 10/100 | Loss 0.346909
Epoch 8 | Batch 20/100 | Loss 0.417401
Epoch 8 | Batch 30/100 | Loss 0.425649
Epoch 8 | Batch 40/100 | Loss 0.428465
Epoch 8 | Batch 50/100 | Loss 0.439191
Epoch 8 | Batch 60/100 | Loss 0.428676
Epoch 8 | Batch 70/100 | Loss 0.441072
Epoch 8 | Batch 80/100 | Loss 0.432821
Epoch 8 | Batch 90/100 | Loss 0.440250
100 Test Acc = 76.68% +- 2.41%
Epoch 8: 76.68
Epoch 9 | Batch 0/100 | Loss 0.629918
Epoch 9 | Batch 10/100 | Loss 0.261069
Epoch 9 | Batch 20/100 | Loss 0.396676
Epoch 9 | Batch 30/100 | Loss 0.429546
Epoch 9 | Batch 40/100 | Loss 0.398276
Epoch 9 | Batch 50/100 | Loss 0.428163
Epoch 9 | Batch 60/100 | Loss 0.483654
Epoch 9 | Batch 70/100 | Loss 0.484517
Epoch 9 | Batch 80/100 | Loss 0.480348
Epoch 9 | Batch 90/100 | Loss 0.499952
100 Test Acc = 75.85% +- 2.67%
Epoch 9: 75.85
Epoch 10 | Batch 0/100 | Loss 0.141968
Epoch 10 | Batch 10/100 | Loss 0.310396
Epoch 10 | Batch 20/100 | Loss 0.371481
Epoch 10 | Batch 30/100 | Loss 0.392649
Epoch 10 | Batch 40/100 | Loss 0.361054
Epoch 10 | Batch 50/100 | Loss 0.396207
Epoch 10 | Batch 60/100 | Loss 0.365383
Epoch 10 | Batch 70/100 | Loss 0.378466
Epoch 10 | Batch 80/100 | Loss 0.377926
Epoch 10 | Batch 90/100 | Loss 0.402691
100 Test Acc = 76.92% +- 2.75%
Epoch 10: 76.92
Epoch 11 | Batch 0/100 | Loss 1.272255
Epoch 11 | Batch 10/100 | Loss 0.480839
Epoch 11 | Batch 20/100 | Loss 0.585203
Epoch 11 | Batch 30/100 | Loss 0.523912
Epoch 11 | Batch 40/100 | Loss 0.506647
Epoch 11 | Batch 50/100 | Loss 0.503773
Epoch 11 | Batch 60/100 | Loss 0.497626
Epoch 11 | Batch 70/100 | Loss 0.502112
Epoch 11 | Batch 80/100 | Loss 0.480273
Epoch 11 | Batch 90/100 | Loss 0.452933
100 Test Acc = 74.91% +- 2.74%
Epoch 11: 74.91
Epoch 12 | Batch 0/100 | Loss 0.262480
Epoch 12 | Batch 10/100 | Loss 0.443874
Epoch 12 | Batch 20/100 | Loss 0.364494
Epoch 12 | Batch 30/100 | Loss 0.366395
Epoch 12 | Batch 40/100 | Loss 0.342226
Epoch 12 | Batch 50/100 | Loss 0.385990
Epoch 12 | Batch 60/100 | Loss 0.421078
Epoch 12 | Batch 70/100 | Loss 0.465851
Epoch 12 | Batch 80/100 | Loss 0.462257
Epoch 12 | Batch 90/100 | Loss 0.469591
100 Test Acc = 76.41% +- 2.61%
Epoch 12: 76.41
Epoch 13 | Batch 0/100 | Loss 1.777054
Epoch 13 | Batch 10/100 | Loss 0.577921
Epoch 13 | Batch 20/100 | Loss 0.572676
Epoch 13 | Batch 30/100 | Loss 0.571728
Epoch 13 | Batch 40/100 | Loss 0.547480
Epoch 13 | Batch 50/100 | Loss 0.499254
Epoch 13 | Batch 60/100 | Loss 0.503295
Epoch 13 | Batch 70/100 | Loss 0.535744
Epoch 13 | Batch 80/100 | Loss 0.524253
Epoch 13 | Batch 90/100 | Loss 0.499478
100 Test Acc = 76.47% +- 2.67%
Epoch 13: 76.47
Epoch 14 | Batch 0/100 | Loss 0.032082
Epoch 14 | Batch 10/100 | Loss 0.251315
Epoch 14 | Batch 20/100 | Loss 0.288581
Epoch 14 | Batch 30/100 | Loss 0.318821
Epoch 14 | Batch 40/100 | Loss 0.328560
Epoch 14 | Batch 50/100 | Loss 0.348688
Epoch 14 | Batch 60/100 | Loss 0.371963
Epoch 14 | Batch 70/100 | Loss 0.399518
Epoch 14 | Batch 80/100 | Loss 0.379590
Epoch 14 | Batch 90/100 | Loss 0.392123
100 Test Acc = 76.44% +- 2.52%
Epoch 14: 76.44
Epoch 15 | Batch 0/100 | Loss 0.074735
Epoch 15 | Batch 10/100 | Loss 0.402444
Epoch 15 | Batch 20/100 | Loss 0.361298
Epoch 15 | Batch 30/100 | Loss 0.372156
Epoch 15 | Batch 40/100 | Loss 0.371736
Epoch 15 | Batch 50/100 | Loss 0.364855
Epoch 15 | Batch 60/100 | Loss 0.384887
Epoch 15 | Batch 70/100 | Loss 0.370530
Epoch 15 | Batch 80/100 | Loss 0.351990
Epoch 15 | Batch 90/100 | Loss 0.368462
100 Test Acc = 78.36% +- 2.31%
Epoch 15: 78.36
Epoch 16 | Batch 0/100 | Loss 0.707291
Epoch 16 | Batch 10/100 | Loss 0.437876
Epoch 16 | Batch 20/100 | Loss 0.357232
Epoch 16 | Batch 30/100 | Loss 0.349485
Epoch 16 | Batch 40/100 | Loss 0.352894
Epoch 16 | Batch 50/100 | Loss 0.356224
Epoch 16 | Batch 60/100 | Loss 0.367632
Epoch 16 | Batch 70/100 | Loss 0.345049
Epoch 16 | Batch 80/100 | Loss 0.335602
Epoch 16 | Batch 90/100 | Loss 0.345401
100 Test Acc = 75.80% +- 2.39%
Epoch 16: 75.80
Epoch 17 | Batch 0/100 | Loss 0.514183
Epoch 17 | Batch 10/100 | Loss 0.331028
Epoch 17 | Batch 20/100 | Loss 0.275021
Epoch 17 | Batch 30/100 | Loss 0.314181
Epoch 17 | Batch 40/100 | Loss 0.312836
Epoch 17 | Batch 50/100 | Loss 0.311030
Epoch 17 | Batch 60/100 | Loss 0.303100
Epoch 17 | Batch 70/100 | Loss 0.329971
Epoch 17 | Batch 80/100 | Loss 0.344344
Epoch 17 | Batch 90/100 | Loss 0.357183
100 Test Acc = 78.68% +- 2.46%
Epoch 17: 78.68
Epoch 18 | Batch 0/100 | Loss 0.023561
Epoch 18 | Batch 10/100 | Loss 0.294917
Epoch 18 | Batch 20/100 | Loss 0.374605
Epoch 18 | Batch 30/100 | Loss 0.395143
Epoch 18 | Batch 40/100 | Loss 0.386389
Epoch 18 | Batch 50/100 | Loss 0.365608
Epoch 18 | Batch 60/100 | Loss 0.388676
Epoch 18 | Batch 70/100 | Loss 0.385443
Epoch 18 | Batch 80/100 | Loss 0.383584
Epoch 18 | Batch 90/100 | Loss 0.399497
100 Test Acc = 76.55% +- 2.65%
Epoch 18: 76.55
Epoch 19 | Batch 0/100 | Loss 0.051270
Epoch 19 | Batch 10/100 | Loss 0.332383
Epoch 19 | Batch 20/100 | Loss 0.319874
Epoch 19 | Batch 30/100 | Loss 0.310847
Epoch 19 | Batch 40/100 | Loss 0.318484
Epoch 19 | Batch 50/100 | Loss 0.297208
Epoch 19 | Batch 60/100 | Loss 0.314100
Epoch 19 | Batch 70/100 | Loss 0.296245
Epoch 19 | Batch 80/100 | Loss 0.315141
Epoch 19 | Batch 90/100 | Loss 0.323829
100 Test Acc = 73.93% +- 2.93%
Epoch 19: 73.93
Epoch 20 | Batch 0/100 | Loss 0.598999
Epoch 20 | Batch 10/100 | Loss 0.289027
Epoch 20 | Batch 20/100 | Loss 0.314026
Epoch 20 | Batch 30/100 | Loss 0.278688
Epoch 20 | Batch 40/100 | Loss 0.303794
Epoch 20 | Batch 50/100 | Loss 0.311627
Epoch 20 | Batch 60/100 | Loss 0.310371
Epoch 20 | Batch 70/100 | Loss 0.293331
Epoch 20 | Batch 80/100 | Loss 0.283430
Epoch 20 | Batch 90/100 | Loss 0.288511
100 Test Acc = 74.45% +- 2.57%
Epoch 20: 74.45
Epoch 21 | Batch 0/100 | Loss 0.434192
Epoch 21 | Batch 10/100 | Loss 0.279032
Epoch 21 | Batch 20/100 | Loss 0.229544
Epoch 21 | Batch 30/100 | Loss 0.268005
Epoch 21 | Batch 40/100 | Loss 0.257484
Epoch 21 | Batch 50/100 | Loss 0.271920
Epoch 21 | Batch 60/100 | Loss 0.298626
Epoch 21 | Batch 70/100 | Loss 0.295458
Epoch 21 | Batch 80/100 | Loss 0.310201
Epoch 21 | Batch 90/100 | Loss 0.302887
100 Test Acc = 75.96% +- 2.56%
Epoch 21: 75.96
Epoch 22 | Batch 0/100 | Loss 0.149081
Epoch 22 | Batch 10/100 | Loss 0.257969
Epoch 22 | Batch 20/100 | Loss 0.284116
Epoch 22 | Batch 30/100 | Loss 0.265774
Epoch 22 | Batch 40/100 | Loss 0.292978
Epoch 22 | Batch 50/100 | Loss 0.287719
Epoch 22 | Batch 60/100 | Loss 0.278695
Epoch 22 | Batch 70/100 | Loss 0.290057
Epoch 22 | Batch 80/100 | Loss 0.283511
Epoch 22 | Batch 90/100 | Loss 0.284545
100 Test Acc = 76.64% +- 2.48%
Epoch 22: 76.64
Epoch 23 | Batch 0/100 | Loss 0.030194
Epoch 23 | Batch 10/100 | Loss 0.212336
Epoch 23 | Batch 20/100 | Loss 0.258038
Epoch 23 | Batch 30/100 | Loss 0.255614
Epoch 23 | Batch 40/100 | Loss 0.251941
Epoch 23 | Batch 50/100 | Loss 0.261291
Epoch 23 | Batch 60/100 | Loss 0.241914
Epoch 23 | Batch 70/100 | Loss 0.245928
Epoch 23 | Batch 80/100 | Loss 0.265067
Epoch 23 | Batch 90/100 | Loss 0.265775
100 Test Acc = 78.91% +- 2.46%
Epoch 23: 78.91
Epoch 24 | Batch 0/100 | Loss 0.623017
Epoch 24 | Batch 10/100 | Loss 0.274355
Epoch 24 | Batch 20/100 | Loss 0.318284
Epoch 24 | Batch 30/100 | Loss 0.344190
Epoch 24 | Batch 40/100 | Loss 0.339355
Epoch 24 | Batch 50/100 | Loss 0.333826
Epoch 24 | Batch 60/100 | Loss 0.339567
Epoch 24 | Batch 70/100 | Loss 0.336731
Epoch 24 | Batch 80/100 | Loss 0.327751
Epoch 24 | Batch 90/100 | Loss 0.326916
100 Test Acc = 74.19% +- 2.75%
Epoch 24: 74.19
Epoch 25 | Batch 0/100 | Loss 0.242122
Epoch 25 | Batch 10/100 | Loss 0.306882
Epoch 25 | Batch 20/100 | Loss 0.231833
Epoch 25 | Batch 30/100 | Loss 0.263264
Epoch 25 | Batch 40/100 | Loss 0.275598
Epoch 25 | Batch 50/100 | Loss 0.320334
Epoch 25 | Batch 60/100 | Loss 0.305879
Epoch 25 | Batch 70/100 | Loss 0.289719
Epoch 25 | Batch 80/100 | Loss 0.275012
Epoch 25 | Batch 90/100 | Loss 0.300887
100 Test Acc = 75.85% +- 2.83%
Epoch 25: 75.85
Epoch 26 | Batch 0/100 | Loss 0.162646
Epoch 26 | Batch 10/100 | Loss 0.431167
Epoch 26 | Batch 20/100 | Loss 0.368459
Epoch 26 | Batch 30/100 | Loss 0.337976
Epoch 26 | Batch 40/100 | Loss 0.334891
Epoch 26 | Batch 50/100 | Loss 0.329545
Epoch 26 | Batch 60/100 | Loss 0.299669
Epoch 26 | Batch 70/100 | Loss 0.290014
Epoch 26 | Batch 80/100 | Loss 0.288739
Epoch 26 | Batch 90/100 | Loss 0.292737
100 Test Acc = 79.12% +- 2.38%
Epoch 26: 79.12
Epoch 27 | Batch 0/100 | Loss 0.279229
Epoch 27 | Batch 10/100 | Loss 0.182535
Epoch 27 | Batch 20/100 | Loss 0.259306
Epoch 27 | Batch 30/100 | Loss 0.272266
Epoch 27 | Batch 40/100 | Loss 0.295781
Epoch 27 | Batch 50/100 | Loss 0.305163
Epoch 27 | Batch 60/100 | Loss 0.287212
Epoch 27 | Batch 70/100 | Loss 0.272237
Epoch 27 | Batch 80/100 | Loss 0.277819
Epoch 27 | Batch 90/100 | Loss 0.269982
100 Test Acc = 74.89% +- 2.44%
Epoch 27: 74.89
Epoch 28 | Batch 0/100 | Loss 0.093626
Epoch 28 | Batch 10/100 | Loss 0.238324
Epoch 28 | Batch 20/100 | Loss 0.333121
Epoch 28 | Batch 30/100 | Loss 0.313499
Epoch 28 | Batch 40/100 | Loss 0.336397
Epoch 28 | Batch 50/100 | Loss 0.323353
Epoch 28 | Batch 60/100 | Loss 0.320843
Epoch 28 | Batch 70/100 | Loss 0.298434
Epoch 28 | Batch 80/100 | Loss 0.285915
Epoch 28 | Batch 90/100 | Loss 0.275803
100 Test Acc = 75.55% +- 2.86%
Epoch 28: 75.55
Epoch 29 | Batch 0/100 | Loss 0.812650
Epoch 29 | Batch 10/100 | Loss 0.304092
Epoch 29 | Batch 20/100 | Loss 0.307592
Epoch 29 | Batch 30/100 | Loss 0.308806
Epoch 29 | Batch 40/100 | Loss 0.312574
Epoch 29 | Batch 50/100 | Loss 0.301530
Epoch 29 | Batch 60/100 | Loss 0.296469
Epoch 29 | Batch 70/100 | Loss 0.295138
Epoch 29 | Batch 80/100 | Loss 0.281639
Epoch 29 | Batch 90/100 | Loss 0.273238
100 Test Acc = 74.49% +- 2.80%
Epoch 29: 74.49
Epoch 30 | Batch 0/100 | Loss 0.183184
Epoch 30 | Batch 10/100 | Loss 0.239073
Epoch 30 | Batch 20/100 | Loss 0.261180
Epoch 30 | Batch 30/100 | Loss 0.327083
Epoch 30 | Batch 40/100 | Loss 0.316840
Epoch 30 | Batch 50/100 | Loss 0.296859
Epoch 30 | Batch 60/100 | Loss 0.317929
Epoch 30 | Batch 70/100 | Loss 0.327214
Epoch 30 | Batch 80/100 | Loss 0.304068
Epoch 30 | Batch 90/100 | Loss 0.297812
100 Test Acc = 73.12% +- 2.49%
Epoch 30: 73.12
Epoch 31 | Batch 0/100 | Loss 0.065869
Epoch 31 | Batch 10/100 | Loss 0.159810
Epoch 31 | Batch 20/100 | Loss 0.187964
Epoch 31 | Batch 30/100 | Loss 0.185174
Epoch 31 | Batch 40/100 | Loss 0.168061
Epoch 31 | Batch 50/100 | Loss 0.163390
Epoch 31 | Batch 60/100 | Loss 0.186747
Epoch 31 | Batch 70/100 | Loss 0.228417
Epoch 31 | Batch 80/100 | Loss 0.233419
Epoch 31 | Batch 90/100 | Loss 0.243091
100 Test Acc = 77.97% +- 2.67%
Epoch 31: 77.97
Epoch 32 | Batch 0/100 | Loss 0.146121
Epoch 32 | Batch 10/100 | Loss 0.136907
Epoch 32 | Batch 20/100 | Loss 0.238701
Epoch 32 | Batch 30/100 | Loss 0.255524
Epoch 32 | Batch 40/100 | Loss 0.236027
Epoch 32 | Batch 50/100 | Loss 0.223803
Epoch 32 | Batch 60/100 | Loss 0.238835
Epoch 32 | Batch 70/100 | Loss 0.257184
Epoch 32 | Batch 80/100 | Loss 0.251770
Epoch 32 | Batch 90/100 | Loss 0.235123
100 Test Acc = 76.11% +- 2.37%
Epoch 32: 76.11
Epoch 33 | Batch 0/100 | Loss 0.552417
Epoch 33 | Batch 10/100 | Loss 0.221513
Epoch 33 | Batch 20/100 | Loss 0.298914
Epoch 33 | Batch 30/100 | Loss 0.325261
Epoch 33 | Batch 40/100 | Loss 0.313536
Epoch 33 | Batch 50/100 | Loss 0.282310
Epoch 33 | Batch 60/100 | Loss 0.284692
Epoch 33 | Batch 70/100 | Loss 0.285552
Epoch 33 | Batch 80/100 | Loss 0.287533
Epoch 33 | Batch 90/100 | Loss 0.268777
100 Test Acc = 77.83% +- 2.35%
Epoch 33: 77.83
Epoch 34 | Batch 0/100 | Loss 0.181436
Epoch 34 | Batch 10/100 | Loss 0.191769
Epoch 34 | Batch 20/100 | Loss 0.170868
Epoch 34 | Batch 30/100 | Loss 0.164618
Epoch 34 | Batch 40/100 | Loss 0.182216
Epoch 34 | Batch 50/100 | Loss 0.173834
Epoch 34 | Batch 60/100 | Loss 0.200042
Epoch 34 | Batch 70/100 | Loss 0.194320
Epoch 34 | Batch 80/100 | Loss 0.212667
Epoch 34 | Batch 90/100 | Loss 0.227589
100 Test Acc = 76.47% +- 2.76%
Epoch 34: 76.47
Epoch 35 | Batch 0/100 | Loss 0.026039
Epoch 35 | Batch 10/100 | Loss 0.132337
Epoch 35 | Batch 20/100 | Loss 0.212880
Epoch 35 | Batch 30/100 | Loss 0.180949
Epoch 35 | Batch 40/100 | Loss 0.171182
Epoch 35 | Batch 50/100 | Loss 0.183056
Epoch 35 | Batch 60/100 | Loss 0.193253
Epoch 35 | Batch 70/100 | Loss 0.181911
Epoch 35 | Batch 80/100 | Loss 0.189165
Epoch 35 | Batch 90/100 | Loss 0.186941
100 Test Acc = 74.41% +- 2.56%
Epoch 35: 74.41
Epoch 36 | Batch 0/100 | Loss 0.153650
Epoch 36 | Batch 10/100 | Loss 0.234903
Epoch 36 | Batch 20/100 | Loss 0.231185
Epoch 36 | Batch 30/100 | Loss 0.257262
Epoch 36 | Batch 40/100 | Loss 0.265804
Epoch 36 | Batch 50/100 | Loss 0.251162
Epoch 36 | Batch 60/100 | Loss 0.240256
Epoch 36 | Batch 70/100 | Loss 0.222496
Epoch 36 | Batch 80/100 | Loss 0.215488
Epoch 36 | Batch 90/100 | Loss 0.212703
100 Test Acc = 76.83% +- 2.37%
Epoch 36: 76.83
Epoch 37 | Batch 0/100 | Loss 0.332243
Epoch 37 | Batch 10/100 | Loss 0.185383
Epoch 37 | Batch 20/100 | Loss 0.205764
Epoch 37 | Batch 30/100 | Loss 0.203563
Epoch 37 | Batch 40/100 | Loss 0.201475
Epoch 37 | Batch 50/100 | Loss 0.213456
Epoch 37 | Batch 60/100 | Loss 0.209626
Epoch 37 | Batch 70/100 | Loss 0.209742
Epoch 37 | Batch 80/100 | Loss 0.206625
Epoch 37 | Batch 90/100 | Loss 0.237345
100 Test Acc = 74.03% +- 2.37%
Epoch 37: 74.03
Epoch 38 | Batch 0/100 | Loss 0.015936
Epoch 38 | Batch 10/100 | Loss 0.178123
Epoch 38 | Batch 20/100 | Loss 0.286493
Epoch 38 | Batch 30/100 | Loss 0.280637
Epoch 38 | Batch 40/100 | Loss 0.294510
Epoch 38 | Batch 50/100 | Loss 0.287083
Epoch 38 | Batch 60/100 | Loss 0.271390
Epoch 38 | Batch 70/100 | Loss 0.279787
Epoch 38 | Batch 80/100 | Loss 0.269301
Epoch 38 | Batch 90/100 | Loss 0.266035
100 Test Acc = 77.20% +- 2.59%
Epoch 38: 77.20
Epoch 39 | Batch 0/100 | Loss 0.954921
Epoch 39 | Batch 10/100 | Loss 0.401729
Epoch 39 | Batch 20/100 | Loss 0.311602
Epoch 39 | Batch 30/100 | Loss 0.286844
Epoch 39 | Batch 40/100 | Loss 0.312821
Epoch 39 | Batch 50/100 | Loss 0.292683
Epoch 39 | Batch 60/100 | Loss 0.269145
Epoch 39 | Batch 70/100 | Loss 0.282589
Epoch 39 | Batch 80/100 | Loss 0.285129
Epoch 39 | Batch 90/100 | Loss 0.277940
100 Test Acc = 78.67% +- 2.74%
Epoch 39: 78.67
Epoch 40 | Batch 0/100 | Loss 0.266388
Epoch 40 | Batch 10/100 | Loss 0.251906
Epoch 40 | Batch 20/100 | Loss 0.254240
Epoch 40 | Batch 30/100 | Loss 0.245428
Epoch 40 | Batch 40/100 | Loss 0.218571
Epoch 40 | Batch 50/100 | Loss 0.229250
Epoch 40 | Batch 60/100 | Loss 0.210233
Epoch 40 | Batch 70/100 | Loss 0.214148
Epoch 40 | Batch 80/100 | Loss 0.215073
Epoch 40 | Batch 90/100 | Loss 0.234839
100 Test Acc = 76.96% +- 2.67%
Epoch 40: 76.96
Epoch 41 | Batch 0/100 | Loss 0.328066
Epoch 41 | Batch 10/100 | Loss 0.307868
Epoch 41 | Batch 20/100 | Loss 0.302252
Epoch 41 | Batch 30/100 | Loss 0.288573
Epoch 41 | Batch 40/100 | Loss 0.276843
Epoch 41 | Batch 50/100 | Loss 0.263160
Epoch 41 | Batch 60/100 | Loss 0.245757
Epoch 41 | Batch 70/100 | Loss 0.240754
Epoch 41 | Batch 80/100 | Loss 0.230597
Epoch 41 | Batch 90/100 | Loss 0.225975
100 Test Acc = 77.40% +- 2.66%
Epoch 41: 77.40
Epoch 42 | Batch 0/100 | Loss 0.002794
Epoch 42 | Batch 10/100 | Loss 0.243055
Epoch 42 | Batch 20/100 | Loss 0.259745
Epoch 42 | Batch 30/100 | Loss 0.252261
Epoch 42 | Batch 40/100 | Loss 0.243432
Epoch 42 | Batch 50/100 | Loss 0.284065
Epoch 42 | Batch 60/100 | Loss 0.259620
Epoch 42 | Batch 70/100 | Loss 0.267869
Epoch 42 | Batch 80/100 | Loss 0.273352
Epoch 42 | Batch 90/100 | Loss 0.269836
100 Test Acc = 76.16% +- 2.35%
Epoch 42: 76.16
Epoch 43 | Batch 0/100 | Loss 0.080791
Epoch 43 | Batch 10/100 | Loss 0.178832
Epoch 43 | Batch 20/100 | Loss 0.234271
Epoch 43 | Batch 30/100 | Loss 0.232351
Epoch 43 | Batch 40/100 | Loss 0.228017
Epoch 43 | Batch 50/100 | Loss 0.209523
Epoch 43 | Batch 60/100 | Loss 0.244810
Epoch 43 | Batch 70/100 | Loss 0.255590
Epoch 43 | Batch 80/100 | Loss 0.251929
Epoch 43 | Batch 90/100 | Loss 0.247593
100 Test Acc = 78.39% +- 2.53%
Epoch 43: 78.39
Epoch 44 | Batch 0/100 | Loss 0.128877
Epoch 44 | Batch 10/100 | Loss 0.128786
Epoch 44 | Batch 20/100 | Loss 0.189715
Epoch 44 | Batch 30/100 | Loss 0.174701
Epoch 44 | Batch 40/100 | Loss 0.188982
Epoch 44 | Batch 50/100 | Loss 0.187216
Epoch 44 | Batch 60/100 | Loss 0.221587
Epoch 44 | Batch 70/100 | Loss 0.227121
Epoch 44 | Batch 80/100 | Loss 0.224955
Epoch 44 | Batch 90/100 | Loss 0.223655
100 Test Acc = 77.99% +- 2.28%
Epoch 44: 77.99
Epoch 45 | Batch 0/100 | Loss 0.520241
Epoch 45 | Batch 10/100 | Loss 0.201248
Epoch 45 | Batch 20/100 | Loss 0.192002
Epoch 45 | Batch 30/100 | Loss 0.183956
Epoch 45 | Batch 40/100 | Loss 0.194362
Epoch 45 | Batch 50/100 | Loss 0.201695
Epoch 45 | Batch 60/100 | Loss 0.185591
Epoch 45 | Batch 70/100 | Loss 0.193630
Epoch 45 | Batch 80/100 | Loss 0.191783
Epoch 45 | Batch 90/100 | Loss 0.194855
100 Test Acc = 78.91% +- 2.61%
Epoch 45: 78.91
Epoch 46 | Batch 0/100 | Loss 0.024231
Epoch 46 | Batch 10/100 | Loss 0.211690
Epoch 46 | Batch 20/100 | Loss 0.199345
Epoch 46 | Batch 30/100 | Loss 0.205476
Epoch 46 | Batch 40/100 | Loss 0.230148
Epoch 46 | Batch 50/100 | Loss 0.247082
Epoch 46 | Batch 60/100 | Loss 0.227636
Epoch 46 | Batch 70/100 | Loss 0.234096
Epoch 46 | Batch 80/100 | Loss 0.217078
Epoch 46 | Batch 90/100 | Loss 0.217733
100 Test Acc = 76.99% +- 2.61%
Epoch 46: 76.99
Epoch 47 | Batch 0/100 | Loss 0.341596
Epoch 47 | Batch 10/100 | Loss 0.220370
Epoch 47 | Batch 20/100 | Loss 0.200758
Epoch 47 | Batch 30/100 | Loss 0.227866
Epoch 47 | Batch 40/100 | Loss 0.209028
Epoch 47 | Batch 50/100 | Loss 0.196017
Epoch 47 | Batch 60/100 | Loss 0.208974
Epoch 47 | Batch 70/100 | Loss 0.204934
Epoch 47 | Batch 80/100 | Loss 0.202254
Epoch 47 | Batch 90/100 | Loss 0.212942
100 Test Acc = 77.59% +- 2.68%
Epoch 47: 77.59
Epoch 48 | Batch 0/100 | Loss 0.221249
Epoch 48 | Batch 10/100 | Loss 0.168536
Epoch 48 | Batch 20/100 | Loss 0.164520
Epoch 48 | Batch 30/100 | Loss 0.190997
Epoch 48 | Batch 40/100 | Loss 0.185824
Epoch 48 | Batch 50/100 | Loss 0.208748
Epoch 48 | Batch 60/100 | Loss 0.189299
Epoch 48 | Batch 70/100 | Loss 0.186462
Epoch 48 | Batch 80/100 | Loss 0.188376
Epoch 48 | Batch 90/100 | Loss 0.194622
100 Test Acc = 77.31% +- 2.63%
Epoch 48: 77.31
Epoch 49 | Batch 0/100 | Loss 0.210520
Epoch 49 | Batch 10/100 | Loss 0.138686
Epoch 49 | Batch 20/100 | Loss 0.209331
Epoch 49 | Batch 30/100 | Loss 0.204254
Epoch 49 | Batch 40/100 | Loss 0.192874
Epoch 49 | Batch 50/100 | Loss 0.181954
Epoch 49 | Batch 60/100 | Loss 0.177045
Epoch 49 | Batch 70/100 | Loss 0.166355
Epoch 49 | Batch 80/100 | Loss 0.162260
Epoch 49 | Batch 90/100 | Loss 0.165347
100 Test Acc = 75.33% +- 2.82%
Epoch 49: 75.33
Epoch 50 | Batch 0/100 | Loss 0.462874
Epoch 50 | Batch 10/100 | Loss 0.361963
Epoch 50 | Batch 20/100 | Loss 0.335206
Epoch 50 | Batch 30/100 | Loss 0.247591
Epoch 50 | Batch 40/100 | Loss 0.222831
Epoch 50 | Batch 50/100 | Loss 0.202109
Epoch 50 | Batch 60/100 | Loss 0.194741
Epoch 50 | Batch 70/100 | Loss 0.188312
Epoch 50 | Batch 80/100 | Loss 0.186135
Epoch 50 | Batch 90/100 | Loss 0.185296
100 Test Acc = 78.47% +- 2.49%
Epoch 50: 78.47
Epoch 51 | Batch 0/100 | Loss 0.464049
Epoch 51 | Batch 10/100 | Loss 0.222767
Epoch 51 | Batch 20/100 | Loss 0.221270
Epoch 51 | Batch 30/100 | Loss 0.214964
Epoch 51 | Batch 40/100 | Loss 0.230643
Epoch 51 | Batch 50/100 | Loss 0.215703
Epoch 51 | Batch 60/100 | Loss 0.209640
Epoch 51 | Batch 70/100 | Loss 0.207329
Epoch 51 | Batch 80/100 | Loss 0.214088
Epoch 51 | Batch 90/100 | Loss 0.215957
100 Test Acc = 77.00% +- 2.37%
Epoch 51: 77.00
Epoch 52 | Batch 0/100 | Loss 0.098412
Epoch 52 | Batch 10/100 | Loss 0.064801
Epoch 52 | Batch 20/100 | Loss 0.142500
Epoch 52 | Batch 30/100 | Loss 0.190916
Epoch 52 | Batch 40/100 | Loss 0.180084
Epoch 52 | Batch 50/100 | Loss 0.203636
Epoch 52 | Batch 60/100 | Loss 0.201621
Epoch 52 | Batch 70/100 | Loss 0.203852
Epoch 52 | Batch 80/100 | Loss 0.210529
Epoch 52 | Batch 90/100 | Loss 0.194057
100 Test Acc = 76.72% +- 2.83%
Epoch 52: 76.72
Epoch 53 | Batch 0/100 | Loss 0.138259
Epoch 53 | Batch 10/100 | Loss 0.156495
Epoch 53 | Batch 20/100 | Loss 0.155715
Epoch 53 | Batch 30/100 | Loss 0.194850
Epoch 53 | Batch 40/100 | Loss 0.175439
Epoch 53 | Batch 50/100 | Loss 0.175290
Epoch 53 | Batch 60/100 | Loss 0.170283
Epoch 53 | Batch 70/100 | Loss 0.162204
Epoch 53 | Batch 80/100 | Loss 0.171721
Epoch 53 | Batch 90/100 | Loss 0.165176
100 Test Acc = 77.45% +- 2.77%
Epoch 53: 77.45
Epoch 54 | Batch 0/100 | Loss 0.104942
Epoch 54 | Batch 10/100 | Loss 0.147457
Epoch 54 | Batch 20/100 | Loss 0.217408
Epoch 54 | Batch 30/100 | Loss 0.191118
Epoch 54 | Batch 40/100 | Loss 0.184209
Epoch 54 | Batch 50/100 | Loss 0.187102
Epoch 54 | Batch 60/100 | Loss 0.196950
Epoch 54 | Batch 70/100 | Loss 0.214371
Epoch 54 | Batch 80/100 | Loss 0.201659
Epoch 54 | Batch 90/100 | Loss 0.196494
100 Test Acc = 76.59% +- 2.79%
Epoch 54: 76.59
Epoch 55 | Batch 0/100 | Loss 0.166896
Epoch 55 | Batch 10/100 | Loss 0.182418
Epoch 55 | Batch 20/100 | Loss 0.193148
Epoch 55 | Batch 30/100 | Loss 0.187896
Epoch 55 | Batch 40/100 | Loss 0.207331
Epoch 55 | Batch 50/100 | Loss 0.202225
Epoch 55 | Batch 60/100 | Loss 0.215716
Epoch 55 | Batch 70/100 | Loss 0.210783
Epoch 55 | Batch 80/100 | Loss 0.198179
Epoch 55 | Batch 90/100 | Loss 0.203412
100 Test Acc = 77.73% +- 2.53%
Epoch 55: 77.73
Epoch 56 | Batch 0/100 | Loss 0.316546
Epoch 56 | Batch 10/100 | Loss 0.209200
Epoch 56 | Batch 20/100 | Loss 0.210643
Epoch 56 | Batch 30/100 | Loss 0.200612
Epoch 56 | Batch 40/100 | Loss 0.213137
Epoch 56 | Batch 50/100 | Loss 0.214588
Epoch 56 | Batch 60/100 | Loss 0.192791
Epoch 56 | Batch 70/100 | Loss 0.197763
Epoch 56 | Batch 80/100 | Loss 0.190674
Epoch 56 | Batch 90/100 | Loss 0.220465
100 Test Acc = 76.64% +- 2.88%
Epoch 56: 76.64
Epoch 57 | Batch 0/100 | Loss 0.098163
Epoch 57 | Batch 10/100 | Loss 0.226031
Epoch 57 | Batch 20/100 | Loss 0.212430
Epoch 57 | Batch 30/100 | Loss 0.186804
Epoch 57 | Batch 40/100 | Loss 0.183519
Epoch 57 | Batch 50/100 | Loss 0.204118
Epoch 57 | Batch 60/100 | Loss 0.194462
Epoch 57 | Batch 70/100 | Loss 0.186960
Epoch 57 | Batch 80/100 | Loss 0.174198
Epoch 57 | Batch 90/100 | Loss 0.171170
100 Test Acc = 78.44% +- 2.36%
Epoch 57: 78.44
Epoch 58 | Batch 0/100 | Loss 0.041022
Epoch 58 | Batch 10/100 | Loss 0.073592
Epoch 58 | Batch 20/100 | Loss 0.176120
Epoch 58 | Batch 30/100 | Loss 0.160159
Epoch 58 | Batch 40/100 | Loss 0.168164
Epoch 58 | Batch 50/100 | Loss 0.167252
Epoch 58 | Batch 60/100 | Loss 0.163214
Epoch 58 | Batch 70/100 | Loss 0.170913
Epoch 58 | Batch 80/100 | Loss 0.183178
Epoch 58 | Batch 90/100 | Loss 0.181413
100 Test Acc = 71.91% +- 2.73%
Epoch 58: 71.91
Epoch 59 | Batch 0/100 | Loss 0.036015
Epoch 59 | Batch 10/100 | Loss 0.310797
Epoch 59 | Batch 20/100 | Loss 0.220907
Epoch 59 | Batch 30/100 | Loss 0.199695
Epoch 59 | Batch 40/100 | Loss 0.186802
Epoch 59 | Batch 50/100 | Loss 0.185258
Epoch 59 | Batch 60/100 | Loss 0.189954
Epoch 59 | Batch 70/100 | Loss 0.194714
Epoch 59 | Batch 80/100 | Loss 0.196136
Epoch 59 | Batch 90/100 | Loss 0.189954
/home/said.gurbuz/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
100 Test Acc = 75.44% +- 2.65%
Epoch 59: 75.44
Checkpoint directory: checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_1/tabula_muris/matchingnet_FCNet
Using checkpoint dir: checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_1/tabula_muris/matchingnet_FCNet/20231209_052622
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
/home/said.gurbuz/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
600 Test Acc = 88.67% +- 0.75%
Using checkpoint dir: checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_1/tabula_muris/matchingnet_FCNet/20231209_052622
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
/home/said.gurbuz/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
600 Test Acc = 76.49% +- 1.05%
Using checkpoint dir: checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_1/tabula_muris/matchingnet_FCNet/20231209_052622
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  a = self.softmax(logit_a)
/home/said.gurbuz/epfl-dl-in-biomed-project/methods/matchingnet.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  softmax = self.softmax(scores)
600 Test Acc = 74.83% +- 1.08%
Results logged to ./checkpoints/method_matchingnet_dataset_tabula_muris_n_shot_1/results.txt
+-------+-------------------+--------------------+
| split |      acc_mean     |      acc_std       |
+-------+-------------------+--------------------+
| train | 88.66888888888889 | 9.387777449007768  |
|  val  | 76.48666666666666 | 13.067694404026943 |
|  test | 74.83111111111111 | 13.436806645907582 |
+-------+-------------------+--------------------+
