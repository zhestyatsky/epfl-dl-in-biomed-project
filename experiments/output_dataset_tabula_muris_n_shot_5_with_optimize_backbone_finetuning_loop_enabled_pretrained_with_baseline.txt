/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 5
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 5
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 5
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 0.5
    finetuning_lr_init: 0.05
    num_adaptation_steps: 5
    kl_coef: 0.01
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 0.1
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 32
    enable_finetuning_loop: true
  n_task: 4
  latent_space_dim: 32
  leo_inner_lr_init: 0.5
  leo_finetuning_lr_init: 0.05
  num_adaptation_steps: 5
  kl_coef: 0.01
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 0.1
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-06
  optimize_backbone: true
  pretrained_backbone_weights_path: pretrained_weights/tabula_muris_baseline_model.tar
  enable_finetuning_loop: true
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_5_with_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.001
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_5_with_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Using pretrained backbone from pretrained_weights/tabula_muris_baseline_model.tar.
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=32, bias=False)
    (relation_net): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=False)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=64, bias=False)
      (3): ReLU()
      (4): Linear(in_features=64, out_features=64, bias=False)
    )
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=32, out_features=130, bias=False)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 1e-06

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Epoch 0 | Batch 0/100 | Loss 5.796108
InnerLR 0.500000
FineTuningLR 0.050000
Epoch 0 | Batch 10/100 | Loss 5.411335
InnerLR 0.502000
FineTuningLR 0.052000
Epoch 0 | Batch 20/100 | Loss 4.939697
InnerLR 0.505000
FineTuningLR 0.055000
Epoch 0 | Batch 30/100 | Loss 4.716931
InnerLR 0.507000
FineTuningLR 0.057000
Epoch 0 | Batch 40/100 | Loss 4.630377
InnerLR 0.510000
FineTuningLR 0.060000
Epoch 0 | Batch 50/100 | Loss 4.534324
InnerLR 0.512000
FineTuningLR 0.062000
Epoch 0 | Batch 60/100 | Loss 4.351092
InnerLR 0.515000
FineTuningLR 0.065000
Epoch 0 | Batch 70/100 | Loss 4.122459
InnerLR 0.517000
FineTuningLR 0.067000
Epoch 0 | Batch 80/100 | Loss 3.994896
InnerLR 0.520000
FineTuningLR 0.070000
Epoch 0 | Batch 90/100 | Loss 3.919341
InnerLR 0.522000
FineTuningLR 0.072000
100 Accuracy = 63.97% +- 2.25%
Epoch 0: 63.97
best model! save...
Epoch 1 | Batch 0/100 | Loss 3.442044
InnerLR 0.525000
FineTuningLR 0.075000
Epoch 1 | Batch 10/100 | Loss 2.518893
InnerLR 0.527000
FineTuningLR 0.077000
Epoch 1 | Batch 20/100 | Loss 2.315038
InnerLR 0.530000
FineTuningLR 0.080000
Epoch 1 | Batch 30/100 | Loss 2.200683
InnerLR 0.532000
FineTuningLR 0.082000
Epoch 1 | Batch 40/100 | Loss 1.940146
InnerLR 0.535000
FineTuningLR 0.085000
Epoch 1 | Batch 50/100 | Loss 1.808351
InnerLR 0.537000
FineTuningLR 0.087000
Epoch 1 | Batch 60/100 | Loss 1.718950
InnerLR 0.539999
FineTuningLR 0.090000
Epoch 1 | Batch 70/100 | Loss 1.612151
InnerLR 0.541999
FineTuningLR 0.092000
Epoch 1 | Batch 80/100 | Loss 1.507213
InnerLR 0.544999
FineTuningLR 0.095000
Epoch 1 | Batch 90/100 | Loss 1.401191
InnerLR 0.546999
FineTuningLR 0.097000
100 Accuracy = 79.87% +- 2.24%
Epoch 1: 79.87
best model! save...
Epoch 2 | Batch 0/100 | Loss 0.605937
InnerLR 0.549999
FineTuningLR 0.100000
Epoch 2 | Batch 10/100 | Loss 0.482345
InnerLR 0.551999
FineTuningLR 0.102000
Epoch 2 | Batch 20/100 | Loss 0.513875
InnerLR 0.554999
FineTuningLR 0.105000
Epoch 2 | Batch 30/100 | Loss 0.465866
InnerLR 0.556999
FineTuningLR 0.107000
Epoch 2 | Batch 40/100 | Loss 0.436895
InnerLR 0.559799
FineTuningLR 0.110000
Epoch 2 | Batch 50/100 | Loss 0.414840
InnerLR 0.561456
FineTuningLR 0.112000
Epoch 2 | Batch 60/100 | Loss 0.394969
InnerLR 0.563518
FineTuningLR 0.115000
Epoch 2 | Batch 70/100 | Loss 0.375779
InnerLR 0.565039
FineTuningLR 0.117000
Epoch 2 | Batch 80/100 | Loss 0.366879
InnerLR 0.567285
FineTuningLR 0.120000
Epoch 2 | Batch 90/100 | Loss 0.353128
InnerLR 0.568660
FineTuningLR 0.122000
100 Accuracy = 82.92% +- 1.88%
Epoch 2: 82.92
best model! save...
Epoch 3 | Batch 0/100 | Loss 0.175730
InnerLR 0.570938
FineTuningLR 0.125000
Epoch 3 | Batch 10/100 | Loss 0.222024
InnerLR 0.572568
FineTuningLR 0.127000
Epoch 3 | Batch 20/100 | Loss 0.222002
InnerLR 0.575142
FineTuningLR 0.130000
Epoch 3 | Batch 30/100 | Loss 0.215998
InnerLR 0.576924
FineTuningLR 0.132000
Epoch 3 | Batch 40/100 | Loss 0.228298
InnerLR 0.579666
FineTuningLR 0.135006
Epoch 3 | Batch 50/100 | Loss 0.225959
InnerLR 0.581526
FineTuningLR 0.137017
Epoch 3 | Batch 60/100 | Loss 0.219843
InnerLR 0.584364
FineTuningLR 0.140028
Epoch 3 | Batch 70/100 | Loss 0.228186
InnerLR 0.585902
FineTuningLR 0.142033
Epoch 3 | Batch 80/100 | Loss 0.231359
InnerLR 0.588114
FineTuningLR 0.145099
Epoch 3 | Batch 90/100 | Loss 0.229626
InnerLR 0.589637
FineTuningLR 0.147148
100 Accuracy = 85.35% +- 1.83%
Epoch 3: 85.35
best model! save...
Epoch 4 | Batch 0/100 | Loss 0.238150
InnerLR 0.591862
FineTuningLR 0.150295
Epoch 4 | Batch 10/100 | Loss 0.200310
InnerLR 0.593471
FineTuningLR 0.152366
Epoch 4 | Batch 20/100 | Loss 0.201985
InnerLR 0.596009
FineTuningLR 0.155457
Epoch 4 | Batch 30/100 | Loss 0.200803
InnerLR 0.597778
FineTuningLR 0.157499
Epoch 4 | Batch 40/100 | Loss 0.219698
InnerLR 0.600133
FineTuningLR 0.160541
Epoch 4 | Batch 50/100 | Loss 0.207198
InnerLR 0.601684
FineTuningLR 0.162566
Epoch 4 | Batch 60/100 | Loss 0.201146
InnerLR 0.604175
FineTuningLR 0.165583
Epoch 4 | Batch 70/100 | Loss 0.198529
InnerLR 0.605923
FineTuningLR 0.167584
Epoch 4 | Batch 80/100 | Loss 0.201937
InnerLR 0.608573
FineTuningLR 0.170623
Epoch 4 | Batch 90/100 | Loss 0.203528
InnerLR 0.609952
FineTuningLR 0.172679
100 Accuracy = 86.76% +- 1.78%
Epoch 4: 86.76
best model! save...
Epoch 5 | Batch 0/100 | Loss 0.219906
InnerLR 0.612175
FineTuningLR 0.175779
Epoch 5 | Batch 10/100 | Loss 0.232464
InnerLR 0.613676
FineTuningLR 0.177891
Epoch 5 | Batch 20/100 | Loss 0.194137
InnerLR 0.616100
FineTuningLR 0.180985
Epoch 5 | Batch 30/100 | Loss 0.185296
InnerLR 0.617795
FineTuningLR 0.182994
Epoch 5 | Batch 40/100 | Loss 0.189868
InnerLR 0.620071
FineTuningLR 0.186166
Epoch 5 | Batch 50/100 | Loss 0.180866
InnerLR 0.621623
FineTuningLR 0.188282
Epoch 5 | Batch 60/100 | Loss 0.177018
InnerLR 0.623892
FineTuningLR 0.191520
Epoch 5 | Batch 70/100 | Loss 0.171998
InnerLR 0.625367
FineTuningLR 0.193700
Epoch 5 | Batch 80/100 | Loss 0.165294
InnerLR 0.627285
FineTuningLR 0.196950
Epoch 5 | Batch 90/100 | Loss 0.169906
InnerLR 0.628311
FineTuningLR 0.199096
100 Accuracy = 86.41% +- 1.52%
Epoch 5: 86.41
Epoch 6 | Batch 0/100 | Loss 0.096535
InnerLR 0.629831
FineTuningLR 0.202287
Epoch 6 | Batch 10/100 | Loss 0.147025
InnerLR 0.630828
FineTuningLR 0.204405
Epoch 6 | Batch 20/100 | Loss 0.159635
InnerLR 0.631992
FineTuningLR 0.207556
Epoch 6 | Batch 30/100 | Loss 0.160536
InnerLR 0.632413
FineTuningLR 0.209628
Epoch 6 | Batch 40/100 | Loss 0.157535
InnerLR 0.633560
FineTuningLR 0.212712
Epoch 6 | Batch 50/100 | Loss 0.160477
InnerLR 0.634633
FineTuningLR 0.214738
Epoch 6 | Batch 60/100 | Loss 0.161450
InnerLR 0.636361
FineTuningLR 0.217868
Epoch 6 | Batch 70/100 | Loss 0.186218
InnerLR 0.637065
FineTuningLR 0.219759
Epoch 6 | Batch 80/100 | Loss 0.177997
InnerLR 0.637737
FineTuningLR 0.222417
Epoch 6 | Batch 90/100 | Loss 0.180435
InnerLR 0.638084
FineTuningLR 0.224100
100 Accuracy = 85.88% +- 2.01%
Epoch 6: 85.88
Epoch 7 | Batch 0/100 | Loss 0.179693
InnerLR 0.637890
FineTuningLR 0.226206
Epoch 7 | Batch 10/100 | Loss 0.142332
InnerLR 0.637967
FineTuningLR 0.227675
Epoch 7 | Batch 20/100 | Loss 0.157074
InnerLR 0.638151
FineTuningLR 0.230070
Epoch 7 | Batch 30/100 | Loss 0.155607
InnerLR 0.638549
FineTuningLR 0.231340
Epoch 7 | Batch 40/100 | Loss 0.143736
InnerLR 0.639789
FineTuningLR 0.233291
Epoch 7 | Batch 50/100 | Loss 0.150175
InnerLR 0.640885
FineTuningLR 0.234716
Epoch 7 | Batch 60/100 | Loss 0.150338
InnerLR 0.642674
FineTuningLR 0.237160
Epoch 7 | Batch 70/100 | Loss 0.144909
InnerLR 0.644082
FineTuningLR 0.238730
Epoch 7 | Batch 80/100 | Loss 0.147193
InnerLR 0.646191
FineTuningLR 0.240720
Epoch 7 | Batch 90/100 | Loss 0.159256
InnerLR 0.647401
FineTuningLR 0.241950
100 Accuracy = 87.04% +- 1.67%
Epoch 7: 87.04
best model! save...
Epoch 8 | Batch 0/100 | Loss 0.111186
InnerLR 0.648254
FineTuningLR 0.243541
Epoch 8 | Batch 10/100 | Loss 0.139422
InnerLR 0.648734
FineTuningLR 0.244928
Epoch 8 | Batch 20/100 | Loss 0.141324
InnerLR 0.649898
FineTuningLR 0.247212
Epoch 8 | Batch 30/100 | Loss 0.141306
InnerLR 0.651023
FineTuningLR 0.248784
Epoch 8 | Batch 40/100 | Loss 0.141723
InnerLR 0.653158
FineTuningLR 0.251035
Epoch 8 | Batch 50/100 | Loss 0.139887
InnerLR 0.654256
FineTuningLR 0.252697
Epoch 8 | Batch 60/100 | Loss 0.145515
InnerLR 0.655278
FineTuningLR 0.254915
Epoch 8 | Batch 70/100 | Loss 0.141201
InnerLR 0.656090
FineTuningLR 0.256246
Epoch 8 | Batch 80/100 | Loss 0.146004
InnerLR 0.657366
FineTuningLR 0.258523
Epoch 8 | Batch 90/100 | Loss 0.147360
InnerLR 0.658204
FineTuningLR 0.260159
100 Accuracy = 87.21% +- 1.62%
Epoch 8: 87.21
best model! save...
Epoch 9 | Batch 0/100 | Loss 0.121968
InnerLR 0.659535
FineTuningLR 0.262815
Epoch 9 | Batch 10/100 | Loss 0.168462
InnerLR 0.660571
FineTuningLR 0.264609
Epoch 9 | Batch 20/100 | Loss 0.168910
InnerLR 0.662383
FineTuningLR 0.267401
Epoch 9 | Batch 30/100 | Loss 0.170286
InnerLR 0.663682
FineTuningLR 0.268962
Epoch 9 | Batch 40/100 | Loss 0.161992
InnerLR 0.665536
FineTuningLR 0.271394
Epoch 9 | Batch 50/100 | Loss 0.161793
InnerLR 0.666622
FineTuningLR 0.272955
Epoch 9 | Batch 60/100 | Loss 0.162822
InnerLR 0.668177
FineTuningLR 0.275206
Epoch 9 | Batch 70/100 | Loss 0.160424
InnerLR 0.669557
FineTuningLR 0.276624
Epoch 9 | Batch 80/100 | Loss 0.162812
InnerLR 0.671211
FineTuningLR 0.278798
Epoch 9 | Batch 90/100 | Loss 0.157251
InnerLR 0.672215
FineTuningLR 0.280334
100 Accuracy = 85.76% +- 1.84%
Epoch 9: 85.76
Epoch 10 | Batch 0/100 | Loss 0.057814
InnerLR 0.673994
FineTuningLR 0.282728
Epoch 10 | Batch 10/100 | Loss 0.114916
InnerLR 0.674913
FineTuningLR 0.284404
Epoch 10 | Batch 20/100 | Loss 0.124068
InnerLR 0.675947
FineTuningLR 0.287141
Epoch 10 | Batch 30/100 | Loss 0.132604
InnerLR 0.676721
FineTuningLR 0.288862
Epoch 10 | Batch 40/100 | Loss 0.133373
InnerLR 0.677834
FineTuningLR 0.291192
Epoch 10 | Batch 50/100 | Loss 0.130843
InnerLR 0.678945
FineTuningLR 0.292775
Epoch 10 | Batch 60/100 | Loss 0.135174
InnerLR 0.680340
FineTuningLR 0.295277
Epoch 10 | Batch 70/100 | Loss 0.136820
InnerLR 0.681466
FineTuningLR 0.297044
Epoch 10 | Batch 80/100 | Loss 0.135920
InnerLR 0.682980
FineTuningLR 0.299193
Epoch 10 | Batch 90/100 | Loss 0.131385
InnerLR 0.683876
FineTuningLR 0.300576
100 Accuracy = 85.77% +- 1.69%
Epoch 10: 85.77
Epoch 11 | Batch 0/100 | Loss 0.144858
InnerLR 0.684958
FineTuningLR 0.302644
Epoch 11 | Batch 10/100 | Loss 0.154481
InnerLR 0.685677
FineTuningLR 0.303884
Epoch 11 | Batch 20/100 | Loss 0.147536
InnerLR 0.686282
FineTuningLR 0.305845
Epoch 11 | Batch 30/100 | Loss 0.155631
InnerLR 0.686284
FineTuningLR 0.307127
Epoch 11 | Batch 40/100 | Loss 0.144097
InnerLR 0.686239
FineTuningLR 0.309125
Epoch 11 | Batch 50/100 | Loss 0.143041
InnerLR 0.686354
FineTuningLR 0.310425
Epoch 11 | Batch 60/100 | Loss 0.137850
InnerLR 0.686854
FineTuningLR 0.312428
Epoch 11 | Batch 70/100 | Loss 0.130430
InnerLR 0.687519
FineTuningLR 0.313949
Epoch 11 | Batch 80/100 | Loss 0.127843
InnerLR 0.688436
FineTuningLR 0.316396
Epoch 11 | Batch 90/100 | Loss 0.129119
InnerLR 0.689128
FineTuningLR 0.317670
100 Accuracy = 86.92% +- 1.51%
Epoch 11: 86.92
Epoch 12 | Batch 0/100 | Loss 0.123902
InnerLR 0.690304
FineTuningLR 0.319814
Epoch 12 | Batch 10/100 | Loss 0.189455
InnerLR 0.691081
FineTuningLR 0.321301
Epoch 12 | Batch 20/100 | Loss 0.140907
InnerLR 0.691595
FineTuningLR 0.323544
Epoch 12 | Batch 30/100 | Loss 0.140795
InnerLR 0.691741
FineTuningLR 0.325067
Epoch 12 | Batch 40/100 | Loss 0.131494
InnerLR 0.692011
FineTuningLR 0.327565
Epoch 12 | Batch 50/100 | Loss 0.134088
InnerLR 0.692204
FineTuningLR 0.329313
Epoch 12 | Batch 60/100 | Loss 0.139951
InnerLR 0.692372
FineTuningLR 0.331210
Epoch 12 | Batch 70/100 | Loss 0.139078
InnerLR 0.692345
FineTuningLR 0.332592
Epoch 12 | Batch 80/100 | Loss 0.136004
InnerLR 0.692004
FineTuningLR 0.334844
Epoch 12 | Batch 90/100 | Loss 0.132458
InnerLR 0.691858
FineTuningLR 0.336068
100 Accuracy = 87.11% +- 1.53%
Epoch 12: 87.11
Epoch 13 | Batch 0/100 | Loss 0.254541
InnerLR 0.691783
FineTuningLR 0.337498
Epoch 13 | Batch 10/100 | Loss 0.128562
InnerLR 0.691766
FineTuningLR 0.338726
Epoch 13 | Batch 20/100 | Loss 0.127981
InnerLR 0.691924
FineTuningLR 0.340347
Epoch 13 | Batch 30/100 | Loss 0.127041
InnerLR 0.692270
FineTuningLR 0.341548
Epoch 13 | Batch 40/100 | Loss 0.120261
InnerLR 0.692174
FineTuningLR 0.343438
Epoch 13 | Batch 50/100 | Loss 0.121150
InnerLR 0.692278
FineTuningLR 0.344839
Epoch 13 | Batch 60/100 | Loss 0.124922
InnerLR 0.692278
FineTuningLR 0.347077
Epoch 13 | Batch 70/100 | Loss 0.125367
InnerLR 0.692390
FineTuningLR 0.348306
Epoch 13 | Batch 80/100 | Loss 0.123103
InnerLR 0.692238
FineTuningLR 0.350065
Epoch 13 | Batch 90/100 | Loss 0.118825
InnerLR 0.692289
FineTuningLR 0.351431
100 Accuracy = 85.85% +- 1.96%
Epoch 13: 85.85
Epoch 14 | Batch 0/100 | Loss 0.087923
InnerLR 0.692157
FineTuningLR 0.353387
Epoch 14 | Batch 10/100 | Loss 0.115339
InnerLR 0.691783
FineTuningLR 0.354466
Epoch 14 | Batch 20/100 | Loss 0.167750
InnerLR 0.691792
FineTuningLR 0.356077
Epoch 14 | Batch 30/100 | Loss 0.177096
InnerLR 0.691300
FineTuningLR 0.356875
Epoch 14 | Batch 40/100 | Loss 0.160827
InnerLR 0.690616
FineTuningLR 0.357689
Epoch 14 | Batch 50/100 | Loss 0.151390
InnerLR 0.690304
FineTuningLR 0.358587
Epoch 14 | Batch 60/100 | Loss 0.144209
InnerLR 0.690619
FineTuningLR 0.360047
Epoch 14 | Batch 70/100 | Loss 0.139169
InnerLR 0.691169
FineTuningLR 0.360924
Epoch 14 | Batch 80/100 | Loss 0.137003
InnerLR 0.692538
FineTuningLR 0.362063
Epoch 14 | Batch 90/100 | Loss 0.131753
InnerLR 0.693319
FineTuningLR 0.363075
100 Accuracy = 87.16% +- 1.76%
Epoch 14: 87.16
Epoch 15 | Batch 0/100 | Loss 0.106986
InnerLR 0.694470
FineTuningLR 0.364769
Epoch 15 | Batch 10/100 | Loss 0.133613
InnerLR 0.694919
FineTuningLR 0.365838
Epoch 15 | Batch 20/100 | Loss 0.155640
InnerLR 0.695294
FineTuningLR 0.366940
Epoch 15 | Batch 30/100 | Loss 0.139618
InnerLR 0.695337
FineTuningLR 0.367425
Epoch 15 | Batch 40/100 | Loss 0.138703
InnerLR 0.695444
FineTuningLR 0.367531
Epoch 15 | Batch 50/100 | Loss 0.141964
InnerLR 0.695254
FineTuningLR 0.367455
Epoch 15 | Batch 60/100 | Loss 0.150485
InnerLR 0.694385
FineTuningLR 0.367930
Epoch 15 | Batch 70/100 | Loss 0.141333
InnerLR 0.693522
FineTuningLR 0.368528
Epoch 15 | Batch 80/100 | Loss 0.135293
InnerLR 0.692896
FineTuningLR 0.369798
Epoch 15 | Batch 90/100 | Loss 0.135007
InnerLR 0.692978
FineTuningLR 0.370636
100 Accuracy = 87.88% +- 1.79%
Epoch 15: 87.88
best model! save...
Epoch 16 | Batch 0/100 | Loss 0.330545
InnerLR 0.693081
FineTuningLR 0.372090
Epoch 16 | Batch 10/100 | Loss 0.118630
InnerLR 0.693451
FineTuningLR 0.372784
Epoch 16 | Batch 20/100 | Loss 0.172108
InnerLR 0.694416
FineTuningLR 0.373836
Epoch 16 | Batch 30/100 | Loss 0.163159
InnerLR 0.694577
FineTuningLR 0.374425
Epoch 16 | Batch 40/100 | Loss 0.167643
InnerLR 0.694366
FineTuningLR 0.375536
Epoch 16 | Batch 50/100 | Loss 0.156609
InnerLR 0.694228
FineTuningLR 0.376043
Epoch 16 | Batch 60/100 | Loss 0.159258
InnerLR 0.693586
FineTuningLR 0.377278
Epoch 16 | Batch 70/100 | Loss 0.151378
InnerLR 0.693449
FineTuningLR 0.378261
Epoch 16 | Batch 80/100 | Loss 0.143722
InnerLR 0.694115
FineTuningLR 0.379544
Epoch 16 | Batch 90/100 | Loss 0.140909
InnerLR 0.694909
FineTuningLR 0.380326
100 Accuracy = 86.24% +- 1.80%
Epoch 16: 86.24
Epoch 17 | Batch 0/100 | Loss 0.095451
InnerLR 0.695342
FineTuningLR 0.381443
Epoch 17 | Batch 10/100 | Loss 0.102306
InnerLR 0.695827
FineTuningLR 0.382419
Epoch 17 | Batch 20/100 | Loss 0.114035
InnerLR 0.696189
FineTuningLR 0.384233
Epoch 17 | Batch 30/100 | Loss 0.113246
InnerLR 0.696619
FineTuningLR 0.385460
Epoch 17 | Batch 40/100 | Loss 0.119847
InnerLR 0.697766
FineTuningLR 0.386677
Epoch 17 | Batch 50/100 | Loss 0.117795
InnerLR 0.698388
FineTuningLR 0.387567
Epoch 17 | Batch 60/100 | Loss 0.113958
InnerLR 0.698819
FineTuningLR 0.389140
Epoch 17 | Batch 70/100 | Loss 0.114388
InnerLR 0.699447
FineTuningLR 0.390157
Epoch 17 | Batch 80/100 | Loss 0.114157
InnerLR 0.700277
FineTuningLR 0.391873
Epoch 17 | Batch 90/100 | Loss 0.117940
InnerLR 0.700358
FineTuningLR 0.392793
100 Accuracy = 86.57% +- 1.83%
Epoch 17: 86.57
Epoch 18 | Batch 0/100 | Loss 0.070755
InnerLR 0.700064
FineTuningLR 0.394296
Epoch 18 | Batch 10/100 | Loss 0.147864
InnerLR 0.699706
FineTuningLR 0.395300
Epoch 18 | Batch 20/100 | Loss 0.130409
InnerLR 0.698818
FineTuningLR 0.396338
Epoch 18 | Batch 30/100 | Loss 0.131798
InnerLR 0.697954
FineTuningLR 0.397306
Epoch 18 | Batch 40/100 | Loss 0.120941
InnerLR 0.696650
FineTuningLR 0.398843
Epoch 18 | Batch 50/100 | Loss 0.119559
InnerLR 0.696223
FineTuningLR 0.399990
Epoch 18 | Batch 60/100 | Loss 0.118880
InnerLR 0.695429
FineTuningLR 0.402062
Epoch 18 | Batch 70/100 | Loss 0.116973
InnerLR 0.694870
FineTuningLR 0.403237
Epoch 18 | Batch 80/100 | Loss 0.114060
InnerLR 0.693873
FineTuningLR 0.405015
Epoch 18 | Batch 90/100 | Loss 0.113936
InnerLR 0.693857
FineTuningLR 0.405920
100 Accuracy = 85.47% +- 2.01%
Epoch 18: 85.47
Epoch 19 | Batch 0/100 | Loss 0.078103
InnerLR 0.693797
FineTuningLR 0.407132
Epoch 19 | Batch 10/100 | Loss 0.141463
InnerLR 0.693979
FineTuningLR 0.408129
Epoch 19 | Batch 20/100 | Loss 0.132027
InnerLR 0.694049
FineTuningLR 0.409515
Epoch 19 | Batch 30/100 | Loss 0.122758
InnerLR 0.694176
FineTuningLR 0.410381
Epoch 19 | Batch 40/100 | Loss 0.131910
InnerLR 0.694605
FineTuningLR 0.411798
Epoch 19 | Batch 50/100 | Loss 0.137166
InnerLR 0.694728
FineTuningLR 0.413119
Epoch 19 | Batch 60/100 | Loss 0.138530
InnerLR 0.695041
FineTuningLR 0.414835
Epoch 19 | Batch 70/100 | Loss 0.133322
InnerLR 0.695354
FineTuningLR 0.416036
Epoch 19 | Batch 80/100 | Loss 0.137291
InnerLR 0.695567
FineTuningLR 0.417292
Epoch 19 | Batch 90/100 | Loss 0.134874
InnerLR 0.696139
FineTuningLR 0.417980
100 Accuracy = 85.31% +- 1.95%
Epoch 19: 85.31
Epoch 20 | Batch 0/100 | Loss 0.085128
InnerLR 0.697441
FineTuningLR 0.419256
Epoch 20 | Batch 10/100 | Loss 0.119458
InnerLR 0.698494
FineTuningLR 0.420131
Epoch 20 | Batch 20/100 | Loss 0.119265
InnerLR 0.700114
FineTuningLR 0.420708
Epoch 20 | Batch 30/100 | Loss 0.113611
InnerLR 0.700786
FineTuningLR 0.421192
Epoch 20 | Batch 40/100 | Loss 0.120653
InnerLR 0.702271
FineTuningLR 0.421657
Epoch 20 | Batch 50/100 | Loss 0.125064
InnerLR 0.702763
FineTuningLR 0.421800
Epoch 20 | Batch 60/100 | Loss 0.121968
InnerLR 0.703303
FineTuningLR 0.422226
Epoch 20 | Batch 70/100 | Loss 0.119840
InnerLR 0.703908
FineTuningLR 0.422690
Epoch 20 | Batch 80/100 | Loss 0.116817
InnerLR 0.704795
FineTuningLR 0.423183
Epoch 20 | Batch 90/100 | Loss 0.116444
InnerLR 0.705762
FineTuningLR 0.423230
100 Accuracy = 86.61% +- 1.93%
Epoch 20: 86.61
Epoch 21 | Batch 0/100 | Loss 0.059023
InnerLR 0.706985
FineTuningLR 0.423561
Epoch 21 | Batch 10/100 | Loss 0.135343
InnerLR 0.707387
FineTuningLR 0.423523
Epoch 21 | Batch 20/100 | Loss 0.126245
InnerLR 0.708203
FineTuningLR 0.423678
Epoch 21 | Batch 30/100 | Loss 0.128204
InnerLR 0.708306
FineTuningLR 0.424128
Epoch 21 | Batch 40/100 | Loss 0.133063
InnerLR 0.708265
FineTuningLR 0.424569
Epoch 21 | Batch 50/100 | Loss 0.125428
InnerLR 0.708275
FineTuningLR 0.425234
Epoch 21 | Batch 60/100 | Loss 0.124070
InnerLR 0.708257
FineTuningLR 0.426575
Epoch 21 | Batch 70/100 | Loss 0.122480
InnerLR 0.708752
FineTuningLR 0.427251
Epoch 21 | Batch 80/100 | Loss 0.120730
InnerLR 0.710048
FineTuningLR 0.427842
Epoch 21 | Batch 90/100 | Loss 0.123732
InnerLR 0.710811
FineTuningLR 0.428439
100 Accuracy = 86.28% +- 1.95%
Epoch 21: 86.28
Epoch 22 | Batch 0/100 | Loss 0.067915
InnerLR 0.711715
FineTuningLR 0.429236
Epoch 22 | Batch 10/100 | Loss 0.172999
InnerLR 0.712353
FineTuningLR 0.429865
Epoch 22 | Batch 20/100 | Loss 0.135401
InnerLR 0.712429
FineTuningLR 0.430380
Epoch 22 | Batch 30/100 | Loss 0.126640
InnerLR 0.712506
FineTuningLR 0.431113
Epoch 22 | Batch 40/100 | Loss 0.120985
InnerLR 0.712238
FineTuningLR 0.432611
Epoch 22 | Batch 50/100 | Loss 0.123465
InnerLR 0.712453
FineTuningLR 0.433211
Epoch 22 | Batch 60/100 | Loss 0.120016
InnerLR 0.712928
FineTuningLR 0.433948
Epoch 22 | Batch 70/100 | Loss 0.117221
InnerLR 0.713509
FineTuningLR 0.434283
Epoch 22 | Batch 80/100 | Loss 0.121341
InnerLR 0.714152
FineTuningLR 0.435111
Epoch 22 | Batch 90/100 | Loss 0.116196
InnerLR 0.714164
FineTuningLR 0.435864
100 Accuracy = 86.49% +- 1.81%
Epoch 22: 86.49
Epoch 23 | Batch 0/100 | Loss 0.107434
InnerLR 0.714313
FineTuningLR 0.436914
Epoch 23 | Batch 10/100 | Loss 0.101468
InnerLR 0.714398
FineTuningLR 0.437633
Epoch 23 | Batch 20/100 | Loss 0.116478
InnerLR 0.714631
FineTuningLR 0.438825
Epoch 23 | Batch 30/100 | Loss 0.117689
InnerLR 0.714431
FineTuningLR 0.439634
Epoch 23 | Batch 40/100 | Loss 0.116955
InnerLR 0.714220
FineTuningLR 0.441198
Epoch 23 | Batch 50/100 | Loss 0.117929
InnerLR 0.714288
FineTuningLR 0.442252
Epoch 23 | Batch 60/100 | Loss 0.115556
InnerLR 0.714541
FineTuningLR 0.443748
Epoch 23 | Batch 70/100 | Loss 0.117119
InnerLR 0.714560
FineTuningLR 0.444686
Epoch 23 | Batch 80/100 | Loss 0.114681
InnerLR 0.715006
FineTuningLR 0.445980
Epoch 23 | Batch 90/100 | Loss 0.112528
InnerLR 0.715202
FineTuningLR 0.446888
100 Accuracy = 87.72% +- 1.50%
Epoch 23: 87.72
Epoch 24 | Batch 0/100 | Loss 0.076978
InnerLR 0.715792
FineTuningLR 0.448156
Epoch 24 | Batch 10/100 | Loss 0.125014
InnerLR 0.715950
FineTuningLR 0.449120
Epoch 24 | Batch 20/100 | Loss 0.124790
InnerLR 0.715418
FineTuningLR 0.450540
Epoch 24 | Batch 30/100 | Loss 0.118549
InnerLR 0.714825
FineTuningLR 0.451540
Epoch 24 | Batch 40/100 | Loss 0.110183
InnerLR 0.714411
FineTuningLR 0.452865
Epoch 24 | Batch 50/100 | Loss 0.103148
InnerLR 0.714624
FineTuningLR 0.453740
Epoch 24 | Batch 60/100 | Loss 0.098718
InnerLR 0.715777
FineTuningLR 0.454619
Epoch 24 | Batch 70/100 | Loss 0.099473
InnerLR 0.716715
FineTuningLR 0.455273
Epoch 24 | Batch 80/100 | Loss 0.104589
InnerLR 0.717844
FineTuningLR 0.456359
Epoch 24 | Batch 90/100 | Loss 0.102479
InnerLR 0.718352
FineTuningLR 0.456902
100 Accuracy = 87.09% +- 1.61%
Epoch 24: 87.09
Epoch 25 | Batch 0/100 | Loss 0.072342
InnerLR 0.719447
FineTuningLR 0.457897
Epoch 25 | Batch 10/100 | Loss 0.117285
InnerLR 0.719913
FineTuningLR 0.458724
Epoch 25 | Batch 20/100 | Loss 0.106573
InnerLR 0.719866
FineTuningLR 0.459945
Epoch 25 | Batch 30/100 | Loss 0.126582
InnerLR 0.719325
FineTuningLR 0.460675
Epoch 25 | Batch 40/100 | Loss 0.121071
InnerLR 0.718321
FineTuningLR 0.461790
Epoch 25 | Batch 50/100 | Loss 0.122536
InnerLR 0.718133
FineTuningLR 0.462216
Epoch 25 | Batch 60/100 | Loss 0.131721
InnerLR 0.717225
FineTuningLR 0.462958
Epoch 25 | Batch 70/100 | Loss 0.126573
InnerLR 0.716468
FineTuningLR 0.463848
Epoch 25 | Batch 80/100 | Loss 0.120594
InnerLR 0.715936
FineTuningLR 0.464998
Epoch 25 | Batch 90/100 | Loss 0.121487
InnerLR 0.715461
FineTuningLR 0.465835
100 Accuracy = 87.23% +- 1.75%
Epoch 25: 87.23
Epoch 26 | Batch 0/100 | Loss 0.145982
InnerLR 0.715346
FineTuningLR 0.466907
Epoch 26 | Batch 10/100 | Loss 0.107520
InnerLR 0.715227
FineTuningLR 0.467773
Epoch 26 | Batch 20/100 | Loss 0.120861
InnerLR 0.714286
FineTuningLR 0.468943
Epoch 26 | Batch 30/100 | Loss 0.115464
InnerLR 0.713879
FineTuningLR 0.469907
Epoch 26 | Batch 40/100 | Loss 0.109885
InnerLR 0.714107
FineTuningLR 0.471701
Epoch 26 | Batch 50/100 | Loss 0.109976
InnerLR 0.714507
FineTuningLR 0.472637
Epoch 26 | Batch 60/100 | Loss 0.109152
InnerLR 0.715838
FineTuningLR 0.473868
Epoch 26 | Batch 70/100 | Loss 0.110972
InnerLR 0.716665
FineTuningLR 0.474409
Epoch 26 | Batch 80/100 | Loss 0.110743
InnerLR 0.717527
FineTuningLR 0.475428
Epoch 26 | Batch 90/100 | Loss 0.106803
InnerLR 0.718103
FineTuningLR 0.476121
100 Accuracy = 86.52% +- 1.62%
Epoch 26: 86.52
Epoch 27 | Batch 0/100 | Loss 0.095081
InnerLR 0.719099
FineTuningLR 0.477465
Epoch 27 | Batch 10/100 | Loss 0.071260
InnerLR 0.719929
FineTuningLR 0.478222
Epoch 27 | Batch 20/100 | Loss 0.085097
InnerLR 0.720477
FineTuningLR 0.479434
Epoch 27 | Batch 30/100 | Loss 0.090334
InnerLR 0.721184
FineTuningLR 0.480258
Epoch 27 | Batch 40/100 | Loss 0.096884
InnerLR 0.722139
FineTuningLR 0.481594
Epoch 27 | Batch 50/100 | Loss 0.096052
InnerLR 0.722873
FineTuningLR 0.482417
Epoch 27 | Batch 60/100 | Loss 0.095162
InnerLR 0.723962
FineTuningLR 0.482763
Epoch 27 | Batch 70/100 | Loss 0.113833
InnerLR 0.724839
FineTuningLR 0.482960
Epoch 27 | Batch 80/100 | Loss 0.115524
InnerLR 0.725937
FineTuningLR 0.483108
Epoch 27 | Batch 90/100 | Loss 0.112369
InnerLR 0.726445
FineTuningLR 0.483416
100 Accuracy = 84.80% +- 1.84%
Epoch 27: 84.80
Epoch 28 | Batch 0/100 | Loss 0.136692
InnerLR 0.727000
FineTuningLR 0.484103
Epoch 28 | Batch 10/100 | Loss 0.145750
InnerLR 0.727582
FineTuningLR 0.484177
Epoch 28 | Batch 20/100 | Loss 0.202302
InnerLR 0.728441
FineTuningLR 0.483590
Epoch 28 | Batch 30/100 | Loss 0.164716
InnerLR 0.729225
FineTuningLR 0.482923
Epoch 28 | Batch 40/100 | Loss 0.179333
InnerLR 0.730230
FineTuningLR 0.482228
Epoch 28 | Batch 50/100 | Loss 0.162023
InnerLR 0.730484
FineTuningLR 0.482207
Epoch 28 | Batch 60/100 | Loss 0.152133
InnerLR 0.731226
FineTuningLR 0.482071
Epoch 28 | Batch 70/100 | Loss 0.151961
InnerLR 0.731631
FineTuningLR 0.482033
Epoch 28 | Batch 80/100 | Loss 0.140948
InnerLR 0.732527
FineTuningLR 0.482208
Epoch 28 | Batch 90/100 | Loss 0.141221
InnerLR 0.733265
FineTuningLR 0.482536
100 Accuracy = 85.76% +- 2.12%
Epoch 28: 85.76
Epoch 29 | Batch 0/100 | Loss 0.063577
InnerLR 0.733889
FineTuningLR 0.482548
Epoch 29 | Batch 10/100 | Loss 0.066173
InnerLR 0.734427
FineTuningLR 0.482706
Epoch 29 | Batch 20/100 | Loss 0.066303
InnerLR 0.735361
FineTuningLR 0.483385
Epoch 29 | Batch 30/100 | Loss 0.097599
InnerLR 0.735748
FineTuningLR 0.483820
Epoch 29 | Batch 40/100 | Loss 0.093051
InnerLR 0.736383
FineTuningLR 0.484708
Epoch 29 | Batch 50/100 | Loss 0.088550
InnerLR 0.736983
FineTuningLR 0.485448
Epoch 29 | Batch 60/100 | Loss 0.093850
InnerLR 0.737707
FineTuningLR 0.486549
Epoch 29 | Batch 70/100 | Loss 0.097825
InnerLR 0.738233
FineTuningLR 0.487158
Epoch 29 | Batch 80/100 | Loss 0.097582
InnerLR 0.739264
FineTuningLR 0.487878
Epoch 29 | Batch 90/100 | Loss 0.102233
InnerLR 0.740324
FineTuningLR 0.488324
100 Accuracy = 86.19% +- 1.73%
Epoch 29: 86.19
Epoch 30 | Batch 0/100 | Loss 0.043131
InnerLR 0.741108
FineTuningLR 0.488914
Epoch 30 | Batch 10/100 | Loss 0.122427
InnerLR 0.741335
FineTuningLR 0.489339
Epoch 30 | Batch 20/100 | Loss 0.138083
InnerLR 0.740975
FineTuningLR 0.489708
Epoch 30 | Batch 30/100 | Loss 0.130605
InnerLR 0.740188
FineTuningLR 0.490002
Epoch 30 | Batch 40/100 | Loss 0.129421
InnerLR 0.738913
FineTuningLR 0.490802
Epoch 30 | Batch 50/100 | Loss 0.125106
InnerLR 0.738412
FineTuningLR 0.491034
Epoch 30 | Batch 60/100 | Loss 0.123087
InnerLR 0.737703
FineTuningLR 0.491568
Epoch 30 | Batch 70/100 | Loss 0.122789
InnerLR 0.737033
FineTuningLR 0.492067
Epoch 30 | Batch 80/100 | Loss 0.124378
InnerLR 0.735805
FineTuningLR 0.493330
Epoch 30 | Batch 90/100 | Loss 0.121146
InnerLR 0.734987
FineTuningLR 0.494297
100 Accuracy = 85.79% +- 1.80%
Epoch 30: 85.79
Epoch 31 | Batch 0/100 | Loss 0.060155
InnerLR 0.733896
FineTuningLR 0.495727
Epoch 31 | Batch 10/100 | Loss 0.066347
InnerLR 0.733482
FineTuningLR 0.496608
Epoch 31 | Batch 20/100 | Loss 0.085212
InnerLR 0.733596
FineTuningLR 0.497645
Epoch 31 | Batch 30/100 | Loss 0.114374
InnerLR 0.733769
FineTuningLR 0.497963
Epoch 31 | Batch 40/100 | Loss 0.109468
InnerLR 0.734138
FineTuningLR 0.498634
Epoch 31 | Batch 50/100 | Loss 0.106603
InnerLR 0.734149
FineTuningLR 0.499418
Epoch 31 | Batch 60/100 | Loss 0.109709
InnerLR 0.734318
FineTuningLR 0.500554
Epoch 31 | Batch 70/100 | Loss 0.108822
InnerLR 0.734119
FineTuningLR 0.501162
Epoch 31 | Batch 80/100 | Loss 0.107695
InnerLR 0.733629
FineTuningLR 0.502499
Epoch 31 | Batch 90/100 | Loss 0.106471
InnerLR 0.733506
FineTuningLR 0.503364
100 Accuracy = 86.79% +- 1.94%
Epoch 31: 86.79
Epoch 32 | Batch 0/100 | Loss 0.212015
InnerLR 0.733092
FineTuningLR 0.504163
Epoch 32 | Batch 10/100 | Loss 0.096000
InnerLR 0.732574
FineTuningLR 0.504575
Epoch 32 | Batch 20/100 | Loss 0.096075
InnerLR 0.731717
FineTuningLR 0.504874
Epoch 32 | Batch 30/100 | Loss 0.094692
InnerLR 0.731170
FineTuningLR 0.504845
Epoch 32 | Batch 40/100 | Loss 0.101765
InnerLR 0.730304
FineTuningLR 0.504976
Epoch 32 | Batch 50/100 | Loss 0.109505
InnerLR 0.729863
FineTuningLR 0.504873
Epoch 32 | Batch 60/100 | Loss 0.106523
InnerLR 0.729026
FineTuningLR 0.504989
Epoch 32 | Batch 70/100 | Loss 0.111192
InnerLR 0.728878
FineTuningLR 0.505334
Epoch 32 | Batch 80/100 | Loss 0.107070
InnerLR 0.728411
FineTuningLR 0.505568
Epoch 32 | Batch 90/100 | Loss 0.106539
InnerLR 0.728437
FineTuningLR 0.505398
100 Accuracy = 87.65% +- 1.83%
Epoch 32: 87.65
Epoch 33 | Batch 0/100 | Loss 0.070248
InnerLR 0.728604
FineTuningLR 0.505256
Epoch 33 | Batch 10/100 | Loss 0.092681
InnerLR 0.728424
FineTuningLR 0.505442
Epoch 33 | Batch 20/100 | Loss 0.101478
InnerLR 0.727786
FineTuningLR 0.506536
Epoch 33 | Batch 30/100 | Loss 0.103549
InnerLR 0.727473
FineTuningLR 0.507026
Epoch 33 | Batch 40/100 | Loss 0.104154
InnerLR 0.727503
FineTuningLR 0.507792
Epoch 33 | Batch 50/100 | Loss 0.102151
InnerLR 0.727576
FineTuningLR 0.508487
Epoch 33 | Batch 60/100 | Loss 0.099120
InnerLR 0.728059
FineTuningLR 0.509613
Epoch 33 | Batch 70/100 | Loss 0.104240
InnerLR 0.728504
FineTuningLR 0.510279
Epoch 33 | Batch 80/100 | Loss 0.109755
InnerLR 0.729279
FineTuningLR 0.510962
Epoch 33 | Batch 90/100 | Loss 0.106675
InnerLR 0.729275
FineTuningLR 0.511361
100 Accuracy = 87.08% +- 1.65%
Epoch 33: 87.08
Epoch 34 | Batch 0/100 | Loss 0.061368
InnerLR 0.728908
FineTuningLR 0.511821
Epoch 34 | Batch 10/100 | Loss 0.124825
InnerLR 0.728914
FineTuningLR 0.512378
Epoch 34 | Batch 20/100 | Loss 0.132194
InnerLR 0.728961
FineTuningLR 0.513488
Epoch 34 | Batch 30/100 | Loss 0.142136
InnerLR 0.728954
FineTuningLR 0.514162
Epoch 34 | Batch 40/100 | Loss 0.128687
InnerLR 0.729330
FineTuningLR 0.515179
Epoch 34 | Batch 50/100 | Loss 0.118523
InnerLR 0.730131
FineTuningLR 0.515960
Epoch 34 | Batch 60/100 | Loss 0.124490
InnerLR 0.730529
FineTuningLR 0.517318
Epoch 34 | Batch 70/100 | Loss 0.117585
InnerLR 0.730619
FineTuningLR 0.518345
Epoch 34 | Batch 80/100 | Loss 0.113664
InnerLR 0.731201
FineTuningLR 0.519445
Epoch 34 | Batch 90/100 | Loss 0.117167
InnerLR 0.731593
FineTuningLR 0.520061
100 Accuracy = 87.33% +- 1.80%
Epoch 34: 87.33
Epoch 35 | Batch 0/100 | Loss 0.180327
InnerLR 0.732541
FineTuningLR 0.520927
Epoch 35 | Batch 10/100 | Loss 0.108412
InnerLR 0.733500
FineTuningLR 0.521321
Epoch 35 | Batch 20/100 | Loss 0.099956
InnerLR 0.734350
FineTuningLR 0.522114
Epoch 35 | Batch 30/100 | Loss 0.106427
InnerLR 0.734733
FineTuningLR 0.522486
Epoch 35 | Batch 40/100 | Loss 0.107239
InnerLR 0.735712
FineTuningLR 0.522473
Epoch 35 | Batch 50/100 | Loss 0.101189
InnerLR 0.736697
FineTuningLR 0.522835
Epoch 35 | Batch 60/100 | Loss 0.101742
InnerLR 0.738277
FineTuningLR 0.523549
Epoch 35 | Batch 70/100 | Loss 0.099814
InnerLR 0.739151
FineTuningLR 0.524180
Epoch 35 | Batch 80/100 | Loss 0.099266
InnerLR 0.740543
FineTuningLR 0.524765
Epoch 35 | Batch 90/100 | Loss 0.096140
InnerLR 0.741600
FineTuningLR 0.525131
100 Accuracy = 86.83% +- 1.73%
Epoch 35: 86.83
Epoch 36 | Batch 0/100 | Loss 0.068269
InnerLR 0.743488
FineTuningLR 0.525169
Epoch 36 | Batch 10/100 | Loss 0.123938
InnerLR 0.744528
FineTuningLR 0.525040
Epoch 36 | Batch 20/100 | Loss 0.114810
InnerLR 0.746232
FineTuningLR 0.524572
Epoch 36 | Batch 30/100 | Loss 0.120138
InnerLR 0.746877
FineTuningLR 0.524693
Epoch 36 | Batch 40/100 | Loss 0.112188
InnerLR 0.747933
FineTuningLR 0.524754
Epoch 36 | Batch 50/100 | Loss 0.109557
InnerLR 0.748519
FineTuningLR 0.524933
Epoch 36 | Batch 60/100 | Loss 0.106168
InnerLR 0.750011
FineTuningLR 0.525141
Epoch 36 | Batch 70/100 | Loss 0.105176
InnerLR 0.750605
FineTuningLR 0.525347
Epoch 36 | Batch 80/100 | Loss 0.105410
InnerLR 0.751664
FineTuningLR 0.525533
Epoch 36 | Batch 90/100 | Loss 0.106976
InnerLR 0.752196
FineTuningLR 0.525769
100 Accuracy = 85.59% +- 1.83%
Epoch 36: 85.59
Epoch 37 | Batch 0/100 | Loss 0.048792
InnerLR 0.752233
FineTuningLR 0.525986
Epoch 37 | Batch 10/100 | Loss 0.138863
InnerLR 0.752520
FineTuningLR 0.526103
Epoch 37 | Batch 20/100 | Loss 0.137920
InnerLR 0.752964
FineTuningLR 0.525680
Epoch 37 | Batch 30/100 | Loss 0.122178
InnerLR 0.753294
FineTuningLR 0.525555
Epoch 37 | Batch 40/100 | Loss 0.112578
InnerLR 0.754038
FineTuningLR 0.525986
Epoch 37 | Batch 50/100 | Loss 0.111669
InnerLR 0.754349
FineTuningLR 0.526331
Epoch 37 | Batch 60/100 | Loss 0.111444
InnerLR 0.755385
FineTuningLR 0.527145
Epoch 37 | Batch 70/100 | Loss 0.108309
InnerLR 0.755817
FineTuningLR 0.527625
Epoch 37 | Batch 80/100 | Loss 0.104098
InnerLR 0.756625
FineTuningLR 0.528749
Epoch 37 | Batch 90/100 | Loss 0.104350
InnerLR 0.757274
FineTuningLR 0.529687
100 Accuracy = 86.11% +- 1.91%
Epoch 37: 86.11
Epoch 38 | Batch 0/100 | Loss 0.326187
InnerLR 0.758341
FineTuningLR 0.531031
Epoch 38 | Batch 10/100 | Loss 0.109758
InnerLR 0.758776
FineTuningLR 0.531936
Epoch 38 | Batch 20/100 | Loss 0.107432
InnerLR 0.759057
FineTuningLR 0.533885
Epoch 38 | Batch 30/100 | Loss 0.104130
InnerLR 0.759563
FineTuningLR 0.535058
Epoch 38 | Batch 40/100 | Loss 0.100888
InnerLR 0.760358
FineTuningLR 0.536946
Epoch 38 | Batch 50/100 | Loss 0.098973
InnerLR 0.761121
FineTuningLR 0.538218
Epoch 38 | Batch 60/100 | Loss 0.094664
InnerLR 0.761707
FineTuningLR 0.540204
Epoch 38 | Batch 70/100 | Loss 0.105599
InnerLR 0.762205
FineTuningLR 0.540972
Epoch 38 | Batch 80/100 | Loss 0.104681
InnerLR 0.762776
FineTuningLR 0.541816
Epoch 38 | Batch 90/100 | Loss 0.102803
InnerLR 0.763356
FineTuningLR 0.542541
100 Accuracy = 86.12% +- 1.72%
Epoch 38: 86.12
Epoch 39 | Batch 0/100 | Loss 0.063690
InnerLR 0.764331
FineTuningLR 0.543983
Epoch 39 | Batch 10/100 | Loss 0.104543
InnerLR 0.764803
FineTuningLR 0.544864
Epoch 39 | Batch 20/100 | Loss 0.093416
InnerLR 0.765197
FineTuningLR 0.545973
Epoch 39 | Batch 30/100 | Loss 0.088908
InnerLR 0.765425
FineTuningLR 0.546713
Epoch 39 | Batch 40/100 | Loss 0.097548
InnerLR 0.765814
FineTuningLR 0.546973
Epoch 39 | Batch 50/100 | Loss 0.097487
InnerLR 0.766518
FineTuningLR 0.546928
Epoch 39 | Batch 60/100 | Loss 0.100628
InnerLR 0.767743
FineTuningLR 0.547351
Epoch 39 | Batch 70/100 | Loss 0.100062
InnerLR 0.768290
FineTuningLR 0.547526
Epoch 39 | Batch 80/100 | Loss 0.097513
InnerLR 0.768841
FineTuningLR 0.547978
Epoch 39 | Batch 90/100 | Loss 0.096601
InnerLR 0.769329
FineTuningLR 0.547978
100 Accuracy = 85.87% +- 1.99%
Epoch 39: 85.87
Epoch 40 | Batch 0/100 | Loss 0.144679
InnerLR 0.769620
FineTuningLR 0.548292
Epoch 40 | Batch 10/100 | Loss 0.089269
InnerLR 0.769626
FineTuningLR 0.548848
Epoch 40 | Batch 20/100 | Loss 0.099138
InnerLR 0.769951
FineTuningLR 0.549682
Epoch 40 | Batch 30/100 | Loss 0.103232
InnerLR 0.770316
FineTuningLR 0.550072
Epoch 40 | Batch 40/100 | Loss 0.095115
InnerLR 0.770569
FineTuningLR 0.550653
Epoch 40 | Batch 50/100 | Loss 0.110406
InnerLR 0.770755
FineTuningLR 0.550935
Epoch 40 | Batch 60/100 | Loss 0.111957
InnerLR 0.770875
FineTuningLR 0.551312
Epoch 40 | Batch 70/100 | Loss 0.106895
InnerLR 0.771129
FineTuningLR 0.551993
Epoch 40 | Batch 80/100 | Loss 0.107337
InnerLR 0.771802
FineTuningLR 0.552830
Epoch 40 | Batch 90/100 | Loss 0.102431
InnerLR 0.772167
FineTuningLR 0.553355
100 Accuracy = 84.87% +- 2.00%
Epoch 40: 84.87
Epoch 41 | Batch 0/100 | Loss 0.206226
InnerLR 0.773198
FineTuningLR 0.554209
Epoch 41 | Batch 10/100 | Loss 0.081332
InnerLR 0.774206
FineTuningLR 0.554560
Epoch 41 | Batch 20/100 | Loss 0.083388
InnerLR 0.775600
FineTuningLR 0.555207
Epoch 41 | Batch 30/100 | Loss 0.087922
InnerLR 0.776602
FineTuningLR 0.555570
Epoch 41 | Batch 40/100 | Loss 0.095817
InnerLR 0.777287
FineTuningLR 0.556456
Epoch 41 | Batch 50/100 | Loss 0.101455
InnerLR 0.777432
FineTuningLR 0.557331
Epoch 41 | Batch 60/100 | Loss 0.101473
InnerLR 0.777254
FineTuningLR 0.558953
Epoch 41 | Batch 70/100 | Loss 0.097860
InnerLR 0.777559
FineTuningLR 0.559889
Epoch 41 | Batch 80/100 | Loss 0.099590
InnerLR 0.777735
FineTuningLR 0.561038
Epoch 41 | Batch 90/100 | Loss 0.099162
InnerLR 0.777779
FineTuningLR 0.561191
100 Accuracy = 85.60% +- 1.90%
Epoch 41: 85.60
Epoch 42 | Batch 0/100 | Loss 0.123024
InnerLR 0.777819
FineTuningLR 0.561126
Epoch 42 | Batch 10/100 | Loss 0.131931
InnerLR 0.777893
FineTuningLR 0.560598
Epoch 42 | Batch 20/100 | Loss 0.107805
InnerLR 0.777611
FineTuningLR 0.559774
Epoch 42 | Batch 30/100 | Loss 0.099739
InnerLR 0.777789
FineTuningLR 0.559193
Epoch 42 | Batch 40/100 | Loss 0.107141
InnerLR 0.778619
FineTuningLR 0.558657
Epoch 42 | Batch 50/100 | Loss 0.105857
InnerLR 0.778938
FineTuningLR 0.558480
Epoch 42 | Batch 60/100 | Loss 0.110021
InnerLR 0.779533
FineTuningLR 0.557920
Epoch 42 | Batch 70/100 | Loss 0.105182
InnerLR 0.779845
FineTuningLR 0.557640
Epoch 42 | Batch 80/100 | Loss 0.104076
InnerLR 0.780626
FineTuningLR 0.557567
Epoch 42 | Batch 90/100 | Loss 0.104943
InnerLR 0.780988
FineTuningLR 0.557744
100 Accuracy = 85.87% +- 1.82%
Epoch 42: 85.87
Epoch 43 | Batch 0/100 | Loss 0.044261
InnerLR 0.781295
FineTuningLR 0.557721
Epoch 43 | Batch 10/100 | Loss 0.099274
InnerLR 0.781147
FineTuningLR 0.557725
Epoch 43 | Batch 20/100 | Loss 0.170497
InnerLR 0.780944
FineTuningLR 0.558123
Epoch 43 | Batch 30/100 | Loss 0.158925
InnerLR 0.780758
FineTuningLR 0.557812
Epoch 43 | Batch 40/100 | Loss 0.140530
InnerLR 0.781212
FineTuningLR 0.556719
Epoch 43 | Batch 50/100 | Loss 0.136291
InnerLR 0.781692
FineTuningLR 0.556275
Epoch 43 | Batch 60/100 | Loss 0.126440
InnerLR 0.781790
FineTuningLR 0.556333
Epoch 43 | Batch 70/100 | Loss 0.122340
InnerLR 0.781930
FineTuningLR 0.556253
Epoch 43 | Batch 80/100 | Loss 0.115749
InnerLR 0.781894
FineTuningLR 0.556457
Epoch 43 | Batch 90/100 | Loss 0.114853
InnerLR 0.781998
FineTuningLR 0.556897
100 Accuracy = 87.64% +- 1.71%
Epoch 43: 87.64
Epoch 44 | Batch 0/100 | Loss 0.181989
InnerLR 0.781283
FineTuningLR 0.557518
Epoch 44 | Batch 10/100 | Loss 0.141146
InnerLR 0.780504
FineTuningLR 0.558090
Epoch 44 | Batch 20/100 | Loss 0.105847
InnerLR 0.779316
FineTuningLR 0.558537
Epoch 44 | Batch 30/100 | Loss 0.099153
InnerLR 0.779232
FineTuningLR 0.558866
Epoch 44 | Batch 40/100 | Loss 0.098740
InnerLR 0.779458
FineTuningLR 0.559565
Epoch 44 | Batch 50/100 | Loss 0.103758
InnerLR 0.779595
FineTuningLR 0.560092
Epoch 44 | Batch 60/100 | Loss 0.101396
InnerLR 0.779961
FineTuningLR 0.560771
Epoch 44 | Batch 70/100 | Loss 0.111707
InnerLR 0.780018
FineTuningLR 0.560822
Epoch 44 | Batch 80/100 | Loss 0.110066
InnerLR 0.779850
FineTuningLR 0.560870
Epoch 44 | Batch 90/100 | Loss 0.112214
InnerLR 0.779534
FineTuningLR 0.560531
100 Accuracy = 86.68% +- 1.84%
Epoch 44: 86.68
Epoch 45 | Batch 0/100 | Loss 0.190324
InnerLR 0.779055
FineTuningLR 0.560361
Epoch 45 | Batch 10/100 | Loss 0.141825
InnerLR 0.778513
FineTuningLR 0.560303
Epoch 45 | Batch 20/100 | Loss 0.135753
InnerLR 0.777758
FineTuningLR 0.559830
Epoch 45 | Batch 30/100 | Loss 0.109553
InnerLR 0.777710
FineTuningLR 0.559453
Epoch 45 | Batch 40/100 | Loss 0.119056
InnerLR 0.777891
FineTuningLR 0.559017
Epoch 45 | Batch 50/100 | Loss 0.111814
InnerLR 0.777793
FineTuningLR 0.558893
Epoch 45 | Batch 60/100 | Loss 0.112112
InnerLR 0.777573
FineTuningLR 0.558899
Epoch 45 | Batch 70/100 | Loss 0.109547
InnerLR 0.777696
FineTuningLR 0.558677
Epoch 45 | Batch 80/100 | Loss 0.108429
InnerLR 0.777926
FineTuningLR 0.558851
Epoch 45 | Batch 90/100 | Loss 0.105364
InnerLR 0.777876
FineTuningLR 0.559245
100 Accuracy = 84.56% +- 2.08%
Epoch 45: 84.56
Epoch 46 | Batch 0/100 | Loss 0.183860
InnerLR 0.778142
FineTuningLR 0.559729
Epoch 46 | Batch 10/100 | Loss 0.086538
InnerLR 0.778071
FineTuningLR 0.560175
Epoch 46 | Batch 20/100 | Loss 0.091761
InnerLR 0.778177
FineTuningLR 0.561252
Epoch 46 | Batch 30/100 | Loss 0.083628
InnerLR 0.778304
FineTuningLR 0.562131
Epoch 46 | Batch 40/100 | Loss 0.098662
InnerLR 0.778815
FineTuningLR 0.562489
Epoch 46 | Batch 50/100 | Loss 0.104617
InnerLR 0.779188
FineTuningLR 0.562351
Epoch 46 | Batch 60/100 | Loss 0.115395
InnerLR 0.779801
FineTuningLR 0.562307
Epoch 46 | Batch 70/100 | Loss 0.112474
InnerLR 0.780338
FineTuningLR 0.562430
Epoch 46 | Batch 80/100 | Loss 0.113386
InnerLR 0.780790
FineTuningLR 0.562603
Epoch 46 | Batch 90/100 | Loss 0.117609
InnerLR 0.780854
FineTuningLR 0.562668
100 Accuracy = 86.28% +- 1.73%
Epoch 46: 86.28
Epoch 47 | Batch 0/100 | Loss 0.189022
InnerLR 0.780813
FineTuningLR 0.562776
Epoch 47 | Batch 10/100 | Loss 0.173607
InnerLR 0.781027
FineTuningLR 0.562908
Epoch 47 | Batch 20/100 | Loss 0.137791
InnerLR 0.781749
FineTuningLR 0.562871
Epoch 47 | Batch 30/100 | Loss 0.118325
InnerLR 0.782164
FineTuningLR 0.562726
Epoch 47 | Batch 40/100 | Loss 0.104071
InnerLR 0.782783
FineTuningLR 0.562930
Epoch 47 | Batch 50/100 | Loss 0.099188
InnerLR 0.783195
FineTuningLR 0.563035
Epoch 47 | Batch 60/100 | Loss 0.096368
InnerLR 0.783757
FineTuningLR 0.563129
Epoch 47 | Batch 70/100 | Loss 0.099692
InnerLR 0.783912
FineTuningLR 0.563569
Epoch 47 | Batch 80/100 | Loss 0.107892
InnerLR 0.783940
FineTuningLR 0.563768
Epoch 47 | Batch 90/100 | Loss 0.117167
InnerLR 0.784093
FineTuningLR 0.563786
100 Accuracy = 87.03% +- 1.66%
Epoch 47: 87.03
Epoch 48 | Batch 0/100 | Loss 0.038080
InnerLR 0.784070
FineTuningLR 0.563807
Epoch 48 | Batch 10/100 | Loss 0.057020
InnerLR 0.784545
FineTuningLR 0.564038
Epoch 48 | Batch 20/100 | Loss 0.080651
InnerLR 0.785453
FineTuningLR 0.564179
Epoch 48 | Batch 30/100 | Loss 0.083392
InnerLR 0.785568
FineTuningLR 0.564485
Epoch 48 | Batch 40/100 | Loss 0.085400
InnerLR 0.785819
FineTuningLR 0.565307
Epoch 48 | Batch 50/100 | Loss 0.081698
InnerLR 0.785869
FineTuningLR 0.565632
Epoch 48 | Batch 60/100 | Loss 0.083375
InnerLR 0.786037
FineTuningLR 0.565904
Epoch 48 | Batch 70/100 | Loss 0.084053
InnerLR 0.786448
FineTuningLR 0.565843
Epoch 48 | Batch 80/100 | Loss 0.086297
InnerLR 0.787322
FineTuningLR 0.566317
Epoch 48 | Batch 90/100 | Loss 0.082838
InnerLR 0.787619
FineTuningLR 0.566853
100 Accuracy = 85.40% +- 1.75%
Epoch 48: 85.40
Epoch 49 | Batch 0/100 | Loss 0.093303
InnerLR 0.788491
FineTuningLR 0.567793
Epoch 49 | Batch 10/100 | Loss 0.065724
InnerLR 0.788980
FineTuningLR 0.568617
Epoch 49 | Batch 20/100 | Loss 0.098206
InnerLR 0.789100
FineTuningLR 0.570163
Epoch 49 | Batch 30/100 | Loss 0.087399
InnerLR 0.789156
FineTuningLR 0.571196
Epoch 49 | Batch 40/100 | Loss 0.098623
InnerLR 0.788742
FineTuningLR 0.572583
Epoch 49 | Batch 50/100 | Loss 0.106246
InnerLR 0.788701
FineTuningLR 0.573242
Epoch 49 | Batch 60/100 | Loss 0.102614
InnerLR 0.788519
FineTuningLR 0.574645
Epoch 49 | Batch 70/100 | Loss 0.097727
InnerLR 0.788530
FineTuningLR 0.575769
Epoch 49 | Batch 80/100 | Loss 0.095989
InnerLR 0.788551
FineTuningLR 0.577306
Epoch 49 | Batch 90/100 | Loss 0.093048
InnerLR 0.788788
FineTuningLR 0.578516
100 Accuracy = 86.36% +- 1.76%
Epoch 49: 86.36
Epoch 50 | Batch 0/100 | Loss 0.046328
InnerLR 0.789148
FineTuningLR 0.580202
Epoch 50 | Batch 10/100 | Loss 0.064138
InnerLR 0.789374
FineTuningLR 0.581409
Epoch 50 | Batch 20/100 | Loss 0.079974
InnerLR 0.789833
FineTuningLR 0.583157
Epoch 50 | Batch 30/100 | Loss 0.081561
InnerLR 0.790373
FineTuningLR 0.584340
Epoch 50 | Batch 40/100 | Loss 0.101084
InnerLR 0.790732
FineTuningLR 0.585626
Epoch 50 | Batch 50/100 | Loss 0.100454
InnerLR 0.790998
FineTuningLR 0.586247
Epoch 50 | Batch 60/100 | Loss 0.108078
InnerLR 0.791109
FineTuningLR 0.586821
Epoch 50 | Batch 70/100 | Loss 0.103319
InnerLR 0.790839
FineTuningLR 0.586909
Epoch 50 | Batch 80/100 | Loss 0.106659
InnerLR 0.791235
FineTuningLR 0.587011
Epoch 50 | Batch 90/100 | Loss 0.103427
InnerLR 0.791696
FineTuningLR 0.587051
100 Accuracy = 86.37% +- 1.68%
Epoch 50: 86.37
Epoch 51 | Batch 0/100 | Loss 0.178158
InnerLR 0.792400
FineTuningLR 0.586415
Epoch 51 | Batch 10/100 | Loss 0.082429
InnerLR 0.792733
FineTuningLR 0.586236
Epoch 51 | Batch 20/100 | Loss 0.094269
InnerLR 0.792970
FineTuningLR 0.586342
Epoch 51 | Batch 30/100 | Loss 0.087248
InnerLR 0.793139
FineTuningLR 0.586907
Epoch 51 | Batch 40/100 | Loss 0.088325
InnerLR 0.793834
FineTuningLR 0.587473
Epoch 51 | Batch 50/100 | Loss 0.094182
InnerLR 0.793906
FineTuningLR 0.587353
Epoch 51 | Batch 60/100 | Loss 0.094821
InnerLR 0.794419
FineTuningLR 0.586905
Epoch 51 | Batch 70/100 | Loss 0.093160
InnerLR 0.794515
FineTuningLR 0.587004
Epoch 51 | Batch 80/100 | Loss 0.092523
InnerLR 0.795329
FineTuningLR 0.586935
Epoch 51 | Batch 90/100 | Loss 0.091706
InnerLR 0.795647
FineTuningLR 0.586959
100 Accuracy = 85.79% +- 1.90%
Epoch 51: 85.79
Epoch 52 | Batch 0/100 | Loss 0.069458
InnerLR 0.796315
FineTuningLR 0.587001
Epoch 52 | Batch 10/100 | Loss 0.087446
InnerLR 0.796816
FineTuningLR 0.587220
Epoch 52 | Batch 20/100 | Loss 0.081540
InnerLR 0.796983
FineTuningLR 0.587901
Epoch 52 | Batch 30/100 | Loss 0.083564
InnerLR 0.797172
FineTuningLR 0.588524
Epoch 52 | Batch 40/100 | Loss 0.081319
InnerLR 0.797198
FineTuningLR 0.589547
Epoch 52 | Batch 50/100 | Loss 0.082372
InnerLR 0.797213
FineTuningLR 0.590189
Epoch 52 | Batch 60/100 | Loss 0.095000
InnerLR 0.796567
FineTuningLR 0.591354
Epoch 52 | Batch 70/100 | Loss 0.095199
InnerLR 0.796113
FineTuningLR 0.592196
Epoch 52 | Batch 80/100 | Loss 0.098930
InnerLR 0.794750
FineTuningLR 0.593475
Epoch 52 | Batch 90/100 | Loss 0.098951
InnerLR 0.793592
FineTuningLR 0.593913
100 Accuracy = 84.69% +- 2.05%
Epoch 52: 84.69
Epoch 53 | Batch 0/100 | Loss 0.066943
InnerLR 0.792124
FineTuningLR 0.594623
Epoch 53 | Batch 10/100 | Loss 0.136138
InnerLR 0.791311
FineTuningLR 0.595041
Epoch 53 | Batch 20/100 | Loss 0.110924
InnerLR 0.790165
FineTuningLR 0.595146
Epoch 53 | Batch 30/100 | Loss 0.120058
InnerLR 0.789544
FineTuningLR 0.595247
Epoch 53 | Batch 40/100 | Loss 0.138179
InnerLR 0.788240
FineTuningLR 0.595201
Epoch 53 | Batch 50/100 | Loss 0.133900
InnerLR 0.787450
FineTuningLR 0.595048
Epoch 53 | Batch 60/100 | Loss 0.126927
InnerLR 0.786044
FineTuningLR 0.594931
Epoch 53 | Batch 70/100 | Loss 0.125593
InnerLR 0.785443
FineTuningLR 0.595145
Epoch 53 | Batch 80/100 | Loss 0.123789
InnerLR 0.785427
FineTuningLR 0.594753
Epoch 53 | Batch 90/100 | Loss 0.117963
InnerLR 0.785851
FineTuningLR 0.594503
100 Accuracy = 85.37% +- 1.83%
Epoch 53: 85.37
Epoch 54 | Batch 0/100 | Loss 0.105686
InnerLR 0.786527
FineTuningLR 0.594338
Epoch 54 | Batch 10/100 | Loss 0.125274
InnerLR 0.786611
FineTuningLR 0.594544
Epoch 54 | Batch 20/100 | Loss 0.098032
InnerLR 0.786771
FineTuningLR 0.595324
Epoch 54 | Batch 30/100 | Loss 0.093703
InnerLR 0.786747
FineTuningLR 0.595997
Epoch 54 | Batch 40/100 | Loss 0.087516
InnerLR 0.786633
FineTuningLR 0.597206
Epoch 54 | Batch 50/100 | Loss 0.083791
InnerLR 0.786520
FineTuningLR 0.598126
Epoch 54 | Batch 60/100 | Loss 0.083221
InnerLR 0.786943
FineTuningLR 0.599520
Epoch 54 | Batch 70/100 | Loss 0.083083
InnerLR 0.787391
FineTuningLR 0.600079
Epoch 54 | Batch 80/100 | Loss 0.084211
InnerLR 0.787496
FineTuningLR 0.600757
Epoch 54 | Batch 90/100 | Loss 0.092844
InnerLR 0.787754
FineTuningLR 0.601108
100 Accuracy = 84.61% +- 1.74%
Epoch 54: 84.61
Epoch 55 | Batch 0/100 | Loss 0.067670
InnerLR 0.788203
FineTuningLR 0.601424
Epoch 55 | Batch 10/100 | Loss 0.072490
InnerLR 0.788191
FineTuningLR 0.601766
Epoch 55 | Batch 20/100 | Loss 0.081585
InnerLR 0.788227
FineTuningLR 0.602267
Epoch 55 | Batch 30/100 | Loss 0.094239
InnerLR 0.788420
FineTuningLR 0.602814
Epoch 55 | Batch 40/100 | Loss 0.089046
InnerLR 0.789259
FineTuningLR 0.603131
Epoch 55 | Batch 50/100 | Loss 0.091683
InnerLR 0.789916
FineTuningLR 0.603181
Epoch 55 | Batch 60/100 | Loss 0.089685
InnerLR 0.791321
FineTuningLR 0.603287
Epoch 55 | Batch 70/100 | Loss 0.095367
InnerLR 0.792219
FineTuningLR 0.603039
Epoch 55 | Batch 80/100 | Loss 0.100780
InnerLR 0.793420
FineTuningLR 0.602386
Epoch 55 | Batch 90/100 | Loss 0.098675
InnerLR 0.794405
FineTuningLR 0.602064
100 Accuracy = 86.59% +- 1.91%
Epoch 55: 86.59
Epoch 56 | Batch 0/100 | Loss 0.073722
InnerLR 0.795170
FineTuningLR 0.601363
Epoch 56 | Batch 10/100 | Loss 0.097715
InnerLR 0.795812
FineTuningLR 0.601067
Epoch 56 | Batch 20/100 | Loss 0.086116
InnerLR 0.796205
FineTuningLR 0.600592
Epoch 56 | Batch 30/100 | Loss 0.097864
InnerLR 0.796218
FineTuningLR 0.600416
Epoch 56 | Batch 40/100 | Loss 0.095090
InnerLR 0.796099
FineTuningLR 0.600612
Epoch 56 | Batch 50/100 | Loss 0.101080
InnerLR 0.795710
FineTuningLR 0.600663
Epoch 56 | Batch 60/100 | Loss 0.103540
InnerLR 0.795445
FineTuningLR 0.600333
Epoch 56 | Batch 70/100 | Loss 0.101107
InnerLR 0.795450
FineTuningLR 0.600207
Epoch 56 | Batch 80/100 | Loss 0.097628
InnerLR 0.795306
FineTuningLR 0.600276
Epoch 56 | Batch 90/100 | Loss 0.097005
InnerLR 0.795323
FineTuningLR 0.600297
100 Accuracy = 86.32% +- 1.93%
Epoch 56: 86.32
Epoch 57 | Batch 0/100 | Loss 0.280274
InnerLR 0.794642
FineTuningLR 0.600325
Epoch 57 | Batch 10/100 | Loss 0.138523
InnerLR 0.794232
FineTuningLR 0.599829
Epoch 57 | Batch 20/100 | Loss 0.110031
InnerLR 0.793565
FineTuningLR 0.599421
Epoch 57 | Batch 30/100 | Loss 0.094699
InnerLR 0.793664
FineTuningLR 0.599223
Epoch 57 | Batch 40/100 | Loss 0.097759
InnerLR 0.793745
FineTuningLR 0.598925
Epoch 57 | Batch 50/100 | Loss 0.099256
InnerLR 0.793670
FineTuningLR 0.598998
Epoch 57 | Batch 60/100 | Loss 0.098479
InnerLR 0.793691
FineTuningLR 0.598861
Epoch 57 | Batch 70/100 | Loss 0.093432
InnerLR 0.793872
FineTuningLR 0.598718
Epoch 57 | Batch 80/100 | Loss 0.094469
InnerLR 0.794072
FineTuningLR 0.598851
Epoch 57 | Batch 90/100 | Loss 0.092174
InnerLR 0.794085
FineTuningLR 0.599169
100 Accuracy = 86.93% +- 1.85%
Epoch 57: 86.93
Epoch 58 | Batch 0/100 | Loss 0.202165
InnerLR 0.794314
FineTuningLR 0.599503
Epoch 58 | Batch 10/100 | Loss 0.113715
InnerLR 0.794454
FineTuningLR 0.599831
Epoch 58 | Batch 20/100 | Loss 0.090130
InnerLR 0.794764
FineTuningLR 0.600462
Epoch 58 | Batch 30/100 | Loss 0.081659
InnerLR 0.794900
FineTuningLR 0.601245
Epoch 58 | Batch 40/100 | Loss 0.079573
InnerLR 0.795465
FineTuningLR 0.602004
Epoch 58 | Batch 50/100 | Loss 0.077347
InnerLR 0.795667
FineTuningLR 0.602448
Epoch 58 | Batch 60/100 | Loss 0.087230
InnerLR 0.796334
FineTuningLR 0.602704
Epoch 58 | Batch 70/100 | Loss 0.084858
InnerLR 0.796931
FineTuningLR 0.602944
Epoch 58 | Batch 80/100 | Loss 0.084386
InnerLR 0.798169
FineTuningLR 0.602967
Epoch 58 | Batch 90/100 | Loss 0.088467
InnerLR 0.798998
FineTuningLR 0.602742
100 Accuracy = 85.65% +- 1.93%
Epoch 58: 85.65
Epoch 59 | Batch 0/100 | Loss 0.210663
InnerLR 0.799451
FineTuningLR 0.602084
Epoch 59 | Batch 10/100 | Loss 0.087232
InnerLR 0.799592
FineTuningLR 0.601532
Epoch 59 | Batch 20/100 | Loss 0.095091
InnerLR 0.799748
FineTuningLR 0.601199
Epoch 59 | Batch 30/100 | Loss 0.098986
InnerLR 0.799349
FineTuningLR 0.600577
Epoch 59 | Batch 40/100 | Loss 0.098831
InnerLR 0.798469
FineTuningLR 0.599808
Epoch 59 | Batch 50/100 | Loss 0.097075
InnerLR 0.797820
FineTuningLR 0.599467
Epoch 59 | Batch 60/100 | Loss 0.094851
InnerLR 0.797196
FineTuningLR 0.599289
Epoch 59 | Batch 70/100 | Loss 0.097232
InnerLR 0.796785
FineTuningLR 0.599344
Epoch 59 | Batch 80/100 | Loss 0.096939
InnerLR 0.796164
FineTuningLR 0.599280
Epoch 59 | Batch 90/100 | Loss 0.097451
InnerLR 0.795442
FineTuningLR 0.599301
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 86.72% +- 1.62%
Epoch 59: 86.72
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_5_with_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_with_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/tabula_muris/leo_FCNet/20231212_141348
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 98.56% +- 0.17%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_with_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/tabula_muris/leo_FCNet/20231212_141348
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 86.57% +- 0.73%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_with_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/tabula_muris/leo_FCNet/20231212_141348
600 Accuracy = 86.79% +- 0.63%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_5_with_optimize_backbone_finetuning_loop_enabled_pretrained_with_baseline/results.txt
+-------+-------------------+-------------------+
| split |      acc_mean     |      acc_std      |
+-------+-------------------+-------------------+
| train | 98.55777777777777 | 2.084864918500731 |
|  val  | 86.57111111111111 | 9.118466136985871 |
|  test | 86.78666666666666 | 7.811698729280146 |
+-------+-------------------+-------------------+
