/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 5
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 5
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 5
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 1
    finetuning_lr_init: 0.001
    num_adaptation_steps: 10
    kl_coef: 0.001
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 1.0e-09
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 16
    optimize_backbone: false
  n_task: 4
  latent_space_dim: 16
  leo_inner_lr_init: 1
  leo_finetuning_lr_init: 0.001
  num_adaptation_steps: 10
  kl_coef: 0.001
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 1.0e-09
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-08
  optimize_backbone: false
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_5_lr_0.0003_latent_space_dim_16_weight_decay_1e-08_num_adaptation_steps_10
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.0003
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.0003
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_5_lr_0.0003_latent_space_dim_16_weight_decay_1e-08_num_adaptation_steps_10/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=16, bias=True)
    (relation_net): Linear(in_features=32, out_features=32, bias=True)
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=80, out_features=650, bias=True)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 1e-08
)
Epoch 0 | Batch 0/100 | Loss 2.056421
InnerLR 1.000000
FineTuningLR 0.001000
Epoch 0 | Batch 10/100 | Loss 1.902283
InnerLR 0.999406
FineTuningLR 0.001594
Epoch 0 | Batch 20/100 | Loss 1.910232
InnerLR 0.998512
FineTuningLR 0.002488
Epoch 0 | Batch 30/100 | Loss 1.871750
InnerLR 0.997915
FineTuningLR 0.003085
Epoch 0 | Batch 40/100 | Loss 1.905458
InnerLR 0.997014
FineTuningLR 0.003986
Epoch 0 | Batch 50/100 | Loss 1.883881
InnerLR 0.996414
FineTuningLR 0.004586
Epoch 0 | Batch 60/100 | Loss 1.881281
InnerLR 0.995507
FineTuningLR 0.005493
Epoch 0 | Batch 70/100 | Loss 1.882807
InnerLR 0.994909
FineTuningLR 0.006091
Epoch 0 | Batch 80/100 | Loss 1.877436
InnerLR 0.994004
FineTuningLR 0.006996
Epoch 0 | Batch 90/100 | Loss 1.881629
InnerLR 0.993398
FineTuningLR 0.007602
100 Accuracy = 38.81% +- 1.80%
Epoch 0: 38.81
best model! save...
Epoch 1 | Batch 0/100 | Loss 1.667523
InnerLR 0.992490
FineTuningLR 0.008510
Epoch 1 | Batch 10/100 | Loss 1.893075
InnerLR 0.991887
FineTuningLR 0.009113
Epoch 1 | Batch 20/100 | Loss 1.814428
InnerLR 0.990976
FineTuningLR 0.010024
Epoch 1 | Batch 30/100 | Loss 1.807100
InnerLR 0.990361
FineTuningLR 0.010639
Epoch 1 | Batch 40/100 | Loss 1.801643
InnerLR 0.989432
FineTuningLR 0.011568
Epoch 1 | Batch 50/100 | Loss 1.814962
InnerLR 0.988808
FineTuningLR 0.012192
Epoch 1 | Batch 60/100 | Loss 1.839122
InnerLR 0.987867
FineTuningLR 0.013133
Epoch 1 | Batch 70/100 | Loss 1.820719
InnerLR 0.987238
FineTuningLR 0.013762
Epoch 1 | Batch 80/100 | Loss 1.828835
InnerLR 0.986293
FineTuningLR 0.014707
Epoch 1 | Batch 90/100 | Loss 1.815147
InnerLR 0.985661
FineTuningLR 0.015339
100 Accuracy = 41.08% +- 1.76%
Epoch 1: 41.08
best model! save...
Epoch 2 | Batch 0/100 | Loss 1.585633
InnerLR 0.984709
FineTuningLR 0.016291
Epoch 2 | Batch 10/100 | Loss 1.758537
InnerLR 0.984078
FineTuningLR 0.016922
Epoch 2 | Batch 20/100 | Loss 1.725581
InnerLR 0.983137
FineTuningLR 0.017863
Epoch 2 | Batch 30/100 | Loss 1.716758
InnerLR 0.982494
FineTuningLR 0.018506
Epoch 2 | Batch 40/100 | Loss 1.755765
InnerLR 0.981525
FineTuningLR 0.019475
Epoch 2 | Batch 50/100 | Loss 1.764332
InnerLR 0.980885
FineTuningLR 0.020115
Epoch 2 | Batch 60/100 | Loss 1.763852
InnerLR 0.979922
FineTuningLR 0.021078
Epoch 2 | Batch 70/100 | Loss 1.753848
InnerLR 0.979277
FineTuningLR 0.021723
Epoch 2 | Batch 80/100 | Loss 1.743348
InnerLR 0.978302
FineTuningLR 0.022698
Epoch 2 | Batch 90/100 | Loss 1.745476
InnerLR 0.977654
FineTuningLR 0.023346
100 Accuracy = 41.07% +- 1.66%
Epoch 2: 41.07
Epoch 3 | Batch 0/100 | Loss 1.599765
InnerLR 0.976678
FineTuningLR 0.024322
Epoch 3 | Batch 10/100 | Loss 1.673792
InnerLR 0.976029
FineTuningLR 0.024971
Epoch 3 | Batch 20/100 | Loss 1.702599
InnerLR 0.975048
FineTuningLR 0.025952
Epoch 3 | Batch 30/100 | Loss 1.679506
InnerLR 0.974394
FineTuningLR 0.026606
Epoch 3 | Batch 40/100 | Loss 1.669496
InnerLR 0.973418
FineTuningLR 0.027582
Epoch 3 | Batch 50/100 | Loss 1.646758
InnerLR 0.972766
FineTuningLR 0.028235
Epoch 3 | Batch 60/100 | Loss 1.642342
InnerLR 0.971778
FineTuningLR 0.029222
Epoch 3 | Batch 70/100 | Loss 1.647145
InnerLR 0.971120
FineTuningLR 0.029880
Epoch 3 | Batch 80/100 | Loss 1.645474
InnerLR 0.970121
FineTuningLR 0.030879
Epoch 3 | Batch 90/100 | Loss 1.643615
InnerLR 0.969452
FineTuningLR 0.031548
100 Accuracy = 43.11% +- 1.62%
Epoch 3: 43.11
best model! save...
Epoch 4 | Batch 0/100 | Loss 1.581216
InnerLR 0.968461
FineTuningLR 0.032539
Epoch 4 | Batch 10/100 | Loss 1.681706
InnerLR 0.967802
FineTuningLR 0.033198
Epoch 4 | Batch 20/100 | Loss 1.651035
InnerLR 0.966804
FineTuningLR 0.034196
Epoch 4 | Batch 30/100 | Loss 1.663292
InnerLR 0.966137
FineTuningLR 0.034863
Epoch 4 | Batch 40/100 | Loss 1.643055
InnerLR 0.965144
FineTuningLR 0.035856
Epoch 4 | Batch 50/100 | Loss 1.622257
InnerLR 0.964485
FineTuningLR 0.036516
Epoch 4 | Batch 60/100 | Loss 1.627552
InnerLR 0.963494
FineTuningLR 0.037506
Epoch 4 | Batch 70/100 | Loss 1.619381
InnerLR 0.962830
FineTuningLR 0.038170
Epoch 4 | Batch 80/100 | Loss 1.612767
InnerLR 0.961821
FineTuningLR 0.039179
Epoch 4 | Batch 90/100 | Loss 1.606651
InnerLR 0.961148
FineTuningLR 0.039852
100 Accuracy = 42.41% +- 1.80%
Epoch 4: 42.41
Epoch 5 | Batch 0/100 | Loss 1.365990
InnerLR 0.960139
FineTuningLR 0.040861
Epoch 5 | Batch 10/100 | Loss 1.563273
InnerLR 0.959461
FineTuningLR 0.041539
Epoch 5 | Batch 20/100 | Loss 1.609526
InnerLR 0.958458
FineTuningLR 0.042542
Epoch 5 | Batch 30/100 | Loss 1.591542
InnerLR 0.957796
FineTuningLR 0.043205
Epoch 5 | Batch 40/100 | Loss 1.624237
InnerLR 0.956807
FineTuningLR 0.044193
Epoch 5 | Batch 50/100 | Loss 1.622165
InnerLR 0.956153
FineTuningLR 0.044847
Epoch 5 | Batch 60/100 | Loss 1.611281
InnerLR 0.955167
FineTuningLR 0.045833
Epoch 5 | Batch 70/100 | Loss 1.596924
InnerLR 0.954500
FineTuningLR 0.046500
Epoch 5 | Batch 80/100 | Loss 1.595853
InnerLR 0.953498
FineTuningLR 0.047502
Epoch 5 | Batch 90/100 | Loss 1.584872
InnerLR 0.952832
FineTuningLR 0.048168
100 Accuracy = 44.19% +- 1.69%
Epoch 5: 44.19
best model! save...
Epoch 6 | Batch 0/100 | Loss 1.611068
InnerLR 0.951848
FineTuningLR 0.049152
Epoch 6 | Batch 10/100 | Loss 1.568342
InnerLR 0.951184
FineTuningLR 0.049816
Epoch 6 | Batch 20/100 | Loss 1.592653
InnerLR 0.950197
FineTuningLR 0.050803
Epoch 6 | Batch 30/100 | Loss 1.620876
InnerLR 0.949531
FineTuningLR 0.051469
Epoch 6 | Batch 40/100 | Loss 1.584962
InnerLR 0.948535
FineTuningLR 0.052465
Epoch 6 | Batch 50/100 | Loss 1.580502
InnerLR 0.947861
FineTuningLR 0.053139
Epoch 6 | Batch 60/100 | Loss 1.577121
InnerLR 0.946841
FineTuningLR 0.054159
Epoch 6 | Batch 70/100 | Loss 1.587498
InnerLR 0.946156
FineTuningLR 0.054845
Epoch 6 | Batch 80/100 | Loss 1.574679
InnerLR 0.945119
FineTuningLR 0.055881
Epoch 6 | Batch 90/100 | Loss 1.573115
InnerLR 0.944424
FineTuningLR 0.056576
100 Accuracy = 45.64% +- 1.77%
Epoch 6: 45.64
best model! save...
Epoch 7 | Batch 0/100 | Loss 1.293366
InnerLR 0.943376
FineTuningLR 0.057625
Epoch 7 | Batch 10/100 | Loss 1.593941
InnerLR 0.942684
FineTuningLR 0.058316
Epoch 7 | Batch 20/100 | Loss 1.544053
InnerLR 0.941652
FineTuningLR 0.059349
Epoch 7 | Batch 30/100 | Loss 1.537409
InnerLR 0.940958
FineTuningLR 0.060042
Epoch 7 | Batch 40/100 | Loss 1.508432
InnerLR 0.939919
FineTuningLR 0.061081
Epoch 7 | Batch 50/100 | Loss 1.491200
InnerLR 0.939221
FineTuningLR 0.061779
Epoch 7 | Batch 60/100 | Loss 1.503246
InnerLR 0.938169
FineTuningLR 0.062831
Epoch 7 | Batch 70/100 | Loss 1.503854
InnerLR 0.937474
FineTuningLR 0.063527
Epoch 7 | Batch 80/100 | Loss 1.509887
InnerLR 0.936420
FineTuningLR 0.064580
Epoch 7 | Batch 90/100 | Loss 1.512201
InnerLR 0.935712
FineTuningLR 0.065288
100 Accuracy = 46.40% +- 1.88%
Epoch 7: 46.40
best model! save...
Epoch 8 | Batch 0/100 | Loss 1.477849
InnerLR 0.934674
FineTuningLR 0.066327
Epoch 8 | Batch 10/100 | Loss 1.442135
InnerLR 0.933983
FineTuningLR 0.067017
Epoch 8 | Batch 20/100 | Loss 1.490793
InnerLR 0.932947
FineTuningLR 0.068053
Epoch 8 | Batch 30/100 | Loss 1.475183
InnerLR 0.932257
FineTuningLR 0.068743
Epoch 8 | Batch 40/100 | Loss 1.510179
InnerLR 0.931242
FineTuningLR 0.069759
Epoch 8 | Batch 50/100 | Loss 1.503966
InnerLR 0.930579
FineTuningLR 0.070421
Epoch 8 | Batch 60/100 | Loss 1.496714
InnerLR 0.929583
FineTuningLR 0.071417
Epoch 8 | Batch 70/100 | Loss 1.506601
InnerLR 0.928924
FineTuningLR 0.072076
Epoch 8 | Batch 80/100 | Loss 1.516280
InnerLR 0.927929
FineTuningLR 0.073071
Epoch 8 | Batch 90/100 | Loss 1.521139
InnerLR 0.927257
FineTuningLR 0.073743
100 Accuracy = 46.64% +- 2.04%
Epoch 8: 46.64
best model! save...
Epoch 9 | Batch 0/100 | Loss 1.473417
InnerLR 0.926241
FineTuningLR 0.074760
Epoch 9 | Batch 10/100 | Loss 1.489536
InnerLR 0.925554
FineTuningLR 0.075446
Epoch 9 | Batch 20/100 | Loss 1.472051
InnerLR 0.924528
FineTuningLR 0.076473
Epoch 9 | Batch 30/100 | Loss 1.454362
InnerLR 0.923843
FineTuningLR 0.077157
Epoch 9 | Batch 40/100 | Loss 1.481816
InnerLR 0.922825
FineTuningLR 0.078176
Epoch 9 | Batch 50/100 | Loss 1.468931
InnerLR 0.922149
FineTuningLR 0.078851
Epoch 9 | Batch 60/100 | Loss 1.466952
InnerLR 0.921142
FineTuningLR 0.079858
Epoch 9 | Batch 70/100 | Loss 1.469504
InnerLR 0.920469
FineTuningLR 0.080532
Epoch 9 | Batch 80/100 | Loss 1.466650
InnerLR 0.919448
FineTuningLR 0.081552
Epoch 9 | Batch 90/100 | Loss 1.464419
InnerLR 0.918753
FineTuningLR 0.082247
100 Accuracy = 48.76% +- 1.83%
Epoch 9: 48.76
best model! save...
Epoch 10 | Batch 0/100 | Loss 1.450068
InnerLR 0.917701
FineTuningLR 0.083299
Epoch 10 | Batch 10/100 | Loss 1.433481
InnerLR 0.916996
FineTuningLR 0.084004
Epoch 10 | Batch 20/100 | Loss 1.413615
InnerLR 0.915938
FineTuningLR 0.085062
Epoch 10 | Batch 30/100 | Loss 1.453612
InnerLR 0.915241
FineTuningLR 0.085759
Epoch 10 | Batch 40/100 | Loss 1.471920
InnerLR 0.914179
FineTuningLR 0.086822
Epoch 10 | Batch 50/100 | Loss 1.463897
InnerLR 0.913463
FineTuningLR 0.087537
Epoch 10 | Batch 60/100 | Loss 1.456596
InnerLR 0.912390
FineTuningLR 0.088610
Epoch 10 | Batch 70/100 | Loss 1.446484
InnerLR 0.911687
FineTuningLR 0.089313
Epoch 10 | Batch 80/100 | Loss 1.445633
InnerLR 0.910631
FineTuningLR 0.090370
Epoch 10 | Batch 90/100 | Loss 1.439695
InnerLR 0.909927
FineTuningLR 0.091073
100 Accuracy = 50.52% +- 1.85%
Epoch 10: 50.52
best model! save...
Epoch 11 | Batch 0/100 | Loss 1.555802
InnerLR 0.908877
FineTuningLR 0.092124
Epoch 11 | Batch 10/100 | Loss 1.462132
InnerLR 0.908180
FineTuningLR 0.092820
Epoch 11 | Batch 20/100 | Loss 1.370836
InnerLR 0.907154
FineTuningLR 0.093847
Epoch 11 | Batch 30/100 | Loss 1.370436
InnerLR 0.906466
FineTuningLR 0.094535
Epoch 11 | Batch 40/100 | Loss 1.383520
InnerLR 0.905450
FineTuningLR 0.095550
Epoch 11 | Batch 50/100 | Loss 1.399285
InnerLR 0.904787
FineTuningLR 0.096213
Epoch 11 | Batch 60/100 | Loss 1.408604
InnerLR 0.903751
FineTuningLR 0.097250
Epoch 11 | Batch 70/100 | Loss 1.396138
InnerLR 0.903055
FineTuningLR 0.097945
Epoch 11 | Batch 80/100 | Loss 1.395095
InnerLR 0.902005
FineTuningLR 0.098995
Epoch 11 | Batch 90/100 | Loss 1.388066
InnerLR 0.901327
FineTuningLR 0.099673
100 Accuracy = 49.68% +- 1.96%
Epoch 11: 49.68
Epoch 12 | Batch 0/100 | Loss 1.110430
InnerLR 0.900316
FineTuningLR 0.100684
Epoch 12 | Batch 10/100 | Loss 1.341975
InnerLR 0.899636
FineTuningLR 0.101364
Epoch 12 | Batch 20/100 | Loss 1.443558
InnerLR 0.898627
FineTuningLR 0.102374
Epoch 12 | Batch 30/100 | Loss 1.408272
InnerLR 0.897948
FineTuningLR 0.103052
Epoch 12 | Batch 40/100 | Loss 1.417078
InnerLR 0.896912
FineTuningLR 0.104089
Epoch 12 | Batch 50/100 | Loss 1.406193
InnerLR 0.896220
FineTuningLR 0.104781
Epoch 12 | Batch 60/100 | Loss 1.417594
InnerLR 0.895247
FineTuningLR 0.105753
Epoch 12 | Batch 70/100 | Loss 1.417270
InnerLR 0.894594
FineTuningLR 0.106406
Epoch 12 | Batch 80/100 | Loss 1.417257
InnerLR 0.893633
FineTuningLR 0.107367
Epoch 12 | Batch 90/100 | Loss 1.412014
InnerLR 0.893007
FineTuningLR 0.107993
100 Accuracy = 50.33% +- 1.87%
Epoch 12: 50.33
Epoch 13 | Batch 0/100 | Loss 1.856387
InnerLR 0.892074
FineTuningLR 0.108927
Epoch 13 | Batch 10/100 | Loss 1.418200
InnerLR 0.891436
FineTuningLR 0.109565
Epoch 13 | Batch 20/100 | Loss 1.424052
InnerLR 0.890451
FineTuningLR 0.110549
Epoch 13 | Batch 30/100 | Loss 1.373692
InnerLR 0.889792
FineTuningLR 0.111209
Epoch 13 | Batch 40/100 | Loss 1.360371
InnerLR 0.888780
FineTuningLR 0.112220
Epoch 13 | Batch 50/100 | Loss 1.347027
InnerLR 0.888096
FineTuningLR 0.112905
Epoch 13 | Batch 60/100 | Loss 1.339501
InnerLR 0.887056
FineTuningLR 0.113944
Epoch 13 | Batch 70/100 | Loss 1.355639
InnerLR 0.886357
FineTuningLR 0.114643
Epoch 13 | Batch 80/100 | Loss 1.338035
InnerLR 0.885311
FineTuningLR 0.115690
Epoch 13 | Batch 90/100 | Loss 1.344809
InnerLR 0.884613
FineTuningLR 0.116388
100 Accuracy = 49.32% +- 1.70%
Epoch 13: 49.32
Epoch 14 | Batch 0/100 | Loss 1.419470
InnerLR 0.883574
FineTuningLR 0.117426
Epoch 14 | Batch 10/100 | Loss 1.468658
InnerLR 0.882881
FineTuningLR 0.118120
Epoch 14 | Batch 20/100 | Loss 1.449825
InnerLR 0.881850
FineTuningLR 0.119151
Epoch 14 | Batch 30/100 | Loss 1.422347
InnerLR 0.881161
FineTuningLR 0.119840
Epoch 14 | Batch 40/100 | Loss 1.410861
InnerLR 0.880137
FineTuningLR 0.120863
Epoch 14 | Batch 50/100 | Loss 1.408215
InnerLR 0.879462
FineTuningLR 0.121538
Epoch 14 | Batch 60/100 | Loss 1.408594
InnerLR 0.878459
FineTuningLR 0.122542
Epoch 14 | Batch 70/100 | Loss 1.400025
InnerLR 0.877787
FineTuningLR 0.123213
Epoch 14 | Batch 80/100 | Loss 1.402973
InnerLR 0.876780
FineTuningLR 0.124221
Epoch 14 | Batch 90/100 | Loss 1.398509
InnerLR 0.876110
FineTuningLR 0.124890
100 Accuracy = 51.93% +- 1.75%
Epoch 14: 51.93
best model! save...
Epoch 15 | Batch 0/100 | Loss 1.546361
InnerLR 0.875085
FineTuningLR 0.125915
Epoch 15 | Batch 10/100 | Loss 1.419363
InnerLR 0.874402
FineTuningLR 0.126598
Epoch 15 | Batch 20/100 | Loss 1.385636
InnerLR 0.873383
FineTuningLR 0.127618
Epoch 15 | Batch 30/100 | Loss 1.351314
InnerLR 0.872696
FineTuningLR 0.128305
Epoch 15 | Batch 40/100 | Loss 1.348553
InnerLR 0.871657
FineTuningLR 0.129343
Epoch 15 | Batch 50/100 | Loss 1.348433
InnerLR 0.870956
FineTuningLR 0.130044
Epoch 15 | Batch 60/100 | Loss 1.342868
InnerLR 0.869880
FineTuningLR 0.131121
Epoch 15 | Batch 70/100 | Loss 1.330761
InnerLR 0.869169
FineTuningLR 0.131831
Epoch 15 | Batch 80/100 | Loss 1.332654
InnerLR 0.868111
FineTuningLR 0.132889
Epoch 15 | Batch 90/100 | Loss 1.325843
InnerLR 0.867417
FineTuningLR 0.133584
100 Accuracy = 53.09% +- 1.99%
Epoch 15: 53.09
best model! save...
Epoch 16 | Batch 0/100 | Loss 1.286541
InnerLR 0.866364
FineTuningLR 0.134636
Epoch 16 | Batch 10/100 | Loss 1.371638
InnerLR 0.865685
FineTuningLR 0.135315
Epoch 16 | Batch 20/100 | Loss 1.333316
InnerLR 0.864682
FineTuningLR 0.136318
Epoch 16 | Batch 30/100 | Loss 1.368229
InnerLR 0.864002
FineTuningLR 0.136998
Epoch 16 | Batch 40/100 | Loss 1.348944
InnerLR 0.862961
FineTuningLR 0.138039
Epoch 16 | Batch 50/100 | Loss 1.359154
InnerLR 0.862267
FineTuningLR 0.138734
Epoch 16 | Batch 60/100 | Loss 1.353060
InnerLR 0.861266
FineTuningLR 0.139734
Epoch 16 | Batch 70/100 | Loss 1.358758
InnerLR 0.860581
FineTuningLR 0.140419
Epoch 16 | Batch 80/100 | Loss 1.342263
InnerLR 0.859553
FineTuningLR 0.141448
Epoch 16 | Batch 90/100 | Loss 1.344683
InnerLR 0.858863
FineTuningLR 0.142137
100 Accuracy = 52.85% +- 1.74%
Epoch 16: 52.85
Epoch 17 | Batch 0/100 | Loss 1.232035
InnerLR 0.857826
FineTuningLR 0.143174
Epoch 17 | Batch 10/100 | Loss 1.358773
InnerLR 0.857133
FineTuningLR 0.143868
Epoch 17 | Batch 20/100 | Loss 1.343940
InnerLR 0.856070
FineTuningLR 0.144930
Epoch 17 | Batch 30/100 | Loss 1.391448
InnerLR 0.855351
FineTuningLR 0.145649
Epoch 17 | Batch 40/100 | Loss 1.359778
InnerLR 0.854253
FineTuningLR 0.146747
Epoch 17 | Batch 50/100 | Loss 1.354107
InnerLR 0.853536
FineTuningLR 0.147465
Epoch 17 | Batch 60/100 | Loss 1.354281
InnerLR 0.852459
FineTuningLR 0.148541
Epoch 17 | Batch 70/100 | Loss 1.346316
InnerLR 0.851739
FineTuningLR 0.149261
Epoch 17 | Batch 80/100 | Loss 1.335101
InnerLR 0.850689
FineTuningLR 0.150311
Epoch 17 | Batch 90/100 | Loss 1.322790
InnerLR 0.849979
FineTuningLR 0.151021
100 Accuracy = 54.21% +- 1.98%
Epoch 17: 54.21
best model! save...
Epoch 18 | Batch 0/100 | Loss 1.116991
InnerLR 0.848906
FineTuningLR 0.152094
Epoch 18 | Batch 10/100 | Loss 1.341291
InnerLR 0.848191
FineTuningLR 0.152810
Epoch 18 | Batch 20/100 | Loss 1.331675
InnerLR 0.847139
FineTuningLR 0.153861
Epoch 18 | Batch 30/100 | Loss 1.321696
InnerLR 0.846452
FineTuningLR 0.154548
Epoch 18 | Batch 40/100 | Loss 1.303292
InnerLR 0.845433
FineTuningLR 0.155568
Epoch 18 | Batch 50/100 | Loss 1.298705
InnerLR 0.844753
FineTuningLR 0.156248
Epoch 18 | Batch 60/100 | Loss 1.294054
InnerLR 0.843718
FineTuningLR 0.157282
Epoch 18 | Batch 70/100 | Loss 1.307568
InnerLR 0.843027
FineTuningLR 0.157973
Epoch 18 | Batch 80/100 | Loss 1.310029
InnerLR 0.842004
FineTuningLR 0.158996
Epoch 18 | Batch 90/100 | Loss 1.319995
InnerLR 0.841332
FineTuningLR 0.159669
100 Accuracy = 53.57% +- 1.84%
Epoch 18: 53.57
Epoch 19 | Batch 0/100 | Loss 1.145134
InnerLR 0.840301
FineTuningLR 0.160699
Epoch 19 | Batch 10/100 | Loss 1.317605
InnerLR 0.839626
FineTuningLR 0.161375
Epoch 19 | Batch 20/100 | Loss 1.328510
InnerLR 0.838595
FineTuningLR 0.162406
Epoch 19 | Batch 30/100 | Loss 1.314933
InnerLR 0.837907
FineTuningLR 0.163093
Epoch 19 | Batch 40/100 | Loss 1.284581
InnerLR 0.836867
FineTuningLR 0.164134
Epoch 19 | Batch 50/100 | Loss 1.278235
InnerLR 0.836154
FineTuningLR 0.164846
Epoch 19 | Batch 60/100 | Loss 1.270612
InnerLR 0.835070
FineTuningLR 0.165930
Epoch 19 | Batch 70/100 | Loss 1.271329
InnerLR 0.834334
FineTuningLR 0.166667
Epoch 19 | Batch 80/100 | Loss 1.262797
InnerLR 0.833241
FineTuningLR 0.167759
Epoch 19 | Batch 90/100 | Loss 1.269681
InnerLR 0.832532
FineTuningLR 0.168468
100 Accuracy = 54.93% +- 2.00%
Epoch 19: 54.93
best model! save...
Epoch 20 | Batch 0/100 | Loss 1.236013
InnerLR 0.831470
FineTuningLR 0.169530
Epoch 20 | Batch 10/100 | Loss 1.264856
InnerLR 0.830777
FineTuningLR 0.170223
Epoch 20 | Batch 20/100 | Loss 1.310494
InnerLR 0.829729
FineTuningLR 0.171271
Epoch 20 | Batch 30/100 | Loss 1.317412
InnerLR 0.829038
FineTuningLR 0.171962
Epoch 20 | Batch 40/100 | Loss 1.299728
InnerLR 0.828011
FineTuningLR 0.172989
Epoch 20 | Batch 50/100 | Loss 1.285748
InnerLR 0.827328
FineTuningLR 0.173672
Epoch 20 | Batch 60/100 | Loss 1.279180
InnerLR 0.826319
FineTuningLR 0.174682
Epoch 20 | Batch 70/100 | Loss 1.269296
InnerLR 0.825647
FineTuningLR 0.175354
Epoch 20 | Batch 80/100 | Loss 1.261578
InnerLR 0.824627
FineTuningLR 0.176373
Epoch 20 | Batch 90/100 | Loss 1.254593
InnerLR 0.823941
FineTuningLR 0.177059
100 Accuracy = 53.32% +- 1.83%
Epoch 20: 53.32
Epoch 21 | Batch 0/100 | Loss 1.099254
InnerLR 0.822918
FineTuningLR 0.178083
Epoch 21 | Batch 10/100 | Loss 1.273555
InnerLR 0.822242
FineTuningLR 0.178758
Epoch 21 | Batch 20/100 | Loss 1.248031
InnerLR 0.821221
FineTuningLR 0.179780
Epoch 21 | Batch 30/100 | Loss 1.250591
InnerLR 0.820532
FineTuningLR 0.180468
Epoch 21 | Batch 40/100 | Loss 1.250929
InnerLR 0.819459
FineTuningLR 0.181541
Epoch 21 | Batch 50/100 | Loss 1.232752
InnerLR 0.818730
FineTuningLR 0.182271
Epoch 21 | Batch 60/100 | Loss 1.240213
InnerLR 0.817648
FineTuningLR 0.183352
Epoch 21 | Batch 70/100 | Loss 1.236335
InnerLR 0.816932
FineTuningLR 0.184069
Epoch 21 | Batch 80/100 | Loss 1.232084
InnerLR 0.815856
FineTuningLR 0.185144
Epoch 21 | Batch 90/100 | Loss 1.231444
InnerLR 0.815128
FineTuningLR 0.185872
100 Accuracy = 53.92% +- 2.39%
Epoch 21: 53.92
Epoch 22 | Batch 0/100 | Loss 1.005242
InnerLR 0.814051
FineTuningLR 0.186950
Epoch 22 | Batch 10/100 | Loss 1.156262
InnerLR 0.813324
FineTuningLR 0.187676
Epoch 22 | Batch 20/100 | Loss 1.196037
InnerLR 0.812234
FineTuningLR 0.188767
Epoch 22 | Batch 30/100 | Loss 1.214161
InnerLR 0.811500
FineTuningLR 0.189501
Epoch 22 | Batch 40/100 | Loss 1.225903
InnerLR 0.810424
FineTuningLR 0.190576
Epoch 22 | Batch 50/100 | Loss 1.238432
InnerLR 0.809718
FineTuningLR 0.191283
Epoch 22 | Batch 60/100 | Loss 1.241781
InnerLR 0.808639
FineTuningLR 0.192361
Epoch 22 | Batch 70/100 | Loss 1.243031
InnerLR 0.807916
FineTuningLR 0.193085
Epoch 22 | Batch 80/100 | Loss 1.238367
InnerLR 0.806826
FineTuningLR 0.194174
Epoch 22 | Batch 90/100 | Loss 1.247747
InnerLR 0.806098
FineTuningLR 0.194902
100 Accuracy = 55.53% +- 1.68%
Epoch 22: 55.53
best model! save...
Epoch 23 | Batch 0/100 | Loss 1.361586
InnerLR 0.805008
FineTuningLR 0.195992
Epoch 23 | Batch 10/100 | Loss 1.319067
InnerLR 0.804284
FineTuningLR 0.196716
Epoch 23 | Batch 20/100 | Loss 1.255630
InnerLR 0.803216
FineTuningLR 0.197785
Epoch 23 | Batch 30/100 | Loss 1.236744
InnerLR 0.802526
FineTuningLR 0.198474
Epoch 23 | Batch 40/100 | Loss 1.234239
InnerLR 0.801475
FineTuningLR 0.199525
Epoch 23 | Batch 50/100 | Loss 1.229674
InnerLR 0.800758
FineTuningLR 0.200243
Epoch 23 | Batch 60/100 | Loss 1.244465
InnerLR 0.799656
FineTuningLR 0.201345
Epoch 23 | Batch 70/100 | Loss 1.240313
InnerLR 0.798941
FineTuningLR 0.202060
Epoch 23 | Batch 80/100 | Loss 1.233717
InnerLR 0.797863
FineTuningLR 0.203147
Epoch 23 | Batch 90/100 | Loss 1.228031
InnerLR 0.797162
FineTuningLR 0.203862
100 Accuracy = 56.19% +- 2.03%
Epoch 23: 56.19
best model! save...
Epoch 24 | Batch 0/100 | Loss 1.204897
InnerLR 0.796097
FineTuningLR 0.204944
Epoch 24 | Batch 10/100 | Loss 1.235061
InnerLR 0.795393
FineTuningLR 0.205657
Epoch 24 | Batch 20/100 | Loss 1.235439
InnerLR 0.794370
FineTuningLR 0.206690
Epoch 24 | Batch 30/100 | Loss 1.263490
InnerLR 0.793720
FineTuningLR 0.207356
Epoch 24 | Batch 40/100 | Loss 1.260650
InnerLR 0.792760
FineTuningLR 0.208348
Epoch 24 | Batch 50/100 | Loss 1.247145
InnerLR 0.792127
FineTuningLR 0.209013
Epoch 24 | Batch 60/100 | Loss 1.226882
InnerLR 0.791181
FineTuningLR 0.209997
Epoch 24 | Batch 70/100 | Loss 1.219969
InnerLR 0.790536
FineTuningLR 0.210660
Epoch 24 | Batch 80/100 | Loss 1.211647
InnerLR 0.789536
FineTuningLR 0.211682
Epoch 24 | Batch 90/100 | Loss 1.205364
InnerLR 0.788852
FineTuningLR 0.212376
100 Accuracy = 55.69% +- 2.05%
Epoch 24: 55.69
Epoch 25 | Batch 0/100 | Loss 1.199014
InnerLR 0.787804
FineTuningLR 0.213435
Epoch 25 | Batch 10/100 | Loss 1.287873
InnerLR 0.787106
FineTuningLR 0.214139
Epoch 25 | Batch 20/100 | Loss 1.253476
InnerLR 0.786078
FineTuningLR 0.215173
Epoch 25 | Batch 30/100 | Loss 1.221359
InnerLR 0.785387
FineTuningLR 0.215866
Epoch 25 | Batch 40/100 | Loss 1.226503
InnerLR 0.784353
FineTuningLR 0.216903
Epoch 25 | Batch 50/100 | Loss 1.201171
InnerLR 0.783664
FineTuningLR 0.217594
Epoch 25 | Batch 60/100 | Loss 1.213348
InnerLR 0.782611
FineTuningLR 0.218647
Epoch 25 | Batch 70/100 | Loss 1.199108
InnerLR 0.781891
FineTuningLR 0.219368
Epoch 25 | Batch 80/100 | Loss 1.196789
InnerLR 0.780808
FineTuningLR 0.220450
Epoch 25 | Batch 90/100 | Loss 1.195955
InnerLR 0.780084
FineTuningLR 0.221175
100 Accuracy = 57.35% +- 1.83%
Epoch 25: 57.35
best model! save...
Epoch 26 | Batch 0/100 | Loss 1.519344
InnerLR 0.779006
FineTuningLR 0.222251
Epoch 26 | Batch 10/100 | Loss 1.217937
InnerLR 0.778289
FineTuningLR 0.222968
Epoch 26 | Batch 20/100 | Loss 1.188947
InnerLR 0.777222
FineTuningLR 0.224034
Epoch 26 | Batch 30/100 | Loss 1.188816
InnerLR 0.776513
FineTuningLR 0.224742
Epoch 26 | Batch 40/100 | Loss 1.203779
InnerLR 0.775458
FineTuningLR 0.225796
Epoch 26 | Batch 50/100 | Loss 1.198116
InnerLR 0.774751
FineTuningLR 0.226501
Epoch 26 | Batch 60/100 | Loss 1.203588
InnerLR 0.773688
FineTuningLR 0.227563
Epoch 26 | Batch 70/100 | Loss 1.191059
InnerLR 0.772982
FineTuningLR 0.228268
Epoch 26 | Batch 80/100 | Loss 1.193784
InnerLR 0.771911
FineTuningLR 0.229337
Epoch 26 | Batch 90/100 | Loss 1.193297
InnerLR 0.771197
FineTuningLR 0.230050
100 Accuracy = 57.23% +- 1.90%
Epoch 26: 57.23
Epoch 27 | Batch 0/100 | Loss 0.980000
InnerLR 0.770116
FineTuningLR 0.231129
Epoch 27 | Batch 10/100 | Loss 1.119617
InnerLR 0.769382
FineTuningLR 0.231862
Epoch 27 | Batch 20/100 | Loss 1.178314
InnerLR 0.768259
FineTuningLR 0.232983
Epoch 27 | Batch 30/100 | Loss 1.173661
InnerLR 0.767503
FineTuningLR 0.233738
Epoch 27 | Batch 40/100 | Loss 1.149227
InnerLR 0.766468
FineTuningLR 0.234856
Epoch 27 | Batch 50/100 | Loss 1.164938
InnerLR 0.765859
FineTuningLR 0.235564
Epoch 27 | Batch 60/100 | Loss 1.165168
InnerLR 0.764949
FineTuningLR 0.236590
Epoch 27 | Batch 70/100 | Loss 1.155423
InnerLR 0.764325
FineTuningLR 0.237271
Epoch 27 | Batch 80/100 | Loss 1.158420
InnerLR 0.763355
FineTuningLR 0.238307
Epoch 27 | Batch 90/100 | Loss 1.158754
InnerLR 0.762697
FineTuningLR 0.238998
100 Accuracy = 58.17% +- 1.98%
Epoch 27: 58.17
best model! save...
Epoch 28 | Batch 0/100 | Loss 1.199240
InnerLR 0.761689
FineTuningLR 0.240043
Epoch 28 | Batch 10/100 | Loss 1.132265
InnerLR 0.760994
FineTuningLR 0.240757
Epoch 28 | Batch 20/100 | Loss 1.109560
InnerLR 0.759964
FineTuningLR 0.241866
Epoch 28 | Batch 30/100 | Loss 1.124834
InnerLR 0.759271
FineTuningLR 0.242599
Epoch 28 | Batch 40/100 | Loss 1.138656
InnerLR 0.758234
FineTuningLR 0.243681
Epoch 28 | Batch 50/100 | Loss 1.136734
InnerLR 0.757531
FineTuningLR 0.244406
Epoch 28 | Batch 60/100 | Loss 1.160470
InnerLR 0.756488
FineTuningLR 0.245473
Epoch 28 | Batch 70/100 | Loss 1.154826
InnerLR 0.755800
FineTuningLR 0.246173
Epoch 28 | Batch 80/100 | Loss 1.162683
InnerLR 0.754752
FineTuningLR 0.247232
Epoch 28 | Batch 90/100 | Loss 1.164053
InnerLR 0.754056
FineTuningLR 0.247934
100 Accuracy = 59.45% +- 1.84%
Epoch 28: 59.45
best model! save...
Epoch 29 | Batch 0/100 | Loss 0.949000
InnerLR 0.753007
FineTuningLR 0.248988
Epoch 29 | Batch 10/100 | Loss 1.088968
InnerLR 0.752292
FineTuningLR 0.249705
Epoch 29 | Batch 20/100 | Loss 1.159829
InnerLR 0.751216
FineTuningLR 0.250781
Epoch 29 | Batch 30/100 | Loss 1.169176
InnerLR 0.750528
FineTuningLR 0.251469
Epoch 29 | Batch 40/100 | Loss 1.157980
InnerLR 0.749503
FineTuningLR 0.252492
Epoch 29 | Batch 50/100 | Loss 1.158823
InnerLR 0.748804
FineTuningLR 0.253189
Epoch 29 | Batch 60/100 | Loss 1.155891
InnerLR 0.747719
FineTuningLR 0.254272
Epoch 29 | Batch 70/100 | Loss 1.149856
InnerLR 0.746985
FineTuningLR 0.255004
Epoch 29 | Batch 80/100 | Loss 1.146570
InnerLR 0.745932
FineTuningLR 0.256116
Epoch 29 | Batch 90/100 | Loss 1.149021
InnerLR 0.745213
FineTuningLR 0.256864
100 Accuracy = 59.40% +- 1.83%
Epoch 29: 59.40
Epoch 30 | Batch 0/100 | Loss 1.291345
InnerLR 0.744119
FineTuningLR 0.257991
Epoch 30 | Batch 10/100 | Loss 1.227334
InnerLR 0.743375
FineTuningLR 0.258750
Epoch 30 | Batch 20/100 | Loss 1.208497
InnerLR 0.742250
FineTuningLR 0.259892
Epoch 30 | Batch 30/100 | Loss 1.197517
InnerLR 0.741492
FineTuningLR 0.260657
Epoch 30 | Batch 40/100 | Loss 1.217044
InnerLR 0.740378
FineTuningLR 0.261778
Epoch 30 | Batch 50/100 | Loss 1.206218
InnerLR 0.739640
FineTuningLR 0.262519
Epoch 30 | Batch 60/100 | Loss 1.181387
InnerLR 0.738523
FineTuningLR 0.263637
Epoch 30 | Batch 70/100 | Loss 1.180085
InnerLR 0.737797
FineTuningLR 0.264364
Epoch 30 | Batch 80/100 | Loss 1.188019
InnerLR 0.736690
FineTuningLR 0.265469
Epoch 30 | Batch 90/100 | Loss 1.174363
InnerLR 0.735961
FineTuningLR 0.266196
100 Accuracy = 59.31% +- 1.98%
Epoch 30: 59.31
Epoch 31 | Batch 0/100 | Loss 1.282062
InnerLR 0.734873
FineTuningLR 0.267281
Epoch 31 | Batch 10/100 | Loss 1.253071
InnerLR 0.734144
FineTuningLR 0.268008
Epoch 31 | Batch 20/100 | Loss 1.219421
InnerLR 0.733022
FineTuningLR 0.269126
Epoch 31 | Batch 30/100 | Loss 1.206470
InnerLR 0.732272
FineTuningLR 0.269872
Epoch 31 | Batch 40/100 | Loss 1.190970
InnerLR 0.731135
FineTuningLR 0.271005
Epoch 31 | Batch 50/100 | Loss 1.162142
InnerLR 0.730374
FineTuningLR 0.271763
Epoch 31 | Batch 60/100 | Loss 1.152401
InnerLR 0.729250
FineTuningLR 0.272896
Epoch 31 | Batch 70/100 | Loss 1.178274
InnerLR 0.728504
FineTuningLR 0.273646
Epoch 31 | Batch 80/100 | Loss 1.172345
InnerLR 0.727391
FineTuningLR 0.274762
Epoch 31 | Batch 90/100 | Loss 1.174351
InnerLR 0.726709
FineTuningLR 0.275504
100 Accuracy = 58.40% +- 1.85%
Epoch 31: 58.40
Epoch 32 | Batch 0/100 | Loss 1.043847
InnerLR 0.725743
FineTuningLR 0.276612
Epoch 32 | Batch 10/100 | Loss 1.143634
InnerLR 0.725095
FineTuningLR 0.277331
Epoch 32 | Batch 20/100 | Loss 1.163594
InnerLR 0.724104
FineTuningLR 0.278403
Epoch 32 | Batch 30/100 | Loss 1.184685
InnerLR 0.723454
FineTuningLR 0.279094
Epoch 32 | Batch 40/100 | Loss 1.189629
InnerLR 0.722450
FineTuningLR 0.280143
Epoch 32 | Batch 50/100 | Loss 1.184188
InnerLR 0.721767
FineTuningLR 0.280848
Epoch 32 | Batch 60/100 | Loss 1.180058
InnerLR 0.720726
FineTuningLR 0.281913
Epoch 32 | Batch 70/100 | Loss 1.171557
InnerLR 0.720041
FineTuningLR 0.282632
Epoch 32 | Batch 80/100 | Loss 1.174573
InnerLR 0.718956
FineTuningLR 0.283754
Epoch 32 | Batch 90/100 | Loss 1.167662
InnerLR 0.718219
FineTuningLR 0.284509
100 Accuracy = 61.17% +- 2.10%
Epoch 32: 61.17
best model! save...
Epoch 33 | Batch 0/100 | Loss 1.083573
InnerLR 0.717113
FineTuningLR 0.285642
Epoch 33 | Batch 10/100 | Loss 1.060237
InnerLR 0.716384
FineTuningLR 0.286385
Epoch 33 | Batch 20/100 | Loss 1.109020
InnerLR 0.715405
FineTuningLR 0.287502
Epoch 33 | Batch 30/100 | Loss 1.145135
InnerLR 0.714736
FineTuningLR 0.288240
Epoch 33 | Batch 40/100 | Loss 1.132761
InnerLR 0.713711
FineTuningLR 0.289344
Epoch 33 | Batch 50/100 | Loss 1.150518
InnerLR 0.713057
FineTuningLR 0.290037
Epoch 33 | Batch 60/100 | Loss 1.143601
InnerLR 0.712062
FineTuningLR 0.291074
Epoch 33 | Batch 70/100 | Loss 1.157332
InnerLR 0.711385
FineTuningLR 0.291772
Epoch 33 | Batch 80/100 | Loss 1.159161
InnerLR 0.710384
FineTuningLR 0.292795
Epoch 33 | Batch 90/100 | Loss 1.160401
InnerLR 0.709711
FineTuningLR 0.293478
100 Accuracy = 59.68% +- 1.86%
Epoch 33: 59.68
Epoch 34 | Batch 0/100 | Loss 1.023333
InnerLR 0.708679
FineTuningLR 0.294519
Epoch 34 | Batch 10/100 | Loss 1.063433
InnerLR 0.708030
FineTuningLR 0.295209
Epoch 34 | Batch 20/100 | Loss 1.096352
InnerLR 0.707019
FineTuningLR 0.296265
Epoch 34 | Batch 30/100 | Loss 1.099748
InnerLR 0.706322
FineTuningLR 0.296984
Epoch 34 | Batch 40/100 | Loss 1.097801
InnerLR 0.705296
FineTuningLR 0.298081
Epoch 34 | Batch 50/100 | Loss 1.105475
InnerLR 0.704586
FineTuningLR 0.298826
Epoch 34 | Batch 60/100 | Loss 1.109730
InnerLR 0.703543
FineTuningLR 0.299907
Epoch 34 | Batch 70/100 | Loss 1.105056
InnerLR 0.702848
FineTuningLR 0.300620
Epoch 34 | Batch 80/100 | Loss 1.104933
InnerLR 0.701798
FineTuningLR 0.301688
Epoch 34 | Batch 90/100 | Loss 1.110279
InnerLR 0.701095
FineTuningLR 0.302400
100 Accuracy = 59.87% +- 1.84%
Epoch 34: 59.87
Epoch 35 | Batch 0/100 | Loss 1.022191
InnerLR 0.700129
FineTuningLR 0.303456
Epoch 35 | Batch 10/100 | Loss 1.167391
InnerLR 0.699498
FineTuningLR 0.304139
Epoch 35 | Batch 20/100 | Loss 1.158609
InnerLR 0.698501
FineTuningLR 0.305195
Epoch 35 | Batch 30/100 | Loss 1.155154
InnerLR 0.697819
FineTuningLR 0.305909
Epoch 35 | Batch 40/100 | Loss 1.130047
InnerLR 0.696781
FineTuningLR 0.306981
Epoch 35 | Batch 50/100 | Loss 1.141864
InnerLR 0.696085
FineTuningLR 0.307693
Epoch 35 | Batch 60/100 | Loss 1.140416
InnerLR 0.694998
FineTuningLR 0.308796
Epoch 35 | Batch 70/100 | Loss 1.134860
InnerLR 0.694281
FineTuningLR 0.309527
Epoch 35 | Batch 80/100 | Loss 1.132346
InnerLR 0.693196
FineTuningLR 0.310637
Epoch 35 | Batch 90/100 | Loss 1.136640
InnerLR 0.692482
FineTuningLR 0.311370
100 Accuracy = 60.93% +- 2.00%
Epoch 35: 60.93
Epoch 36 | Batch 0/100 | Loss 1.137988
InnerLR 0.691406
FineTuningLR 0.312478
Epoch 36 | Batch 10/100 | Loss 1.236706
InnerLR 0.690670
FineTuningLR 0.313228
Epoch 36 | Batch 20/100 | Loss 1.204995
InnerLR 0.689553
FineTuningLR 0.314359
Epoch 36 | Batch 30/100 | Loss 1.175408
InnerLR 0.688792
FineTuningLR 0.315124
Epoch 36 | Batch 40/100 | Loss 1.158118
InnerLR 0.687648
FineTuningLR 0.316271
Epoch 36 | Batch 50/100 | Loss 1.149620
InnerLR 0.686906
FineTuningLR 0.317013
Epoch 36 | Batch 60/100 | Loss 1.141491
InnerLR 0.685787
FineTuningLR 0.318129
Epoch 36 | Batch 70/100 | Loss 1.129564
InnerLR 0.685108
FineTuningLR 0.318877
Epoch 36 | Batch 80/100 | Loss 1.134232
InnerLR 0.684128
FineTuningLR 0.319988
Epoch 36 | Batch 90/100 | Loss 1.127548
InnerLR 0.683458
FineTuningLR 0.320722
100 Accuracy = 61.16% +- 1.84%
Epoch 36: 61.16
Epoch 37 | Batch 0/100 | Loss 1.359111
InnerLR 0.682489
FineTuningLR 0.321792
Epoch 37 | Batch 10/100 | Loss 1.213220
InnerLR 0.681822
FineTuningLR 0.322509
Epoch 37 | Batch 20/100 | Loss 1.204261
InnerLR 0.680830
FineTuningLR 0.323574
Epoch 37 | Batch 30/100 | Loss 1.153311
InnerLR 0.680157
FineTuningLR 0.324287
Epoch 37 | Batch 40/100 | Loss 1.135346
InnerLR 0.679170
FineTuningLR 0.325327
Epoch 37 | Batch 50/100 | Loss 1.128754
InnerLR 0.678506
FineTuningLR 0.326018
Epoch 37 | Batch 60/100 | Loss 1.134169
InnerLR 0.677477
FineTuningLR 0.327074
Epoch 37 | Batch 70/100 | Loss 1.133675
InnerLR 0.676837
FineTuningLR 0.327794
Epoch 37 | Batch 80/100 | Loss 1.134891
InnerLR 0.675932
FineTuningLR 0.328874
Epoch 37 | Batch 90/100 | Loss 1.131151
InnerLR 0.675302
FineTuningLR 0.329592
100 Accuracy = 62.69% +- 1.97%
Epoch 37: 62.69
best model! save...
Epoch 38 | Batch 0/100 | Loss 1.074312
InnerLR 0.674294
FineTuningLR 0.330696
Epoch 38 | Batch 10/100 | Loss 1.182580
InnerLR 0.673587
FineTuningLR 0.331451
Epoch 38 | Batch 20/100 | Loss 1.165521
InnerLR 0.672519
FineTuningLR 0.332570
Epoch 38 | Batch 30/100 | Loss 1.157223
InnerLR 0.671850
FineTuningLR 0.333320
Epoch 38 | Batch 40/100 | Loss 1.130684
InnerLR 0.670820
FineTuningLR 0.334441
Epoch 38 | Batch 50/100 | Loss 1.143152
InnerLR 0.670112
FineTuningLR 0.335193
Epoch 38 | Batch 60/100 | Loss 1.142159
InnerLR 0.669035
FineTuningLR 0.336316
Epoch 38 | Batch 70/100 | Loss 1.141257
InnerLR 0.668314
FineTuningLR 0.337060
Epoch 38 | Batch 80/100 | Loss 1.118781
InnerLR 0.667210
FineTuningLR 0.338185
Epoch 38 | Batch 90/100 | Loss 1.118280
InnerLR 0.666470
FineTuningLR 0.338933
100 Accuracy = 59.83% +- 1.94%
Epoch 38: 59.83
Epoch 39 | Batch 0/100 | Loss 1.161139
InnerLR 0.665349
FineTuningLR 0.340061
Epoch 39 | Batch 10/100 | Loss 1.192816
InnerLR 0.664630
FineTuningLR 0.340802
Epoch 39 | Batch 20/100 | Loss 1.152990
InnerLR 0.663590
FineTuningLR 0.341903
Epoch 39 | Batch 30/100 | Loss 1.118064
InnerLR 0.662895
FineTuningLR 0.342639
Epoch 39 | Batch 40/100 | Loss 1.113955
InnerLR 0.661849
FineTuningLR 0.343729
Epoch 39 | Batch 50/100 | Loss 1.115469
InnerLR 0.661147
FineTuningLR 0.344451
Epoch 39 | Batch 60/100 | Loss 1.103664
InnerLR 0.660107
FineTuningLR 0.345540
Epoch 39 | Batch 70/100 | Loss 1.097897
InnerLR 0.659431
FineTuningLR 0.346275
Epoch 39 | Batch 80/100 | Loss 1.106490
InnerLR 0.658399
FineTuningLR 0.347371
Epoch 39 | Batch 90/100 | Loss 1.107205
InnerLR 0.657711
FineTuningLR 0.348089
100 Accuracy = 61.29% +- 1.93%
Epoch 39: 61.29
Epoch 40 | Batch 0/100 | Loss 1.335658
InnerLR 0.656649
FineTuningLR 0.349183
Epoch 40 | Batch 10/100 | Loss 1.155681
InnerLR 0.655931
FineTuningLR 0.349914
Epoch 40 | Batch 20/100 | Loss 1.120168
InnerLR 0.654863
FineTuningLR 0.350994
Epoch 40 | Batch 30/100 | Loss 1.111104
InnerLR 0.654152
FineTuningLR 0.351708
Epoch 40 | Batch 40/100 | Loss 1.084849
InnerLR 0.653097
FineTuningLR 0.352768
Epoch 40 | Batch 50/100 | Loss 1.106091
InnerLR 0.652391
FineTuningLR 0.353480
Epoch 40 | Batch 60/100 | Loss 1.105765
InnerLR 0.651308
FineTuningLR 0.354564
Epoch 40 | Batch 70/100 | Loss 1.115780
InnerLR 0.650579
FineTuningLR 0.355300
Epoch 40 | Batch 80/100 | Loss 1.129141
InnerLR 0.649473
FineTuningLR 0.356421
Epoch 40 | Batch 90/100 | Loss 1.142967
InnerLR 0.648731
FineTuningLR 0.357168
100 Accuracy = 61.40% +- 1.69%
Epoch 40: 61.40
Epoch 41 | Batch 0/100 | Loss 1.134433
InnerLR 0.647607
FineTuningLR 0.358294
Epoch 41 | Batch 10/100 | Loss 1.073698
InnerLR 0.646838
FineTuningLR 0.359061
Epoch 41 | Batch 20/100 | Loss 1.040335
InnerLR 0.645677
FineTuningLR 0.360215
Epoch 41 | Batch 30/100 | Loss 1.071575
InnerLR 0.644902
FineTuningLR 0.360985
Epoch 41 | Batch 40/100 | Loss 1.059302
InnerLR 0.643807
FineTuningLR 0.362122
Epoch 41 | Batch 50/100 | Loss 1.051703
InnerLR 0.643081
FineTuningLR 0.362882
Epoch 41 | Batch 60/100 | Loss 1.065908
InnerLR 0.642008
FineTuningLR 0.363991
Epoch 41 | Batch 70/100 | Loss 1.067087
InnerLR 0.641276
FineTuningLR 0.364739
Epoch 41 | Batch 80/100 | Loss 1.086687
InnerLR 0.640162
FineTuningLR 0.365868
Epoch 41 | Batch 90/100 | Loss 1.085903
InnerLR 0.639405
FineTuningLR 0.366629
100 Accuracy = 59.77% +- 1.81%
Epoch 41: 59.77
Epoch 42 | Batch 0/100 | Loss 1.015866
InnerLR 0.638266
FineTuningLR 0.367769
Epoch 42 | Batch 10/100 | Loss 1.042296
InnerLR 0.637491
FineTuningLR 0.368542
Epoch 42 | Batch 20/100 | Loss 1.062078
InnerLR 0.636334
FineTuningLR 0.369693
Epoch 42 | Batch 30/100 | Loss 1.087794
InnerLR 0.635564
FineTuningLR 0.370457
Epoch 42 | Batch 40/100 | Loss 1.091305
InnerLR 0.634443
FineTuningLR 0.371586
Epoch 42 | Batch 50/100 | Loss 1.089234
InnerLR 0.633722
FineTuningLR 0.372333
Epoch 42 | Batch 60/100 | Loss 1.091749
InnerLR 0.632640
FineTuningLR 0.373441
Epoch 42 | Batch 70/100 | Loss 1.092920
InnerLR 0.631924
FineTuningLR 0.374168
Epoch 42 | Batch 80/100 | Loss 1.082800
InnerLR 0.630975
FineTuningLR 0.375265
Epoch 42 | Batch 90/100 | Loss 1.068668
InnerLR 0.630440
FineTuningLR 0.375989
100 Accuracy = 63.08% +- 2.02%
Epoch 42: 63.08
best model! save...
Epoch 43 | Batch 0/100 | Loss 1.158919
InnerLR 0.629559
FineTuningLR 0.377095
Epoch 43 | Batch 10/100 | Loss 1.198075
InnerLR 0.628935
FineTuningLR 0.377831
Epoch 43 | Batch 20/100 | Loss 1.141079
InnerLR 0.627989
FineTuningLR 0.378911
Epoch 43 | Batch 30/100 | Loss 1.155471
InnerLR 0.627324
FineTuningLR 0.379642
Epoch 43 | Batch 40/100 | Loss 1.129135
InnerLR 0.626365
FineTuningLR 0.380673
Epoch 43 | Batch 50/100 | Loss 1.120356
InnerLR 0.625703
FineTuningLR 0.381369
Epoch 43 | Batch 60/100 | Loss 1.117174
InnerLR 0.624676
FineTuningLR 0.382432
Epoch 43 | Batch 70/100 | Loss 1.113895
InnerLR 0.623966
FineTuningLR 0.383156
Epoch 43 | Batch 80/100 | Loss 1.117922
InnerLR 0.622855
FineTuningLR 0.384280
Epoch 43 | Batch 90/100 | Loss 1.114750
InnerLR 0.622108
FineTuningLR 0.385031
100 Accuracy = 62.91% +- 1.94%
Epoch 43: 62.91
Epoch 44 | Batch 0/100 | Loss 1.183320
InnerLR 0.621181
FineTuningLR 0.386160
Epoch 44 | Batch 10/100 | Loss 1.167033
InnerLR 0.620518
FineTuningLR 0.386923
Epoch 44 | Batch 20/100 | Loss 1.119325
InnerLR 0.619494
FineTuningLR 0.388072
Epoch 44 | Batch 30/100 | Loss 1.098413
InnerLR 0.618802
FineTuningLR 0.388829
Epoch 44 | Batch 40/100 | Loss 1.083992
InnerLR 0.617744
FineTuningLR 0.389959
Epoch 44 | Batch 50/100 | Loss 1.080901
InnerLR 0.617027
FineTuningLR 0.390710
Epoch 44 | Batch 60/100 | Loss 1.089958
InnerLR 0.616061
FineTuningLR 0.391811
Epoch 44 | Batch 70/100 | Loss 1.096105
InnerLR 0.615395
FineTuningLR 0.392498
Epoch 44 | Batch 80/100 | Loss 1.104721
InnerLR 0.614376
FineTuningLR 0.393536
Epoch 44 | Batch 90/100 | Loss 1.094453
InnerLR 0.613667
FineTuningLR 0.394251
100 Accuracy = 62.59% +- 2.12%
Epoch 44: 62.59
Epoch 45 | Batch 0/100 | Loss 1.114148
InnerLR 0.612617
FineTuningLR 0.395346
Epoch 45 | Batch 10/100 | Loss 1.068121
InnerLR 0.612011
FineTuningLR 0.396085
Epoch 45 | Batch 20/100 | Loss 1.065473
InnerLR 0.611149
FineTuningLR 0.397181
Epoch 45 | Batch 30/100 | Loss 1.069397
InnerLR 0.610532
FineTuningLR 0.397916
Epoch 45 | Batch 40/100 | Loss 1.081719
InnerLR 0.609576
FineTuningLR 0.399004
Epoch 45 | Batch 50/100 | Loss 1.081439
InnerLR 0.608939
FineTuningLR 0.399728
Epoch 45 | Batch 60/100 | Loss 1.070898
InnerLR 0.608056
FineTuningLR 0.400779
Epoch 45 | Batch 70/100 | Loss 1.077600
InnerLR 0.607560
FineTuningLR 0.401485
Epoch 45 | Batch 80/100 | Loss 1.067983
InnerLR 0.606795
FineTuningLR 0.402564
Epoch 45 | Batch 90/100 | Loss 1.070032
InnerLR 0.606400
FineTuningLR 0.403277
100 Accuracy = 63.20% +- 2.00%
Epoch 45: 63.20
best model! save...
Epoch 46 | Batch 0/100 | Loss 1.087376
InnerLR 0.605787
FineTuningLR 0.404359
Epoch 46 | Batch 10/100 | Loss 1.055618
InnerLR 0.605316
FineTuningLR 0.405066
Epoch 46 | Batch 20/100 | Loss 1.100330
InnerLR 0.604530
FineTuningLR 0.406120
Epoch 46 | Batch 30/100 | Loss 1.089403
InnerLR 0.603970
FineTuningLR 0.406751
Epoch 46 | Batch 40/100 | Loss 1.086763
InnerLR 0.603102
FineTuningLR 0.407748
Epoch 46 | Batch 50/100 | Loss 1.100624
InnerLR 0.602482
FineTuningLR 0.408412
Epoch 46 | Batch 60/100 | Loss 1.118045
InnerLR 0.601501
FineTuningLR 0.409322
Epoch 46 | Batch 70/100 | Loss 1.117894
InnerLR 0.600812
FineTuningLR 0.409809
Epoch 46 | Batch 80/100 | Loss 1.120500
InnerLR 0.599726
FineTuningLR 0.410557
Epoch 46 | Batch 90/100 | Loss 1.126678
InnerLR 0.598996
FineTuningLR 0.411112
100 Accuracy = 60.99% +- 1.88%
Epoch 46: 60.99
Epoch 47 | Batch 0/100 | Loss 1.161594
InnerLR 0.597963
FineTuningLR 0.412009
Epoch 47 | Batch 10/100 | Loss 1.076803
InnerLR 0.597352
FineTuningLR 0.412635
Epoch 47 | Batch 20/100 | Loss 1.168824
InnerLR 0.596394
FineTuningLR 0.413503
Epoch 47 | Batch 30/100 | Loss 1.134140
InnerLR 0.595787
FineTuningLR 0.414027
Epoch 47 | Batch 40/100 | Loss 1.113737
InnerLR 0.594961
FineTuningLR 0.414855
Epoch 47 | Batch 50/100 | Loss 1.117811
InnerLR 0.594378
FineTuningLR 0.415437
Epoch 47 | Batch 60/100 | Loss 1.127220
InnerLR 0.593465
FineTuningLR 0.416203
Epoch 47 | Batch 70/100 | Loss 1.135186
InnerLR 0.592814
FineTuningLR 0.416735
Epoch 47 | Batch 80/100 | Loss 1.142312
InnerLR 0.591904
FineTuningLR 0.417577
Epoch 47 | Batch 90/100 | Loss 1.132739
InnerLR 0.591336
FineTuningLR 0.418170
100 Accuracy = 63.47% +- 2.11%
Epoch 47: 63.47
best model! save...
Epoch 48 | Batch 0/100 | Loss 0.962996
InnerLR 0.590540
FineTuningLR 0.419112
Epoch 48 | Batch 10/100 | Loss 1.017744
InnerLR 0.589956
FineTuningLR 0.419766
Epoch 48 | Batch 20/100 | Loss 1.042979
InnerLR 0.589088
FineTuningLR 0.420775
Epoch 48 | Batch 30/100 | Loss 1.040869
InnerLR 0.588476
FineTuningLR 0.421474
Epoch 48 | Batch 40/100 | Loss 1.070549
InnerLR 0.587496
FineTuningLR 0.422550
Epoch 48 | Batch 50/100 | Loss 1.061831
InnerLR 0.586806
FineTuningLR 0.423284
Epoch 48 | Batch 60/100 | Loss 1.062780
InnerLR 0.585717
FineTuningLR 0.424419
Epoch 48 | Batch 70/100 | Loss 1.057707
InnerLR 0.585007
FineTuningLR 0.425194
Epoch 48 | Batch 80/100 | Loss 1.068687
InnerLR 0.583974
FineTuningLR 0.426279
Epoch 48 | Batch 90/100 | Loss 1.076215
InnerLR 0.583266
FineTuningLR 0.426933
100 Accuracy = 62.72% +- 2.19%
Epoch 48: 62.72
Epoch 49 | Batch 0/100 | Loss 1.031549
InnerLR 0.582208
FineTuningLR 0.427821
Epoch 49 | Batch 10/100 | Loss 1.024363
InnerLR 0.581513
FineTuningLR 0.428416
Epoch 49 | Batch 20/100 | Loss 1.040594
InnerLR 0.580480
FineTuningLR 0.429366
Epoch 49 | Batch 30/100 | Loss 1.061064
InnerLR 0.579807
FineTuningLR 0.430016
Epoch 49 | Batch 40/100 | Loss 1.048878
InnerLR 0.578813
FineTuningLR 0.431032
Epoch 49 | Batch 50/100 | Loss 1.046832
InnerLR 0.578197
FineTuningLR 0.431720
Epoch 49 | Batch 60/100 | Loss 1.050800
InnerLR 0.577226
FineTuningLR 0.432768
Epoch 49 | Batch 70/100 | Loss 1.049835
InnerLR 0.576544
FineTuningLR 0.433485
Epoch 49 | Batch 80/100 | Loss 1.064008
InnerLR 0.575469
FineTuningLR 0.434569
Epoch 49 | Batch 90/100 | Loss 1.054728
InnerLR 0.574766
FineTuningLR 0.435284
100 Accuracy = 62.79% +- 2.15%
Epoch 49: 62.79
Epoch 50 | Batch 0/100 | Loss 1.084196
InnerLR 0.573693
FineTuningLR 0.436244
Epoch 50 | Batch 10/100 | Loss 1.056255
InnerLR 0.572959
FineTuningLR 0.436873
Epoch 50 | Batch 20/100 | Loss 1.035780
InnerLR 0.572047
FineTuningLR 0.437791
Epoch 50 | Batch 30/100 | Loss 1.038742
InnerLR 0.571436
FineTuningLR 0.438448
Epoch 50 | Batch 40/100 | Loss 1.048109
InnerLR 0.570584
FineTuningLR 0.439502
Epoch 50 | Batch 50/100 | Loss 1.051936
InnerLR 0.569974
FineTuningLR 0.440165
Epoch 50 | Batch 60/100 | Loss 1.047267
InnerLR 0.569049
FineTuningLR 0.441067
Epoch 50 | Batch 70/100 | Loss 1.062082
InnerLR 0.568393
FineTuningLR 0.441636
Epoch 50 | Batch 80/100 | Loss 1.060358
InnerLR 0.567377
FineTuningLR 0.442460
Epoch 50 | Batch 90/100 | Loss 1.074582
InnerLR 0.566689
FineTuningLR 0.443045
100 Accuracy = 63.80% +- 1.97%
Epoch 50: 63.80
best model! save...
Epoch 51 | Batch 0/100 | Loss 1.105542
InnerLR 0.565663
FineTuningLR 0.443944
Epoch 51 | Batch 10/100 | Loss 1.044757
InnerLR 0.564959
FineTuningLR 0.444578
Epoch 51 | Batch 20/100 | Loss 1.007864
InnerLR 0.564006
FineTuningLR 0.445581
Epoch 51 | Batch 30/100 | Loss 1.021700
InnerLR 0.563429
FineTuningLR 0.446237
Epoch 51 | Batch 40/100 | Loss 1.004849
InnerLR 0.562572
FineTuningLR 0.447258
Epoch 51 | Batch 50/100 | Loss 1.036302
InnerLR 0.562032
FineTuningLR 0.447879
Epoch 51 | Batch 60/100 | Loss 1.039066
InnerLR 0.561179
FineTuningLR 0.448742
Epoch 51 | Batch 70/100 | Loss 1.023341
InnerLR 0.560600
FineTuningLR 0.449363
Epoch 51 | Batch 80/100 | Loss 1.024907
InnerLR 0.559947
FineTuningLR 0.450334
Epoch 51 | Batch 90/100 | Loss 1.015124
InnerLR 0.559442
FineTuningLR 0.451019
100 Accuracy = 63.24% +- 2.26%
Epoch 51: 63.24
Epoch 52 | Batch 0/100 | Loss 1.304413
InnerLR 0.558646
FineTuningLR 0.452028
Epoch 52 | Batch 10/100 | Loss 1.149632
InnerLR 0.558081
FineTuningLR 0.452599
Epoch 52 | Batch 20/100 | Loss 1.104916
InnerLR 0.557182
FineTuningLR 0.453322
Epoch 52 | Batch 30/100 | Loss 1.114658
InnerLR 0.556536
FineTuningLR 0.453873
Epoch 52 | Batch 40/100 | Loss 1.111031
InnerLR 0.555511
FineTuningLR 0.454791
Epoch 52 | Batch 50/100 | Loss 1.110854
InnerLR 0.554802
FineTuningLR 0.455441
Epoch 52 | Batch 60/100 | Loss 1.097544
InnerLR 0.553892
FineTuningLR 0.456447
Epoch 52 | Batch 70/100 | Loss 1.093611
InnerLR 0.553374
FineTuningLR 0.457101
Epoch 52 | Batch 80/100 | Loss 1.083547
InnerLR 0.552645
FineTuningLR 0.458105
Epoch 52 | Batch 90/100 | Loss 1.080370
InnerLR 0.552194
FineTuningLR 0.458800
100 Accuracy = 63.72% +- 2.00%
Epoch 52: 63.72
Epoch 53 | Batch 0/100 | Loss 1.024112
InnerLR 0.551483
FineTuningLR 0.459893
Epoch 53 | Batch 10/100 | Loss 0.940078
InnerLR 0.551121
FineTuningLR 0.460630
Epoch 53 | Batch 20/100 | Loss 1.014849
InnerLR 0.550540
FineTuningLR 0.461577
Epoch 53 | Batch 30/100 | Loss 1.072466
InnerLR 0.550152
FineTuningLR 0.462128
Epoch 53 | Batch 40/100 | Loss 1.095837
InnerLR 0.549442
FineTuningLR 0.462765
Epoch 53 | Batch 50/100 | Loss 1.106455
InnerLR 0.548962
FineTuningLR 0.463193
Epoch 53 | Batch 60/100 | Loss 1.120509
InnerLR 0.548146
FineTuningLR 0.463822
Epoch 53 | Batch 70/100 | Loss 1.131611
InnerLR 0.547549
FineTuningLR 0.464020
Epoch 53 | Batch 80/100 | Loss 1.127461
InnerLR 0.546574
FineTuningLR 0.464412
Epoch 53 | Batch 90/100 | Loss 1.125322
InnerLR 0.545915
FineTuningLR 0.464714
100 Accuracy = 61.76% +- 1.94%
Epoch 53: 61.76
Epoch 54 | Batch 0/100 | Loss 1.203204
InnerLR 0.544904
FineTuningLR 0.465202
Epoch 54 | Batch 10/100 | Loss 1.105959
InnerLR 0.544327
FineTuningLR 0.465628
Epoch 54 | Batch 20/100 | Loss 1.090784
InnerLR 0.543476
FineTuningLR 0.466350
Epoch 54 | Batch 30/100 | Loss 1.097813
InnerLR 0.542923
FineTuningLR 0.466868
Epoch 54 | Batch 40/100 | Loss 1.070035
InnerLR 0.542060
FineTuningLR 0.467700
Epoch 54 | Batch 50/100 | Loss 1.053936
InnerLR 0.541556
FineTuningLR 0.468244
Epoch 54 | Batch 60/100 | Loss 1.064751
InnerLR 0.540791
FineTuningLR 0.469150
Epoch 54 | Batch 70/100 | Loss 1.068816
InnerLR 0.540249
FineTuningLR 0.469798
Epoch 54 | Batch 80/100 | Loss 1.054504
InnerLR 0.539460
FineTuningLR 0.470805
Epoch 54 | Batch 90/100 | Loss 1.059445
InnerLR 0.538929
FineTuningLR 0.471507
100 Accuracy = 63.32% +- 2.08%
Epoch 54: 63.32
Epoch 55 | Batch 0/100 | Loss 0.925910
InnerLR 0.538071
FineTuningLR 0.472575
Epoch 55 | Batch 10/100 | Loss 0.898285
InnerLR 0.537616
FineTuningLR 0.473304
Epoch 55 | Batch 20/100 | Loss 0.917538
InnerLR 0.536879
FineTuningLR 0.474420
Epoch 55 | Batch 30/100 | Loss 0.936908
InnerLR 0.536419
FineTuningLR 0.475164
Epoch 55 | Batch 40/100 | Loss 0.947102
InnerLR 0.535645
FineTuningLR 0.476288
Epoch 55 | Batch 50/100 | Loss 0.969050
InnerLR 0.535164
FineTuningLR 0.477041
Epoch 55 | Batch 60/100 | Loss 0.986187
InnerLR 0.534318
FineTuningLR 0.478190
Epoch 55 | Batch 70/100 | Loss 0.996792
InnerLR 0.533789
FineTuningLR 0.478873
Epoch 55 | Batch 80/100 | Loss 0.997209
InnerLR 0.532926
FineTuningLR 0.479908
Epoch 55 | Batch 90/100 | Loss 0.997436
InnerLR 0.532326
FineTuningLR 0.480484
100 Accuracy = 62.89% +- 2.04%
Epoch 55: 62.89
Epoch 56 | Batch 0/100 | Loss 0.942076
InnerLR 0.531402
FineTuningLR 0.481466
Epoch 56 | Batch 10/100 | Loss 1.078011
InnerLR 0.530773
FineTuningLR 0.482145
Epoch 56 | Batch 20/100 | Loss 1.073087
InnerLR 0.529797
FineTuningLR 0.483204
Epoch 56 | Batch 30/100 | Loss 1.064220
InnerLR 0.529107
FineTuningLR 0.483930
Epoch 56 | Batch 40/100 | Loss 1.064573
InnerLR 0.528124
FineTuningLR 0.485022
Epoch 56 | Batch 50/100 | Loss 1.047129
InnerLR 0.527485
FineTuningLR 0.485658
Epoch 56 | Batch 60/100 | Loss 1.058704
InnerLR 0.526522
FineTuningLR 0.486661
Epoch 56 | Batch 70/100 | Loss 1.054641
InnerLR 0.525989
FineTuningLR 0.487351
Epoch 56 | Batch 80/100 | Loss 1.047834
InnerLR 0.525308
FineTuningLR 0.488399
Epoch 56 | Batch 90/100 | Loss 1.063774
InnerLR 0.524805
FineTuningLR 0.489001
100 Accuracy = 62.95% +- 2.00%
Epoch 56: 62.95
Epoch 57 | Batch 0/100 | Loss 1.353025
InnerLR 0.524124
FineTuningLR 0.489829
Epoch 57 | Batch 10/100 | Loss 1.031196
InnerLR 0.523624
FineTuningLR 0.490407
Epoch 57 | Batch 20/100 | Loss 1.051844
InnerLR 0.522897
FineTuningLR 0.491340
Epoch 57 | Batch 30/100 | Loss 1.043060
InnerLR 0.522331
FineTuningLR 0.491976
Epoch 57 | Batch 40/100 | Loss 1.047654
InnerLR 0.521435
FineTuningLR 0.492965
Epoch 57 | Batch 50/100 | Loss 1.071491
InnerLR 0.520853
FineTuningLR 0.493523
Epoch 57 | Batch 60/100 | Loss 1.056148
InnerLR 0.519909
FineTuningLR 0.494409
Epoch 57 | Batch 70/100 | Loss 1.065710
InnerLR 0.519249
FineTuningLR 0.494943
Epoch 57 | Batch 80/100 | Loss 1.061123
InnerLR 0.518360
FineTuningLR 0.495730
Epoch 57 | Batch 90/100 | Loss 1.071447
InnerLR 0.517820
FineTuningLR 0.496224
100 Accuracy = 63.65% +- 2.31%
Epoch 57: 63.65
Epoch 58 | Batch 0/100 | Loss 1.322196
InnerLR 0.516969
FineTuningLR 0.496722
Epoch 58 | Batch 10/100 | Loss 0.976303
InnerLR 0.516518
FineTuningLR 0.497145
Epoch 58 | Batch 20/100 | Loss 1.009644
InnerLR 0.515888
FineTuningLR 0.497794
Epoch 58 | Batch 30/100 | Loss 1.011868
InnerLR 0.515549
FineTuningLR 0.498266
Epoch 58 | Batch 40/100 | Loss 1.020378
InnerLR 0.514940
FineTuningLR 0.499068
Epoch 58 | Batch 50/100 | Loss 1.031818
InnerLR 0.514539
FineTuningLR 0.499598
Epoch 58 | Batch 60/100 | Loss 1.037846
InnerLR 0.513975
FineTuningLR 0.500401
Epoch 58 | Batch 70/100 | Loss 1.043270
InnerLR 0.513711
FineTuningLR 0.500885
Epoch 58 | Batch 80/100 | Loss 1.038601
InnerLR 0.513276
FineTuningLR 0.501467
Epoch 58 | Batch 90/100 | Loss 1.043717
InnerLR 0.512996
FineTuningLR 0.501826
100 Accuracy = 64.71% +- 2.15%
Epoch 58: 64.71
best model! save...
Epoch 59 | Batch 0/100 | Loss 0.786078
InnerLR 0.512547
FineTuningLR 0.502380
Epoch 59 | Batch 10/100 | Loss 1.165565
InnerLR 0.512157
FineTuningLR 0.502817
Epoch 59 | Batch 20/100 | Loss 1.113068
InnerLR 0.511467
FineTuningLR 0.503229
Epoch 59 | Batch 30/100 | Loss 1.075970
InnerLR 0.511042
FineTuningLR 0.503602
Epoch 59 | Batch 40/100 | Loss 1.043265
InnerLR 0.510436
FineTuningLR 0.504307
Epoch 59 | Batch 50/100 | Loss 1.044995
InnerLR 0.510147
FineTuningLR 0.504768
Epoch 59 | Batch 60/100 | Loss 1.039693
InnerLR 0.509652
FineTuningLR 0.505421
Epoch 59 | Batch 70/100 | Loss 1.034872
InnerLR 0.509341
FineTuningLR 0.505836
Epoch 59 | Batch 80/100 | Loss 1.045075
InnerLR 0.508790
FineTuningLR 0.506504
Epoch 59 | Batch 90/100 | Loss 1.052736
InnerLR 0.508337
FineTuningLR 0.506830
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 62.17% +- 2.19%
Epoch 59: 62.17
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_5_lr_0.0003_latent_space_dim_16_weight_decay_1e-08_num_adaptation_steps_10/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_lr_0.0003_latent_space_dim_16_weight_decay_1e-08_num_adaptation_steps_10/tabula_muris/leo_FCNet/20231209_115916
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 67.89% +- 0.85%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_lr_0.0003_latent_space_dim_16_weight_decay_1e-08_num_adaptation_steps_10/tabula_muris/leo_FCNet/20231209_115916
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 64.41% +- 0.84%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_5_lr_0.0003_latent_space_dim_16_weight_decay_1e-08_num_adaptation_steps_10/tabula_muris/leo_FCNet/20231209_115916
600 Accuracy = 63.56% +- 0.76%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_5_lr_0.0003_latent_space_dim_16_weight_decay_1e-08_num_adaptation_steps_10/results.txt
+-------+-------------------+--------------------+
| split |      acc_mean     |      acc_std       |
+-------+-------------------+--------------------+
| train | 67.89333333333333 | 10.572943806752248 |
|  val  | 64.41111111111113 | 10.486246135996014 |
|  test | 63.55555555555555 | 9.482511518124193  |
+-------+-------------------+--------------------+
