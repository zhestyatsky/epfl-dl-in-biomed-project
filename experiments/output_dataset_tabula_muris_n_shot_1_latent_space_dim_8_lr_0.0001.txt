/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 1
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 1
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 1
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 0.5
    finetuning_lr_init: 0.05
    num_adaptation_steps: 5
    kl_coef: 0.01
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 0.1
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 8
    enable_finetuning_loop: true
  n_task: 4
  latent_space_dim: 8
  leo_inner_lr_init: 0.5
  leo_finetuning_lr_init: 0.05
  num_adaptation_steps: 5
  kl_coef: 0.01
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 0.1
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-06
  optimize_backbone: false
  pretrained_backbone_weights_path: pretrained_weights/tabula_muris_baseline_model.tar
  enable_finetuning_loop: true
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_1_latent_space_dim_8_lr_0.0001
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.0001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.0001
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_8_lr_0.0001/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Using pretrained backbone from pretrained_weights/tabula_muris_baseline_model.tar.
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=8, bias=False)
    (relation_net): Sequential(
      (0): Linear(in_features=16, out_features=16, bias=False)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=16, bias=False)
      (3): ReLU()
      (4): Linear(in_features=16, out_features=16, bias=False)
    )
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=8, out_features=130, bias=False)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 1e-06

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
)
Epoch 0 | Batch 0/100 | Loss 4.405344
InnerLR 0.500000
FineTuningLR 0.050000
Epoch 0 | Batch 10/100 | Loss 6.446897
InnerLR 0.499905
FineTuningLR 0.050200
Epoch 0 | Batch 20/100 | Loss 6.934994
InnerLR 0.499754
FineTuningLR 0.050500
Epoch 0 | Batch 30/100 | Loss 6.958309
InnerLR 0.499605
FineTuningLR 0.050700
Epoch 0 | Batch 40/100 | Loss 6.793344
InnerLR 0.499383
FineTuningLR 0.051000
Epoch 0 | Batch 50/100 | Loss 6.829509
InnerLR 0.499253
FineTuningLR 0.051200
Epoch 0 | Batch 60/100 | Loss 6.842072
InnerLR 0.499075
FineTuningLR 0.051500
Epoch 0 | Batch 70/100 | Loss 7.089187
InnerLR 0.498948
FineTuningLR 0.051700
Epoch 0 | Batch 80/100 | Loss 7.155565
InnerLR 0.498728
FineTuningLR 0.052000
Epoch 0 | Batch 90/100 | Loss 7.115072
InnerLR 0.498567
FineTuningLR 0.052200
100 Accuracy = 44.16% +- 2.57%
Epoch 0: 44.16
best model! save...
Epoch 1 | Batch 0/100 | Loss 5.614159
InnerLR 0.498370
FineTuningLR 0.052500
Epoch 1 | Batch 10/100 | Loss 6.456604
InnerLR 0.498243
FineTuningLR 0.052700
Epoch 1 | Batch 20/100 | Loss 6.395470
InnerLR 0.498114
FineTuningLR 0.053000
Epoch 1 | Batch 30/100 | Loss 6.532928
InnerLR 0.498037
FineTuningLR 0.053200
Epoch 1 | Batch 40/100 | Loss 6.590999
InnerLR 0.497937
FineTuningLR 0.053500
Epoch 1 | Batch 50/100 | Loss 6.541260
InnerLR 0.497875
FineTuningLR 0.053700
Epoch 1 | Batch 60/100 | Loss 6.762129
InnerLR 0.497828
FineTuningLR 0.054000
Epoch 1 | Batch 70/100 | Loss 6.817293
InnerLR 0.497768
FineTuningLR 0.054200
Epoch 1 | Batch 80/100 | Loss 6.879913
InnerLR 0.497722
FineTuningLR 0.054500
Epoch 1 | Batch 90/100 | Loss 6.678597
InnerLR 0.497663
FineTuningLR 0.054700
100 Accuracy = 43.77% +- 2.62%
Epoch 1: 43.77
Epoch 2 | Batch 0/100 | Loss 11.602075
InnerLR 0.497526
FineTuningLR 0.055000
Epoch 2 | Batch 10/100 | Loss 7.180180
InnerLR 0.497409
FineTuningLR 0.055200
Epoch 2 | Batch 20/100 | Loss 7.363736
InnerLR 0.497205
FineTuningLR 0.055500
Epoch 2 | Batch 30/100 | Loss 7.182071
InnerLR 0.497054
FineTuningLR 0.055700
Epoch 2 | Batch 40/100 | Loss 6.996406
InnerLR 0.496830
FineTuningLR 0.056000
Epoch 2 | Batch 50/100 | Loss 7.141228
InnerLR 0.496694
FineTuningLR 0.056200
Epoch 2 | Batch 60/100 | Loss 7.213825
InnerLR 0.496466
FineTuningLR 0.056500
Epoch 2 | Batch 70/100 | Loss 7.042401
InnerLR 0.496304
FineTuningLR 0.056700
Epoch 2 | Batch 80/100 | Loss 6.961311
InnerLR 0.496047
FineTuningLR 0.057000
Epoch 2 | Batch 90/100 | Loss 6.794796
InnerLR 0.495907
FineTuningLR 0.057200
100 Accuracy = 41.33% +- 2.28%
Epoch 2: 41.33
Epoch 3 | Batch 0/100 | Loss 7.336308
InnerLR 0.495750
FineTuningLR 0.057500
Epoch 3 | Batch 10/100 | Loss 6.722647
InnerLR 0.495668
FineTuningLR 0.057700
Epoch 3 | Batch 20/100 | Loss 6.317539
InnerLR 0.495549
FineTuningLR 0.058000
Epoch 3 | Batch 30/100 | Loss 6.314559
InnerLR 0.495466
FineTuningLR 0.058200
Epoch 3 | Batch 40/100 | Loss 6.146664
InnerLR 0.495392
FineTuningLR 0.058500
Epoch 3 | Batch 50/100 | Loss 5.985777
InnerLR 0.495358
FineTuningLR 0.058700
Epoch 3 | Batch 60/100 | Loss 6.116167
InnerLR 0.495249
FineTuningLR 0.059000
Epoch 3 | Batch 70/100 | Loss 6.275540
InnerLR 0.495146
FineTuningLR 0.059200
Epoch 3 | Batch 80/100 | Loss 6.414316
InnerLR 0.495013
FineTuningLR 0.059500
Epoch 3 | Batch 90/100 | Loss 6.375505
InnerLR 0.494899
FineTuningLR 0.059700
100 Accuracy = 41.32% +- 2.31%
Epoch 3: 41.32
Epoch 4 | Batch 0/100 | Loss 5.326219
InnerLR 0.494697
FineTuningLR 0.060000
Epoch 4 | Batch 10/100 | Loss 5.897588
InnerLR 0.494548
FineTuningLR 0.060200
Epoch 4 | Batch 20/100 | Loss 6.467326
InnerLR 0.494306
FineTuningLR 0.060500
Epoch 4 | Batch 30/100 | Loss 6.219928
InnerLR 0.494174
FineTuningLR 0.060700
Epoch 4 | Batch 40/100 | Loss 6.215189
InnerLR 0.493952
FineTuningLR 0.061000
Epoch 4 | Batch 50/100 | Loss 6.131775
InnerLR 0.493830
FineTuningLR 0.061200
Epoch 4 | Batch 60/100 | Loss 6.216793
InnerLR 0.493640
FineTuningLR 0.061500
Epoch 4 | Batch 70/100 | Loss 6.154780
InnerLR 0.493521
FineTuningLR 0.061700
Epoch 4 | Batch 80/100 | Loss 6.422577
InnerLR 0.493313
FineTuningLR 0.062000
Epoch 4 | Batch 90/100 | Loss 6.428749
InnerLR 0.493161
FineTuningLR 0.062200
100 Accuracy = 43.27% +- 2.35%
Epoch 4: 43.27
Epoch 5 | Batch 0/100 | Loss 5.613297
InnerLR 0.492916
FineTuningLR 0.062500
Epoch 5 | Batch 10/100 | Loss 5.725570
InnerLR 0.492743
FineTuningLR 0.062700
Epoch 5 | Batch 20/100 | Loss 6.325064
InnerLR 0.492476
FineTuningLR 0.063000
Epoch 5 | Batch 30/100 | Loss 6.647774
InnerLR 0.492292
FineTuningLR 0.063200
Epoch 5 | Batch 40/100 | Loss 6.706126
InnerLR 0.492011
FineTuningLR 0.063500
Epoch 5 | Batch 50/100 | Loss 6.800106
InnerLR 0.491821
FineTuningLR 0.063700
Epoch 5 | Batch 60/100 | Loss 6.544217
InnerLR 0.491552
FineTuningLR 0.064000
Epoch 5 | Batch 70/100 | Loss 6.318589
InnerLR 0.491392
FineTuningLR 0.064200
Epoch 5 | Batch 80/100 | Loss 6.080527
InnerLR 0.491139
FineTuningLR 0.064500
Epoch 5 | Batch 90/100 | Loss 5.985285
InnerLR 0.490962
FineTuningLR 0.064700
100 Accuracy = 42.61% +- 2.20%
Epoch 5: 42.61
Epoch 6 | Batch 0/100 | Loss 3.453448
InnerLR 0.490727
FineTuningLR 0.065000
Epoch 6 | Batch 10/100 | Loss 6.473671
InnerLR 0.490572
FineTuningLR 0.065200
Epoch 6 | Batch 20/100 | Loss 6.470722
InnerLR 0.490324
FineTuningLR 0.065500
Epoch 6 | Batch 30/100 | Loss 6.069986
InnerLR 0.490170
FineTuningLR 0.065700
Epoch 6 | Batch 40/100 | Loss 6.063510
InnerLR 0.489949
FineTuningLR 0.066000
Epoch 6 | Batch 50/100 | Loss 6.443252
InnerLR 0.489790
FineTuningLR 0.066200
Epoch 6 | Batch 60/100 | Loss 6.446894
InnerLR 0.489537
FineTuningLR 0.066500
Epoch 6 | Batch 70/100 | Loss 6.265721
InnerLR 0.489361
FineTuningLR 0.066700
Epoch 6 | Batch 80/100 | Loss 6.348975
InnerLR 0.489126
FineTuningLR 0.067000
Epoch 6 | Batch 90/100 | Loss 6.432467
InnerLR 0.488971
FineTuningLR 0.067200
100 Accuracy = 42.32% +- 2.41%
Epoch 6: 42.32
Epoch 7 | Batch 0/100 | Loss 5.759084
InnerLR 0.488797
FineTuningLR 0.067500
Epoch 7 | Batch 10/100 | Loss 6.374582
InnerLR 0.488724
FineTuningLR 0.067700
Epoch 7 | Batch 20/100 | Loss 5.800792
InnerLR 0.488570
FineTuningLR 0.068000
Epoch 7 | Batch 30/100 | Loss 6.093597
InnerLR 0.488445
FineTuningLR 0.068200
Epoch 7 | Batch 40/100 | Loss 5.886363
InnerLR 0.488231
FineTuningLR 0.068500
Epoch 7 | Batch 50/100 | Loss 5.931468
InnerLR 0.488075
FineTuningLR 0.068700
Epoch 7 | Batch 60/100 | Loss 5.815677
InnerLR 0.487826
FineTuningLR 0.069000
Epoch 7 | Batch 70/100 | Loss 5.753366
InnerLR 0.487672
FineTuningLR 0.069200
Epoch 7 | Batch 80/100 | Loss 5.793010
InnerLR 0.487505
FineTuningLR 0.069500
Epoch 7 | Batch 90/100 | Loss 5.655078
InnerLR 0.487373
FineTuningLR 0.069700
100 Accuracy = 43.21% +- 2.29%
Epoch 7: 43.21
Epoch 8 | Batch 0/100 | Loss 7.252676
InnerLR 0.487151
FineTuningLR 0.070000
Epoch 8 | Batch 10/100 | Loss 6.182435
InnerLR 0.486992
FineTuningLR 0.070200
Epoch 8 | Batch 20/100 | Loss 6.267526
InnerLR 0.486738
FineTuningLR 0.070500
Epoch 8 | Batch 30/100 | Loss 6.129594
InnerLR 0.486600
FineTuningLR 0.070700
Epoch 8 | Batch 40/100 | Loss 6.059645
InnerLR 0.486371
FineTuningLR 0.071000
Epoch 8 | Batch 50/100 | Loss 6.046684
InnerLR 0.486207
FineTuningLR 0.071200
Epoch 8 | Batch 60/100 | Loss 5.805154
InnerLR 0.485970
FineTuningLR 0.071500
Epoch 8 | Batch 70/100 | Loss 5.758079
InnerLR 0.485845
FineTuningLR 0.071700
Epoch 8 | Batch 80/100 | Loss 5.957773
InnerLR 0.485677
FineTuningLR 0.072001
Epoch 8 | Batch 90/100 | Loss 5.925164
InnerLR 0.485567
FineTuningLR 0.072203
100 Accuracy = 43.01% +- 2.34%
Epoch 8: 43.01
Epoch 9 | Batch 0/100 | Loss 5.134673
InnerLR 0.485370
FineTuningLR 0.072505
Epoch 9 | Batch 10/100 | Loss 5.888018
InnerLR 0.485261
FineTuningLR 0.072706
Epoch 9 | Batch 20/100 | Loss 5.449507
InnerLR 0.485105
FineTuningLR 0.073008
Epoch 9 | Batch 30/100 | Loss 5.644841
InnerLR 0.484989
FineTuningLR 0.073208
Epoch 9 | Batch 40/100 | Loss 5.817583
InnerLR 0.484787
FineTuningLR 0.073509
Epoch 9 | Batch 50/100 | Loss 5.903416
InnerLR 0.484674
FineTuningLR 0.073709
Epoch 9 | Batch 60/100 | Loss 5.721414
InnerLR 0.484514
FineTuningLR 0.074009
Epoch 9 | Batch 70/100 | Loss 5.713862
InnerLR 0.484417
FineTuningLR 0.074210
Epoch 9 | Batch 80/100 | Loss 5.738748
InnerLR 0.484281
FineTuningLR 0.074510
Epoch 9 | Batch 90/100 | Loss 5.662060
InnerLR 0.484189
FineTuningLR 0.074710
100 Accuracy = 44.16% +- 2.32%
Epoch 9: 44.16
best model! save...
Epoch 10 | Batch 0/100 | Loss 5.028193
InnerLR 0.484013
FineTuningLR 0.075010
Epoch 10 | Batch 10/100 | Loss 5.176672
InnerLR 0.483877
FineTuningLR 0.075210
Epoch 10 | Batch 20/100 | Loss 5.155648
InnerLR 0.483689
FineTuningLR 0.075510
Epoch 10 | Batch 30/100 | Loss 5.369302
InnerLR 0.483557
FineTuningLR 0.075710
Epoch 10 | Batch 40/100 | Loss 5.399598
InnerLR 0.483336
FineTuningLR 0.076009
Epoch 10 | Batch 50/100 | Loss 5.548343
InnerLR 0.483176
FineTuningLR 0.076209
Epoch 10 | Batch 60/100 | Loss 5.519402
InnerLR 0.482977
FineTuningLR 0.076509
Epoch 10 | Batch 70/100 | Loss 5.571119
InnerLR 0.482828
FineTuningLR 0.076709
Epoch 10 | Batch 80/100 | Loss 5.575072
InnerLR 0.482588
FineTuningLR 0.077009
Epoch 10 | Batch 90/100 | Loss 5.506916
InnerLR 0.482476
FineTuningLR 0.077209
100 Accuracy = 43.56% +- 2.20%
Epoch 10: 43.56
Epoch 11 | Batch 0/100 | Loss 4.749702
InnerLR 0.482358
FineTuningLR 0.077509
Epoch 11 | Batch 10/100 | Loss 5.352021
InnerLR 0.482289
FineTuningLR 0.077709
Epoch 11 | Batch 20/100 | Loss 5.077360
InnerLR 0.482141
FineTuningLR 0.078009
Epoch 11 | Batch 30/100 | Loss 5.323783
InnerLR 0.482038
FineTuningLR 0.078208
Epoch 11 | Batch 40/100 | Loss 5.343767
InnerLR 0.481896
FineTuningLR 0.078508
Epoch 11 | Batch 50/100 | Loss 5.389364
InnerLR 0.481801
FineTuningLR 0.078708
Epoch 11 | Batch 60/100 | Loss 5.466177
InnerLR 0.481622
FineTuningLR 0.079008
Epoch 11 | Batch 70/100 | Loss 5.521000
InnerLR 0.481484
FineTuningLR 0.079208
Epoch 11 | Batch 80/100 | Loss 5.516580
InnerLR 0.481255
FineTuningLR 0.079508
Epoch 11 | Batch 90/100 | Loss 5.543491
InnerLR 0.481150
FineTuningLR 0.079708
100 Accuracy = 43.97% +- 2.35%
Epoch 11: 43.97
Epoch 12 | Batch 0/100 | Loss 7.641264
InnerLR 0.481005
FineTuningLR 0.080008
Epoch 12 | Batch 10/100 | Loss 5.215384
InnerLR 0.480908
FineTuningLR 0.080208
Epoch 12 | Batch 20/100 | Loss 5.108217
InnerLR 0.480727
FineTuningLR 0.080508
Epoch 12 | Batch 30/100 | Loss 5.573175
InnerLR 0.480625
FineTuningLR 0.080708
Epoch 12 | Batch 40/100 | Loss 5.426682
InnerLR 0.480477
FineTuningLR 0.081008
Epoch 12 | Batch 50/100 | Loss 5.472495
InnerLR 0.480366
FineTuningLR 0.081208
Epoch 12 | Batch 60/100 | Loss 5.519567
InnerLR 0.480168
FineTuningLR 0.081508
Epoch 12 | Batch 70/100 | Loss 5.473784
InnerLR 0.480021
FineTuningLR 0.081709
Epoch 12 | Batch 80/100 | Loss 5.439240
InnerLR 0.479801
FineTuningLR 0.082009
Epoch 12 | Batch 90/100 | Loss 5.589380
InnerLR 0.479686
FineTuningLR 0.082209
100 Accuracy = 45.36% +- 2.47%
Epoch 12: 45.36
best model! save...
Epoch 13 | Batch 0/100 | Loss 6.465363
InnerLR 0.479511
FineTuningLR 0.082508
Epoch 13 | Batch 10/100 | Loss 5.624164
InnerLR 0.479374
FineTuningLR 0.082708
Epoch 13 | Batch 20/100 | Loss 5.454542
InnerLR 0.479147
FineTuningLR 0.083008
Epoch 13 | Batch 30/100 | Loss 5.348832
InnerLR 0.478984
FineTuningLR 0.083208
Epoch 13 | Batch 40/100 | Loss 5.353930
InnerLR 0.478728
FineTuningLR 0.083508
Epoch 13 | Batch 50/100 | Loss 5.280702
InnerLR 0.478570
FineTuningLR 0.083708
Epoch 13 | Batch 60/100 | Loss 5.380914
InnerLR 0.478364
FineTuningLR 0.084008
Epoch 13 | Batch 70/100 | Loss 5.425569
InnerLR 0.478236
FineTuningLR 0.084208
Epoch 13 | Batch 80/100 | Loss 5.363732
InnerLR 0.478081
FineTuningLR 0.084513
Epoch 13 | Batch 90/100 | Loss 5.366424
InnerLR 0.477961
FineTuningLR 0.084720
100 Accuracy = 44.92% +- 2.34%
Epoch 13: 44.92
Epoch 14 | Batch 0/100 | Loss 6.306280
InnerLR 0.477791
FineTuningLR 0.085028
Epoch 14 | Batch 10/100 | Loss 5.753650
InnerLR 0.477668
FineTuningLR 0.085232
Epoch 14 | Batch 20/100 | Loss 5.139711
InnerLR 0.477516
FineTuningLR 0.085536
Epoch 14 | Batch 30/100 | Loss 4.882990
InnerLR 0.477465
FineTuningLR 0.085738
Epoch 14 | Batch 40/100 | Loss 4.698853
InnerLR 0.477337
FineTuningLR 0.086040
Epoch 14 | Batch 50/100 | Loss 4.835106
InnerLR 0.477225
FineTuningLR 0.086241
Epoch 14 | Batch 60/100 | Loss 4.700982
InnerLR 0.477046
FineTuningLR 0.086542
Epoch 14 | Batch 70/100 | Loss 4.771331
InnerLR 0.476932
FineTuningLR 0.086743
Epoch 14 | Batch 80/100 | Loss 4.993208
InnerLR 0.476731
FineTuningLR 0.087043
Epoch 14 | Batch 90/100 | Loss 5.046686
InnerLR 0.476640
FineTuningLR 0.087243
100 Accuracy = 44.33% +- 2.34%
Epoch 14: 44.33
Epoch 15 | Batch 0/100 | Loss 5.809588
InnerLR 0.476565
FineTuningLR 0.087543
Epoch 15 | Batch 10/100 | Loss 5.441398
InnerLR 0.476505
FineTuningLR 0.087743
Epoch 15 | Batch 20/100 | Loss 5.536991
InnerLR 0.476420
FineTuningLR 0.088043
Epoch 15 | Batch 30/100 | Loss 5.231619
InnerLR 0.476329
FineTuningLR 0.088243
Epoch 15 | Batch 40/100 | Loss 5.177290
InnerLR 0.476156
FineTuningLR 0.088543
Epoch 15 | Batch 50/100 | Loss 5.148754
InnerLR 0.476021
FineTuningLR 0.088742
Epoch 15 | Batch 60/100 | Loss 5.182923
InnerLR 0.475815
FineTuningLR 0.089042
Epoch 15 | Batch 70/100 | Loss 5.190309
InnerLR 0.475688
FineTuningLR 0.089242
Epoch 15 | Batch 80/100 | Loss 5.207719
InnerLR 0.475471
FineTuningLR 0.089541
Epoch 15 | Batch 90/100 | Loss 5.248386
InnerLR 0.475314
FineTuningLR 0.089741
100 Accuracy = 44.45% +- 2.29%
Epoch 15: 44.45
Epoch 16 | Batch 0/100 | Loss 5.909256
InnerLR 0.475083
FineTuningLR 0.090040
Epoch 16 | Batch 10/100 | Loss 5.646692
InnerLR 0.475000
FineTuningLR 0.090240
Epoch 16 | Batch 20/100 | Loss 5.345984
InnerLR 0.474916
FineTuningLR 0.090540
Epoch 16 | Batch 30/100 | Loss 5.250031
InnerLR 0.474826
FineTuningLR 0.090739
Epoch 16 | Batch 40/100 | Loss 5.396115
InnerLR 0.474673
FineTuningLR 0.091039
Epoch 16 | Batch 50/100 | Loss 5.463218
InnerLR 0.474592
FineTuningLR 0.091238
Epoch 16 | Batch 60/100 | Loss 5.407995
InnerLR 0.474455
FineTuningLR 0.091538
Epoch 16 | Batch 70/100 | Loss 5.365515
InnerLR 0.474338
FineTuningLR 0.091738
Epoch 16 | Batch 80/100 | Loss 5.426124
InnerLR 0.474173
FineTuningLR 0.092037
Epoch 16 | Batch 90/100 | Loss 5.394858
InnerLR 0.474053
FineTuningLR 0.092237
100 Accuracy = 44.87% +- 2.45%
Epoch 16: 44.87
Epoch 17 | Batch 0/100 | Loss 7.534641
InnerLR 0.473845
FineTuningLR 0.092536
Epoch 17 | Batch 10/100 | Loss 5.038195
InnerLR 0.473692
FineTuningLR 0.092736
Epoch 17 | Batch 20/100 | Loss 4.725002
InnerLR 0.473446
FineTuningLR 0.093035
Epoch 17 | Batch 30/100 | Loss 5.028335
InnerLR 0.473274
FineTuningLR 0.093235
Epoch 17 | Batch 40/100 | Loss 5.030908
InnerLR 0.473006
FineTuningLR 0.093535
Epoch 17 | Batch 50/100 | Loss 5.088945
InnerLR 0.472860
FineTuningLR 0.093734
Epoch 17 | Batch 60/100 | Loss 5.164724
InnerLR 0.472677
FineTuningLR 0.094034
Epoch 17 | Batch 70/100 | Loss 5.073611
InnerLR 0.472536
FineTuningLR 0.094234
Epoch 17 | Batch 80/100 | Loss 5.129954
InnerLR 0.472343
FineTuningLR 0.094533
Epoch 17 | Batch 90/100 | Loss 5.130947
InnerLR 0.472247
FineTuningLR 0.094733
100 Accuracy = 46.41% +- 2.30%
Epoch 17: 46.41
best model! save...
Epoch 18 | Batch 0/100 | Loss 6.338784
InnerLR 0.472067
FineTuningLR 0.095032
Epoch 18 | Batch 10/100 | Loss 5.347143
InnerLR 0.471967
FineTuningLR 0.095232
Epoch 18 | Batch 20/100 | Loss 5.888328
InnerLR 0.471781
FineTuningLR 0.095532
Epoch 18 | Batch 30/100 | Loss 5.839493
InnerLR 0.471660
FineTuningLR 0.095731
Epoch 18 | Batch 40/100 | Loss 5.744916
InnerLR 0.471476
FineTuningLR 0.096031
Epoch 18 | Batch 50/100 | Loss 5.536232
InnerLR 0.471336
FineTuningLR 0.096231
Epoch 18 | Batch 60/100 | Loss 5.409123
InnerLR 0.471142
FineTuningLR 0.096530
Epoch 18 | Batch 70/100 | Loss 5.329804
InnerLR 0.471008
FineTuningLR 0.096730
Epoch 18 | Batch 80/100 | Loss 5.299403
InnerLR 0.470842
FineTuningLR 0.097029
Epoch 18 | Batch 90/100 | Loss 5.261171
InnerLR 0.470746
FineTuningLR 0.097229
100 Accuracy = 46.61% +- 2.30%
Epoch 18: 46.61
best model! save...
Epoch 19 | Batch 0/100 | Loss 6.179628
InnerLR 0.470604
FineTuningLR 0.097538
Epoch 19 | Batch 10/100 | Loss 5.417739
InnerLR 0.470485
FineTuningLR 0.097742
Epoch 19 | Batch 20/100 | Loss 5.037107
InnerLR 0.470333
FineTuningLR 0.098047
Epoch 19 | Batch 30/100 | Loss 4.908514
InnerLR 0.470228
FineTuningLR 0.098249
Epoch 19 | Batch 40/100 | Loss 4.830894
InnerLR 0.470064
FineTuningLR 0.098552
Epoch 19 | Batch 50/100 | Loss 4.725644
InnerLR 0.469991
FineTuningLR 0.098753
Epoch 19 | Batch 60/100 | Loss 4.772145
InnerLR 0.469902
FineTuningLR 0.099054
Epoch 19 | Batch 70/100 | Loss 4.609679
InnerLR 0.469841
FineTuningLR 0.099255
Epoch 19 | Batch 80/100 | Loss 4.627218
InnerLR 0.469728
FineTuningLR 0.099555
Epoch 19 | Batch 90/100 | Loss 4.565795
InnerLR 0.469661
FineTuningLR 0.099755
100 Accuracy = 45.13% +- 2.37%
Epoch 19: 45.13
Epoch 20 | Batch 0/100 | Loss 4.281903
InnerLR 0.469534
FineTuningLR 0.100055
Epoch 20 | Batch 10/100 | Loss 4.558027
InnerLR 0.469485
FineTuningLR 0.100255
Epoch 20 | Batch 20/100 | Loss 4.797126
InnerLR 0.469359
FineTuningLR 0.100555
Epoch 20 | Batch 30/100 | Loss 4.662501
InnerLR 0.469248
FineTuningLR 0.100754
Epoch 20 | Batch 40/100 | Loss 4.600272
InnerLR 0.469051
FineTuningLR 0.101054
Epoch 20 | Batch 50/100 | Loss 4.646239
InnerLR 0.468903
FineTuningLR 0.101254
Epoch 20 | Batch 60/100 | Loss 4.523306
InnerLR 0.468738
FineTuningLR 0.101553
Epoch 20 | Batch 70/100 | Loss 4.599708
InnerLR 0.468630
FineTuningLR 0.101753
Epoch 20 | Batch 80/100 | Loss 4.621573
InnerLR 0.468437
FineTuningLR 0.102052
Epoch 20 | Batch 90/100 | Loss 4.609476
InnerLR 0.468292
FineTuningLR 0.102252
100 Accuracy = 46.20% +- 2.28%
Epoch 20: 46.20
Epoch 21 | Batch 0/100 | Loss 4.637309
InnerLR 0.468055
FineTuningLR 0.102551
Epoch 21 | Batch 10/100 | Loss 4.963217
InnerLR 0.467887
FineTuningLR 0.102751
Epoch 21 | Batch 20/100 | Loss 4.648443
InnerLR 0.467678
FineTuningLR 0.103050
Epoch 21 | Batch 30/100 | Loss 5.019719
InnerLR 0.467563
FineTuningLR 0.103250
Epoch 21 | Batch 40/100 | Loss 4.713882
InnerLR 0.467380
FineTuningLR 0.103549
Epoch 21 | Batch 50/100 | Loss 4.703049
InnerLR 0.467265
FineTuningLR 0.103749
Epoch 21 | Batch 60/100 | Loss 4.719341
InnerLR 0.467061
FineTuningLR 0.104048
Epoch 21 | Batch 70/100 | Loss 4.601296
InnerLR 0.466949
FineTuningLR 0.104248
Epoch 21 | Batch 80/100 | Loss 4.634439
InnerLR 0.466842
FineTuningLR 0.104547
Epoch 21 | Batch 90/100 | Loss 4.620392
InnerLR 0.466791
FineTuningLR 0.104747
100 Accuracy = 44.73% +- 2.63%
Epoch 21: 44.73
Epoch 22 | Batch 0/100 | Loss 2.999971
InnerLR 0.466720
FineTuningLR 0.105046
Epoch 22 | Batch 10/100 | Loss 5.386125
InnerLR 0.466672
FineTuningLR 0.105246
Epoch 22 | Batch 20/100 | Loss 5.142600
InnerLR 0.466603
FineTuningLR 0.105545
Epoch 22 | Batch 30/100 | Loss 5.094463
InnerLR 0.466520
FineTuningLR 0.105745
Epoch 22 | Batch 40/100 | Loss 5.125568
InnerLR 0.466356
FineTuningLR 0.106044
Epoch 22 | Batch 50/100 | Loss 5.107027
InnerLR 0.466225
FineTuningLR 0.106244
Epoch 22 | Batch 60/100 | Loss 5.074847
InnerLR 0.466005
FineTuningLR 0.106543
Epoch 22 | Batch 70/100 | Loss 5.154733
InnerLR 0.465846
FineTuningLR 0.106743
Epoch 22 | Batch 80/100 | Loss 5.091402
InnerLR 0.465631
FineTuningLR 0.107042
Epoch 22 | Batch 90/100 | Loss 5.054218
InnerLR 0.465486
FineTuningLR 0.107242
100 Accuracy = 46.17% +- 2.06%
Epoch 22: 46.17
Epoch 23 | Batch 0/100 | Loss 5.149596
InnerLR 0.465269
FineTuningLR 0.107541
Epoch 23 | Batch 10/100 | Loss 5.835027
InnerLR 0.465135
FineTuningLR 0.107741
Epoch 23 | Batch 20/100 | Loss 5.717236
InnerLR 0.464912
FineTuningLR 0.108040
Epoch 23 | Batch 30/100 | Loss 5.510363
InnerLR 0.464789
FineTuningLR 0.108240
Epoch 23 | Batch 40/100 | Loss 5.664415
InnerLR 0.464598
FineTuningLR 0.108539
Epoch 23 | Batch 50/100 | Loss 5.368468
InnerLR 0.464478
FineTuningLR 0.108739
Epoch 23 | Batch 60/100 | Loss 5.266402
InnerLR 0.464324
FineTuningLR 0.109038
Epoch 23 | Batch 70/100 | Loss 5.146335
InnerLR 0.464199
FineTuningLR 0.109238
Epoch 23 | Batch 80/100 | Loss 5.110403
InnerLR 0.464039
FineTuningLR 0.109537
Epoch 23 | Batch 90/100 | Loss 5.134417
InnerLR 0.463911
FineTuningLR 0.109737
100 Accuracy = 45.81% +- 2.37%
Epoch 23: 45.81
Epoch 24 | Batch 0/100 | Loss 5.062916
InnerLR 0.463693
FineTuningLR 0.110036
Epoch 24 | Batch 10/100 | Loss 4.469798
InnerLR 0.463535
FineTuningLR 0.110236
Epoch 24 | Batch 20/100 | Loss 4.411913
InnerLR 0.463358
FineTuningLR 0.110535
Epoch 24 | Batch 30/100 | Loss 4.673146
InnerLR 0.463265
FineTuningLR 0.110735
Epoch 24 | Batch 40/100 | Loss 4.756238
InnerLR 0.463227
FineTuningLR 0.111034
Epoch 24 | Batch 50/100 | Loss 4.733564
InnerLR 0.463196
FineTuningLR 0.111234
Epoch 24 | Batch 60/100 | Loss 4.633245
InnerLR 0.463091
FineTuningLR 0.111533
Epoch 24 | Batch 70/100 | Loss 4.630310
InnerLR 0.462990
FineTuningLR 0.111733
Epoch 24 | Batch 80/100 | Loss 4.523784
InnerLR 0.462859
FineTuningLR 0.112033
Epoch 24 | Batch 90/100 | Loss 4.542898
InnerLR 0.462784
FineTuningLR 0.112232
100 Accuracy = 45.35% +- 2.48%
Epoch 24: 45.35
Epoch 25 | Batch 0/100 | Loss 5.355783
InnerLR 0.462628
FineTuningLR 0.112532
Epoch 25 | Batch 10/100 | Loss 4.744095
InnerLR 0.462501
FineTuningLR 0.112731
Epoch 25 | Batch 20/100 | Loss 4.811608
InnerLR 0.462324
FineTuningLR 0.113031
Epoch 25 | Batch 30/100 | Loss 4.675849
InnerLR 0.462198
FineTuningLR 0.113230
Epoch 25 | Batch 40/100 | Loss 4.755873
InnerLR 0.462041
FineTuningLR 0.113530
Epoch 25 | Batch 50/100 | Loss 4.711834
InnerLR 0.461950
FineTuningLR 0.113730
Epoch 25 | Batch 60/100 | Loss 4.682692
InnerLR 0.461775
FineTuningLR 0.114029
Epoch 25 | Batch 70/100 | Loss 4.840486
InnerLR 0.461639
FineTuningLR 0.114229
Epoch 25 | Batch 80/100 | Loss 4.776276
InnerLR 0.461467
FineTuningLR 0.114528
Epoch 25 | Batch 90/100 | Loss 4.729143
InnerLR 0.461333
FineTuningLR 0.114728
100 Accuracy = 45.77% +- 2.51%
Epoch 25: 45.77
Epoch 26 | Batch 0/100 | Loss 4.734841
InnerLR 0.461146
FineTuningLR 0.115027
Epoch 26 | Batch 10/100 | Loss 5.280784
InnerLR 0.461016
FineTuningLR 0.115227
Epoch 26 | Batch 20/100 | Loss 4.599761
InnerLR 0.460850
FineTuningLR 0.115527
Epoch 26 | Batch 30/100 | Loss 4.658562
InnerLR 0.460757
FineTuningLR 0.115726
Epoch 26 | Batch 40/100 | Loss 4.910056
InnerLR 0.460580
FineTuningLR 0.116026
Epoch 26 | Batch 50/100 | Loss 4.996688
InnerLR 0.460442
FineTuningLR 0.116225
Epoch 26 | Batch 60/100 | Loss 4.827168
InnerLR 0.460215
FineTuningLR 0.116525
Epoch 26 | Batch 70/100 | Loss 4.702782
InnerLR 0.460052
FineTuningLR 0.116725
Epoch 26 | Batch 80/100 | Loss 4.667854
InnerLR 0.459833
FineTuningLR 0.117024
Epoch 26 | Batch 90/100 | Loss 4.690820
InnerLR 0.459685
FineTuningLR 0.117224
100 Accuracy = 45.79% +- 2.53%
Epoch 26: 45.79
Epoch 27 | Batch 0/100 | Loss 3.025196
InnerLR 0.459446
FineTuningLR 0.117523
Epoch 27 | Batch 10/100 | Loss 4.606665
InnerLR 0.459277
FineTuningLR 0.117723
Epoch 27 | Batch 20/100 | Loss 4.963070
InnerLR 0.459050
FineTuningLR 0.118023
Epoch 27 | Batch 30/100 | Loss 4.815150
InnerLR 0.458899
FineTuningLR 0.118222
Epoch 27 | Batch 40/100 | Loss 4.717235
InnerLR 0.458656
FineTuningLR 0.118522
Epoch 27 | Batch 50/100 | Loss 4.534269
InnerLR 0.458484
FineTuningLR 0.118722
Epoch 27 | Batch 60/100 | Loss 4.407921
InnerLR 0.458217
FineTuningLR 0.119021
Epoch 27 | Batch 70/100 | Loss 4.503801
InnerLR 0.458054
FineTuningLR 0.119221
Epoch 27 | Batch 80/100 | Loss 4.513510
InnerLR 0.457823
FineTuningLR 0.119520
Epoch 27 | Batch 90/100 | Loss 4.487553
InnerLR 0.457657
FineTuningLR 0.119720
100 Accuracy = 48.55% +- 2.55%
Epoch 27: 48.55
best model! save...
Epoch 28 | Batch 0/100 | Loss 2.502649
InnerLR 0.457452
FineTuningLR 0.120020
Epoch 28 | Batch 10/100 | Loss 4.075815
InnerLR 0.457300
FineTuningLR 0.120219
Epoch 28 | Batch 20/100 | Loss 4.415922
InnerLR 0.457056
FineTuningLR 0.120519
Epoch 28 | Batch 30/100 | Loss 4.544874
InnerLR 0.456884
FineTuningLR 0.120719
Epoch 28 | Batch 40/100 | Loss 4.521068
InnerLR 0.456636
FineTuningLR 0.121018
Epoch 28 | Batch 50/100 | Loss 4.437819
InnerLR 0.456486
FineTuningLR 0.121219
Epoch 28 | Batch 60/100 | Loss 4.339738
InnerLR 0.456302
FineTuningLR 0.121519
Epoch 28 | Batch 70/100 | Loss 4.337147
InnerLR 0.456197
FineTuningLR 0.121719
Epoch 28 | Batch 80/100 | Loss 4.256833
InnerLR 0.456006
FineTuningLR 0.122019
Epoch 28 | Batch 90/100 | Loss 4.171634
InnerLR 0.455862
FineTuningLR 0.122219
100 Accuracy = 47.85% +- 2.28%
Epoch 28: 47.85
Epoch 29 | Batch 0/100 | Loss 2.836388
InnerLR 0.455626
FineTuningLR 0.122519
Epoch 29 | Batch 10/100 | Loss 3.461769
InnerLR 0.455497
FineTuningLR 0.122719
Epoch 29 | Batch 20/100 | Loss 3.638639
InnerLR 0.455278
FineTuningLR 0.123019
Epoch 29 | Batch 30/100 | Loss 3.741594
InnerLR 0.455120
FineTuningLR 0.123218
Epoch 29 | Batch 40/100 | Loss 3.861737
InnerLR 0.454888
FineTuningLR 0.123518
Epoch 29 | Batch 50/100 | Loss 3.908555
InnerLR 0.454747
FineTuningLR 0.123718
Epoch 29 | Batch 60/100 | Loss 4.052517
InnerLR 0.454515
FineTuningLR 0.124017
Epoch 29 | Batch 70/100 | Loss 4.020148
InnerLR 0.454349
FineTuningLR 0.124217
Epoch 29 | Batch 80/100 | Loss 3.959951
InnerLR 0.454089
FineTuningLR 0.124517
Epoch 29 | Batch 90/100 | Loss 3.970225
InnerLR 0.453909
FineTuningLR 0.124716
100 Accuracy = 46.43% +- 2.33%
Epoch 29: 46.43
Epoch 30 | Batch 0/100 | Loss 2.082613
InnerLR 0.453633
FineTuningLR 0.125016
Epoch 30 | Batch 10/100 | Loss 3.226722
InnerLR 0.453483
FineTuningLR 0.125216
Epoch 30 | Batch 20/100 | Loss 4.092711
InnerLR 0.453240
FineTuningLR 0.125515
Epoch 30 | Batch 30/100 | Loss 4.144679
InnerLR 0.453070
FineTuningLR 0.125715
Epoch 30 | Batch 40/100 | Loss 4.145682
InnerLR 0.452804
FineTuningLR 0.126015
Epoch 30 | Batch 50/100 | Loss 4.211272
InnerLR 0.452621
FineTuningLR 0.126214
Epoch 30 | Batch 60/100 | Loss 4.222984
InnerLR 0.452379
FineTuningLR 0.126514
Epoch 30 | Batch 70/100 | Loss 4.116302
InnerLR 0.452220
FineTuningLR 0.126714
Epoch 30 | Batch 80/100 | Loss 4.004367
InnerLR 0.451967
FineTuningLR 0.127013
Epoch 30 | Batch 90/100 | Loss 4.039002
InnerLR 0.451791
FineTuningLR 0.127213
100 Accuracy = 46.27% +- 2.33%
Epoch 30: 46.27
Epoch 31 | Batch 0/100 | Loss 2.827805
InnerLR 0.451518
FineTuningLR 0.127513
Epoch 31 | Batch 10/100 | Loss 3.806874
InnerLR 0.451371
FineTuningLR 0.127713
Epoch 31 | Batch 20/100 | Loss 3.640912
InnerLR 0.451169
FineTuningLR 0.128012
Epoch 31 | Batch 30/100 | Loss 3.702822
InnerLR 0.451068
FineTuningLR 0.128212
Epoch 31 | Batch 40/100 | Loss 3.597321
InnerLR 0.450937
FineTuningLR 0.128511
Epoch 31 | Batch 50/100 | Loss 3.474584
InnerLR 0.450824
FineTuningLR 0.128711
Epoch 31 | Batch 60/100 | Loss 3.641918
InnerLR 0.450624
FineTuningLR 0.129011
Epoch 31 | Batch 70/100 | Loss 3.687767
InnerLR 0.450475
FineTuningLR 0.129211
Epoch 31 | Batch 80/100 | Loss 3.689394
InnerLR 0.450233
FineTuningLR 0.129510
Epoch 31 | Batch 90/100 | Loss 3.655364
InnerLR 0.450063
FineTuningLR 0.129710
100 Accuracy = 46.44% +- 2.30%
Epoch 31: 46.44
Epoch 32 | Batch 0/100 | Loss 4.446860
InnerLR 0.449798
FineTuningLR 0.130009
Epoch 32 | Batch 10/100 | Loss 4.302453
InnerLR 0.449615
FineTuningLR 0.130209
Epoch 32 | Batch 20/100 | Loss 4.356524
InnerLR 0.449374
FineTuningLR 0.130509
Epoch 32 | Batch 30/100 | Loss 4.328756
InnerLR 0.449215
FineTuningLR 0.130709
Epoch 32 | Batch 40/100 | Loss 4.232690
InnerLR 0.448962
FineTuningLR 0.131008
Epoch 32 | Batch 50/100 | Loss 4.319767
InnerLR 0.448786
FineTuningLR 0.131208
Epoch 32 | Batch 60/100 | Loss 4.209126
InnerLR 0.448552
FineTuningLR 0.131507
Epoch 32 | Batch 70/100 | Loss 4.165260
InnerLR 0.448397
FineTuningLR 0.131707
Epoch 32 | Batch 80/100 | Loss 4.071442
InnerLR 0.448149
FineTuningLR 0.132007
Epoch 32 | Batch 90/100 | Loss 4.029319
InnerLR 0.447976
FineTuningLR 0.132207
100 Accuracy = 49.93% +- 2.32%
Epoch 32: 49.93
best model! save...
Epoch 33 | Batch 0/100 | Loss 5.514831
InnerLR 0.447706
FineTuningLR 0.132506
Epoch 33 | Batch 10/100 | Loss 4.289258
InnerLR 0.447580
FineTuningLR 0.132706
Epoch 33 | Batch 20/100 | Loss 4.446030
InnerLR 0.447390
FineTuningLR 0.133006
Epoch 33 | Batch 30/100 | Loss 4.395836
InnerLR 0.447285
FineTuningLR 0.133205
Epoch 33 | Batch 40/100 | Loss 4.275270
InnerLR 0.447094
FineTuningLR 0.133505
Epoch 33 | Batch 50/100 | Loss 4.197396
InnerLR 0.446950
FineTuningLR 0.133705
Epoch 33 | Batch 60/100 | Loss 4.260526
InnerLR 0.446768
FineTuningLR 0.134004
Epoch 33 | Batch 70/100 | Loss 4.228940
InnerLR 0.446629
FineTuningLR 0.134204
Epoch 33 | Batch 80/100 | Loss 4.254385
InnerLR 0.446419
FineTuningLR 0.134504
Epoch 33 | Batch 90/100 | Loss 4.239999
InnerLR 0.446289
FineTuningLR 0.134704
100 Accuracy = 47.57% +- 2.23%
Epoch 33: 47.57
Epoch 34 | Batch 0/100 | Loss 3.831992
InnerLR 0.446069
FineTuningLR 0.135003
Epoch 34 | Batch 10/100 | Loss 4.154478
InnerLR 0.445930
FineTuningLR 0.135211
Epoch 34 | Batch 20/100 | Loss 3.949507
InnerLR 0.445701
FineTuningLR 0.135519
Epoch 34 | Batch 30/100 | Loss 4.281195
InnerLR 0.445537
FineTuningLR 0.135723
Epoch 34 | Batch 40/100 | Loss 3.980191
InnerLR 0.445278
FineTuningLR 0.136028
Epoch 34 | Batch 50/100 | Loss 3.829756
InnerLR 0.445099
FineTuningLR 0.136230
Epoch 34 | Batch 60/100 | Loss 3.912743
InnerLR 0.444824
FineTuningLR 0.136533
Epoch 34 | Batch 70/100 | Loss 3.985674
InnerLR 0.444636
FineTuningLR 0.136734
Epoch 34 | Batch 80/100 | Loss 3.941940
InnerLR 0.444350
FineTuningLR 0.137035
Epoch 34 | Batch 90/100 | Loss 3.915418
InnerLR 0.444177
FineTuningLR 0.137236
100 Accuracy = 46.49% +- 2.45%
Epoch 34: 46.49
Epoch 35 | Batch 0/100 | Loss 6.099625
InnerLR 0.443934
FineTuningLR 0.137536
Epoch 35 | Batch 10/100 | Loss 4.033993
InnerLR 0.443763
FineTuningLR 0.137737
Epoch 35 | Batch 20/100 | Loss 4.077849
InnerLR 0.443516
FineTuningLR 0.138037
Epoch 35 | Batch 30/100 | Loss 4.150098
InnerLR 0.443368
FineTuningLR 0.138237
Epoch 35 | Batch 40/100 | Loss 4.150777
InnerLR 0.443147
FineTuningLR 0.138536
Epoch 35 | Batch 50/100 | Loss 4.332068
InnerLR 0.443049
FineTuningLR 0.138736
Epoch 35 | Batch 60/100 | Loss 4.204958
InnerLR 0.442922
FineTuningLR 0.139036
Epoch 35 | Batch 70/100 | Loss 4.249378
InnerLR 0.442810
FineTuningLR 0.139235
Epoch 35 | Batch 80/100 | Loss 4.310250
InnerLR 0.442611
FineTuningLR 0.139535
Epoch 35 | Batch 90/100 | Loss 4.228226
InnerLR 0.442463
FineTuningLR 0.139735
100 Accuracy = 47.16% +- 2.55%
Epoch 35: 47.16
Epoch 36 | Batch 0/100 | Loss 2.464432
InnerLR 0.442243
FineTuningLR 0.140034
Epoch 36 | Batch 10/100 | Loss 4.197459
InnerLR 0.442108
FineTuningLR 0.140234
Epoch 36 | Batch 20/100 | Loss 4.023515
InnerLR 0.441883
FineTuningLR 0.140533
Epoch 36 | Batch 30/100 | Loss 3.799783
InnerLR 0.441759
FineTuningLR 0.140733
Epoch 36 | Batch 40/100 | Loss 3.754533
InnerLR 0.441601
FineTuningLR 0.141032
Epoch 36 | Batch 50/100 | Loss 3.712235
InnerLR 0.441473
FineTuningLR 0.141232
Epoch 36 | Batch 60/100 | Loss 3.757219
InnerLR 0.441257
FineTuningLR 0.141532
Epoch 36 | Batch 70/100 | Loss 3.731528
InnerLR 0.441100
FineTuningLR 0.141731
Epoch 36 | Batch 80/100 | Loss 3.681567
InnerLR 0.440903
FineTuningLR 0.142031
Epoch 36 | Batch 90/100 | Loss 3.690904
InnerLR 0.440794
FineTuningLR 0.142230
100 Accuracy = 45.63% +- 2.32%
Epoch 36: 45.63
Epoch 37 | Batch 0/100 | Loss 3.273604
InnerLR 0.440599
FineTuningLR 0.142530
Epoch 37 | Batch 10/100 | Loss 4.072833
InnerLR 0.440453
FineTuningLR 0.142729
Epoch 37 | Batch 20/100 | Loss 4.088162
InnerLR 0.440234
FineTuningLR 0.143029
Epoch 37 | Batch 30/100 | Loss 4.158850
InnerLR 0.440100
FineTuningLR 0.143229
Epoch 37 | Batch 40/100 | Loss 4.095849
InnerLR 0.439876
FineTuningLR 0.143528
Epoch 37 | Batch 50/100 | Loss 4.082585
InnerLR 0.439714
FineTuningLR 0.143728
Epoch 37 | Batch 60/100 | Loss 3.949620
InnerLR 0.439459
FineTuningLR 0.144027
Epoch 37 | Batch 70/100 | Loss 3.957759
InnerLR 0.439282
FineTuningLR 0.144227
Epoch 37 | Batch 80/100 | Loss 3.990806
InnerLR 0.439008
FineTuningLR 0.144526
Epoch 37 | Batch 90/100 | Loss 3.990243
InnerLR 0.438821
FineTuningLR 0.144726
100 Accuracy = 48.96% +- 2.64%
Epoch 37: 48.96
Epoch 38 | Batch 0/100 | Loss 3.041004
InnerLR 0.438536
FineTuningLR 0.145025
Epoch 38 | Batch 10/100 | Loss 3.105541
InnerLR 0.438364
FineTuningLR 0.145225
Epoch 38 | Batch 20/100 | Loss 3.361934
InnerLR 0.438122
FineTuningLR 0.145525
Epoch 38 | Batch 30/100 | Loss 3.498995
InnerLR 0.437951
FineTuningLR 0.145724
Epoch 38 | Batch 40/100 | Loss 3.482401
InnerLR 0.437739
FineTuningLR 0.146024
Epoch 38 | Batch 50/100 | Loss 3.658240
InnerLR 0.437584
FineTuningLR 0.146223
Epoch 38 | Batch 60/100 | Loss 3.643922
InnerLR 0.437336
FineTuningLR 0.146469
Epoch 38 | Batch 70/100 | Loss 3.661286
InnerLR 0.437162
FineTuningLR 0.146641
Epoch 38 | Batch 80/100 | Loss 3.789157
InnerLR 0.436893
FineTuningLR 0.146908
Epoch 38 | Batch 90/100 | Loss 3.767313
InnerLR 0.436708
FineTuningLR 0.147092
100 Accuracy = 47.09% +- 2.50%
Epoch 38: 47.09
Epoch 39 | Batch 0/100 | Loss 3.164606
InnerLR 0.436446
FineTuningLR 0.147372
Epoch 39 | Batch 10/100 | Loss 2.943949
InnerLR 0.436289
FineTuningLR 0.147562
Epoch 39 | Batch 20/100 | Loss 3.393507
InnerLR 0.436093
FineTuningLR 0.147850
Epoch 39 | Batch 30/100 | Loss 3.678975
InnerLR 0.435947
FineTuningLR 0.148044
Epoch 39 | Batch 40/100 | Loss 3.707847
InnerLR 0.435708
FineTuningLR 0.148337
Epoch 39 | Batch 50/100 | Loss 3.724311
InnerLR 0.435575
FineTuningLR 0.148535
Epoch 39 | Batch 60/100 | Loss 3.678147
InnerLR 0.435353
FineTuningLR 0.148833
Epoch 39 | Batch 70/100 | Loss 3.704048
InnerLR 0.435194
FineTuningLR 0.149033
Epoch 39 | Batch 80/100 | Loss 3.705561
InnerLR 0.434940
FineTuningLR 0.149332
Epoch 39 | Batch 90/100 | Loss 3.676361
InnerLR 0.434764
FineTuningLR 0.149532
100 Accuracy = 49.00% +- 2.53%
Epoch 39: 49.00
Epoch 40 | Batch 0/100 | Loss 1.965385
InnerLR 0.434492
FineTuningLR 0.149832
Epoch 40 | Batch 10/100 | Loss 3.915414
InnerLR 0.434306
FineTuningLR 0.150031
Epoch 40 | Batch 20/100 | Loss 3.650181
InnerLR 0.434042
FineTuningLR 0.150331
Epoch 40 | Batch 30/100 | Loss 3.509851
InnerLR 0.433884
FineTuningLR 0.150530
Epoch 40 | Batch 40/100 | Loss 3.727643
InnerLR 0.433687
FineTuningLR 0.150830
Epoch 40 | Batch 50/100 | Loss 3.835540
InnerLR 0.433540
FineTuningLR 0.151029
Epoch 40 | Batch 60/100 | Loss 3.868395
InnerLR 0.433300
FineTuningLR 0.151329
Epoch 40 | Batch 70/100 | Loss 3.850096
InnerLR 0.433131
FineTuningLR 0.151529
Epoch 40 | Batch 80/100 | Loss 3.832000
InnerLR 0.432921
FineTuningLR 0.151828
Epoch 40 | Batch 90/100 | Loss 3.814232
InnerLR 0.432805
FineTuningLR 0.152028
100 Accuracy = 46.97% +- 2.55%
Epoch 40: 46.97
Epoch 41 | Batch 0/100 | Loss 2.558716
InnerLR 0.432656
FineTuningLR 0.152327
Epoch 41 | Batch 10/100 | Loss 3.715587
InnerLR 0.432533
FineTuningLR 0.152527
Epoch 41 | Batch 20/100 | Loss 4.220835
InnerLR 0.432330
FineTuningLR 0.152830
Epoch 41 | Batch 30/100 | Loss 4.055970
InnerLR 0.432189
FineTuningLR 0.153036
Epoch 41 | Batch 40/100 | Loss 3.960751
InnerLR 0.432049
FineTuningLR 0.153344
Epoch 41 | Batch 50/100 | Loss 3.778426
InnerLR 0.431942
FineTuningLR 0.153547
Epoch 41 | Batch 60/100 | Loss 3.858350
InnerLR 0.431750
FineTuningLR 0.153851
Epoch 41 | Batch 70/100 | Loss 3.781356
InnerLR 0.431605
FineTuningLR 0.154053
Epoch 41 | Batch 80/100 | Loss 3.760977
InnerLR 0.431368
FineTuningLR 0.154355
Epoch 41 | Batch 90/100 | Loss 3.757559
InnerLR 0.431200
FineTuningLR 0.154556
100 Accuracy = 50.23% +- 2.55%
Epoch 41: 50.23
best model! save...
Epoch 42 | Batch 0/100 | Loss 2.792344
InnerLR 0.430975
FineTuningLR 0.154857
Epoch 42 | Batch 10/100 | Loss 3.998389
InnerLR 0.430825
FineTuningLR 0.155057
Epoch 42 | Batch 20/100 | Loss 3.826408
InnerLR 0.430602
FineTuningLR 0.155357
Epoch 42 | Batch 30/100 | Loss 3.627397
InnerLR 0.430465
FineTuningLR 0.155557
Epoch 42 | Batch 40/100 | Loss 3.642148
InnerLR 0.430238
FineTuningLR 0.155857
Epoch 42 | Batch 50/100 | Loss 3.567605
InnerLR 0.430096
FineTuningLR 0.156057
Epoch 42 | Batch 60/100 | Loss 3.616065
InnerLR 0.429888
FineTuningLR 0.156356
Epoch 42 | Batch 70/100 | Loss 3.728923
InnerLR 0.429734
FineTuningLR 0.156556
Epoch 42 | Batch 80/100 | Loss 3.707018
InnerLR 0.429508
FineTuningLR 0.156856
Epoch 42 | Batch 90/100 | Loss 3.579658
InnerLR 0.429370
FineTuningLR 0.157055
100 Accuracy = 47.15% +- 2.87%
Epoch 42: 47.15
Epoch 43 | Batch 0/100 | Loss 1.727628
InnerLR 0.429141
FineTuningLR 0.157355
Epoch 43 | Batch 10/100 | Loss 3.340640
InnerLR 0.428977
FineTuningLR 0.157554
Epoch 43 | Batch 20/100 | Loss 3.256175
InnerLR 0.428719
FineTuningLR 0.157854
Epoch 43 | Batch 30/100 | Loss 3.127745
InnerLR 0.428540
FineTuningLR 0.158053
Epoch 43 | Batch 40/100 | Loss 3.034426
InnerLR 0.428265
FineTuningLR 0.158353
Epoch 43 | Batch 50/100 | Loss 3.001025
InnerLR 0.428135
FineTuningLR 0.158552
Epoch 43 | Batch 60/100 | Loss 3.047873
InnerLR 0.427942
FineTuningLR 0.158851
Epoch 43 | Batch 70/100 | Loss 3.029546
InnerLR 0.427835
FineTuningLR 0.159051
Epoch 43 | Batch 80/100 | Loss 3.063654
InnerLR 0.427662
FineTuningLR 0.159350
Epoch 43 | Batch 90/100 | Loss 3.134532
InnerLR 0.427551
FineTuningLR 0.159550
100 Accuracy = 47.84% +- 2.23%
Epoch 43: 47.84
Epoch 44 | Batch 0/100 | Loss 0.769794
InnerLR 0.427391
FineTuningLR 0.159849
Epoch 44 | Batch 10/100 | Loss 3.282997
InnerLR 0.427274
FineTuningLR 0.160049
Epoch 44 | Batch 20/100 | Loss 3.399835
InnerLR 0.427070
FineTuningLR 0.160348
Epoch 44 | Batch 30/100 | Loss 3.578731
InnerLR 0.426939
FineTuningLR 0.160548
Epoch 44 | Batch 40/100 | Loss 3.558174
InnerLR 0.426744
FineTuningLR 0.160847
Epoch 44 | Batch 50/100 | Loss 3.580025
InnerLR 0.426598
FineTuningLR 0.161047
Epoch 44 | Batch 60/100 | Loss 3.468656
InnerLR 0.426414
FineTuningLR 0.161346
Epoch 44 | Batch 70/100 | Loss 3.429767
InnerLR 0.426311
FineTuningLR 0.161545
Epoch 44 | Batch 80/100 | Loss 3.365078
InnerLR 0.426124
FineTuningLR 0.161845
Epoch 44 | Batch 90/100 | Loss 3.425331
InnerLR 0.425981
FineTuningLR 0.162044
100 Accuracy = 49.57% +- 2.49%
Epoch 44: 49.57
Epoch 45 | Batch 0/100 | Loss 9.036521
InnerLR 0.425747
FineTuningLR 0.162344
Epoch 45 | Batch 10/100 | Loss 3.738070
InnerLR 0.425581
FineTuningLR 0.162543
Epoch 45 | Batch 20/100 | Loss 3.438498
InnerLR 0.425320
FineTuningLR 0.162843
Epoch 45 | Batch 30/100 | Loss 3.714059
InnerLR 0.425139
FineTuningLR 0.163042
Epoch 45 | Batch 40/100 | Loss 3.714053
InnerLR 0.424900
FineTuningLR 0.163341
Epoch 45 | Batch 50/100 | Loss 3.663176
InnerLR 0.424780
FineTuningLR 0.163541
Epoch 45 | Batch 60/100 | Loss 3.611370
InnerLR 0.424627
FineTuningLR 0.163840
Epoch 45 | Batch 70/100 | Loss 3.531320
InnerLR 0.424502
FineTuningLR 0.164040
Epoch 45 | Batch 80/100 | Loss 3.578885
InnerLR 0.424289
FineTuningLR 0.164339
Epoch 45 | Batch 90/100 | Loss 3.566895
InnerLR 0.424140
FineTuningLR 0.164543
100 Accuracy = 48.09% +- 2.21%
Epoch 45: 48.09
Epoch 46 | Batch 0/100 | Loss 2.369087
InnerLR 0.423927
FineTuningLR 0.164851
Epoch 46 | Batch 10/100 | Loss 3.926419
InnerLR 0.423816
FineTuningLR 0.165055
Epoch 46 | Batch 20/100 | Loss 3.561001
InnerLR 0.423644
FineTuningLR 0.165360
Epoch 46 | Batch 30/100 | Loss 3.595584
InnerLR 0.423529
FineTuningLR 0.165562
Epoch 46 | Batch 40/100 | Loss 3.594992
InnerLR 0.423354
FineTuningLR 0.165864
Epoch 46 | Batch 50/100 | Loss 3.529201
InnerLR 0.423217
FineTuningLR 0.166066
Epoch 46 | Batch 60/100 | Loss 3.461577
InnerLR 0.423044
FineTuningLR 0.166367
Epoch 46 | Batch 70/100 | Loss 3.456486
InnerLR 0.422909
FineTuningLR 0.166567
Epoch 46 | Batch 80/100 | Loss 3.375961
InnerLR 0.422704
FineTuningLR 0.166867
Epoch 46 | Batch 90/100 | Loss 3.378956
InnerLR 0.422615
FineTuningLR 0.167067
100 Accuracy = 49.23% +- 2.65%
Epoch 46: 49.23
Epoch 47 | Batch 0/100 | Loss 2.707446
InnerLR 0.422442
FineTuningLR 0.167367
Epoch 47 | Batch 10/100 | Loss 2.747229
InnerLR 0.422307
FineTuningLR 0.167567
Epoch 47 | Batch 20/100 | Loss 2.712724
InnerLR 0.422140
FineTuningLR 0.167867
Epoch 47 | Batch 30/100 | Loss 2.975731
InnerLR 0.422044
FineTuningLR 0.168066
Epoch 47 | Batch 40/100 | Loss 2.987465
InnerLR 0.421883
FineTuningLR 0.168366
Epoch 47 | Batch 50/100 | Loss 3.081422
InnerLR 0.421778
FineTuningLR 0.168565
Epoch 47 | Batch 60/100 | Loss 3.265106
InnerLR 0.421626
FineTuningLR 0.168865
Epoch 47 | Batch 70/100 | Loss 3.346994
InnerLR 0.421513
FineTuningLR 0.169064
Epoch 47 | Batch 80/100 | Loss 3.411920
InnerLR 0.421313
FineTuningLR 0.169364
Epoch 47 | Batch 90/100 | Loss 3.282712
InnerLR 0.421164
FineTuningLR 0.169563
100 Accuracy = 49.76% +- 2.46%
Epoch 47: 49.76
Epoch 48 | Batch 0/100 | Loss 1.830536
InnerLR 0.420943
FineTuningLR 0.169862
Epoch 48 | Batch 10/100 | Loss 2.765525
InnerLR 0.420845
FineTuningLR 0.170062
Epoch 48 | Batch 20/100 | Loss 3.119536
InnerLR 0.420663
FineTuningLR 0.170361
Epoch 48 | Batch 30/100 | Loss 3.109979
InnerLR 0.420523
FineTuningLR 0.170561
Epoch 48 | Batch 40/100 | Loss 3.043730
InnerLR 0.420293
FineTuningLR 0.170860
Epoch 48 | Batch 50/100 | Loss 3.110447
InnerLR 0.420148
FineTuningLR 0.171059
Epoch 48 | Batch 60/100 | Loss 3.118316
InnerLR 0.419938
FineTuningLR 0.171339
Epoch 48 | Batch 70/100 | Loss 3.159573
InnerLR 0.419821
FineTuningLR 0.171504
Epoch 48 | Batch 80/100 | Loss 3.201708
InnerLR 0.419618
FineTuningLR 0.171764
Epoch 48 | Batch 90/100 | Loss 3.225445
InnerLR 0.419467
FineTuningLR 0.171943
100 Accuracy = 48.95% +- 2.43%
Epoch 48: 48.95
Epoch 49 | Batch 0/100 | Loss 6.376782
InnerLR 0.419224
FineTuningLR 0.172219
Epoch 49 | Batch 10/100 | Loss 3.657381
InnerLR 0.419053
FineTuningLR 0.172407
Epoch 49 | Batch 20/100 | Loss 3.506728
InnerLR 0.418786
FineTuningLR 0.172692
Epoch 49 | Batch 30/100 | Loss 3.183854
InnerLR 0.418603
FineTuningLR 0.172885
Epoch 49 | Batch 40/100 | Loss 3.273577
InnerLR 0.418377
FineTuningLR 0.173176
Epoch 49 | Batch 50/100 | Loss 3.107148
InnerLR 0.418252
FineTuningLR 0.173371
Epoch 49 | Batch 60/100 | Loss 3.183826
InnerLR 0.418132
FineTuningLR 0.173666
Epoch 49 | Batch 70/100 | Loss 3.236180
InnerLR 0.418035
FineTuningLR 0.173863
Epoch 49 | Batch 80/100 | Loss 3.241129
InnerLR 0.417854
FineTuningLR 0.174159
Epoch 49 | Batch 90/100 | Loss 3.228737
InnerLR 0.417735
FineTuningLR 0.174358
100 Accuracy = 51.32% +- 2.28%
Epoch 49: 51.32
best model! save...
Epoch 50 | Batch 0/100 | Loss 2.763608
InnerLR 0.417553
FineTuningLR 0.174655
Epoch 50 | Batch 10/100 | Loss 4.079057
InnerLR 0.417414
FineTuningLR 0.174854
Epoch 50 | Batch 20/100 | Loss 3.826430
InnerLR 0.417238
FineTuningLR 0.175152
Epoch 50 | Batch 30/100 | Loss 3.758119
InnerLR 0.417122
FineTuningLR 0.175351
Epoch 50 | Batch 40/100 | Loss 3.756410
InnerLR 0.416944
FineTuningLR 0.175650
Epoch 50 | Batch 50/100 | Loss 3.479706
InnerLR 0.416826
FineTuningLR 0.175849
Epoch 50 | Batch 60/100 | Loss 3.433527
InnerLR 0.416646
FineTuningLR 0.176148
Epoch 50 | Batch 70/100 | Loss 3.348362
InnerLR 0.416528
FineTuningLR 0.176347
Epoch 50 | Batch 80/100 | Loss 3.332998
InnerLR 0.416348
FineTuningLR 0.176647
Epoch 50 | Batch 90/100 | Loss 3.274273
InnerLR 0.416209
FineTuningLR 0.176846
100 Accuracy = 48.99% +- 2.09%
Epoch 50: 48.99
Epoch 51 | Batch 0/100 | Loss 3.136032
InnerLR 0.416034
FineTuningLR 0.177145
Epoch 51 | Batch 10/100 | Loss 3.474827
InnerLR 0.415898
FineTuningLR 0.177345
Epoch 51 | Batch 20/100 | Loss 3.472800
InnerLR 0.415671
FineTuningLR 0.177624
Epoch 51 | Batch 30/100 | Loss 3.488465
InnerLR 0.415508
FineTuningLR 0.177789
Epoch 51 | Batch 40/100 | Loss 3.421957
InnerLR 0.415260
FineTuningLR 0.178055
Epoch 51 | Batch 50/100 | Loss 3.238847
InnerLR 0.415106
FineTuningLR 0.178238
Epoch 51 | Batch 60/100 | Loss 3.203185
InnerLR 0.414885
FineTuningLR 0.178518
Epoch 51 | Batch 70/100 | Loss 3.211451
InnerLR 0.414745
FineTuningLR 0.178707
Epoch 51 | Batch 80/100 | Loss 3.229742
InnerLR 0.414541
FineTuningLR 0.178995
Epoch 51 | Batch 90/100 | Loss 3.181772
InnerLR 0.414389
FineTuningLR 0.179188
100 Accuracy = 46.12% +- 2.25%
Epoch 51: 46.12
Epoch 52 | Batch 0/100 | Loss 4.774829
InnerLR 0.414200
FineTuningLR 0.179481
Epoch 52 | Batch 10/100 | Loss 3.677540
InnerLR 0.414056
FineTuningLR 0.179677
Epoch 52 | Batch 20/100 | Loss 3.226767
InnerLR 0.413879
FineTuningLR 0.179972
Epoch 52 | Batch 30/100 | Loss 2.994065
InnerLR 0.413777
FineTuningLR 0.180170
Epoch 52 | Batch 40/100 | Loss 2.919921
InnerLR 0.413590
FineTuningLR 0.180428
Epoch 52 | Batch 50/100 | Loss 2.914429
InnerLR 0.413468
FineTuningLR 0.180558
Epoch 52 | Batch 60/100 | Loss 2.974861
InnerLR 0.413283
FineTuningLR 0.180777
Epoch 52 | Batch 70/100 | Loss 3.118270
InnerLR 0.413180
FineTuningLR 0.180935
Epoch 52 | Batch 80/100 | Loss 3.142921
InnerLR 0.413105
FineTuningLR 0.181187
Epoch 52 | Batch 90/100 | Loss 3.104463
InnerLR 0.413075
FineTuningLR 0.181362
100 Accuracy = 51.12% +- 2.38%
Epoch 52: 51.12
Epoch 53 | Batch 0/100 | Loss 5.067605
InnerLR 0.412997
FineTuningLR 0.181633
Epoch 53 | Batch 10/100 | Loss 3.232121
InnerLR 0.412930
FineTuningLR 0.181818
Epoch 53 | Batch 20/100 | Loss 2.986092
InnerLR 0.412810
FineTuningLR 0.182101
Epoch 53 | Batch 30/100 | Loss 2.868313
InnerLR 0.412701
FineTuningLR 0.182292
Epoch 53 | Batch 40/100 | Loss 2.953857
InnerLR 0.412507
FineTuningLR 0.182581
Epoch 53 | Batch 50/100 | Loss 3.112090
InnerLR 0.412361
FineTuningLR 0.182776
Epoch 53 | Batch 60/100 | Loss 3.081629
InnerLR 0.412123
FineTuningLR 0.183069
Epoch 53 | Batch 70/100 | Loss 3.046571
InnerLR 0.411955
FineTuningLR 0.183266
Epoch 53 | Batch 80/100 | Loss 2.991790
InnerLR 0.411712
FineTuningLR 0.183561
Epoch 53 | Batch 90/100 | Loss 2.959751
InnerLR 0.411564
FineTuningLR 0.183759
100 Accuracy = 49.49% +- 2.62%
Epoch 53: 49.49
Epoch 54 | Batch 0/100 | Loss 2.419390
InnerLR 0.411325
FineTuningLR 0.184056
Epoch 54 | Batch 10/100 | Loss 3.153630
InnerLR 0.411214
FineTuningLR 0.184255
Epoch 54 | Batch 20/100 | Loss 3.211100
InnerLR 0.411059
FineTuningLR 0.184519
Epoch 54 | Batch 30/100 | Loss 3.025936
InnerLR 0.410955
FineTuningLR 0.184691
Epoch 54 | Batch 40/100 | Loss 2.954734
InnerLR 0.410804
FineTuningLR 0.184958
Epoch 54 | Batch 50/100 | Loss 2.930117
InnerLR 0.410692
FineTuningLR 0.185142
Epoch 54 | Batch 60/100 | Loss 2.917911
InnerLR 0.410547
FineTuningLR 0.185422
Epoch 54 | Batch 70/100 | Loss 2.967450
InnerLR 0.410426
FineTuningLR 0.185612
Epoch 54 | Batch 80/100 | Loss 2.922514
InnerLR 0.410272
FineTuningLR 0.185901
Epoch 54 | Batch 90/100 | Loss 2.927778
InnerLR 0.410146
FineTuningLR 0.186094
100 Accuracy = 50.76% +- 2.31%
Epoch 54: 50.76
Epoch 55 | Batch 0/100 | Loss 2.216151
InnerLR 0.409932
FineTuningLR 0.186387
Epoch 55 | Batch 10/100 | Loss 2.856084
InnerLR 0.409814
FineTuningLR 0.186583
Epoch 55 | Batch 20/100 | Loss 2.729018
InnerLR 0.409608
FineTuningLR 0.186879
Epoch 55 | Batch 30/100 | Loss 2.732275
InnerLR 0.409456
FineTuningLR 0.187076
Epoch 55 | Batch 40/100 | Loss 2.772039
InnerLR 0.409250
FineTuningLR 0.187373
Epoch 55 | Batch 50/100 | Loss 2.664059
InnerLR 0.409109
FineTuningLR 0.187572
Epoch 55 | Batch 60/100 | Loss 2.664446
InnerLR 0.408886
FineTuningLR 0.187876
Epoch 55 | Batch 70/100 | Loss 2.657133
InnerLR 0.408767
FineTuningLR 0.188080
Epoch 55 | Batch 80/100 | Loss 2.601836
InnerLR 0.408560
FineTuningLR 0.188384
Epoch 55 | Batch 90/100 | Loss 2.603628
InnerLR 0.408407
FineTuningLR 0.188586
100 Accuracy = 49.35% +- 2.39%
Epoch 55: 49.35
Epoch 56 | Batch 0/100 | Loss 3.008602
InnerLR 0.408216
FineTuningLR 0.188888
Epoch 56 | Batch 10/100 | Loss 3.071746
InnerLR 0.408072
FineTuningLR 0.189089
Epoch 56 | Batch 20/100 | Loss 3.188970
InnerLR 0.407856
FineTuningLR 0.189390
Epoch 56 | Batch 30/100 | Loss 3.042811
InnerLR 0.407722
FineTuningLR 0.189590
Epoch 56 | Batch 40/100 | Loss 3.014650
InnerLR 0.407499
FineTuningLR 0.189890
Epoch 56 | Batch 50/100 | Loss 2.986409
InnerLR 0.407339
FineTuningLR 0.190090
Epoch 56 | Batch 60/100 | Loss 2.968488
InnerLR 0.407084
FineTuningLR 0.190390
Epoch 56 | Batch 70/100 | Loss 3.017259
InnerLR 0.406907
FineTuningLR 0.190590
Epoch 56 | Batch 80/100 | Loss 2.971293
InnerLR 0.406633
FineTuningLR 0.190890
Epoch 56 | Batch 90/100 | Loss 2.945105
InnerLR 0.406467
FineTuningLR 0.191089
100 Accuracy = 49.25% +- 2.60%
Epoch 56: 49.25
Epoch 57 | Batch 0/100 | Loss 2.422840
InnerLR 0.406231
FineTuningLR 0.191335
Epoch 57 | Batch 10/100 | Loss 2.464866
InnerLR 0.406063
FineTuningLR 0.191507
Epoch 57 | Batch 20/100 | Loss 2.271371
InnerLR 0.405859
FineTuningLR 0.191774
Epoch 57 | Batch 30/100 | Loss 2.697591
InnerLR 0.405743
FineTuningLR 0.191957
Epoch 57 | Batch 40/100 | Loss 2.726947
InnerLR 0.405561
FineTuningLR 0.192238
Epoch 57 | Batch 50/100 | Loss 2.705853
InnerLR 0.405444
FineTuningLR 0.192428
Epoch 57 | Batch 60/100 | Loss 2.693523
InnerLR 0.405241
FineTuningLR 0.192716
Epoch 57 | Batch 70/100 | Loss 2.746406
InnerLR 0.405090
FineTuningLR 0.192909
Epoch 57 | Batch 80/100 | Loss 2.737938
InnerLR 0.404901
FineTuningLR 0.193202
Epoch 57 | Batch 90/100 | Loss 2.800915
InnerLR 0.404796
FineTuningLR 0.193378
100 Accuracy = 50.29% +- 2.56%
Epoch 57: 50.29
Epoch 58 | Batch 0/100 | Loss 8.518327
InnerLR 0.404606
FineTuningLR 0.193625
Epoch 58 | Batch 10/100 | Loss 3.418956
InnerLR 0.404481
FineTuningLR 0.193798
Epoch 58 | Batch 20/100 | Loss 2.724356
InnerLR 0.404294
FineTuningLR 0.194066
Epoch 58 | Batch 30/100 | Loss 2.661612
InnerLR 0.404152
FineTuningLR 0.194250
Epoch 58 | Batch 40/100 | Loss 2.790475
InnerLR 0.403919
FineTuningLR 0.194531
Epoch 58 | Batch 50/100 | Loss 2.803367
InnerLR 0.403773
FineTuningLR 0.194721
Epoch 58 | Batch 60/100 | Loss 2.780798
InnerLR 0.403599
FineTuningLR 0.195009
Epoch 58 | Batch 70/100 | Loss 2.755822
InnerLR 0.403474
FineTuningLR 0.195203
Epoch 58 | Batch 80/100 | Loss 2.794210
InnerLR 0.403316
FineTuningLR 0.195496
Epoch 58 | Batch 90/100 | Loss 2.751636
InnerLR 0.403208
FineTuningLR 0.195692
100 Accuracy = 48.11% +- 2.48%
Epoch 58: 48.11
Epoch 59 | Batch 0/100 | Loss 2.363298
InnerLR 0.403040
FineTuningLR 0.195988
Epoch 59 | Batch 10/100 | Loss 2.471451
InnerLR 0.402908
FineTuningLR 0.196185
Epoch 59 | Batch 20/100 | Loss 2.377379
InnerLR 0.402740
FineTuningLR 0.196482
Epoch 59 | Batch 30/100 | Loss 2.560177
InnerLR 0.402645
FineTuningLR 0.196681
Epoch 59 | Batch 40/100 | Loss 2.746376
InnerLR 0.402467
FineTuningLR 0.196979
Epoch 59 | Batch 50/100 | Loss 2.826238
InnerLR 0.402329
FineTuningLR 0.197177
Epoch 59 | Batch 60/100 | Loss 2.922867
InnerLR 0.402101
FineTuningLR 0.197476
Epoch 59 | Batch 70/100 | Loss 2.902951
InnerLR 0.401937
FineTuningLR 0.197675
Epoch 59 | Batch 80/100 | Loss 2.888895
InnerLR 0.401679
FineTuningLR 0.197974
Epoch 59 | Batch 90/100 | Loss 2.861040
InnerLR 0.401520
FineTuningLR 0.198173
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 52.37% +- 2.71%
Epoch 59: 52.37
best model! save...
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_8_lr_0.0001/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_8_lr_0.0001/tabula_muris/leo_FCNet/20231211_160912
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 64.98% +- 1.04%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_8_lr_0.0001/tabula_muris/leo_FCNet/20231211_160912
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 50.60% +- 1.00%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_8_lr_0.0001/tabula_muris/leo_FCNet/20231211_160912
600 Accuracy = 47.06% +- 0.98%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_8_lr_0.0001/results.txt
+-------+-------------------+--------------------+
| split |      acc_mean     |      acc_std       |
+-------+-------------------+--------------------+
| train |       64.98       | 13.027249503622382 |
|  val  |        50.6       | 12.525115509188668 |
|  test | 47.06444444444444 | 12.264202449747602 |
+-------+-------------------+--------------------+
