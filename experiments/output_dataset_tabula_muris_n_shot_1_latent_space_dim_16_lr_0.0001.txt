/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset:
  type: classification
  simple_cls:
    _target_: datasets.cell.tabula_muris.TMSimpleDataset
  set_cls:
    n_way: 5
    n_support: 1
    n_query: 15
    _target_: datasets.cell.tabula_muris.TMSetDataset
  name: tabula_muris
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 64
  - 64
train_classes: 59
n_way: 5
n_shot: 1
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 1
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 0.5
    finetuning_lr_init: 0.05
    num_adaptation_steps: 5
    kl_coef: 0.01
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 0.1
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 16
    enable_finetuning_loop: true
  n_task: 4
  latent_space_dim: 16
  leo_inner_lr_init: 0.5
  leo_finetuning_lr_init: 0.05
  num_adaptation_steps: 5
  kl_coef: 0.01
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 0.1
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-06
  optimize_backbone: false
  pretrained_backbone_weights_path: pretrained_weights/tabula_muris_baseline_model.tar
  enable_finetuning_loop: true
model: FCNet
mode: train
exp:
  name: dataset_tabula_muris_n_shot_1_latent_space_dim_16_lr_0.0001
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.0001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.0001
checkpoint:
  dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_16_lr_0.0001/tabula_muris/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

Using pretrained backbone from pretrained_weights/tabula_muris_baseline_model.tar.
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=2866, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d_fw(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=64, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=2866, out_features=16, bias=False)
    (relation_net): Sequential(
      (0): Linear(in_features=32, out_features=32, bias=False)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=False)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=False)
    )
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=16, out_features=130, bias=False)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 1e-06

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
)
Epoch 0 | Batch 0/100 | Loss 9.625081
InnerLR 0.500000
FineTuningLR 0.050000
Epoch 0 | Batch 10/100 | Loss 6.131278
InnerLR 0.499905
FineTuningLR 0.050200
Epoch 0 | Batch 20/100 | Loss 6.377622
InnerLR 0.500071
FineTuningLR 0.050500
Epoch 0 | Batch 30/100 | Loss 6.273516
InnerLR 0.500148
FineTuningLR 0.050700
Epoch 0 | Batch 40/100 | Loss 6.159019
InnerLR 0.500333
FineTuningLR 0.051000
Epoch 0 | Batch 50/100 | Loss 6.166433
InnerLR 0.500428
FineTuningLR 0.051200
Epoch 0 | Batch 60/100 | Loss 5.989071
InnerLR 0.500592
FineTuningLR 0.051500
Epoch 0 | Batch 70/100 | Loss 5.906289
InnerLR 0.500698
FineTuningLR 0.051700
Epoch 0 | Batch 80/100 | Loss 6.019603
InnerLR 0.500871
FineTuningLR 0.052000
Epoch 0 | Batch 90/100 | Loss 6.025428
InnerLR 0.500959
FineTuningLR 0.052200
100 Accuracy = 43.97% +- 2.39%
Epoch 0: 43.97
best model! save...
Epoch 1 | Batch 0/100 | Loss 4.742128
InnerLR 0.501065
FineTuningLR 0.052500
Epoch 1 | Batch 10/100 | Loss 6.124989
InnerLR 0.501155
FineTuningLR 0.052700
Epoch 1 | Batch 20/100 | Loss 6.267240
InnerLR 0.501233
FineTuningLR 0.053000
Epoch 1 | Batch 30/100 | Loss 6.100876
InnerLR 0.501270
FineTuningLR 0.053200
Epoch 1 | Batch 40/100 | Loss 6.298368
InnerLR 0.501344
FineTuningLR 0.053500
Epoch 1 | Batch 50/100 | Loss 6.427535
InnerLR 0.501418
FineTuningLR 0.053700
Epoch 1 | Batch 60/100 | Loss 6.428791
InnerLR 0.501567
FineTuningLR 0.054003
Epoch 1 | Batch 70/100 | Loss 6.583390
InnerLR 0.501645
FineTuningLR 0.054207
Epoch 1 | Batch 80/100 | Loss 6.498068
InnerLR 0.501750
FineTuningLR 0.054511
Epoch 1 | Batch 90/100 | Loss 6.340855
InnerLR 0.501851
FineTuningLR 0.054713
100 Accuracy = 44.20% +- 2.38%
Epoch 1: 44.20
best model! save...
Epoch 2 | Batch 0/100 | Loss 2.125210
InnerLR 0.501998
FineTuningLR 0.055014
Epoch 2 | Batch 10/100 | Loss 4.898740
InnerLR 0.502089
FineTuningLR 0.055215
Epoch 2 | Batch 20/100 | Loss 5.458785
InnerLR 0.502238
FineTuningLR 0.055515
Epoch 2 | Batch 30/100 | Loss 5.612785
InnerLR 0.502361
FineTuningLR 0.055715
Epoch 2 | Batch 40/100 | Loss 5.698073
InnerLR 0.502534
FineTuningLR 0.056014
Epoch 2 | Batch 50/100 | Loss 5.837760
InnerLR 0.502620
FineTuningLR 0.056213
Epoch 2 | Batch 60/100 | Loss 6.038607
InnerLR 0.502768
FineTuningLR 0.056512
Epoch 2 | Batch 70/100 | Loss 6.061513
InnerLR 0.502808
FineTuningLR 0.056711
Epoch 2 | Batch 80/100 | Loss 6.098678
InnerLR 0.502898
FineTuningLR 0.057010
Epoch 2 | Batch 90/100 | Loss 6.129208
InnerLR 0.502971
FineTuningLR 0.057209
100 Accuracy = 45.29% +- 2.34%
Epoch 2: 45.29
best model! save...
Epoch 3 | Batch 0/100 | Loss 6.089874
InnerLR 0.503099
FineTuningLR 0.057508
Epoch 3 | Batch 10/100 | Loss 7.287355
InnerLR 0.503211
FineTuningLR 0.057707
Epoch 3 | Batch 20/100 | Loss 6.623323
InnerLR 0.503355
FineTuningLR 0.058005
Epoch 3 | Batch 30/100 | Loss 6.194972
InnerLR 0.503476
FineTuningLR 0.058204
Epoch 3 | Batch 40/100 | Loss 6.036192
InnerLR 0.503664
FineTuningLR 0.058503
Epoch 3 | Batch 50/100 | Loss 5.880792
InnerLR 0.503784
FineTuningLR 0.058702
Epoch 3 | Batch 60/100 | Loss 5.965535
InnerLR 0.503991
FineTuningLR 0.059001
Epoch 3 | Batch 70/100 | Loss 5.935399
InnerLR 0.504143
FineTuningLR 0.059200
Epoch 3 | Batch 80/100 | Loss 5.904584
InnerLR 0.504276
FineTuningLR 0.059499
Epoch 3 | Batch 90/100 | Loss 5.893598
InnerLR 0.504355
FineTuningLR 0.059698
100 Accuracy = 49.27% +- 2.25%
Epoch 3: 49.27
best model! save...
Epoch 4 | Batch 0/100 | Loss 6.270656
InnerLR 0.504423
FineTuningLR 0.059997
Epoch 4 | Batch 10/100 | Loss 5.947980
InnerLR 0.504474
FineTuningLR 0.060196
Epoch 4 | Batch 20/100 | Loss 6.050706
InnerLR 0.504483
FineTuningLR 0.060495
Epoch 4 | Batch 30/100 | Loss 5.871131
InnerLR 0.504484
FineTuningLR 0.060694
Epoch 4 | Batch 40/100 | Loss 5.819884
InnerLR 0.504518
FineTuningLR 0.060993
Epoch 4 | Batch 50/100 | Loss 5.793419
InnerLR 0.504550
FineTuningLR 0.061192
Epoch 4 | Batch 60/100 | Loss 5.568143
InnerLR 0.504518
FineTuningLR 0.061491
Epoch 4 | Batch 70/100 | Loss 5.602719
InnerLR 0.504493
FineTuningLR 0.061690
Epoch 4 | Batch 80/100 | Loss 5.690192
InnerLR 0.504433
FineTuningLR 0.061989
Epoch 4 | Batch 90/100 | Loss 5.721223
InnerLR 0.504367
FineTuningLR 0.062189
100 Accuracy = 45.67% +- 2.17%
Epoch 4: 45.67
Epoch 5 | Batch 0/100 | Loss 6.573472
InnerLR 0.504280
FineTuningLR 0.062488
Epoch 5 | Batch 10/100 | Loss 4.999964
InnerLR 0.504244
FineTuningLR 0.062687
Epoch 5 | Batch 20/100 | Loss 5.442430
InnerLR 0.504272
FineTuningLR 0.062986
Epoch 5 | Batch 30/100 | Loss 5.642771
InnerLR 0.504274
FineTuningLR 0.063185
Epoch 5 | Batch 40/100 | Loss 5.765572
InnerLR 0.504247
FineTuningLR 0.063484
Epoch 5 | Batch 50/100 | Loss 6.015263
InnerLR 0.504217
FineTuningLR 0.063684
Epoch 5 | Batch 60/100 | Loss 6.014815
InnerLR 0.504252
FineTuningLR 0.063983
Epoch 5 | Batch 70/100 | Loss 5.884706
InnerLR 0.504258
FineTuningLR 0.064182
Epoch 5 | Batch 80/100 | Loss 5.869156
InnerLR 0.504255
FineTuningLR 0.064482
Epoch 5 | Batch 90/100 | Loss 5.917445
InnerLR 0.504242
FineTuningLR 0.064681
100 Accuracy = 45.24% +- 2.46%
Epoch 5: 45.24
Epoch 6 | Batch 0/100 | Loss 7.686781
InnerLR 0.504212
FineTuningLR 0.064980
Epoch 6 | Batch 10/100 | Loss 6.908884
InnerLR 0.504150
FineTuningLR 0.065180
Epoch 6 | Batch 20/100 | Loss 5.886598
InnerLR 0.504047
FineTuningLR 0.065479
Epoch 6 | Batch 30/100 | Loss 5.900758
InnerLR 0.504017
FineTuningLR 0.065678
Epoch 6 | Batch 40/100 | Loss 5.639496
InnerLR 0.503994
FineTuningLR 0.065978
Epoch 6 | Batch 50/100 | Loss 5.693804
InnerLR 0.503955
FineTuningLR 0.066177
Epoch 6 | Batch 60/100 | Loss 5.610076
InnerLR 0.503867
FineTuningLR 0.066476
Epoch 6 | Batch 70/100 | Loss 5.586694
InnerLR 0.503796
FineTuningLR 0.066676
Epoch 6 | Batch 80/100 | Loss 5.718916
InnerLR 0.503762
FineTuningLR 0.066975
Epoch 6 | Batch 90/100 | Loss 5.815845
InnerLR 0.503767
FineTuningLR 0.067175
100 Accuracy = 47.52% +- 2.48%
Epoch 6: 47.52
Epoch 7 | Batch 0/100 | Loss 3.733264
InnerLR 0.503730
FineTuningLR 0.067474
Epoch 7 | Batch 10/100 | Loss 5.082514
InnerLR 0.503664
FineTuningLR 0.067674
Epoch 7 | Batch 20/100 | Loss 5.501226
InnerLR 0.503594
FineTuningLR 0.067973
Epoch 7 | Batch 30/100 | Loss 6.003329
InnerLR 0.503593
FineTuningLR 0.068173
Epoch 7 | Batch 40/100 | Loss 5.928601
InnerLR 0.503661
FineTuningLR 0.068472
Epoch 7 | Batch 50/100 | Loss 5.919785
InnerLR 0.503743
FineTuningLR 0.068671
Epoch 7 | Batch 60/100 | Loss 5.733726
InnerLR 0.503852
FineTuningLR 0.068971
Epoch 7 | Batch 70/100 | Loss 5.713277
InnerLR 0.503913
FineTuningLR 0.069173
Epoch 7 | Batch 80/100 | Loss 5.648936
InnerLR 0.504050
FineTuningLR 0.069477
Epoch 7 | Batch 90/100 | Loss 5.712372
InnerLR 0.504108
FineTuningLR 0.069679
100 Accuracy = 48.51% +- 2.31%
Epoch 7: 48.51
Epoch 8 | Batch 0/100 | Loss 3.492638
InnerLR 0.504127
FineTuningLR 0.069981
Epoch 8 | Batch 10/100 | Loss 6.380146
InnerLR 0.504113
FineTuningLR 0.070182
Epoch 8 | Batch 20/100 | Loss 5.307750
InnerLR 0.504141
FineTuningLR 0.070483
Epoch 8 | Batch 30/100 | Loss 5.320573
InnerLR 0.504202
FineTuningLR 0.070684
Epoch 8 | Batch 40/100 | Loss 5.212696
InnerLR 0.504284
FineTuningLR 0.070984
Epoch 8 | Batch 50/100 | Loss 5.078288
InnerLR 0.504337
FineTuningLR 0.071184
Epoch 8 | Batch 60/100 | Loss 5.114399
InnerLR 0.504355
FineTuningLR 0.071483
Epoch 8 | Batch 70/100 | Loss 5.180813
InnerLR 0.504317
FineTuningLR 0.071683
Epoch 8 | Batch 80/100 | Loss 5.222721
InnerLR 0.504259
FineTuningLR 0.071983
Epoch 8 | Batch 90/100 | Loss 5.250445
InnerLR 0.504221
FineTuningLR 0.072182
100 Accuracy = 46.97% +- 2.57%
Epoch 8: 46.97
Epoch 9 | Batch 0/100 | Loss 4.106089
InnerLR 0.504161
FineTuningLR 0.072482
Epoch 9 | Batch 10/100 | Loss 5.650198
InnerLR 0.504084
FineTuningLR 0.072681
Epoch 9 | Batch 20/100 | Loss 5.649143
InnerLR 0.503980
FineTuningLR 0.072980
Epoch 9 | Batch 30/100 | Loss 5.398239
InnerLR 0.503881
FineTuningLR 0.073180
Epoch 9 | Batch 40/100 | Loss 5.248796
InnerLR 0.503770
FineTuningLR 0.073479
Epoch 9 | Batch 50/100 | Loss 5.106467
InnerLR 0.503730
FineTuningLR 0.073679
Epoch 9 | Batch 60/100 | Loss 5.251965
InnerLR 0.503688
FineTuningLR 0.073978
Epoch 9 | Batch 70/100 | Loss 5.114045
InnerLR 0.503681
FineTuningLR 0.074177
Epoch 9 | Batch 80/100 | Loss 5.248909
InnerLR 0.503643
FineTuningLR 0.074477
Epoch 9 | Batch 90/100 | Loss 5.126447
InnerLR 0.503588
FineTuningLR 0.074676
100 Accuracy = 47.51% +- 2.39%
Epoch 9: 47.51
Epoch 10 | Batch 0/100 | Loss 3.148572
InnerLR 0.503456
FineTuningLR 0.074975
Epoch 10 | Batch 10/100 | Loss 4.955779
InnerLR 0.503380
FineTuningLR 0.075175
Epoch 10 | Batch 20/100 | Loss 4.942221
InnerLR 0.503280
FineTuningLR 0.075474
Epoch 10 | Batch 30/100 | Loss 5.174359
InnerLR 0.503276
FineTuningLR 0.075674
Epoch 10 | Batch 40/100 | Loss 5.164116
InnerLR 0.503267
FineTuningLR 0.075973
Epoch 10 | Batch 50/100 | Loss 5.020702
InnerLR 0.503264
FineTuningLR 0.076172
Epoch 10 | Batch 60/100 | Loss 5.267652
InnerLR 0.503285
FineTuningLR 0.076472
Epoch 10 | Batch 70/100 | Loss 5.175464
InnerLR 0.503280
FineTuningLR 0.076671
Epoch 10 | Batch 80/100 | Loss 5.200553
InnerLR 0.503324
FineTuningLR 0.076970
Epoch 10 | Batch 90/100 | Loss 5.148948
InnerLR 0.503349
FineTuningLR 0.077170
100 Accuracy = 47.12% +- 2.48%
Epoch 10: 47.12
Epoch 11 | Batch 0/100 | Loss 4.577186
InnerLR 0.503421
FineTuningLR 0.077469
Epoch 11 | Batch 10/100 | Loss 4.120475
InnerLR 0.503484
FineTuningLR 0.077669
Epoch 11 | Batch 20/100 | Loss 4.480979
InnerLR 0.503543
FineTuningLR 0.077968
Epoch 11 | Batch 30/100 | Loss 4.866399
InnerLR 0.503564
FineTuningLR 0.078168
Epoch 11 | Batch 40/100 | Loss 4.872909
InnerLR 0.503574
FineTuningLR 0.078467
Epoch 11 | Batch 50/100 | Loss 4.714788
InnerLR 0.503571
FineTuningLR 0.078667
Epoch 11 | Batch 60/100 | Loss 4.725958
InnerLR 0.503610
FineTuningLR 0.078966
Epoch 11 | Batch 70/100 | Loss 4.697356
InnerLR 0.503657
FineTuningLR 0.079165
Epoch 11 | Batch 80/100 | Loss 4.686361
InnerLR 0.503641
FineTuningLR 0.079465
Epoch 11 | Batch 90/100 | Loss 4.614979
InnerLR 0.503607
FineTuningLR 0.079664
100 Accuracy = 49.00% +- 2.51%
Epoch 11: 49.00
Epoch 12 | Batch 0/100 | Loss 3.799567
InnerLR 0.503616
FineTuningLR 0.079964
Epoch 12 | Batch 10/100 | Loss 4.623179
InnerLR 0.503644
FineTuningLR 0.080163
Epoch 12 | Batch 20/100 | Loss 4.420157
InnerLR 0.503706
FineTuningLR 0.080463
Epoch 12 | Batch 30/100 | Loss 4.594176
InnerLR 0.503774
FineTuningLR 0.080662
Epoch 12 | Batch 40/100 | Loss 4.668950
InnerLR 0.503921
FineTuningLR 0.080962
Epoch 12 | Batch 50/100 | Loss 4.761098
InnerLR 0.504023
FineTuningLR 0.081161
Epoch 12 | Batch 60/100 | Loss 4.817071
InnerLR 0.504109
FineTuningLR 0.081461
Epoch 12 | Batch 70/100 | Loss 4.661473
InnerLR 0.504138
FineTuningLR 0.081660
Epoch 12 | Batch 80/100 | Loss 4.679183
InnerLR 0.504167
FineTuningLR 0.081960
Epoch 12 | Batch 90/100 | Loss 4.717544
InnerLR 0.504184
FineTuningLR 0.082159
100 Accuracy = 49.39% +- 2.53%
Epoch 12: 49.39
best model! save...
Epoch 13 | Batch 0/100 | Loss 4.028302
InnerLR 0.504247
FineTuningLR 0.082459
Epoch 13 | Batch 10/100 | Loss 5.168470
InnerLR 0.504288
FineTuningLR 0.082658
Epoch 13 | Batch 20/100 | Loss 4.989209
InnerLR 0.504350
FineTuningLR 0.082958
Epoch 13 | Batch 30/100 | Loss 4.895943
InnerLR 0.504370
FineTuningLR 0.083157
Epoch 13 | Batch 40/100 | Loss 4.879437
InnerLR 0.504437
FineTuningLR 0.083457
Epoch 13 | Batch 50/100 | Loss 4.899948
InnerLR 0.504498
FineTuningLR 0.083657
Epoch 13 | Batch 60/100 | Loss 4.833916
InnerLR 0.504591
FineTuningLR 0.083956
Epoch 13 | Batch 70/100 | Loss 4.722757
InnerLR 0.504603
FineTuningLR 0.084156
Epoch 13 | Batch 80/100 | Loss 4.661680
InnerLR 0.504607
FineTuningLR 0.084456
Epoch 13 | Batch 90/100 | Loss 4.631645
InnerLR 0.504617
FineTuningLR 0.084655
100 Accuracy = 47.31% +- 2.36%
Epoch 13: 47.31
Epoch 14 | Batch 0/100 | Loss 5.444046
InnerLR 0.504678
FineTuningLR 0.084955
Epoch 14 | Batch 10/100 | Loss 5.224252
InnerLR 0.504674
FineTuningLR 0.085155
Epoch 14 | Batch 20/100 | Loss 4.920841
InnerLR 0.504654
FineTuningLR 0.085454
Epoch 14 | Batch 30/100 | Loss 4.707694
InnerLR 0.504617
FineTuningLR 0.085654
Epoch 14 | Batch 40/100 | Loss 4.819477
InnerLR 0.504565
FineTuningLR 0.085960
Epoch 14 | Batch 50/100 | Loss 4.758692
InnerLR 0.504558
FineTuningLR 0.086166
Epoch 14 | Batch 60/100 | Loss 4.612861
InnerLR 0.504500
FineTuningLR 0.086472
Epoch 14 | Batch 70/100 | Loss 4.534595
InnerLR 0.504486
FineTuningLR 0.086674
Epoch 14 | Batch 80/100 | Loss 4.528931
InnerLR 0.504455
FineTuningLR 0.086978
Epoch 14 | Batch 90/100 | Loss 4.449156
InnerLR 0.504393
FineTuningLR 0.087179
100 Accuracy = 46.20% +- 2.36%
Epoch 14: 46.20
Epoch 15 | Batch 0/100 | Loss 4.181624
InnerLR 0.504309
FineTuningLR 0.087480
Epoch 15 | Batch 10/100 | Loss 4.083315
InnerLR 0.504293
FineTuningLR 0.087681
Epoch 15 | Batch 20/100 | Loss 4.143119
InnerLR 0.504264
FineTuningLR 0.087982
Epoch 15 | Batch 30/100 | Loss 4.312170
InnerLR 0.504238
FineTuningLR 0.088182
Epoch 15 | Batch 40/100 | Loss 4.244788
InnerLR 0.504158
FineTuningLR 0.088482
Epoch 15 | Batch 50/100 | Loss 4.161402
InnerLR 0.504115
FineTuningLR 0.088681
Epoch 15 | Batch 60/100 | Loss 4.092421
InnerLR 0.504080
FineTuningLR 0.088981
Epoch 15 | Batch 70/100 | Loss 4.129761
InnerLR 0.504050
FineTuningLR 0.089181
Epoch 15 | Batch 80/100 | Loss 4.003902
InnerLR 0.504001
FineTuningLR 0.089480
Epoch 15 | Batch 90/100 | Loss 4.057658
InnerLR 0.503968
FineTuningLR 0.089680
100 Accuracy = 52.84% +- 2.57%
Epoch 15: 52.84
best model! save...
Epoch 16 | Batch 0/100 | Loss 4.719524
InnerLR 0.503880
FineTuningLR 0.089979
Epoch 16 | Batch 10/100 | Loss 4.766364
InnerLR 0.503850
FineTuningLR 0.090179
Epoch 16 | Batch 20/100 | Loss 4.804367
InnerLR 0.503840
FineTuningLR 0.090478
Epoch 16 | Batch 30/100 | Loss 4.573166
InnerLR 0.503837
FineTuningLR 0.090677
Epoch 16 | Batch 40/100 | Loss 4.571084
InnerLR 0.503811
FineTuningLR 0.090980
Epoch 16 | Batch 50/100 | Loss 4.548857
InnerLR 0.503773
FineTuningLR 0.091187
Epoch 16 | Batch 60/100 | Loss 4.523465
InnerLR 0.503715
FineTuningLR 0.091493
Epoch 16 | Batch 70/100 | Loss 4.473848
InnerLR 0.503696
FineTuningLR 0.091697
Epoch 16 | Batch 80/100 | Loss 4.386284
InnerLR 0.503651
FineTuningLR 0.092000
Epoch 16 | Batch 90/100 | Loss 4.385728
InnerLR 0.503644
FineTuningLR 0.092202
100 Accuracy = 48.61% +- 2.47%
Epoch 16: 48.61
Epoch 17 | Batch 0/100 | Loss 4.901989
InnerLR 0.503659
FineTuningLR 0.092503
Epoch 17 | Batch 10/100 | Loss 3.953632
InnerLR 0.503651
FineTuningLR 0.092704
Epoch 17 | Batch 20/100 | Loss 4.130212
InnerLR 0.503673
FineTuningLR 0.093005
Epoch 17 | Batch 30/100 | Loss 3.908210
InnerLR 0.503719
FineTuningLR 0.093205
Epoch 17 | Batch 40/100 | Loss 3.991176
InnerLR 0.503784
FineTuningLR 0.093504
Epoch 17 | Batch 50/100 | Loss 4.004443
InnerLR 0.503809
FineTuningLR 0.093704
Epoch 17 | Batch 60/100 | Loss 3.883789
InnerLR 0.503826
FineTuningLR 0.094004
Epoch 17 | Batch 70/100 | Loss 3.856387
InnerLR 0.503844
FineTuningLR 0.094203
Epoch 17 | Batch 80/100 | Loss 3.923903
InnerLR 0.503859
FineTuningLR 0.094502
Epoch 17 | Batch 90/100 | Loss 3.954864
InnerLR 0.503889
FineTuningLR 0.094702
100 Accuracy = 50.24% +- 2.44%
Epoch 17: 50.24
Epoch 18 | Batch 0/100 | Loss 5.545599
InnerLR 0.503993
FineTuningLR 0.095001
Epoch 18 | Batch 10/100 | Loss 4.376976
InnerLR 0.504094
FineTuningLR 0.095200
Epoch 18 | Batch 20/100 | Loss 4.579000
InnerLR 0.504186
FineTuningLR 0.095499
Epoch 18 | Batch 30/100 | Loss 4.623241
InnerLR 0.504230
FineTuningLR 0.095698
Epoch 18 | Batch 40/100 | Loss 4.414526
InnerLR 0.504238
FineTuningLR 0.095997
Epoch 18 | Batch 50/100 | Loss 4.178887
InnerLR 0.504234
FineTuningLR 0.096197
Epoch 18 | Batch 60/100 | Loss 4.115075
InnerLR 0.504159
FineTuningLR 0.096496
Epoch 18 | Batch 70/100 | Loss 4.025370
InnerLR 0.504133
FineTuningLR 0.096695
Epoch 18 | Batch 80/100 | Loss 4.030338
InnerLR 0.504151
FineTuningLR 0.096994
Epoch 18 | Batch 90/100 | Loss 4.076110
InnerLR 0.504125
FineTuningLR 0.097193
100 Accuracy = 51.55% +- 2.56%
Epoch 18: 51.55
Epoch 19 | Batch 0/100 | Loss 3.916723
InnerLR 0.504067
FineTuningLR 0.097500
Epoch 19 | Batch 10/100 | Loss 3.816420
InnerLR 0.504022
FineTuningLR 0.097705
Epoch 19 | Batch 20/100 | Loss 3.756621
InnerLR 0.503974
FineTuningLR 0.098011
Epoch 19 | Batch 30/100 | Loss 3.653090
InnerLR 0.503927
FineTuningLR 0.098213
Epoch 19 | Batch 40/100 | Loss 3.611283
InnerLR 0.503878
FineTuningLR 0.098516
Epoch 19 | Batch 50/100 | Loss 3.523263
InnerLR 0.503869
FineTuningLR 0.098717
Epoch 19 | Batch 60/100 | Loss 3.662576
InnerLR 0.503901
FineTuningLR 0.099019
Epoch 19 | Batch 70/100 | Loss 3.676895
InnerLR 0.503964
FineTuningLR 0.099219
Epoch 19 | Batch 80/100 | Loss 3.619617
InnerLR 0.504053
FineTuningLR 0.099519
Epoch 19 | Batch 90/100 | Loss 3.692061
InnerLR 0.504124
FineTuningLR 0.099719
100 Accuracy = 50.13% +- 2.52%
Epoch 19: 50.13
Epoch 20 | Batch 0/100 | Loss 3.854064
InnerLR 0.504251
FineTuningLR 0.100018
Epoch 20 | Batch 10/100 | Loss 4.003525
InnerLR 0.504324
FineTuningLR 0.100218
Epoch 20 | Batch 20/100 | Loss 3.777687
InnerLR 0.504420
FineTuningLR 0.100517
Epoch 20 | Batch 30/100 | Loss 3.783095
InnerLR 0.504422
FineTuningLR 0.100716
Epoch 20 | Batch 40/100 | Loss 3.737076
InnerLR 0.504413
FineTuningLR 0.101015
Epoch 20 | Batch 50/100 | Loss 3.702684
InnerLR 0.504456
FineTuningLR 0.101215
Epoch 20 | Batch 60/100 | Loss 3.648443
InnerLR 0.504481
FineTuningLR 0.101514
Epoch 20 | Batch 70/100 | Loss 3.699438
InnerLR 0.504530
FineTuningLR 0.101713
Epoch 20 | Batch 80/100 | Loss 3.626565
InnerLR 0.504635
FineTuningLR 0.102012
Epoch 20 | Batch 90/100 | Loss 3.644589
InnerLR 0.504674
FineTuningLR 0.102211
100 Accuracy = 51.12% +- 2.57%
Epoch 20: 51.12
Epoch 21 | Batch 0/100 | Loss 5.510220
InnerLR 0.504767
FineTuningLR 0.102510
Epoch 21 | Batch 10/100 | Loss 3.079976
InnerLR 0.504838
FineTuningLR 0.102709
Epoch 21 | Batch 20/100 | Loss 3.203483
InnerLR 0.504914
FineTuningLR 0.103008
Epoch 21 | Batch 30/100 | Loss 3.278601
InnerLR 0.504918
FineTuningLR 0.103207
Epoch 21 | Batch 40/100 | Loss 3.306016
InnerLR 0.504852
FineTuningLR 0.103506
Epoch 21 | Batch 50/100 | Loss 3.341852
InnerLR 0.504830
FineTuningLR 0.103705
Epoch 21 | Batch 60/100 | Loss 3.361230
InnerLR 0.504782
FineTuningLR 0.104004
Epoch 21 | Batch 70/100 | Loss 3.339123
InnerLR 0.504734
FineTuningLR 0.104203
Epoch 21 | Batch 80/100 | Loss 3.340937
InnerLR 0.504685
FineTuningLR 0.104502
Epoch 21 | Batch 90/100 | Loss 3.330774
InnerLR 0.504636
FineTuningLR 0.104701
100 Accuracy = 50.89% +- 2.67%
Epoch 21: 50.89
Epoch 22 | Batch 0/100 | Loss 5.542171
InnerLR 0.504531
FineTuningLR 0.105000
Epoch 22 | Batch 10/100 | Loss 2.795408
InnerLR 0.504455
FineTuningLR 0.105199
Epoch 22 | Batch 20/100 | Loss 3.309498
InnerLR 0.504372
FineTuningLR 0.105498
Epoch 22 | Batch 30/100 | Loss 3.394406
InnerLR 0.504345
FineTuningLR 0.105697
Epoch 22 | Batch 40/100 | Loss 3.339844
InnerLR 0.504337
FineTuningLR 0.105996
Epoch 22 | Batch 50/100 | Loss 3.345159
InnerLR 0.504318
FineTuningLR 0.106195
Epoch 22 | Batch 60/100 | Loss 3.319686
InnerLR 0.504306
FineTuningLR 0.106494
Epoch 22 | Batch 70/100 | Loss 3.346162
InnerLR 0.504254
FineTuningLR 0.106693
Epoch 22 | Batch 80/100 | Loss 3.334998
InnerLR 0.504124
FineTuningLR 0.106992
Epoch 22 | Batch 90/100 | Loss 3.314596
InnerLR 0.504010
FineTuningLR 0.107191
100 Accuracy = 51.17% +- 2.30%
Epoch 22: 51.17
Epoch 23 | Batch 0/100 | Loss 4.037023
InnerLR 0.503830
FineTuningLR 0.107490
Epoch 23 | Batch 10/100 | Loss 3.732020
InnerLR 0.503715
FineTuningLR 0.107689
Epoch 23 | Batch 20/100 | Loss 3.460130
InnerLR 0.503514
FineTuningLR 0.107988
Epoch 23 | Batch 30/100 | Loss 3.430135
InnerLR 0.503402
FineTuningLR 0.108187
Epoch 23 | Batch 40/100 | Loss 3.571478
InnerLR 0.503258
FineTuningLR 0.108486
Epoch 23 | Batch 50/100 | Loss 3.414191
InnerLR 0.503137
FineTuningLR 0.108685
Epoch 23 | Batch 60/100 | Loss 3.349147
InnerLR 0.502929
FineTuningLR 0.108984
Epoch 23 | Batch 70/100 | Loss 3.378273
InnerLR 0.502834
FineTuningLR 0.109184
Epoch 23 | Batch 80/100 | Loss 3.425284
InnerLR 0.502681
FineTuningLR 0.109482
Epoch 23 | Batch 90/100 | Loss 3.377239
InnerLR 0.502555
FineTuningLR 0.109682
100 Accuracy = 50.77% +- 2.39%
Epoch 23: 50.77
Epoch 24 | Batch 0/100 | Loss 2.078765
InnerLR 0.502342
FineTuningLR 0.109981
Epoch 24 | Batch 10/100 | Loss 3.368445
InnerLR 0.502185
FineTuningLR 0.110180
Epoch 24 | Batch 20/100 | Loss 3.215399
InnerLR 0.502028
FineTuningLR 0.110479
Epoch 24 | Batch 30/100 | Loss 3.566449
InnerLR 0.501913
FineTuningLR 0.110678
Epoch 24 | Batch 40/100 | Loss 3.399696
InnerLR 0.501730
FineTuningLR 0.110977
Epoch 24 | Batch 50/100 | Loss 3.240367
InnerLR 0.501672
FineTuningLR 0.111177
Epoch 24 | Batch 60/100 | Loss 3.188044
InnerLR 0.501562
FineTuningLR 0.111475
Epoch 24 | Batch 70/100 | Loss 3.228743
InnerLR 0.501497
FineTuningLR 0.111675
Epoch 24 | Batch 80/100 | Loss 3.219276
InnerLR 0.501352
FineTuningLR 0.111974
Epoch 24 | Batch 90/100 | Loss 3.213827
InnerLR 0.501231
FineTuningLR 0.112173
100 Accuracy = 54.64% +- 2.53%
Epoch 24: 54.64
best model! save...
Epoch 25 | Batch 0/100 | Loss 3.339137
InnerLR 0.501023
FineTuningLR 0.112472
Epoch 25 | Batch 10/100 | Loss 2.688050
InnerLR 0.500908
FineTuningLR 0.112671
Epoch 25 | Batch 20/100 | Loss 2.905270
InnerLR 0.500763
FineTuningLR 0.112970
Epoch 25 | Batch 30/100 | Loss 3.110376
InnerLR 0.500717
FineTuningLR 0.113170
Epoch 25 | Batch 40/100 | Loss 3.248577
InnerLR 0.500599
FineTuningLR 0.113473
Epoch 25 | Batch 50/100 | Loss 3.266228
InnerLR 0.500512
FineTuningLR 0.113675
Epoch 25 | Batch 60/100 | Loss 3.118490
InnerLR 0.500388
FineTuningLR 0.113977
Epoch 25 | Batch 70/100 | Loss 3.104837
InnerLR 0.500322
FineTuningLR 0.114177
Epoch 25 | Batch 80/100 | Loss 3.189663
InnerLR 0.500241
FineTuningLR 0.114478
Epoch 25 | Batch 90/100 | Loss 3.150654
InnerLR 0.500222
FineTuningLR 0.114678
100 Accuracy = 51.75% +- 2.58%
Epoch 25: 51.75
Epoch 26 | Batch 0/100 | Loss 4.814943
InnerLR 0.500211
FineTuningLR 0.114978
Epoch 26 | Batch 10/100 | Loss 3.276100
InnerLR 0.500159
FineTuningLR 0.115178
Epoch 26 | Batch 20/100 | Loss 3.069175
InnerLR 0.500029
FineTuningLR 0.115477
Epoch 26 | Batch 30/100 | Loss 3.102407
InnerLR 0.499954
FineTuningLR 0.115677
Epoch 26 | Batch 40/100 | Loss 3.031546
InnerLR 0.499873
FineTuningLR 0.115976
Epoch 26 | Batch 50/100 | Loss 3.006924
InnerLR 0.499809
FineTuningLR 0.116176
Epoch 26 | Batch 60/100 | Loss 2.966510
InnerLR 0.499685
FineTuningLR 0.116475
Epoch 26 | Batch 70/100 | Loss 2.827478
InnerLR 0.499599
FineTuningLR 0.116674
Epoch 26 | Batch 80/100 | Loss 2.929156
InnerLR 0.499485
FineTuningLR 0.116973
Epoch 26 | Batch 90/100 | Loss 2.908959
InnerLR 0.499400
FineTuningLR 0.117173
100 Accuracy = 52.27% +- 2.85%
Epoch 26: 52.27
Epoch 27 | Batch 0/100 | Loss 3.919065
InnerLR 0.499259
FineTuningLR 0.117472
Epoch 27 | Batch 10/100 | Loss 2.299817
InnerLR 0.499160
FineTuningLR 0.117671
Epoch 27 | Batch 20/100 | Loss 2.485511
InnerLR 0.499093
FineTuningLR 0.117971
Epoch 27 | Batch 30/100 | Loss 2.524361
InnerLR 0.499081
FineTuningLR 0.118172
Epoch 27 | Batch 40/100 | Loss 2.720162
InnerLR 0.499024
FineTuningLR 0.118472
Epoch 27 | Batch 50/100 | Loss 2.726089
InnerLR 0.498966
FineTuningLR 0.118674
Epoch 27 | Batch 60/100 | Loss 2.708036
InnerLR 0.498873
FineTuningLR 0.118977
Epoch 27 | Batch 70/100 | Loss 2.747168
InnerLR 0.498820
FineTuningLR 0.119181
Epoch 27 | Batch 80/100 | Loss 2.754588
InnerLR 0.498731
FineTuningLR 0.119488
Epoch 27 | Batch 90/100 | Loss 2.792539
InnerLR 0.498683
FineTuningLR 0.119692
100 Accuracy = 53.31% +- 2.66%
Epoch 27: 53.31
Epoch 28 | Batch 0/100 | Loss 3.252516
InnerLR 0.498638
FineTuningLR 0.119995
Epoch 28 | Batch 10/100 | Loss 2.603900
InnerLR 0.498627
FineTuningLR 0.120197
Epoch 28 | Batch 20/100 | Loss 2.704992
InnerLR 0.498590
FineTuningLR 0.120499
Epoch 28 | Batch 30/100 | Loss 2.725119
InnerLR 0.498587
FineTuningLR 0.120699
Epoch 28 | Batch 40/100 | Loss 2.669578
InnerLR 0.498525
FineTuningLR 0.121004
Epoch 28 | Batch 50/100 | Loss 2.646226
InnerLR 0.498479
FineTuningLR 0.121211
Epoch 28 | Batch 60/100 | Loss 2.748290
InnerLR 0.498420
FineTuningLR 0.121518
Epoch 28 | Batch 70/100 | Loss 2.700169
InnerLR 0.498355
FineTuningLR 0.121722
Epoch 28 | Batch 80/100 | Loss 2.633887
InnerLR 0.498230
FineTuningLR 0.122026
Epoch 28 | Batch 90/100 | Loss 2.651946
InnerLR 0.498164
FineTuningLR 0.122228
100 Accuracy = 53.83% +- 2.34%
Epoch 28: 53.83
Epoch 29 | Batch 0/100 | Loss 1.003178
InnerLR 0.498098
FineTuningLR 0.122529
Epoch 29 | Batch 10/100 | Loss 2.648764
InnerLR 0.498018
FineTuningLR 0.122730
Epoch 29 | Batch 20/100 | Loss 2.494848
InnerLR 0.497855
FineTuningLR 0.123030
Epoch 29 | Batch 30/100 | Loss 2.435320
InnerLR 0.497764
FineTuningLR 0.123230
Epoch 29 | Batch 40/100 | Loss 2.528106
InnerLR 0.497643
FineTuningLR 0.123530
Epoch 29 | Batch 50/100 | Loss 2.527769
InnerLR 0.497534
FineTuningLR 0.123730
Epoch 29 | Batch 60/100 | Loss 2.439418
InnerLR 0.497432
FineTuningLR 0.124029
Epoch 29 | Batch 70/100 | Loss 2.444043
InnerLR 0.497345
FineTuningLR 0.124228
Epoch 29 | Batch 80/100 | Loss 2.437408
InnerLR 0.497194
FineTuningLR 0.124527
Epoch 29 | Batch 90/100 | Loss 2.430608
InnerLR 0.497115
FineTuningLR 0.124726
100 Accuracy = 56.56% +- 2.83%
Epoch 29: 56.56
best model! save...
Epoch 30 | Batch 0/100 | Loss 1.742108
InnerLR 0.496999
FineTuningLR 0.125025
Epoch 30 | Batch 10/100 | Loss 2.368232
InnerLR 0.496976
FineTuningLR 0.125224
Epoch 30 | Batch 20/100 | Loss 2.280756
InnerLR 0.496925
FineTuningLR 0.125523
Epoch 30 | Batch 30/100 | Loss 2.467353
InnerLR 0.496915
FineTuningLR 0.125722
Epoch 30 | Batch 40/100 | Loss 2.429617
InnerLR 0.496834
FineTuningLR 0.126021
Epoch 30 | Batch 50/100 | Loss 2.448123
InnerLR 0.496746
FineTuningLR 0.126221
Epoch 30 | Batch 60/100 | Loss 2.508340
InnerLR 0.496650
FineTuningLR 0.126520
Epoch 30 | Batch 70/100 | Loss 2.438479
InnerLR 0.496597
FineTuningLR 0.126721
Epoch 30 | Batch 80/100 | Loss 2.471622
InnerLR 0.496530
FineTuningLR 0.127022
Epoch 30 | Batch 90/100 | Loss 2.472508
InnerLR 0.496460
FineTuningLR 0.127222
100 Accuracy = 52.65% +- 2.36%
Epoch 30: 52.65
Epoch 31 | Batch 0/100 | Loss 2.142847
InnerLR 0.496384
FineTuningLR 0.127522
Epoch 31 | Batch 10/100 | Loss 1.944934
InnerLR 0.496353
FineTuningLR 0.127728
Epoch 31 | Batch 20/100 | Loss 2.239710
InnerLR 0.496311
FineTuningLR 0.128035
Epoch 31 | Batch 30/100 | Loss 2.410869
InnerLR 0.496254
FineTuningLR 0.128238
Epoch 31 | Batch 40/100 | Loss 2.477319
InnerLR 0.496157
FineTuningLR 0.128541
Epoch 31 | Batch 50/100 | Loss 2.419575
InnerLR 0.496131
FineTuningLR 0.128742
Epoch 31 | Batch 60/100 | Loss 2.405785
InnerLR 0.496149
FineTuningLR 0.129044
Epoch 31 | Batch 70/100 | Loss 2.551794
InnerLR 0.496123
FineTuningLR 0.129244
Epoch 31 | Batch 80/100 | Loss 2.634878
InnerLR 0.496062
FineTuningLR 0.129544
Epoch 31 | Batch 90/100 | Loss 2.594634
InnerLR 0.496053
FineTuningLR 0.129744
100 Accuracy = 55.12% +- 3.10%
Epoch 31: 55.12
Epoch 32 | Batch 0/100 | Loss 3.070667
InnerLR 0.496074
FineTuningLR 0.130043
Epoch 32 | Batch 10/100 | Loss 2.282898
InnerLR 0.496121
FineTuningLR 0.130243
Epoch 32 | Batch 20/100 | Loss 2.158877
InnerLR 0.496206
FineTuningLR 0.130542
Epoch 32 | Batch 30/100 | Loss 2.126125
InnerLR 0.496246
FineTuningLR 0.130741
Epoch 32 | Batch 40/100 | Loss 2.185911
InnerLR 0.496304
FineTuningLR 0.131040
Epoch 32 | Batch 50/100 | Loss 2.142319
InnerLR 0.496345
FineTuningLR 0.131239
Epoch 32 | Batch 60/100 | Loss 2.180992
InnerLR 0.496349
FineTuningLR 0.131538
Epoch 32 | Batch 70/100 | Loss 2.195775
InnerLR 0.496342
FineTuningLR 0.131737
Epoch 32 | Batch 80/100 | Loss 2.196626
InnerLR 0.496319
FineTuningLR 0.132035
Epoch 32 | Batch 90/100 | Loss 2.175238
InnerLR 0.496299
FineTuningLR 0.132234
100 Accuracy = 54.88% +- 2.54%
Epoch 32: 54.88
Epoch 33 | Batch 0/100 | Loss 1.525571
InnerLR 0.496265
FineTuningLR 0.132533
Epoch 33 | Batch 10/100 | Loss 2.427505
InnerLR 0.496236
FineTuningLR 0.132732
Epoch 33 | Batch 20/100 | Loss 2.150340
InnerLR 0.496187
FineTuningLR 0.133031
Epoch 33 | Batch 30/100 | Loss 2.342591
InnerLR 0.496116
FineTuningLR 0.133230
Epoch 33 | Batch 40/100 | Loss 2.215434
InnerLR 0.495964
FineTuningLR 0.133528
Epoch 33 | Batch 50/100 | Loss 2.219988
InnerLR 0.495839
FineTuningLR 0.133727
Epoch 33 | Batch 60/100 | Loss 2.173844
InnerLR 0.495664
FineTuningLR 0.134026
Epoch 33 | Batch 70/100 | Loss 2.203337
InnerLR 0.495539
FineTuningLR 0.134225
Epoch 33 | Batch 80/100 | Loss 2.294563
InnerLR 0.495326
FineTuningLR 0.134523
Epoch 33 | Batch 90/100 | Loss 2.244032
InnerLR 0.495170
FineTuningLR 0.134722
100 Accuracy = 57.81% +- 2.49%
Epoch 33: 57.81
best model! save...
Epoch 34 | Batch 0/100 | Loss 2.534736
InnerLR 0.494921
FineTuningLR 0.135022
Epoch 34 | Batch 10/100 | Loss 2.216887
InnerLR 0.494749
FineTuningLR 0.135223
Epoch 34 | Batch 20/100 | Loss 2.309158
InnerLR 0.494481
FineTuningLR 0.135524
Epoch 34 | Batch 30/100 | Loss 2.443196
InnerLR 0.494335
FineTuningLR 0.135724
Epoch 34 | Batch 40/100 | Loss 2.367275
InnerLR 0.494155
FineTuningLR 0.136024
Epoch 34 | Batch 50/100 | Loss 2.306290
InnerLR 0.494111
FineTuningLR 0.136224
Epoch 34 | Batch 60/100 | Loss 2.319481
InnerLR 0.494108
FineTuningLR 0.136523
Epoch 34 | Batch 70/100 | Loss 2.239307
InnerLR 0.494071
FineTuningLR 0.136722
Epoch 34 | Batch 80/100 | Loss 2.227190
InnerLR 0.494014
FineTuningLR 0.137021
Epoch 34 | Batch 90/100 | Loss 2.205144
InnerLR 0.493938
FineTuningLR 0.137221
100 Accuracy = 58.63% +- 2.73%
Epoch 34: 58.63
best model! save...
Epoch 35 | Batch 0/100 | Loss 2.910262
InnerLR 0.493873
FineTuningLR 0.137520
Epoch 35 | Batch 10/100 | Loss 2.179975
InnerLR 0.493804
FineTuningLR 0.137719
Epoch 35 | Batch 20/100 | Loss 1.937788
InnerLR 0.493731
FineTuningLR 0.138017
Epoch 35 | Batch 30/100 | Loss 2.066385
InnerLR 0.493670
FineTuningLR 0.138217
Epoch 35 | Batch 40/100 | Loss 2.120655
InnerLR 0.493551
FineTuningLR 0.138515
Epoch 35 | Batch 50/100 | Loss 2.206537
InnerLR 0.493525
FineTuningLR 0.138714
Epoch 35 | Batch 60/100 | Loss 2.175971
InnerLR 0.493470
FineTuningLR 0.139021
Epoch 35 | Batch 70/100 | Loss 2.269136
InnerLR 0.493399
FineTuningLR 0.139226
Epoch 35 | Batch 80/100 | Loss 2.254850
InnerLR 0.493249
FineTuningLR 0.139532
Epoch 35 | Batch 90/100 | Loss 2.280696
InnerLR 0.493163
FineTuningLR 0.139734
100 Accuracy = 57.92% +- 2.44%
Epoch 35: 57.92
Epoch 36 | Batch 0/100 | Loss 2.121182
InnerLR 0.493033
FineTuningLR 0.140037
Epoch 36 | Batch 10/100 | Loss 2.299720
InnerLR 0.492951
FineTuningLR 0.140238
Epoch 36 | Batch 20/100 | Loss 2.115041
InnerLR 0.492813
FineTuningLR 0.140539
Epoch 36 | Batch 30/100 | Loss 2.080088
InnerLR 0.492696
FineTuningLR 0.140739
Epoch 36 | Batch 40/100 | Loss 2.151058
InnerLR 0.492565
FineTuningLR 0.141039
Epoch 36 | Batch 50/100 | Loss 2.122662
InnerLR 0.492496
FineTuningLR 0.141239
Epoch 36 | Batch 60/100 | Loss 2.144050
InnerLR 0.492411
FineTuningLR 0.141518
Epoch 36 | Batch 70/100 | Loss 2.096030
InnerLR 0.492331
FineTuningLR 0.141684
Epoch 36 | Batch 80/100 | Loss 2.058922
InnerLR 0.492171
FineTuningLR 0.141943
Epoch 36 | Batch 90/100 | Loss 2.039733
InnerLR 0.492041
FineTuningLR 0.142122
100 Accuracy = 56.97% +- 2.46%
Epoch 36: 56.97
Epoch 37 | Batch 0/100 | Loss 1.175325
InnerLR 0.491878
FineTuningLR 0.142398
Epoch 37 | Batch 10/100 | Loss 1.871193
InnerLR 0.491747
FineTuningLR 0.142585
Epoch 37 | Batch 20/100 | Loss 1.791738
InnerLR 0.491585
FineTuningLR 0.142870
Epoch 37 | Batch 30/100 | Loss 1.820238
InnerLR 0.491491
FineTuningLR 0.143062
Epoch 37 | Batch 40/100 | Loss 1.916779
InnerLR 0.491313
FineTuningLR 0.143353
Epoch 37 | Batch 50/100 | Loss 1.982571
InnerLR 0.491233
FineTuningLR 0.143548
Epoch 37 | Batch 60/100 | Loss 1.958617
InnerLR 0.491152
FineTuningLR 0.143787
Epoch 37 | Batch 70/100 | Loss 1.890508
InnerLR 0.491122
FineTuningLR 0.143956
Epoch 37 | Batch 80/100 | Loss 1.869381
InnerLR 0.491064
FineTuningLR 0.144220
Epoch 37 | Batch 90/100 | Loss 1.846541
InnerLR 0.491031
FineTuningLR 0.144402
100 Accuracy = 57.65% +- 2.44%
Epoch 37: 57.65
Epoch 38 | Batch 0/100 | Loss 1.146041
InnerLR 0.491005
FineTuningLR 0.144680
Epoch 38 | Batch 10/100 | Loss 2.425900
InnerLR 0.490945
FineTuningLR 0.144868
Epoch 38 | Batch 20/100 | Loss 2.016466
InnerLR 0.490860
FineTuningLR 0.145155
Epoch 38 | Batch 30/100 | Loss 2.014072
InnerLR 0.490790
FineTuningLR 0.145347
Epoch 38 | Batch 40/100 | Loss 2.000767
InnerLR 0.490666
FineTuningLR 0.145619
Epoch 38 | Batch 50/100 | Loss 1.908407
InnerLR 0.490555
FineTuningLR 0.145780
Epoch 38 | Batch 60/100 | Loss 1.915235
InnerLR 0.490378
FineTuningLR 0.146035
Epoch 38 | Batch 70/100 | Loss 1.833748
InnerLR 0.490285
FineTuningLR 0.146212
Epoch 38 | Batch 80/100 | Loss 1.757960
InnerLR 0.490209
FineTuningLR 0.146485
Epoch 38 | Batch 90/100 | Loss 1.749522
InnerLR 0.490167
FineTuningLR 0.146671
100 Accuracy = 59.08% +- 2.16%
Epoch 38: 59.08
best model! save...
Epoch 39 | Batch 0/100 | Loss 3.246523
InnerLR 0.490133
FineTuningLR 0.146957
Epoch 39 | Batch 10/100 | Loss 1.946130
InnerLR 0.490089
FineTuningLR 0.147150
Epoch 39 | Batch 20/100 | Loss 1.798332
InnerLR 0.489995
FineTuningLR 0.147442
Epoch 39 | Batch 30/100 | Loss 1.700642
InnerLR 0.489920
FineTuningLR 0.147637
Epoch 39 | Batch 40/100 | Loss 1.664586
InnerLR 0.489790
FineTuningLR 0.147932
Epoch 39 | Batch 50/100 | Loss 1.703663
InnerLR 0.489677
FineTuningLR 0.148129
Epoch 39 | Batch 60/100 | Loss 1.657958
InnerLR 0.489477
FineTuningLR 0.148425
Epoch 39 | Batch 70/100 | Loss 1.656223
InnerLR 0.489328
FineTuningLR 0.148623
Epoch 39 | Batch 80/100 | Loss 1.678490
InnerLR 0.489086
FineTuningLR 0.148920
Epoch 39 | Batch 90/100 | Loss 1.711796
InnerLR 0.488916
FineTuningLR 0.149118
100 Accuracy = 58.65% +- 2.51%
Epoch 39: 58.65
Epoch 40 | Batch 0/100 | Loss 4.285577
InnerLR 0.488688
FineTuningLR 0.149416
Epoch 40 | Batch 10/100 | Loss 1.804543
InnerLR 0.488536
FineTuningLR 0.149615
Epoch 40 | Batch 20/100 | Loss 1.625116
InnerLR 0.488300
FineTuningLR 0.149863
Epoch 40 | Batch 30/100 | Loss 1.703248
InnerLR 0.488145
FineTuningLR 0.150043
Epoch 40 | Batch 40/100 | Loss 1.637609
InnerLR 0.487896
FineTuningLR 0.150319
Epoch 40 | Batch 50/100 | Loss 1.593517
InnerLR 0.487722
FineTuningLR 0.150507
Epoch 40 | Batch 60/100 | Loss 1.584508
InnerLR 0.487452
FineTuningLR 0.150792
Epoch 40 | Batch 70/100 | Loss 1.637011
InnerLR 0.487266
FineTuningLR 0.150984
Epoch 40 | Batch 80/100 | Loss 1.596630
InnerLR 0.487022
FineTuningLR 0.151275
Epoch 40 | Batch 90/100 | Loss 1.565555
InnerLR 0.486861
FineTuningLR 0.151470
100 Accuracy = 55.84% +- 2.54%
Epoch 40: 55.84
Epoch 41 | Batch 0/100 | Loss 0.966303
InnerLR 0.486626
FineTuningLR 0.151764
Epoch 41 | Batch 10/100 | Loss 1.521847
InnerLR 0.486483
FineTuningLR 0.151960
Epoch 41 | Batch 20/100 | Loss 1.522463
InnerLR 0.486249
FineTuningLR 0.152256
Epoch 41 | Batch 30/100 | Loss 1.596421
InnerLR 0.486140
FineTuningLR 0.152453
Epoch 41 | Batch 40/100 | Loss 1.602074
InnerLR 0.485972
FineTuningLR 0.152750
Epoch 41 | Batch 50/100 | Loss 1.594396
InnerLR 0.485838
FineTuningLR 0.152948
Epoch 41 | Batch 60/100 | Loss 1.573494
InnerLR 0.485615
FineTuningLR 0.153246
Epoch 41 | Batch 70/100 | Loss 1.593645
InnerLR 0.485454
FineTuningLR 0.153444
Epoch 41 | Batch 80/100 | Loss 1.537601
InnerLR 0.485199
FineTuningLR 0.153742
Epoch 41 | Batch 90/100 | Loss 1.523244
InnerLR 0.485060
FineTuningLR 0.153941
100 Accuracy = 60.04% +- 2.33%
Epoch 41: 60.04
best model! save...
Epoch 42 | Batch 0/100 | Loss 2.305317
InnerLR 0.484830
FineTuningLR 0.154239
Epoch 42 | Batch 10/100 | Loss 1.457616
InnerLR 0.484665
FineTuningLR 0.154438
Epoch 42 | Batch 20/100 | Loss 1.534740
InnerLR 0.484406
FineTuningLR 0.154736
Epoch 42 | Batch 30/100 | Loss 1.567801
InnerLR 0.484226
FineTuningLR 0.154935
Epoch 42 | Batch 40/100 | Loss 1.578280
InnerLR 0.483950
FineTuningLR 0.155233
Epoch 42 | Batch 50/100 | Loss 1.561455
InnerLR 0.483761
FineTuningLR 0.155432
Epoch 42 | Batch 60/100 | Loss 1.575920
InnerLR 0.483513
FineTuningLR 0.155730
Epoch 42 | Batch 70/100 | Loss 1.570009
InnerLR 0.483350
FineTuningLR 0.155929
Epoch 42 | Batch 80/100 | Loss 1.538890
InnerLR 0.483131
FineTuningLR 0.156228
Epoch 42 | Batch 90/100 | Loss 1.575593
InnerLR 0.482984
FineTuningLR 0.156427
100 Accuracy = 60.72% +- 2.29%
Epoch 42: 60.72
best model! save...
Epoch 43 | Batch 0/100 | Loss 1.024510
InnerLR 0.482744
FineTuningLR 0.156725
Epoch 43 | Batch 10/100 | Loss 1.044119
InnerLR 0.482595
FineTuningLR 0.156924
Epoch 43 | Batch 20/100 | Loss 1.124174
InnerLR 0.482379
FineTuningLR 0.157203
Epoch 43 | Batch 30/100 | Loss 1.222440
InnerLR 0.482222
FineTuningLR 0.157368
Epoch 43 | Batch 40/100 | Loss 1.289898
InnerLR 0.481971
FineTuningLR 0.157627
Epoch 43 | Batch 50/100 | Loss 1.329233
InnerLR 0.481796
FineTuningLR 0.157806
Epoch 43 | Batch 60/100 | Loss 1.434950
InnerLR 0.481524
FineTuningLR 0.158081
Epoch 43 | Batch 70/100 | Loss 1.471542
InnerLR 0.481338
FineTuningLR 0.158268
Epoch 43 | Batch 80/100 | Loss 1.458982
InnerLR 0.481067
FineTuningLR 0.158561
Epoch 43 | Batch 90/100 | Loss 1.422949
InnerLR 0.480882
FineTuningLR 0.158720
100 Accuracy = 61.33% +- 2.46%
Epoch 43: 61.33
best model! save...
Epoch 44 | Batch 0/100 | Loss 1.066426
InnerLR 0.480598
FineTuningLR 0.158971
Epoch 44 | Batch 10/100 | Loss 1.527475
InnerLR 0.480406
FineTuningLR 0.159146
Epoch 44 | Batch 20/100 | Loss 1.594761
InnerLR 0.480154
FineTuningLR 0.159417
Epoch 44 | Batch 30/100 | Loss 1.541600
InnerLR 0.479989
FineTuningLR 0.159602
Epoch 44 | Batch 40/100 | Loss 1.508120
InnerLR 0.479729
FineTuningLR 0.159884
Epoch 44 | Batch 50/100 | Loss 1.440607
InnerLR 0.479550
FineTuningLR 0.160074
Epoch 44 | Batch 60/100 | Loss 1.379056
InnerLR 0.479327
FineTuningLR 0.160343
Epoch 44 | Batch 70/100 | Loss 1.349316
InnerLR 0.479187
FineTuningLR 0.160483
Epoch 44 | Batch 80/100 | Loss 1.347532
InnerLR 0.479001
FineTuningLR 0.160688
Epoch 44 | Batch 90/100 | Loss 1.362949
InnerLR 0.478884
FineTuningLR 0.160839
100 Accuracy = 59.44% +- 2.61%
Epoch 44: 59.44
Epoch 45 | Batch 0/100 | Loss 0.624831
InnerLR 0.478680
FineTuningLR 0.161084
Epoch 45 | Batch 10/100 | Loss 0.991933
InnerLR 0.478531
FineTuningLR 0.161257
Epoch 45 | Batch 20/100 | Loss 1.135952
InnerLR 0.478310
FineTuningLR 0.161452
Epoch 45 | Batch 30/100 | Loss 1.161875
InnerLR 0.478194
FineTuningLR 0.161574
Epoch 45 | Batch 40/100 | Loss 1.131844
InnerLR 0.478071
FineTuningLR 0.161784
Epoch 45 | Batch 50/100 | Loss 1.175289
InnerLR 0.477961
FineTuningLR 0.161937
Epoch 45 | Batch 60/100 | Loss 1.168942
InnerLR 0.477803
FineTuningLR 0.162183
Epoch 45 | Batch 70/100 | Loss 1.197225
InnerLR 0.477687
FineTuningLR 0.162355
Epoch 45 | Batch 80/100 | Loss 1.244729
InnerLR 0.477484
FineTuningLR 0.162623
Epoch 45 | Batch 90/100 | Loss 1.248499
InnerLR 0.477333
FineTuningLR 0.162768
100 Accuracy = 62.93% +- 2.45%
Epoch 45: 62.93
best model! save...
Epoch 46 | Batch 0/100 | Loss 0.904464
InnerLR 0.477089
FineTuningLR 0.163005
Epoch 46 | Batch 10/100 | Loss 1.285367
InnerLR 0.476918
FineTuningLR 0.163152
Epoch 46 | Batch 20/100 | Loss 1.422421
InnerLR 0.476650
FineTuningLR 0.163345
Epoch 46 | Batch 30/100 | Loss 1.451169
InnerLR 0.476525
FineTuningLR 0.163467
Epoch 46 | Batch 40/100 | Loss 1.403691
InnerLR 0.476357
FineTuningLR 0.163676
Epoch 46 | Batch 50/100 | Loss 1.409404
InnerLR 0.476248
FineTuningLR 0.163829
Epoch 46 | Batch 60/100 | Loss 1.375388
InnerLR 0.476108
FineTuningLR 0.164074
Epoch 46 | Batch 70/100 | Loss 1.338132
InnerLR 0.475989
FineTuningLR 0.164246
Epoch 46 | Batch 80/100 | Loss 1.300325
InnerLR 0.475783
FineTuningLR 0.164514
Epoch 46 | Batch 90/100 | Loss 1.273163
InnerLR 0.475650
FineTuningLR 0.164697
100 Accuracy = 61.28% +- 2.85%
Epoch 46: 61.28
Epoch 47 | Batch 0/100 | Loss 1.479683
InnerLR 0.475454
FineTuningLR 0.164977
Epoch 47 | Batch 10/100 | Loss 1.098204
InnerLR 0.475307
FineTuningLR 0.165166
Epoch 47 | Batch 20/100 | Loss 1.058061
InnerLR 0.475067
FineTuningLR 0.165454
Epoch 47 | Batch 30/100 | Loss 1.109995
InnerLR 0.474898
FineTuningLR 0.165647
Epoch 47 | Batch 40/100 | Loss 1.102864
InnerLR 0.474651
FineTuningLR 0.165941
Epoch 47 | Batch 50/100 | Loss 1.086002
InnerLR 0.474519
FineTuningLR 0.166140
Epoch 47 | Batch 60/100 | Loss 1.098589
InnerLR 0.474361
FineTuningLR 0.166401
Epoch 47 | Batch 70/100 | Loss 1.128541
InnerLR 0.474283
FineTuningLR 0.166569
Epoch 47 | Batch 80/100 | Loss 1.131879
InnerLR 0.474123
FineTuningLR 0.166759
Epoch 47 | Batch 90/100 | Loss 1.152238
InnerLR 0.473995
FineTuningLR 0.166878
100 Accuracy = 61.64% +- 2.63%
Epoch 47: 61.64
Epoch 48 | Batch 0/100 | Loss 1.371863
InnerLR 0.473835
FineTuningLR 0.167065
Epoch 48 | Batch 10/100 | Loss 1.331597
InnerLR 0.473763
FineTuningLR 0.167183
Epoch 48 | Batch 20/100 | Loss 1.155970
InnerLR 0.473690
FineTuningLR 0.167387
Epoch 48 | Batch 30/100 | Loss 1.274714
InnerLR 0.473605
FineTuningLR 0.167538
Epoch 48 | Batch 40/100 | Loss 1.178974
InnerLR 0.473459
FineTuningLR 0.167782
Epoch 48 | Batch 50/100 | Loss 1.175573
InnerLR 0.473361
FineTuningLR 0.167952
Epoch 48 | Batch 60/100 | Loss 1.146899
InnerLR 0.473199
FineTuningLR 0.168218
Epoch 48 | Batch 70/100 | Loss 1.127862
InnerLR 0.473094
FineTuningLR 0.168400
Epoch 48 | Batch 80/100 | Loss 1.133012
InnerLR 0.472902
FineTuningLR 0.168642
Epoch 48 | Batch 90/100 | Loss 1.118831
InnerLR 0.472774
FineTuningLR 0.168803
100 Accuracy = 59.99% +- 2.85%
Epoch 48: 59.99
Epoch 49 | Batch 0/100 | Loss 1.673443
InnerLR 0.472577
FineTuningLR 0.169061
Epoch 49 | Batch 10/100 | Loss 0.930913
InnerLR 0.472468
FineTuningLR 0.169202
Epoch 49 | Batch 20/100 | Loss 0.979940
InnerLR 0.472272
FineTuningLR 0.169433
Epoch 49 | Batch 30/100 | Loss 1.024696
InnerLR 0.472135
FineTuningLR 0.169604
Epoch 49 | Batch 40/100 | Loss 0.996618
InnerLR 0.471907
FineTuningLR 0.169869
Epoch 49 | Batch 50/100 | Loss 1.027227
InnerLR 0.471802
FineTuningLR 0.170052
Epoch 49 | Batch 60/100 | Loss 1.038467
InnerLR 0.471638
FineTuningLR 0.170331
Epoch 49 | Batch 70/100 | Loss 1.078131
InnerLR 0.471507
FineTuningLR 0.170520
Epoch 49 | Batch 80/100 | Loss 1.061206
InnerLR 0.471286
FineTuningLR 0.170807
Epoch 49 | Batch 90/100 | Loss 1.075772
InnerLR 0.471126
FineTuningLR 0.171000
100 Accuracy = 63.95% +- 2.57%
Epoch 49: 63.95
best model! save...
Epoch 50 | Batch 0/100 | Loss 0.455889
InnerLR 0.470872
FineTuningLR 0.171271
Epoch 50 | Batch 10/100 | Loss 0.798999
InnerLR 0.470753
FineTuningLR 0.171395
Epoch 50 | Batch 20/100 | Loss 1.037130
InnerLR 0.470573
FineTuningLR 0.171586
Epoch 50 | Batch 30/100 | Loss 0.971859
InnerLR 0.470433
FineTuningLR 0.171706
Epoch 50 | Batch 40/100 | Loss 1.037523
InnerLR 0.470264
FineTuningLR 0.171871
Epoch 50 | Batch 50/100 | Loss 1.005320
InnerLR 0.470150
FineTuningLR 0.172010
Epoch 50 | Batch 60/100 | Loss 1.032292
InnerLR 0.469988
FineTuningLR 0.172240
Epoch 50 | Batch 70/100 | Loss 0.995761
InnerLR 0.469907
FineTuningLR 0.172365
Epoch 50 | Batch 80/100 | Loss 1.001021
InnerLR 0.469745
FineTuningLR 0.172579
Epoch 50 | Batch 90/100 | Loss 0.989543
InnerLR 0.469615
FineTuningLR 0.172735
100 Accuracy = 64.63% +- 2.52%
Epoch 50: 64.63
best model! save...
Epoch 51 | Batch 0/100 | Loss 0.580282
InnerLR 0.469396
FineTuningLR 0.172983
Epoch 51 | Batch 10/100 | Loss 0.810551
InnerLR 0.469237
FineTuningLR 0.173156
Epoch 51 | Batch 20/100 | Loss 0.937593
InnerLR 0.468984
FineTuningLR 0.173425
Epoch 51 | Batch 30/100 | Loss 0.986385
InnerLR 0.468808
FineTuningLR 0.173609
Epoch 51 | Batch 40/100 | Loss 0.981281
InnerLR 0.468535
FineTuningLR 0.173890
Epoch 51 | Batch 50/100 | Loss 0.968899
InnerLR 0.468348
FineTuningLR 0.174042
Epoch 51 | Batch 60/100 | Loss 0.969836
InnerLR 0.468084
FineTuningLR 0.174287
Epoch 51 | Batch 70/100 | Loss 0.962984
InnerLR 0.467926
FineTuningLR 0.174420
Epoch 51 | Batch 80/100 | Loss 0.968637
InnerLR 0.467674
FineTuningLR 0.174623
Epoch 51 | Batch 90/100 | Loss 0.976899
InnerLR 0.467498
FineTuningLR 0.174712
100 Accuracy = 63.97% +- 2.72%
Epoch 51: 63.97
Epoch 52 | Batch 0/100 | Loss 0.610490
InnerLR 0.467226
FineTuningLR 0.174883
Epoch 52 | Batch 10/100 | Loss 1.002581
InnerLR 0.467040
FineTuningLR 0.174996
Epoch 52 | Batch 20/100 | Loss 1.102601
InnerLR 0.466756
FineTuningLR 0.175171
Epoch 52 | Batch 30/100 | Loss 0.998227
InnerLR 0.466602
FineTuningLR 0.175307
Epoch 52 | Batch 40/100 | Loss 0.995255
InnerLR 0.466354
FineTuningLR 0.175532
Epoch 52 | Batch 50/100 | Loss 0.975173
InnerLR 0.466181
FineTuningLR 0.175693
Epoch 52 | Batch 60/100 | Loss 0.941823
InnerLR 0.465912
FineTuningLR 0.175949
Epoch 52 | Batch 70/100 | Loss 0.925813
InnerLR 0.465727
FineTuningLR 0.176126
Epoch 52 | Batch 80/100 | Loss 0.900239
InnerLR 0.465444
FineTuningLR 0.176398
Epoch 52 | Batch 90/100 | Loss 0.899042
InnerLR 0.465253
FineTuningLR 0.176584
100 Accuracy = 63.56% +- 2.54%
Epoch 52: 63.56
Epoch 53 | Batch 0/100 | Loss 0.886738
InnerLR 0.464963
FineTuningLR 0.176814
Epoch 53 | Batch 10/100 | Loss 1.061932
InnerLR 0.464767
FineTuningLR 0.176978
Epoch 53 | Batch 20/100 | Loss 0.955206
InnerLR 0.464510
FineTuningLR 0.177197
Epoch 53 | Batch 30/100 | Loss 0.968470
InnerLR 0.464344
FineTuningLR 0.177345
Epoch 53 | Batch 40/100 | Loss 0.953747
InnerLR 0.464082
FineTuningLR 0.177564
Epoch 53 | Batch 50/100 | Loss 0.953782
InnerLR 0.463901
FineTuningLR 0.177679
Epoch 53 | Batch 60/100 | Loss 0.946360
InnerLR 0.463618
FineTuningLR 0.177806
Epoch 53 | Batch 70/100 | Loss 0.960148
InnerLR 0.463465
FineTuningLR 0.177917
Epoch 53 | Batch 80/100 | Loss 0.928050
InnerLR 0.463239
FineTuningLR 0.178114
Epoch 53 | Batch 90/100 | Loss 0.916107
InnerLR 0.463101
FineTuningLR 0.178261
100 Accuracy = 64.57% +- 2.68%
Epoch 53: 64.57
Epoch 54 | Batch 0/100 | Loss 0.717482
InnerLR 0.462872
FineTuningLR 0.178500
Epoch 54 | Batch 10/100 | Loss 0.778722
InnerLR 0.462708
FineTuningLR 0.178669
Epoch 54 | Batch 20/100 | Loss 0.848937
InnerLR 0.462449
FineTuningLR 0.178894
Epoch 54 | Batch 30/100 | Loss 0.890843
InnerLR 0.462270
FineTuningLR 0.179007
Epoch 54 | Batch 40/100 | Loss 0.865920
InnerLR 0.461994
FineTuningLR 0.179205
Epoch 54 | Batch 50/100 | Loss 0.851841
InnerLR 0.461806
FineTuningLR 0.179333
Epoch 54 | Batch 60/100 | Loss 0.826678
InnerLR 0.461539
FineTuningLR 0.179524
Epoch 54 | Batch 70/100 | Loss 0.803026
InnerLR 0.461380
FineTuningLR 0.179668
Epoch 54 | Batch 80/100 | Loss 0.796814
InnerLR 0.461171
FineTuningLR 0.179911
Epoch 54 | Batch 90/100 | Loss 0.805130
InnerLR 0.461043
FineTuningLR 0.180088
100 Accuracy = 69.03% +- 2.33%
Epoch 54: 69.03
best model! save...
Epoch 55 | Batch 0/100 | Loss 0.343316
InnerLR 0.460845
FineTuningLR 0.180349
Epoch 55 | Batch 10/100 | Loss 0.718039
InnerLR 0.460702
FineTuningLR 0.180470
Epoch 55 | Batch 20/100 | Loss 0.909044
InnerLR 0.460469
FineTuningLR 0.180640
Epoch 55 | Batch 30/100 | Loss 0.837111
InnerLR 0.460341
FineTuningLR 0.180762
Epoch 55 | Batch 40/100 | Loss 0.842407
InnerLR 0.460123
FineTuningLR 0.180918
Epoch 55 | Batch 50/100 | Loss 0.847313
InnerLR 0.459965
FineTuningLR 0.181006
Epoch 55 | Batch 60/100 | Loss 0.865639
InnerLR 0.459706
FineTuningLR 0.181144
Epoch 55 | Batch 70/100 | Loss 0.837616
InnerLR 0.459583
FineTuningLR 0.181234
Epoch 55 | Batch 80/100 | Loss 0.848512
InnerLR 0.459398
FineTuningLR 0.181406
Epoch 55 | Batch 90/100 | Loss 0.834246
InnerLR 0.459252
FineTuningLR 0.181526
100 Accuracy = 66.67% +- 2.64%
Epoch 55: 66.67
Epoch 56 | Batch 0/100 | Loss 0.510211
InnerLR 0.459011
FineTuningLR 0.181714
Epoch 56 | Batch 10/100 | Loss 0.689111
InnerLR 0.458841
FineTuningLR 0.181820
Epoch 56 | Batch 20/100 | Loss 0.778218
InnerLR 0.458577
FineTuningLR 0.182012
Epoch 56 | Batch 30/100 | Loss 0.738752
InnerLR 0.458396
FineTuningLR 0.182119
Epoch 56 | Batch 40/100 | Loss 0.760665
InnerLR 0.458118
FineTuningLR 0.182312
Epoch 56 | Batch 50/100 | Loss 0.761617
InnerLR 0.457929
FineTuningLR 0.182457
Epoch 56 | Batch 60/100 | Loss 0.775218
InnerLR 0.457641
FineTuningLR 0.182673
Epoch 56 | Batch 70/100 | Loss 0.813429
InnerLR 0.457447
FineTuningLR 0.182787
Epoch 56 | Batch 80/100 | Loss 0.794921
InnerLR 0.457208
FineTuningLR 0.182906
Epoch 56 | Batch 90/100 | Loss 0.785347
InnerLR 0.457059
FineTuningLR 0.183014
100 Accuracy = 67.95% +- 2.78%
Epoch 56: 67.95
Epoch 57 | Batch 0/100 | Loss 1.236865
InnerLR 0.456882
FineTuningLR 0.183207
Epoch 57 | Batch 10/100 | Loss 0.775592
InnerLR 0.456756
FineTuningLR 0.183314
Epoch 57 | Batch 20/100 | Loss 0.727834
InnerLR 0.456541
FineTuningLR 0.183507
Epoch 57 | Batch 30/100 | Loss 0.741856
InnerLR 0.456422
FineTuningLR 0.183652
Epoch 57 | Batch 40/100 | Loss 0.712846
InnerLR 0.456228
FineTuningLR 0.183841
Epoch 57 | Batch 50/100 | Loss 0.708806
InnerLR 0.456106
FineTuningLR 0.183966
Epoch 57 | Batch 60/100 | Loss 0.699090
InnerLR 0.455921
FineTuningLR 0.184153
Epoch 57 | Batch 70/100 | Loss 0.720623
InnerLR 0.455779
FineTuningLR 0.184258
Epoch 57 | Batch 80/100 | Loss 0.706748
InnerLR 0.455546
FineTuningLR 0.184447
Epoch 57 | Batch 90/100 | Loss 0.706763
InnerLR 0.455381
FineTuningLR 0.184553
100 Accuracy = 66.89% +- 2.64%
Epoch 57: 66.89
Epoch 58 | Batch 0/100 | Loss 0.451583
InnerLR 0.455120
FineTuningLR 0.184743
Epoch 58 | Batch 10/100 | Loss 0.600077
InnerLR 0.454939
FineTuningLR 0.184887
Epoch 58 | Batch 20/100 | Loss 0.705745
InnerLR 0.454662
FineTuningLR 0.185083
Epoch 58 | Batch 30/100 | Loss 0.712783
InnerLR 0.454493
FineTuningLR 0.185181
Epoch 58 | Batch 40/100 | Loss 0.732825
InnerLR 0.454255
FineTuningLR 0.185343
Epoch 58 | Batch 50/100 | Loss 0.721002
InnerLR 0.454100
FineTuningLR 0.185452
Epoch 58 | Batch 60/100 | Loss 0.710758
InnerLR 0.453907
FineTuningLR 0.185613
Epoch 58 | Batch 70/100 | Loss 0.706856
InnerLR 0.453773
FineTuningLR 0.185711
Epoch 58 | Batch 80/100 | Loss 0.707875
InnerLR 0.453603
FineTuningLR 0.185812
Epoch 58 | Batch 90/100 | Loss 0.704002
InnerLR 0.453470
FineTuningLR 0.185911
100 Accuracy = 64.65% +- 2.72%
Epoch 58: 64.65
Epoch 59 | Batch 0/100 | Loss 0.466199
InnerLR 0.453266
FineTuningLR 0.186093
Epoch 59 | Batch 10/100 | Loss 0.634094
InnerLR 0.453175
FineTuningLR 0.186229
Epoch 59 | Batch 20/100 | Loss 0.713884
InnerLR 0.452996
FineTuningLR 0.186448
Epoch 59 | Batch 30/100 | Loss 0.763306
InnerLR 0.452852
FineTuningLR 0.186577
Epoch 59 | Batch 40/100 | Loss 0.744642
InnerLR 0.452617
FineTuningLR 0.186794
Epoch 59 | Batch 50/100 | Loss 0.714799
InnerLR 0.452450
FineTuningLR 0.186951
Epoch 59 | Batch 60/100 | Loss 0.697842
InnerLR 0.452206
FineTuningLR 0.187203
Epoch 59 | Batch 70/100 | Loss 0.666777
InnerLR 0.452074
FineTuningLR 0.187382
Epoch 59 | Batch 80/100 | Loss 0.647221
InnerLR 0.451912
FineTuningLR 0.187622
Epoch 59 | Batch 90/100 | Loss 0.655791
InnerLR 0.451794
FineTuningLR 0.187743
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
100 Accuracy = 68.91% +- 2.72%
Epoch 59: 68.91
Checkpoint directory: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_16_lr_0.0001/tabula_muris/leo_FCNet
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_16_lr_0.0001/tabula_muris/leo_FCNet/20231211_163846
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 87.00% +- 0.74%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_16_lr_0.0001/tabula_muris/leo_FCNet/20231211_163846
/home/boris_zhestyankin/epfl-dl-in-biomed-project/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.
  self.adata.obs['label'] = pd.Categorical(values=truth_labels)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.
  view_to_actual(adata)
/home/boris_zhestyankin/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
600 Accuracy = 65.67% +- 1.13%
Using checkpoint dir: checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_16_lr_0.0001/tabula_muris/leo_FCNet/20231211_163846
600 Accuracy = 54.96% +- 1.03%
Results logged to ./checkpoints/dataset_tabula_muris_n_shot_1_latent_space_dim_16_lr_0.0001/results.txt
+-------+-------------------+--------------------+
| split |      acc_mean     |      acc_std       |
+-------+-------------------+--------------------+
| train | 86.99555555555555 | 9.205713738331143  |
|  val  | 65.66888888888889 | 14.091447191492335 |
|  test | 54.95555555555556 | 12.88511438984948  |
+-------+-------------------+--------------------+
