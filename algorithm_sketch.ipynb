{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7fb91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Linear_fw_no_bias(torch.nn.Linear): \n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear_fw_no_bias, self).__init__(in_features, out_features, bias=False)\n",
    "        self.weight.fast = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.weight.fast is not None:\n",
    "            out = F.linear(x, self.weight.fast)\n",
    "        else:\n",
    "            out = super(Linear_fw, self).forward(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac03f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "#class Encoder(nn.Module):\n",
    "#    def __init__(self, mean, ):\n",
    "#        super(Encoder, self).__init__()\n",
    "#        self.mean ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5901cd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.7962]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.9256]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.4684]], requires_grad=True))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "encoder = torch.nn.Linear(1, 1, bias=False) # phi_encoder\n",
    "decoder = torch.nn.Linear(1, 1, bias=False) # phi_decoder\n",
    "\n",
    "model = Linear_fw_no_bias(1, 1) # theta\n",
    "\n",
    "encoder.weight, decoder.weight, model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede19a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0275, 1.0000],\n",
       "        [0.5516, 0.0000],\n",
       "        [0.9406, 1.0000],\n",
       "        [0.8959, 1.0000],\n",
       "        [0.3911, 0.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_data = torch.cat((torch.rand((5, 1)), torch.tensor([[1., 0., 1., 1., 0.]]).view(5, 1)), dim=1)\n",
    "tasks_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83cac802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2762)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mu = torch.nn.Parameter()\n",
    "#sigma = torch.nn.Parameter()\n",
    "\n",
    "torch.normal(torch.tensor(0.), torch.tensor(1.)) * sigma + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f286529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.5153753757476807\n",
      "loss: 2.512507915496826\n",
      "loss: 2.510213851928711\n",
      "loss: 2.5083136558532715\n",
      "loss: 2.5066981315612793\n",
      "loss: 2.505297899246216\n",
      "loss: 2.5040643215179443\n",
      "loss: 2.5029635429382324\n",
      "loss: 2.5019707679748535\n",
      "loss: 2.501067638397217\n"
     ]
    }
   ],
   "source": [
    "n_adaptation_steps = 1000\n",
    "epochs = 10\n",
    "lr = 0.5\n",
    "inner_lr = 0.5\n",
    "\n",
    "optimizer = torch.optim.SGD([*encoder.parameters(), *decoder.parameters()], lr)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss_all = []\n",
    "\n",
    "    for (x, y) in tasks_data:\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        z = encoder(x)\n",
    "\n",
    "        w = decoder(z)\n",
    "        for weight in model.parameters():\n",
    "            weight.fast = w\n",
    "\n",
    "        for i in range(n_adaptation_steps):\n",
    "            loss = criterion(torch.sigmoid(model(x)), y)\n",
    "            grad = torch.autograd.grad(loss, z, create_graph=True)[0]\n",
    "            z = z - inner_lr * grad\n",
    "            \n",
    "            w = decoder(z)\n",
    "            for weight in model.parameters():\n",
    "                weight.fast = w        \n",
    "\n",
    "        loss_all.append(loss)\n",
    "\n",
    "    loss_q = torch.stack(loss_all).sum(0)\n",
    "    loss_q.backward()\n",
    "    print(f\"loss: {loss_q}\")\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9036b617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.7966]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[1.2002]], requires_grad=True),\n",
       " tensor([-9.9105], grad_fn=<SqueezeBackward4>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.weight, decoder.weight, model.weight.fast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
