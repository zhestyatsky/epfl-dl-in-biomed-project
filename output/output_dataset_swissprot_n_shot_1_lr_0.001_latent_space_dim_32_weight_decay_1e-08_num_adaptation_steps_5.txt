/home/said.gurbuz/miniconda3/envs/fewshotbench/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'main': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
dataset:
  type: classification
  simple_cls:
    _target_: datasets.prot.swissprot.SPSimpleDataset
  set_cls:
    n_way: 5
    n_support: 1
    n_query: 15
    _target_: datasets.prot.swissprot.SPSetDataset
  name: swissprot
eval_split:
- train
- val
- test
backbone:
  _target_: backbones.fcnet.FCNet
  layer_dim:
  - 512
  - 512
train_classes: 7195
n_way: 5
n_shot: 1
n_query: 15
method:
  name: leo
  train_batch: null
  val_batch: null
  fast_weight: true
  start_epoch: 0
  eval_type: set
  stop_epoch: 60
  type: meta
  cls:
    n_way: 5
    n_support: 1
    _target_: methods.leo.LEO
    n_task: 4
    inner_lr_init: 1
    finetuning_lr_init: 0.001
    num_adaptation_steps: 5
    kl_coef: 0.001
    orthogonality_penalty_coef: 0.1
    encoder_penalty_coef: 1.0e-09
    dropout: 0.3
    gradient_threshold: 0.1
    gradient_norm_threshold: 0.1
    latent_space_dim: 32
    optimize_backbone: false
  n_task: 4
  latent_space_dim: 32
  leo_inner_lr_init: 1
  leo_finetuning_lr_init: 0.001
  num_adaptation_steps: 5
  kl_coef: 0.001
  orthogonality_penalty_coef: 0.1
  encoder_penalty_coef: 1.0e-09
  dropout: 0.3
  gradient_threshold: 0.1
  gradient_norm_threshold: 0.1
  weight_decay: 1.0e-08
  optimize_backbone: false
model: FCNet
mode: train
exp:
  name: dataset_swissprot_n_shot_1_lr_0.001_latent_space_dim_32_weight_decay_1e-08_num_adaptation_steps_5
  save_freq: 10
  resume: false
  seed: 42
  val_freq: 1
optimizer: Adam
lr: 0.001
optimizer_cls:
  _target_: torch.optim.Adam
  lr: 0.001
checkpoint:
  dir: checkpoints/dataset_swissprot_n_shot_1_lr_0.001_latent_space_dim_32_weight_decay_1e-08_num_adaptation_steps_5/swissprot/leo_FCNet
  test_iter: best_model
  time: latest
wandb:
  project: leo
  entity: leo
  mode: disabled
iter_num: 600

  EXISTS: go-basic.obo
go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)

**WARNING: NO VERSION LINE FOUND IN GAF FILE. USING:
!gaf-version: 2.2
[2023-12-09 10:36:01,019][root][ERROR] - Failed to validate header as GAF v2.2:
[]
HMS:0:00:06.550245 310,057 annotations READ: ./data/swissprot/filtered_goa_uniprot_all_noiea.gaf 
25933 IDs in loaded association branch, BP

**WARNING: NO VERSION LINE FOUND IN GAF FILE. USING:
!gaf-version: 2.2
[2023-12-09 10:37:46,496][root][ERROR] - Failed to validate header as GAF v2.2:
[]
HMS:0:00:06.478061 310,057 annotations READ: ./data/swissprot/filtered_goa_uniprot_all_noiea.gaf 
25933 IDs in loaded association branch, BP
Model Architecture:
LEO(
  (feature): FCNet(
    (encoder): Sequential(
      (0): Sequential(
        (0): Linear_fw(in_features=1280, out_features=512, bias=True)
        (1): BatchNorm1d_fw(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
      (1): Sequential(
        (0): Linear_fw(in_features=512, out_features=512, bias=True)
        (1): BatchNorm1d_fw(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (classifier): Linear_fw(in_features=512, out_features=5, bias=True)
  (loss_fn): CrossEntropyLoss()
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): EncodingNetwork(
    (dropout): Dropout(p=0.3, inplace=False)
    (encoding_layer): Linear(in_features=1280, out_features=32, bias=True)
    (relation_net): Linear(in_features=64, out_features=64, bias=True)
    (normal_distribution): NormalDistribution()
  )
  (decoder): DecodingNetwork(
    (decoding_layer): Linear(in_features=160, out_features=5130, bias=True)
    (normal_distribution): NormalDistribution()
  )
)
Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 1e-08
)
Epoch 0 | Batch 0/100 | Loss 13.406057
InnerLR 1.000000
FineTuningLR 0.001000
Epoch 0 | Batch 10/100 | Loss 13.951865
InnerLR 0.998000
FineTuningLR 0.003000
Epoch 0 | Batch 20/100 | Loss 14.064789
InnerLR 0.994997
FineTuningLR 0.006003
Epoch 0 | Batch 30/100 | Loss 14.102716
InnerLR 0.992996
FineTuningLR 0.008004
Epoch 0 | Batch 40/100 | Loss 14.487893
InnerLR 0.989999
FineTuningLR 0.011001
Epoch 0 | Batch 50/100 | Loss 14.637735
InnerLR 0.988001
FineTuningLR 0.012999
Epoch 0 | Batch 60/100 | Loss 14.816834
InnerLR 0.985482
FineTuningLR 0.015997
Epoch 0 | Batch 70/100 | Loss 15.219976
InnerLR 0.983856
FineTuningLR 0.017993
Epoch 0 | Batch 80/100 | Loss 15.552188
InnerLR 0.981266
FineTuningLR 0.020989
Epoch 0 | Batch 90/100 | Loss 15.928308
InnerLR 0.979470
FineTuningLR 0.022986
100 Accuracy = 35.15% +- 2.03%
Epoch 0: 35.15
best model! save...
Epoch 1 | Batch 0/100 | Loss 24.167540
InnerLR 0.976698
FineTuningLR 0.025983
Epoch 1 | Batch 10/100 | Loss 18.432053
InnerLR 0.975023
FineTuningLR 0.027982
Epoch 1 | Batch 20/100 | Loss 18.164927
InnerLR 0.972658
FineTuningLR 0.030984
Epoch 1 | Batch 30/100 | Loss 18.222656
InnerLR 0.971369
FineTuningLR 0.032986
Epoch 1 | Batch 40/100 | Loss 18.227742
InnerLR 0.969731
FineTuningLR 0.035987
Epoch 1 | Batch 50/100 | Loss 18.537382
InnerLR 0.968421
FineTuningLR 0.037988
Epoch 1 | Batch 60/100 | Loss 18.325203
InnerLR 0.966218
FineTuningLR 0.040986
Epoch 1 | Batch 70/100 | Loss 18.508417
InnerLR 0.964627
FineTuningLR 0.042983
Epoch 1 | Batch 80/100 | Loss 18.610983
InnerLR 0.962480
FineTuningLR 0.045975
Epoch 1 | Batch 90/100 | Loss 18.552644
InnerLR 0.961024
FineTuningLR 0.047975
100 Accuracy = 34.65% +- 1.86%
Epoch 1: 34.65
Epoch 2 | Batch 0/100 | Loss 26.246048
InnerLR 0.958651
FineTuningLR 0.050975
Epoch 2 | Batch 10/100 | Loss 19.083244
InnerLR 0.956973
FineTuningLR 0.052973
Epoch 2 | Batch 20/100 | Loss 18.440368
InnerLR 0.954888
FineTuningLR 0.055965
Epoch 2 | Batch 30/100 | Loss 18.489287
InnerLR 0.953933
FineTuningLR 0.057960
Epoch 2 | Batch 40/100 | Loss 18.144551
InnerLR 0.952582
FineTuningLR 0.060963
Epoch 2 | Batch 50/100 | Loss 18.370544
InnerLR 0.952042
FineTuningLR 0.062961
Epoch 2 | Batch 60/100 | Loss 18.615136
InnerLR 0.950732
FineTuningLR 0.065957
Epoch 2 | Batch 70/100 | Loss 18.898032
InnerLR 0.949970
FineTuningLR 0.067957
Epoch 2 | Batch 80/100 | Loss 19.098285
InnerLR 0.948933
FineTuningLR 0.070961
Epoch 2 | Batch 90/100 | Loss 19.360915
InnerLR 0.947941
FineTuningLR 0.072958
100 Accuracy = 34.19% +- 1.91%
Epoch 2: 34.19
Epoch 3 | Batch 0/100 | Loss 29.077246
InnerLR 0.946114
FineTuningLR 0.075947
Epoch 3 | Batch 10/100 | Loss 23.268507
InnerLR 0.944715
FineTuningLR 0.077940
Epoch 3 | Batch 20/100 | Loss 23.645784
InnerLR 0.943151
FineTuningLR 0.080921
Epoch 3 | Batch 30/100 | Loss 22.520371
InnerLR 0.942121
FineTuningLR 0.082912
Epoch 3 | Batch 40/100 | Loss 22.153002
InnerLR 0.940238
FineTuningLR 0.085904
Epoch 3 | Batch 50/100 | Loss 22.499169
InnerLR 0.938810
FineTuningLR 0.087899
Epoch 3 | Batch 60/100 | Loss 22.453344
InnerLR 0.936463
FineTuningLR 0.090901
Epoch 3 | Batch 70/100 | Loss 21.933982
InnerLR 0.934794
FineTuningLR 0.092904
Epoch 3 | Batch 80/100 | Loss 22.134240
InnerLR 0.932367
FineTuningLR 0.095915
Epoch 3 | Batch 90/100 | Loss 22.450895
InnerLR 0.931476
FineTuningLR 0.097916
100 Accuracy = 34.43% +- 2.05%
Epoch 3: 34.43
Epoch 4 | Batch 0/100 | Loss 18.624130
InnerLR 0.930542
FineTuningLR 0.100921
Epoch 4 | Batch 10/100 | Loss 19.835549
InnerLR 0.929592
FineTuningLR 0.102928
Epoch 4 | Batch 20/100 | Loss 20.108476
InnerLR 0.928009
FineTuningLR 0.105935
Epoch 4 | Batch 30/100 | Loss 19.805574
InnerLR 0.926972
FineTuningLR 0.107939
Epoch 4 | Batch 40/100 | Loss 20.222488
InnerLR 0.925088
FineTuningLR 0.110942
Epoch 4 | Batch 50/100 | Loss 20.205109
InnerLR 0.923653
FineTuningLR 0.112948
Epoch 4 | Batch 60/100 | Loss 20.482625
InnerLR 0.921840
FineTuningLR 0.115953
Epoch 4 | Batch 70/100 | Loss 20.525976
InnerLR 0.920452
FineTuningLR 0.117950
Epoch 4 | Batch 80/100 | Loss 20.557607
InnerLR 0.918155
FineTuningLR 0.120951
Epoch 4 | Batch 90/100 | Loss 20.142783
InnerLR 0.916711
FineTuningLR 0.122952
100 Accuracy = 33.80% +- 1.89%
Epoch 4: 33.80
Epoch 5 | Batch 0/100 | Loss 20.254269
InnerLR 0.915188
FineTuningLR 0.125943
Epoch 5 | Batch 10/100 | Loss 18.681715
InnerLR 0.914674
FineTuningLR 0.127934
Epoch 5 | Batch 20/100 | Loss 18.606943
InnerLR 0.913383
FineTuningLR 0.130931
Epoch 5 | Batch 30/100 | Loss 18.344687
InnerLR 0.912451
FineTuningLR 0.132930
Epoch 5 | Batch 40/100 | Loss 18.478714
InnerLR 0.911142
FineTuningLR 0.135922
Epoch 5 | Batch 50/100 | Loss 18.472430
InnerLR 0.910248
FineTuningLR 0.137914
Epoch 5 | Batch 60/100 | Loss 18.289645
InnerLR 0.909062
FineTuningLR 0.140902
Epoch 5 | Batch 70/100 | Loss 18.452505
InnerLR 0.907982
FineTuningLR 0.142902
Epoch 5 | Batch 80/100 | Loss 18.489945
InnerLR 0.906224
FineTuningLR 0.145923
Epoch 5 | Batch 90/100 | Loss 18.657130
InnerLR 0.905096
FineTuningLR 0.147933
100 Accuracy = 32.47% +- 1.83%
Epoch 5: 32.47
Epoch 6 | Batch 0/100 | Loss 13.359003
InnerLR 0.903105
FineTuningLR 0.150943
Epoch 6 | Batch 10/100 | Loss 15.437291
InnerLR 0.902000
FineTuningLR 0.152944
Epoch 6 | Batch 20/100 | Loss 17.060323
InnerLR 0.900232
FineTuningLR 0.155947
Epoch 6 | Batch 30/100 | Loss 17.749985
InnerLR 0.899477
FineTuningLR 0.157944
Epoch 6 | Batch 40/100 | Loss 18.265034
InnerLR 0.898453
FineTuningLR 0.160951
Epoch 6 | Batch 50/100 | Loss 17.982889
InnerLR 0.897461
FineTuningLR 0.162956
Epoch 6 | Batch 60/100 | Loss 18.552858
InnerLR 0.896009
FineTuningLR 0.165956
Epoch 6 | Batch 70/100 | Loss 18.425501
InnerLR 0.894910
FineTuningLR 0.167958
Epoch 6 | Batch 80/100 | Loss 18.529943
InnerLR 0.893324
FineTuningLR 0.170962
Epoch 6 | Batch 90/100 | Loss 18.744925
InnerLR 0.892737
FineTuningLR 0.172959
100 Accuracy = 35.69% +- 2.09%
Epoch 6: 35.69
best model! save...
Epoch 7 | Batch 0/100 | Loss 25.164051
InnerLR 0.892146
FineTuningLR 0.175231
Epoch 7 | Batch 10/100 | Loss 19.451822
InnerLR 0.891365
FineTuningLR 0.176627
Epoch 7 | Batch 20/100 | Loss 19.836176
InnerLR 0.889764
FineTuningLR 0.178938
Epoch 7 | Batch 30/100 | Loss 19.151283
InnerLR 0.888851
FineTuningLR 0.180589
Epoch 7 | Batch 40/100 | Loss 19.081073
InnerLR 0.887630
FineTuningLR 0.183194
Epoch 7 | Batch 50/100 | Loss 19.409660
InnerLR 0.886532
FineTuningLR 0.184998
Epoch 7 | Batch 60/100 | Loss 19.668865
InnerLR 0.885114
FineTuningLR 0.187763
Epoch 7 | Batch 70/100 | Loss 19.789246
InnerLR 0.883925
FineTuningLR 0.189641
Epoch 7 | Batch 80/100 | Loss 19.647745
InnerLR 0.882066
FineTuningLR 0.192500
Epoch 7 | Batch 90/100 | Loss 19.575864
InnerLR 0.880890
FineTuningLR 0.194430
100 Accuracy = 34.89% +- 2.03%
Epoch 7: 34.89
Epoch 8 | Batch 0/100 | Loss 16.496166
InnerLR 0.878842
FineTuningLR 0.197350
Epoch 8 | Batch 10/100 | Loss 18.539841
InnerLR 0.877332
FineTuningLR 0.199306
Epoch 8 | Batch 20/100 | Loss 18.289524
InnerLR 0.874895
FineTuningLR 0.202257
Epoch 8 | Batch 30/100 | Loss 18.995301
InnerLR 0.873185
FineTuningLR 0.204230
Epoch 8 | Batch 40/100 | Loss 18.768722
InnerLR 0.870526
FineTuningLR 0.207193
Epoch 8 | Batch 50/100 | Loss 19.058312
InnerLR 0.868704
FineTuningLR 0.209171
Epoch 8 | Batch 60/100 | Loss 19.766681
InnerLR 0.866476
FineTuningLR 0.212146
Epoch 8 | Batch 70/100 | Loss 19.696546
InnerLR 0.865224
FineTuningLR 0.213554
Epoch 8 | Batch 80/100 | Loss 19.885069
InnerLR 0.863628
FineTuningLR 0.215608
Epoch 8 | Batch 90/100 | Loss 19.854304
InnerLR 0.862345
FineTuningLR 0.217124
100 Accuracy = 36.59% +- 1.96%
Epoch 8: 36.59
best model! save...
Epoch 9 | Batch 0/100 | Loss 24.585043
InnerLR 0.860370
FineTuningLR 0.219566
Epoch 9 | Batch 10/100 | Loss 22.439950
InnerLR 0.859322
FineTuningLR 0.221286
Epoch 9 | Batch 20/100 | Loss 22.299005
InnerLR 0.857685
FineTuningLR 0.223574
Epoch 9 | Batch 30/100 | Loss 19.837304
InnerLR 0.856385
FineTuningLR 0.224711
Epoch 9 | Batch 40/100 | Loss 20.894458
InnerLR 0.854185
FineTuningLR 0.226722
Epoch 9 | Batch 50/100 | Loss 20.669434
InnerLR 0.852597
FineTuningLR 0.228214
Epoch 9 | Batch 60/100 | Loss 20.810177
InnerLR 0.850077
FineTuningLR 0.230623
Epoch 9 | Batch 70/100 | Loss 20.699723
InnerLR 0.848321
FineTuningLR 0.232321
Epoch 9 | Batch 80/100 | Loss 20.346623
InnerLR 0.846183
FineTuningLR 0.234970
Epoch 9 | Batch 90/100 | Loss 20.265284
InnerLR 0.844974
FineTuningLR 0.236788
100 Accuracy = 35.75% +- 2.42%
Epoch 9: 35.75
Epoch 10 | Batch 0/100 | Loss 15.273568
InnerLR 0.842889
FineTuningLR 0.239577
Epoch 10 | Batch 10/100 | Loss 17.433216
InnerLR 0.841556
FineTuningLR 0.241467
Epoch 10 | Batch 20/100 | Loss 19.443104
InnerLR 0.840502
FineTuningLR 0.243794
Epoch 10 | Batch 30/100 | Loss 20.236198
InnerLR 0.839991
FineTuningLR 0.245446
Epoch 10 | Batch 40/100 | Loss 20.381644
InnerLR 0.838717
FineTuningLR 0.248037
Epoch 10 | Batch 50/100 | Loss 21.308148
InnerLR 0.837981
FineTuningLR 0.249823
Epoch 10 | Batch 60/100 | Loss 22.188502
InnerLR 0.837558
FineTuningLR 0.252030
Epoch 10 | Batch 70/100 | Loss 22.327880
InnerLR 0.837606
FineTuningLR 0.253621
Epoch 10 | Batch 80/100 | Loss 22.272233
InnerLR 0.836981
FineTuningLR 0.256138
Epoch 10 | Batch 90/100 | Loss 22.117736
InnerLR 0.836192
FineTuningLR 0.257894
100 Accuracy = 34.53% +- 2.08%
Epoch 10: 34.53
Epoch 11 | Batch 0/100 | Loss 26.377863
InnerLR 0.834969
FineTuningLR 0.260618
Epoch 11 | Batch 10/100 | Loss 21.545037
InnerLR 0.834190
FineTuningLR 0.262093
Epoch 11 | Batch 20/100 | Loss 21.242155
InnerLR 0.833057
FineTuningLR 0.264481
Epoch 11 | Batch 30/100 | Loss 21.022229
InnerLR 0.832636
FineTuningLR 0.266173
Epoch 11 | Batch 40/100 | Loss 21.341555
InnerLR 0.831456
FineTuningLR 0.268821
Epoch 11 | Batch 50/100 | Loss 21.426510
InnerLR 0.830764
FineTuningLR 0.270640
Epoch 11 | Batch 60/100 | Loss 21.622387
InnerLR 0.829280
FineTuningLR 0.273052
Epoch 11 | Batch 70/100 | Loss 21.241518
InnerLR 0.828257
FineTuningLR 0.274637
Epoch 11 | Batch 80/100 | Loss 21.045914
InnerLR 0.826826
FineTuningLR 0.277168
Epoch 11 | Batch 90/100 | Loss 21.331887
InnerLR 0.825862
FineTuningLR 0.278931
100 Accuracy = 34.72% +- 1.75%
Epoch 11: 34.72
Epoch 12 | Batch 0/100 | Loss 20.149532
InnerLR 0.824248
FineTuningLR 0.281664
Epoch 12 | Batch 10/100 | Loss 23.106608
InnerLR 0.823777
FineTuningLR 0.283525
Epoch 12 | Batch 20/100 | Loss 20.663275
InnerLR 0.823336
FineTuningLR 0.286365
Epoch 12 | Batch 30/100 | Loss 20.710854
InnerLR 0.822646
FineTuningLR 0.288281
Epoch 12 | Batch 40/100 | Loss 21.110198
InnerLR 0.821159
FineTuningLR 0.291186
Epoch 12 | Batch 50/100 | Loss 21.544730
InnerLR 0.819928
FineTuningLR 0.293140
Epoch 12 | Batch 60/100 | Loss 21.691882
InnerLR 0.818357
FineTuningLR 0.296085
Epoch 12 | Batch 70/100 | Loss 22.121334
InnerLR 0.817289
FineTuningLR 0.298054
Epoch 12 | Batch 80/100 | Loss 22.048100
InnerLR 0.816001
FineTuningLR 0.301010
Epoch 12 | Batch 90/100 | Loss 22.372482
InnerLR 0.815365
FineTuningLR 0.302985
100 Accuracy = 36.08% +- 1.84%
Epoch 12: 36.08
Epoch 13 | Batch 0/100 | Loss 19.014908
InnerLR 0.813937
FineTuningLR 0.305962
Epoch 13 | Batch 10/100 | Loss 18.751127
InnerLR 0.813108
FineTuningLR 0.307959
Epoch 13 | Batch 20/100 | Loss 20.111318
InnerLR 0.811650
FineTuningLR 0.310963
Epoch 13 | Batch 30/100 | Loss 20.354517
InnerLR 0.811258
FineTuningLR 0.312965
Epoch 13 | Batch 40/100 | Loss 19.881120
InnerLR 0.810374
FineTuningLR 0.315969
Epoch 13 | Batch 50/100 | Loss 20.872449
InnerLR 0.809455
FineTuningLR 0.317972
Epoch 13 | Batch 60/100 | Loss 21.109240
InnerLR 0.808817
FineTuningLR 0.320967
Epoch 13 | Batch 70/100 | Loss 21.263243
InnerLR 0.808756
FineTuningLR 0.322962
Epoch 13 | Batch 80/100 | Loss 21.573223
InnerLR 0.808914
FineTuningLR 0.325952
Epoch 13 | Batch 90/100 | Loss 21.859943
InnerLR 0.808644
FineTuningLR 0.327943
100 Accuracy = 36.39% +- 2.15%
Epoch 13: 36.39
Epoch 14 | Batch 0/100 | Loss 11.790181
InnerLR 0.807850
FineTuningLR 0.330925
Epoch 14 | Batch 10/100 | Loss 21.286287
InnerLR 0.807216
FineTuningLR 0.332915
Epoch 14 | Batch 20/100 | Loss 20.842679
InnerLR 0.805788
FineTuningLR 0.335518
Epoch 14 | Batch 30/100 | Loss 22.396347
InnerLR 0.804790
FineTuningLR 0.337198
Epoch 14 | Batch 40/100 | Loss 21.960069
InnerLR 0.803203
FineTuningLR 0.339826
Epoch 14 | Batch 50/100 | Loss 21.373800
InnerLR 0.802305
FineTuningLR 0.341440
Epoch 14 | Batch 60/100 | Loss 21.540610
InnerLR 0.800575
FineTuningLR 0.343542
Epoch 14 | Batch 70/100 | Loss 21.937884
InnerLR 0.799598
FineTuningLR 0.344638
Epoch 14 | Batch 80/100 | Loss 22.121330
InnerLR 0.798157
FineTuningLR 0.346336
Epoch 14 | Batch 90/100 | Loss 22.454493
InnerLR 0.797065
FineTuningLR 0.347474
100 Accuracy = 34.32% +- 1.76%
Epoch 14: 34.32
Epoch 15 | Batch 0/100 | Loss 21.141802
InnerLR 0.795662
FineTuningLR 0.348098
Epoch 15 | Batch 10/100 | Loss 23.807935
InnerLR 0.794857
FineTuningLR 0.348525
Epoch 15 | Batch 20/100 | Loss 24.286343
InnerLR 0.793433
FineTuningLR 0.349711
Epoch 15 | Batch 30/100 | Loss 23.602423
InnerLR 0.792675
FineTuningLR 0.350585
Epoch 15 | Batch 40/100 | Loss 23.511106
InnerLR 0.791371
FineTuningLR 0.351483
Epoch 15 | Batch 50/100 | Loss 23.203480
InnerLR 0.790427
FineTuningLR 0.352218
Epoch 15 | Batch 60/100 | Loss 23.605695
InnerLR 0.789444
FineTuningLR 0.352384
Epoch 15 | Batch 70/100 | Loss 22.974280
InnerLR 0.788670
FineTuningLR 0.352197
Epoch 15 | Batch 80/100 | Loss 22.451163
InnerLR 0.788261
FineTuningLR 0.352661
Epoch 15 | Batch 90/100 | Loss 22.425856
InnerLR 0.787898
FineTuningLR 0.353359
100 Accuracy = 33.35% +- 1.93%
Epoch 15: 33.35
Epoch 16 | Batch 0/100 | Loss 21.188684
InnerLR 0.787237
FineTuningLR 0.354106
Epoch 16 | Batch 10/100 | Loss 21.839130
InnerLR 0.786676
FineTuningLR 0.354710
Epoch 16 | Batch 20/100 | Loss 21.520270
InnerLR 0.786258
FineTuningLR 0.356086
Epoch 16 | Batch 30/100 | Loss 21.483094
InnerLR 0.786267
FineTuningLR 0.357249
Epoch 16 | Batch 40/100 | Loss 21.023741
InnerLR 0.785851
FineTuningLR 0.358701
Epoch 16 | Batch 50/100 | Loss 20.793720
InnerLR 0.785555
FineTuningLR 0.358981
Epoch 16 | Batch 60/100 | Loss 21.257124
InnerLR 0.784528
FineTuningLR 0.359364
Epoch 16 | Batch 70/100 | Loss 21.339686
InnerLR 0.783735
FineTuningLR 0.359918
Epoch 16 | Batch 80/100 | Loss 21.365771
InnerLR 0.782392
FineTuningLR 0.360706
Epoch 16 | Batch 90/100 | Loss 21.551284
InnerLR 0.781618
FineTuningLR 0.361573
100 Accuracy = 35.80% +- 2.10%
Epoch 16: 35.80
Epoch 17 | Batch 0/100 | Loss 22.203644
InnerLR 0.780242
FineTuningLR 0.363262
Epoch 17 | Batch 10/100 | Loss 22.177791
InnerLR 0.779689
FineTuningLR 0.364219
Epoch 17 | Batch 20/100 | Loss 22.588440
InnerLR 0.778739
FineTuningLR 0.365277
Epoch 17 | Batch 30/100 | Loss 21.716696
InnerLR 0.777897
FineTuningLR 0.365841
Epoch 17 | Batch 40/100 | Loss 22.357469
InnerLR 0.776781
FineTuningLR 0.366923
Epoch 17 | Batch 50/100 | Loss 22.506186
InnerLR 0.776120
FineTuningLR 0.367940
Epoch 17 | Batch 60/100 | Loss 22.347951
InnerLR 0.775041
FineTuningLR 0.369807
Epoch 17 | Batch 70/100 | Loss 22.709644
InnerLR 0.774134
FineTuningLR 0.370649
Epoch 17 | Batch 80/100 | Loss 22.979414
InnerLR 0.772780
FineTuningLR 0.372050
Epoch 17 | Batch 90/100 | Loss 23.192850
InnerLR 0.771739
FineTuningLR 0.373226
100 Accuracy = 36.68% +- 2.18%
Epoch 17: 36.68
best model! save...
Epoch 18 | Batch 0/100 | Loss 19.424223
InnerLR 0.770421
FineTuningLR 0.374724
Epoch 18 | Batch 10/100 | Loss 22.542382
InnerLR 0.770213
FineTuningLR 0.375956
Epoch 18 | Batch 20/100 | Loss 21.394871
InnerLR 0.769928
FineTuningLR 0.377156
Epoch 18 | Batch 30/100 | Loss 21.940593
InnerLR 0.769802
FineTuningLR 0.378122
Epoch 18 | Batch 40/100 | Loss 22.913472
InnerLR 0.769698
FineTuningLR 0.379734
Epoch 18 | Batch 50/100 | Loss 22.832909
InnerLR 0.769419
FineTuningLR 0.380587
Epoch 18 | Batch 60/100 | Loss 23.288946
InnerLR 0.768982
FineTuningLR 0.381635
Epoch 18 | Batch 70/100 | Loss 22.835755
InnerLR 0.768834
FineTuningLR 0.382330
Epoch 18 | Batch 80/100 | Loss 22.639111
InnerLR 0.768611
FineTuningLR 0.383373
Epoch 18 | Batch 90/100 | Loss 22.730031
InnerLR 0.768528
FineTuningLR 0.383755
100 Accuracy = 37.08% +- 2.14%
Epoch 18: 37.08
best model! save...
Epoch 19 | Batch 0/100 | Loss 25.221977
InnerLR 0.768282
FineTuningLR 0.384885
Epoch 19 | Batch 10/100 | Loss 23.030788
InnerLR 0.767886
FineTuningLR 0.385930
Epoch 19 | Batch 20/100 | Loss 22.137323
InnerLR 0.767913
FineTuningLR 0.387624
Epoch 19 | Batch 30/100 | Loss 22.953057
InnerLR 0.767774
FineTuningLR 0.388710
Epoch 19 | Batch 40/100 | Loss 22.399749
InnerLR 0.767751
FineTuningLR 0.390655
Epoch 19 | Batch 50/100 | Loss 21.826026
InnerLR 0.767625
FineTuningLR 0.391917
Epoch 19 | Batch 60/100 | Loss 22.103725
InnerLR 0.767903
FineTuningLR 0.393799
Epoch 19 | Batch 70/100 | Loss 22.243800
InnerLR 0.768129
FineTuningLR 0.395023
Epoch 19 | Batch 80/100 | Loss 22.059401
InnerLR 0.769077
FineTuningLR 0.396873
Epoch 19 | Batch 90/100 | Loss 21.955331
InnerLR 0.769643
FineTuningLR 0.398284
100 Accuracy = 35.44% +- 1.77%
Epoch 19: 35.44
Epoch 20 | Batch 0/100 | Loss 18.746267
InnerLR 0.770246
FineTuningLR 0.400594
Epoch 20 | Batch 10/100 | Loss 24.992823
InnerLR 0.770404
FineTuningLR 0.402236
Epoch 20 | Batch 20/100 | Loss 26.063137
InnerLR 0.771272
FineTuningLR 0.404818
Epoch 20 | Batch 30/100 | Loss 28.357915
InnerLR 0.771606
FineTuningLR 0.406597
Epoch 20 | Batch 40/100 | Loss 26.455530
InnerLR 0.771691
FineTuningLR 0.409338
Epoch 20 | Batch 50/100 | Loss 25.871175
InnerLR 0.771579
FineTuningLR 0.411209
Epoch 20 | Batch 60/100 | Loss 26.137108
InnerLR 0.771400
FineTuningLR 0.414052
Epoch 20 | Batch 70/100 | Loss 26.113377
InnerLR 0.770958
FineTuningLR 0.415966
Epoch 20 | Batch 80/100 | Loss 25.682773
InnerLR 0.769770
FineTuningLR 0.418661
Epoch 20 | Batch 90/100 | Loss 26.160902
InnerLR 0.768901
FineTuningLR 0.420262
100 Accuracy = 34.41% +- 1.83%
Epoch 20: 34.41
Epoch 21 | Batch 0/100 | Loss 30.445963
InnerLR 0.767663
FineTuningLR 0.422598
Epoch 21 | Batch 10/100 | Loss 29.520485
InnerLR 0.766804
FineTuningLR 0.423643
Epoch 21 | Batch 20/100 | Loss 27.671613
InnerLR 0.765507
FineTuningLR 0.425156
Epoch 21 | Batch 30/100 | Loss 27.054265
InnerLR 0.764867
FineTuningLR 0.426281
Epoch 21 | Batch 40/100 | Loss 25.159045
InnerLR 0.764352
FineTuningLR 0.427733
Epoch 21 | Batch 50/100 | Loss 25.199877
InnerLR 0.763733
FineTuningLR 0.428745
Epoch 21 | Batch 60/100 | Loss 24.519476
InnerLR 0.762330
FineTuningLR 0.429601
Epoch 21 | Batch 70/100 | Loss 24.055103
InnerLR 0.761526
FineTuningLR 0.429886
Epoch 21 | Batch 80/100 | Loss 23.850964
InnerLR 0.760449
FineTuningLR 0.430895
Epoch 21 | Batch 90/100 | Loss 23.347234
InnerLR 0.759812
FineTuningLR 0.431869
100 Accuracy = 35.79% +- 2.19%
Epoch 21: 35.79
Epoch 22 | Batch 0/100 | Loss 19.776134
InnerLR 0.758595
FineTuningLR 0.433672
Epoch 22 | Batch 10/100 | Loss 21.951371
InnerLR 0.757939
FineTuningLR 0.434673
Epoch 22 | Batch 20/100 | Loss 25.920807
InnerLR 0.756955
FineTuningLR 0.436135
Epoch 22 | Batch 30/100 | Loss 25.996415
InnerLR 0.756798
FineTuningLR 0.437228
Epoch 22 | Batch 40/100 | Loss 25.878798
InnerLR 0.756189
FineTuningLR 0.439170
Epoch 22 | Batch 50/100 | Loss 24.718782
InnerLR 0.755420
FineTuningLR 0.440425
Epoch 22 | Batch 60/100 | Loss 24.473093
InnerLR 0.753853
FineTuningLR 0.442303
Epoch 22 | Batch 70/100 | Loss 24.786861
InnerLR 0.752591
FineTuningLR 0.443723
Epoch 22 | Batch 80/100 | Loss 25.090683
InnerLR 0.750984
FineTuningLR 0.445670
Epoch 22 | Batch 90/100 | Loss 25.645780
InnerLR 0.750077
FineTuningLR 0.446640
100 Accuracy = 37.05% +- 2.30%
Epoch 22: 37.05
